# Normalverteilungstransformationen {#sec-normalverteilungstransformationen}
\normalsize 

In diesem Kapitel diskutieren wir sechs Transformationen normalverteilter 
Zufallsvariablen, die in der Frequentistischen Inferenz zentrale Rollen spielen
und bei denen es sich um Anwendungen von den in @sec-transformationstheoreme eingeführten
Transformationtheore handelt. Unsere Aussagen sind dabei von der allgemeinen Form 
"Wenn $\xi_i, i = 1,...,n$  unabhängig und identisch normalverteilte Zufallsvariablen 
sind und $\upsilon := f(\xi_1,...,\xi_n)$ eine Transformation dieser Zufallsvariablen ist, 
dann ist die WDF von $\upsilon$ durch die Formel $p_\upsilon := \{\mbox{Formel}\}$ gegeben und 
man nennt die Verteilung von $\upsilon$ *Verteilungsname*". Aussagen dieser Form sind 
für die Frequentistische Inferenz zentral, weil

(1)  die Zentralen Grenzwertsätze die Annahme additiv unabhängig normalverteilter
Störvariablen, und damit normalverteilter Daten, begründet,
(2) wie wir in @sec-grundbegriffe-frequentistischer-inferenz sehen werden, es 
sich bei Schätzern und Statistiken um Transformationen von Zufallsvariablen handelt, und
(3) Parameterschätzergütekriterien, Konfidenzintervalle und Hypothesentests der 
Frequentistischen Inferenz durch die Verteilungen der jeweiligen Schätzer und 
Statistiken charakterisiert und begründet sind.

## Summentransformation und Mittelwertstransformation {#sec-summentransformation-und-mittelwerttransformation}

In diesem Abschnitt betrachten wir die resultierenden Verteilung bei Summation
und Mittelwertbildung von unabhängig und identisch normalverteilten Zufallsvariablen.
Speziell besagt das @thm-summationstransformation besagt, dass die Summe
unabhängig normalverteilter Zufallsvariablen wiederum normalverteilt ist und gibt die
Parameter dieser Verteilung an, während @thm-mittelwerttransformation
besagt, dass das Stichprobenmittel unabhängig normalverteilter Zufallsvariablen wiederum normalverteilt ist und
gibt die Parameter dieser Verteilung an.

:::{#thm-summationstransformation}
## Summationstransformation

Für $i = 1,...,n$ seien $\xi_i \sim N(\mu_i,\sigma^2_i)$ unabhängige normalverteilte
Zufallsvariablen. Dann gilt für die Summe $\upsilon := \sum_{i=1}^n \xi_i$ , dass
\begin{equation}
\upsilon \sim N\left(\sum_{i=1}^n \mu_i, \sum_{i=1}^n \sigma^2_i\right)
\end{equation}
Für unabhängige und identisch normalverteilte Zufallsvariablen
$\xi_i \sim N(\mu,\sigma^2)$ gilt folglich
\begin{equation}
\upsilon \sim N(n\mu, n \sigma^2).
\end{equation}
:::

:::{.proof}
Wir skizzieren mithilfe von @thm-summe-unabhängiger-zufallsvariablen-konvolution, dass für $\xi_1 \sim N(\mu_1,\sigma^2_1)$,
$\xi_2 \sim N(\mu_2,\sigma^2_2)$, und $\upsilon := \xi_1 + \xi_2$ gilt, dass
$\upsilon \sim N(\mu_1 + \mu_2,\sigma_1^2 + \sigma_2^2)$. Für $n > 2$ folgt das Theorem
dann durch Iteration. Mit der Definition der WDF der Normalverteilung erhalten
wir zunächst
\begin{align}
\begin{split}
p_\upsilon(y)
& = \int_{-\infty}^\infty p_{\xi_1}(x_1)p_{\xi_2}(y - x_1)\,dx_1
\\
& = \int_{-\infty}^\infty
    \frac{1}{\sqrt{2 \pi} \sigma_1} \exp\left(-\frac{1}{2}\left(\frac{x_1 - \mu_1}{\sigma_1}\right)^2\right)
	\frac{1}{\sqrt{2 \pi} \sigma_2} \exp\left(-\frac{1}{2}\left(\frac{y - x_1 - \mu_2}{\sigma_2}\right)^2\right)
	\,dx_1
\\
& = \int_{-\infty}^\infty
    \frac{1}{2 \pi \sigma_1\sigma_2}\exp
    \left(
    -\frac{1}{2}\left(\frac{x_1 - \mu_1}{\sigma_1}\right)^2
    -\frac{1}{2}\left(\frac{y - x_1 - \mu_2}{\sigma_2}\right)^2
    \right)
	\,dx_1 .
\\
\end{split}
\end{align}
Mit einigem algebraischen Aufwand erhält man die Identität
\begin{multline}
-\frac{1}{2}\left(\frac{x_1 - \mu_1}{\sigma_1}\right)^2
-\frac{1}{2}\left(\frac{y - x_1 - \mu_2}{\sigma_2}\right)^2
=
-\frac{(y - \mu_1 - \mu_2)^2}
      {2(\sigma_1^2 + \sigma_2^2)}
-\frac{((\sigma_1^2 + \sigma_2^2)x_1 -\sigma_1^2y + \mu_2 \sigma_1^2 - \mu_1 \sigma_2^2)^2}
      {2\sigma_1^2\sigma_2^2(\sigma_1^2 + \sigma_2^2)},
\end{multline}
so dass weiterhin gilt, dass
\begin{align}
\begin{split}
p_\upsilon(y)
& = \int_{-\infty}^\infty
	\frac{1}{2 \pi \sigma_1\sigma_2}
	\exp\left(
 	-\frac{(y - \mu_1 - \mu_2)^2}
      {2(\sigma_1^2 + \sigma_2^2)}
	-\frac{((\sigma_1^2 + \sigma_2^2)x_1 -\sigma_1^2y + \mu_2 \sigma_1^2 - \mu_1 \sigma_2^2)^2}
      {2\sigma_1^2\sigma_2^2(\sigma_1^2 + \sigma_2^2)}
    \right)
	\,dx_1
\\
& = \int_{-\infty}^\infty
	\frac{1}{2 \pi \sigma_1\sigma_2}
	\exp\left(
 	-\frac{(y - \mu_1 - \mu_2)^2}
      {2(\sigma_1^2 + \sigma_2^2)}
    \right)
	\exp\left(
	-\frac{((\sigma_1^2 + \sigma_2^2)x_1 -\sigma_1^2y + \mu_2 \sigma_1^2 - \mu_1 \sigma_2^2)^2}
      {2\sigma_1^2\sigma_2^2(\sigma_1^2 + \sigma_2^2)}
    \right)
	\,dx_1
\\
& = \frac{1}{2 \pi \sigma_1\sigma_2}
	\exp\left(
 	-\frac{(y - \mu_1 - \mu_2)^2}
      {2(\sigma_1^2 + \sigma_2^2)}
    \right)
	\int_{-\infty}^\infty
	\exp\left(
	-\frac{((\sigma_1^2 + \sigma_2^2)x_1 -\sigma_1^2y + \mu_2 \sigma_1^2 - \mu_1 \sigma_2^2)^2}
      {2\sigma_1^2\sigma_2^2(\sigma_1^2 + \sigma_2^2)}
    \right)
	\,dx_1.
\end{split}
\end{align}
Für das verbleibende Integral zeigt man mithilfe der Integration durch Substitution, dass
\begin{equation}
\int_{-\infty}^\infty
	\exp\left(
	-\frac{((\sigma_1^2 + \sigma_2^2)x_1 -\sigma_1^2y + \mu_2 \sigma_1^2 - \mu_1 \sigma_2^2)^2}
      {2\sigma_1^2\sigma_2^2(\sigma_1^2 + \sigma_2^2)}
    \right)
	\,dx_1
= \frac{\sqrt{2\pi}\sigma_1\sigma_2}{\sqrt{\sigma_1^2 + \sigma_2^2}}.
\end{equation}
Es ergibt sich also
\begin{align}
\begin{split}
p_\upsilon(y)
& = \frac{1}{2 \pi \sigma_1\sigma_2}
	\frac{\sqrt{2\pi}\sigma_1\sigma_2}{\sqrt{\sigma_1^2 + \sigma_2^2}}
	\exp\left(
 	-\frac{(y - \mu_1 - \mu_2)^2}
      {2(\sigma_1^2 + \sigma_2^2)}
    \right)
\\
& = \frac{(2\pi)^{-1}(2\pi)^2}{\sqrt{\sigma_1^2 + \sigma_2^2}}
	\exp\left(
 	-\frac{(y - \mu_1 - \mu_2)^2}
      {2(\sigma_1^2 + \sigma_2^2)}
    \right)
\\
& = \frac{1}{\sqrt{2\pi}\sqrt{\sigma_1^2 + \sigma_2^2}}
	\exp\left(
 	-\frac{(y - \mu_1 - \mu_2)^2}
      {2(\sigma_1^2 + \sigma_2^2)}
    \right).
\end{split}
\end{align}
Schließlich folgt, dass
\begin{align}
\begin{split}
p_\upsilon(y)
& = \frac{1}{\sqrt{2\pi(\sigma_1^2 + \sigma_2^2)}}
    \exp\left(-\frac{1}{2(\sigma_1^2 + \sigma_2^2)}\left(y - (\mu_1 + \mu_2)\right)^2\right) 
  = N(y; \mu_1 + \mu_2, \sigma_1^2 + \sigma_2^2)
\end{split}
\end{align}
Ein einfacheres Vorgehen ergibt sich vermutlich nach Fouriertransformation der
WDF im Sinne der sogenannten charakteristischen Funktion einer Zufallsvariable.
In diesem Fall würde die Faltung der WDFen der Multiplikation der charakteristischen
Funktionen entsprechen.
:::

Ein wichtiger Anwendungsfall von @thm-summationstransformation
ist das nachfolgende @thm-mittelwerttransformation
sowie die in @eq-generalisierung-zentraler-grenzwertsatz-lindenberg-levy und 
@eq-generalisierung-zentraler-grenzwertsatz-liapunov erwähnten Generalisierungen
der Zentralen Grenzwertsätze. Wir visualisieren @thm-summationstransformation
exemplarisch in @fig-summation.

```{r, echo = F, eval = F}
library(latex2exp)
pdf(file =  "./_figures/209-summation.pdf", width = 12, height = 5)                                                                      
par(                                                                   
family     = "sans",                                                 
mfcol      = c(1,3),                                                  
pty        = "m",                                                      
bty        = "l",                                                     
lwd        = 1,                                                       
las        = 1,                                                      
mgp        = c(2,1,0),                                                
xaxs       = "i",                                                    
yaxs       = "i",                                                     
cex        = 1.1,                                                     
font.main  = 1,                                                       
cex.main   = 1.2)

# outcome space of interest
x_min       = -5                                                                 
x_max       = 5                                                                   
x_res       = 1e3                                                                 
x           = seq(x_min, x_max, len = x_res)                                     

# \xi_1 sample
mu_1        = -2                                                                # \mu_1
sigsqr_1    = .5                                                                # \sigma_1^2
n           = 1e4                                                               # number of samples
X_1         = rnorm(n, mu_1, sqrt(sigsqr_1))                                    # n samples of \xi_1 \sim N(\mu_1,\sigma_1^2)
p_X_1       = dnorm(x, mu_1, sqrt(sigsqr_1))                                    # density
hist(
X_1,                                                                         
breaks = 50,                                                                
col   = "gray90",                                                           
prob  = TRUE,                                                               
xlim  = c(-5, 5),                                                           
ylim  = c(0,.7),                                                             
xlab  = expression("x"[1]),                                                                
ylab  = "",                                                                 
main  = TeX("$\\xi_1 \\sim N(-2.0,0.5)$"))                                      

lines(
x,                                                                          
p_X_1,                                                                      
lwd   = 2,                                                                  
col   = "darkorange")                                                       

# \xi_2 sample
mu_2        = 1                                                                 # \mu_2
sigsqr_2    = .7                                                                # \sigma_2^2
n           = 1e4                                                               # number of samples
X_2         = rnorm(n, mu_2, sqrt(sigsqr_2))                                    # n samples of \xi_2 \sim N(\mu_2,\sigma_2^2)
p_X_2       = dnorm(x, mu_2, sqrt(sigsqr_2))                                    # density
hist(
X_2,                                                                        
breaks = 50,                                                                
col   = "gray90",                                                           
prob  = TRUE,                                                               
xlim  = c(-5, 5),                                                           
ylim  = c(0,.7),                                                           
xlab  = expression("x"[2]),                                                 
ylab  = "",                                                                
main  = TeX("$\\xi_2 \\sim N(1.0,0.7)$"))
lines(
x,                                                                          
p_X_2,                                                                      
lwd   = 2,                                                                  
col   = "darkorange")                                                       

# Y = X_1 + \xi_2 sample
Y           = X_1 + X_2                                                           
p_Y        = dnorm(x, mu_1+mu_2, sqrt(sigsqr_1+sigsqr_2))                         
hist(
Y,                                                                          
breaks = 50,                                                                
col   = "gray90",                                                           
prob  = TRUE,                                                              
xlim  = c(-5, 5),                                                          
ylim  = c(0,.7),                                                           
xlab  = TeX("$x_1 + x_2$"),                                                
ylab  = "",                                                                 
main  = TeX("$\\xi_1 + \\xi_2 \\sim N(-1.0,1.2)$"))
lines(
x,                                                                          
p_Y,                                                                        
lwd   = 2,                                                                  
col   = "darkorange")
dev.off()
```

![Summation normalverteilter Zufallsvariablen.](./_figures/209-summation){#fig-summation fig-align="center" width=100%}

:::{#thm-mittelwerttransformation}
## Mittelwertstransformation

Für $i = 1,...,n$ seien $\xi_i \sim N(\mu,\sigma^2)$ unabhängig und identisch
normalverteilte Zufallsvariablen. Dann gilt für das Stichprobenmittel
$\bar{\xi}_n := \frac{1}{n}\sum_{i=1}^n \xi_i$ , dass
\begin{equation}
\bar{\xi}_n \sim N\left(\mu, \frac{\sigma^2}{n}\right).
\end{equation}
:::

:::{.proof}
Wir halten zunächst fest, dass mit dem Theorem zur Summe von unabhängig
normalverteilten Zufallsvariablen gilt, dass $\bar{\xi}_n = \frac{1}{n}\upsilon$ mit
$\upsilon := \sum_{i=1}^n \xi_i \sim N(n\mu,n\sigma^2)$. Einsetzen in @thm-univariates-wdf-transformationstheorem-bei-linear-affinen-abbildungen ergibt dann
\begin{align}
\begin{split}
p_{\bar{\xi}_n}(\bar{x}_n)
& = \frac{1}{|1/n|}N\left(n\bar{x}_n; n\mu , n\sigma^2 \right) \\
& = \frac{n}{\sqrt{2\pi n\sigma^2}}\exp\left(-\frac{1}{2n\sigma^2}
\left(n\bar{x}_n - n\mu\right)^2 \right) \\
& = \frac{n}{\sqrt{2\pi n\sigma^2}}\exp\left(-\frac{1}{2n\sigma^2}
\left(n\bar{x}_n - n\mu\right)^2 \right) \\
& = nn^{-\frac{1}{2}}\frac{1}{\sqrt{2\pi\sigma^2}}
\exp\left(
			-\frac{(n\bar{x}_n)^2}{2n\sigma^2}
		  	+ \frac{2(n\bar{x}_n)(n\mu)}{2n\sigma^2}
		  	- \frac{(n\mu)^2}{2n\sigma^2}
		 \right) \\
& = \sqrt{n}\frac{1}{\sqrt{2\pi\sigma^2}}
\exp\left(
			-\frac{n\bar{x}_n^2}{2\sigma^2}
		  	+ \frac{2n\bar{x}_n\mu}{2\sigma^2}
		  	- \frac{n\mu^2}{2\sigma^2}
		 \right) \\
& = \frac{1}{1/\sqrt{n}}\frac{1}{\sqrt{2\pi\sigma^2}}
\exp\left(
			-\frac{\bar{x}_n^2}{2(\sigma^2/n)}
		  	+ \frac{2\bar{x}_n\mu}{2(\sigma^2/n)}
		  	- \frac{\mu^2}{2(\sigma^2/n)}
		 \right) \\
& = \frac{1}{\sqrt{2\pi(\sigma^2/n)}}
\exp\left(-\frac{1}{2(\sigma^2/n)}
			(\bar{x}_n - \mu)^2
		 \right) \\
& = N\left(\bar{x}_n;\mu,\sigma^2/n \right)
\end{split}
\end{align}
:::

Wichtige Anwendungsfälle von @thm-mittelwerttransformation
sind die Analyse von Erwartungswertschätzern in @sec-punktschaetzung sowie die
sowie die in @eq-generalisierung-zentraler-grenzwertsatz-lindenberg-levy erwähnte Generalisierung
des Zentralen Grenzwertsatzes nach Lindenberg-Lévy. Wir visualisieren 
@thm-mittelwerttransformation exemplarisch in @fig-mittelwert.


```{r, echo = F, eval = F}
# figure setup
library(latex2exp)
pdf(file = "./_figures/209-mittelwert.pdf", width = 12, height = 5)                                                                      
par(                                                                   
family      = "sans",                                                 
mfcol       = c(1,2),                                                
pty         = "m",                                                   
bty         = "l",                                                   
lwd         = 1,                                                      
las         = 1,                                                      
mgp         = c(2,1,0),                                               
xaxs        = "i",                                                    
yaxs        = "i",                                                    
font.main   = 1,                                                      
cex         = 1.2,                                                   
cex.main    = 1.2)                                                     

# N(\mu,\sigma^2) sample
mu          = 2                                                                  
sigsqr      = 4                                                                 
sigma       = sqrt(sigsqr)                                                       
n           = 1e1                                                                
n_sim       = 1e4                                                                
x_min       = -5                                                                 
x_max       = 10                                                                  
x_res       = 1e3                                                                 
x           = seq(x_min, x_max, len = x_res)                                      
p_X         = dnorm(x,mu, sigma)                                                  
X           = matrix(rep(NaN,n*n_sim), nrow = n) 

# n_sim simulations of n samples of \xi \sim N(\mu,\sigma^2)
for(i in 1:n_sim){
    X[,i] = rnorm(n, mu, sqrt(sigsqr))                                           
}

# histogram
hist(
X,                                                                          
breaks = 50,                                                               
col   = "gray90",                                                          
prob  = TRUE,                                                               
xlim  = c(-5, 10),                                                          
ylim  = c(0,.7),                                                           
xlab  = "x",                                                               
ylab  = "",                                                                
main  = TeX("$\\xi_i \\sim N(2,4),\\, i = 1,...,10$"))

# density
lines(
x,                                                                          
p_X,                                                                        
lwd   = 2,                                                                 
col   = "darkorange")                                                       

X_bar       = colMeans(X)                                                         
p_X_bar     = dnorm(x, mu, sqrt(sigsqr/n))                                        

# histogram
hist(
X_bar,                                                                      
breaks = 50,                                                                
col   = "gray90",                                                           
prob  = TRUE,                                                               
xlim  = c(-5, 10),                                                          
ylim  = c(0,.7),                                                           
xlab  = TeX("$\\bar{x}_n$"),                                               
ylab  = "",                                                                
main  = TeX("$\\bar{\\xi}_n \\sim N(2,4/10)$"))

# density
lines(
x,                                                                        
p_X_bar,                                                                  
lwd   = 2,                                                                
col   = "darkorange")                                                      
dev.off()                                                                    
```

![Mittelwertbildung bei normalverteilten Zufallsvariablen.](./_figures/209-mittelwert){#fig-mittelwert fig-align="center" width=100%}

## $Z$-Transformation

Das @thm-z-transformation besagt, dass Subtraktion des Erwartungswertparameters 
und gleichzeitige Division mit der Wurzel des Varianzsparameters die Verteilung 
einer normalverteilten Zufallsvariable in eine Standardnormalverteilung transformiert.

:::{#thm-z-transformation}
## $Z$-Transformation
Es sei $\upsilon \sim N(\mu,\sigma^2)$ eine normalverteilte Zufallsvariable. Dann ist
die Zufallsvariable
\begin{equation}
Z := \frac{\upsilon - \mu}{\sigma}
\end{equation}
eine standardnormalverteilte Zufallsvariable, es gilt also $Z \sim N(0,1)$.
:::

:::{.proof}
Wir nutzen @thm-univariates-wdf-transformationstheorem-bei-linear-affinen-abbildungen.
Dazu halten wir zunächst fest, dass die $Z$-Transformation einer Funktion der Form
\begin{equation}
f(\upsilon) := \frac{\upsilon - \mu}{\sigma} =: Z
\end{equation}
entspricht. Wir stellen weiterhin fest, dass die Umkehrfunktion von $f$ durch
\begin{equation}
f^{-1}(Z) := \sigma Z + \mu
\end{equation}
gegeben ist, da für alle $z \in \mathbb{R}$ mit $z = {y - \mu}{\sigma}$ gilt, dass
\begin{equation}
\zeta^{-1}(z)
= \zeta^{-1}\left(\frac{y - \mu}{\sigma}\right)
= \frac{\sigma(y- \mu)}{\sigma} + \mu
= y - \mu + \mu
= y.
\end{equation}
Schließlich stellen wir fest, dass für die Ableitung $f'$ von $f$ gilt, dass
\begin{equation}
f'(y)
= \frac{d}{dy}\left(\frac{y - \mu}{\sigma} \right)
= \frac{d}{dy}\left(\frac{y}{\sigma} -\frac{\mu}{\sigma} \right)
= \frac{1}{\sigma}.
\end{equation}
Einsetzen in das univariate WDF Transformationstheorem für lineare Funktionen ergibt dann
\begin{align}
\begin{split}
p_Z(z)
& = \frac{1}{|1/\sigma|}N\left(\sigma z + \mu; \mu , \sigma^2 \right) \\
& = \frac{1}{1/\sqrt{\sigma^2}}\frac{1}{\sqrt{2\pi\sigma^2}}\exp\left(-\frac{1}{2\sigma^2}\left(\sigma z + \mu - \mu\right)^2 \right) \\
& = \frac{\sqrt{\sigma^2}}{\sqrt{2\pi\sigma^2}}\exp\left(-\frac{1}{2\sigma^2}\sigma^2 z^2\right)\\
& = \frac{1}{\sqrt{2\pi}}\exp\left(-\frac{1}{2} z^2\right)\\
& = N(z;0,1)
\end{split}
\end{align}
also, dass $Z \sim N(0,1)$. 
:::
Wichtige Anwendungsfälle von @thm-z-transformation sind neben der häufig angewandten 
Standardisierung von normalverteilten Zufallsvariablen im Sinne der sogenannten 
*$Z$-Werte ($Z$-Scores)* die $Z$-Konfidenzintervallstatistik und die $Z$-Teststatistik.
Wir visualisieren @thm-z-transformation exemplarisch in @fig-z-transformation.

```{r, echo = F, eval = F}
# figure setup
library(latex2exp)
pdf(file = "./_figures/209-z-transformation.pdf", width = 5, height = 3)                                                                        
par(                                                                    
family     = "sans",                                                  
mfcol      = c(1,2),                                                  
pty        = "m",                                                     
bty        = "l",                                                     
lwd        = 1,                                                       
las        = 1,                                                       
mgp        = c(2,1,0),                                               
xaxs       = "i",                                                     
yaxs       = "i",                                                     
font.main  = 1,                                                      
cex        = .7,
cex.main   = 1)

# N(\mu,\sigma^2) sample
mu          = 2                                                                  # expectation parameter
sigsqr      = 3                                                                  # variance parameter
sigma       = sqrt(sigsqr)                                                       # standard deviation
n           = 1e5                                                                # number of samples
X           = rnorm(n ,mu, sqrt(sigsqr))                                         # n samples of \xi \sim N(\mu,\sigma^2)
x_min       = -5                                                                 # minimum x-value
x_max       = 10                                                                 # maximum x-value
x_res       = 1e3                                                                # x-space resolution
x           = seq(x_min, x_max, len = x_res)                                     # x-space
p_X         = dnorm(x,mu, sigma)                                                 # X density

# histogram
hist(
X,                                                                          
breaks = 50,                                                                
col   = "gray90",                                                           
prob  = TRUE,                                                               
xlim  = c(-5, 10),                                                          
ylim  = c(0,.42),                                                           
xlab  = TeX("y"),                                                               
ylab  = "",                                                                 
main  = TeX("$\\upsilon \\sim N(2,3)$"))

# density
lines(x,                                                                          
p_X,                                                                        
lwd   = 2,                                                                  
col   = "darkorange")                                                      

# Transformation der  N(\mu,\sigma^2) sample
Z           = (X - mu)/sigma                                                     # vector arithmetic
z_min       = -5                                                                 # minimum x-value
z_max       = 10                                                                 # maximum x-value
z_res       = 1e3                                                                # x-space resolution
z           = seq(z_min, z_max, len = z_res)                                     # x-space
p_Z         = dnorm(z, 0, 1)                                                     # Z density N(z;0,1)


# histogram
hist(
Z,                                                                          
breaks = 50,                                                                
col   = "gray90",                                                           
prob  = TRUE,                                                               
xlim  = c(-5, 10),                                                          
ylim  = c(0,.42),                                                          
xlab  = "z",                                                                
ylab  = "",                                                                 
main  = TeX("$Z = \\frac{\\upsilon - \\mu}{\\sigma} \\sim N(0,1)$"))

# density
lines(
z,                                                                          
p_Z,                                                                        
lwd   = 2,                                                                  
col   = "darkorange")   
dev.off()                                                                                                                        
```

![$Z$-Transformation normalverteilter Zufallsvariablen.](./_figures/209-z-transformation){#fig-z-transformation fig-align="center" width=100%}

## $\chi^2$-Transformation {#sec-chi-quadrat-transformation}

Mit der $\chi^2$-Transformation führen wir nun eine erste Transformation unabhängig
und identisch normalverteilter Zufallsvariablen ein, die *nicht* wiederrum auf
eine Normalverteilung führt. Speziell besagt @thm-chi2-transformation, dass 
die Summe quadrierter unabhängiger standardnormalverteilter Zufallsvariablen 
eine $\chi^2$-verteilte Zufallsvariable ist. Dazu erinnern wir zunächst an den
Begriff der $\chi^2$-Zufallsvariable als Spezialfall der in @sec-zufallsvariablen
betrachteten Gammazufallsvariablen (vgl. @def-gamma-zufallsvariable).

:::{#def-chi-quadrat-zufallsvariable}
## $\chi^2$-Zufallsvariable
$U$ sei eine Zufallsvariable mit Ergebnisraum $\mathbb{R}_{>0}$ und WDF
\begin{equation}
p : \mathbb{R}_{>0} \to \mathbb{R}_{>0},
u \mapsto p(u)
:= \frac{1}{\Gamma\left(\frac{n}{2}\right)2^{\frac{n}{2}}}
u^{\frac{n}{2}-1}\exp\left(-\frac{1}{2}u\right),
\end{equation}
wobei $\Gamma$ die Gammafunktion bezeichne. Dann sagen wir, dass $U$ einer
$\chi^2$-Verteilung mit Freiheitsgradparameter $n$ unterliegt und nennen $U$ eine
$\chi^2$-Zufallsvariable mit Freiheitsgradparameter $n$. Wir kürzen dies mit
$U \sim \chi^2(n)$ ab. Die WDF einer $\chi^2$-Zufallsvariable bezeichnen wir mit
\begin{equation}
\chi^2(u;n) :=
\frac{1}{\Gamma\left(\frac{n}{2}\right)2^{\frac{n}{2}}}
u^{\frac{n}{2}-1}\exp\left(-\frac{1}{2}u\right).
\end{equation}
:::
Wir erinnern daran, dass die WDF der $\chi^2$-Verteilung der WDF $G\left(u;\frac{n}{2},2\right)$ 
einer Gammaverteilung entspricht. In @fig-chi2-wdf visualisieren wir exemplarisch
einige WDFen von $\chi^2$-Zufallsvariablen. Wir beobachten, dass mit ansteigendem
$n$ sich  $\chi^2(u;n)$ verbreiter und  Wahrscheinlichkeitsmasse zur größeren Werten
von $u$ verschoben wird.

```{r, eval = F, echo = F}
library(latex2exp)
pdf(file = "./_figures/209-chi2-wdf.pdf", width = 6,height = 4)                                                                        
par(                                                                    
family     = "sans",                                                  
pty        = "m",                                                     
bty        = "l",                                                     
lwd        = 1,                                                       
las        = 1,                                                       
mgp        = c(2,1,0),                                                
xaxs         = "i",                                                   
yaxs         = "i",                                                   
font.main  = 1,                                                       
cex.main   = 1.2)

# chi^2 space
u_min   = 1e-5                                                                   # minimum z-value
u_max   = 10                                                                     # maximum z-value
u_res   = 1e3                                                                    # z-space resolution
u       = seq(u_min,u_max, len = u_res)                                          # z-space

# parameters of interest
n       = c(1,2,3,5,10)                                                          # degrees of freedom

# plotting
matplot(
u,
matrix(
c(dchisq(u,n[1]),
dchisq(u,n[2]),
dchisq(u,n[3]),
dchisq(u,n[4]),
dchisq(u,n[5])),
ncol  = 5),
type  = "l",                                                       
lty   = 1,                                                         
lwd   = 2,                                                         
col   = c("gray90","gray70", "gray50", "gray30", "gray10"),        
ylim  = c(0,.6),                                                    
xlim  = c(u_min,u_max),                                            
ylab  = " ",                                                       
xlab  = "u",                                                       
main  = TeX("$\\chi^2(u;n)$"))                                     

legend(
7,                                                                        
.6,                                                                       
c("n = 1", "n = 2", "n = 3", "n = 5", "n = 10"),                          
lty         = 1,                                                          
lwd         = 2,                                                          
col         =  c("gray90","gray70", "gray50", "gray30", "gray10"),        
bty         = "n",                                                         
cex         = 1.1,                                                        
y.intersp   = 1)                                                         
dev.off()                                                                     
```

![WDFen von $\chi^2$ Zufallsvariablen.](./_figures/209-chi2-wdf){#fig-chi2-wdf fig-align="center" width=80%}

:::{#thm-chi2-transformation}
## $\chi^2$-Transformation
$Z_1,...,Z_n \sim N(0,1)$ seien unabhängig und identisch standardnormalverteilte 
Zufallsvariablen. Dann ist die Zufallsvariable
\begin{equation}
U := \sum_{i=1}^n Z_i^2
\end{equation}
eine $\chi^2$-verteilte Zufallsvariable mit Freiheitsgradparameter $n$, es gilt also
$U \sim \chi^2(n)$. Insbesondere gilt für $Z \sim N(0,1)$ und $U := Z^2$, dass
$U \sim \chi^2(1)$.
:::

:::{.proof}
Wir zeigen das Theorem nur für den Fall $n := 1$ mithilfe von  @thm-univariate-wdf-transformation-bei-stückweise-bijektiven-abbildungen. 
Danach ist die WDF einer Zufallsvariable $U := f(Z)$, welche aus der Transformation einer
Zufallsvariable $Z$ mit WDF $p_\zeta$ durch eine stückweise bijektive Abbildung
hervorgeht, gegeben durch
\begin{equation}\label{eq:piecewise_pdf_transform}
p_U(u) = \sum_{i=1}^k 1_{\mathcal{U}_i} \frac{1}{|f'_i(f_i^{-1}(u))|}p_\zeta\left(f_i^{-1} (u)\right).
\end{equation}
Wir definieren
\begin{equation}
\mathcal{U}_1 := ]-\infty,0[,
\mathcal{U}_2 := ]0,\infty[, \mbox{ und }
\mathcal{U}_i := \mathbb{R}_{>0} \mbox{ für } i = 1,2,
\end{equation}
sowie
\begin{equation}
f_i : \mathcal{Z}_i \to \mathcal{U}_i, x \mapsto f_i(z) := z^2 =: u \mbox{ für } i = 1,2.
\end{equation}
Die Ableitung und die Umkehrfunktion der $f_i$ ergeben sich zu
\begin{equation}
f_i' : \mathcal{Z}_i \to \mathcal{Z}_i, x \mapsto f_i'(z) = 2z \mbox{ für } i = 1,2,
\end{equation}
und
\begin{equation}
f_1^{-1} : \mathcal{U}_1 \to \mathcal{U}_1, u \mapsto f_1^{-1}(u) = - \sqrt{u}
\mbox{ und }
f_2^{-1} : \mathcal{U}_2 \to \mathcal{U}_2, u \mapsto f_2^{-1}(u) = \sqrt{u},
\end{equation}
respektive.
Einsetzen in Gleichung \eqref{eq:piecewise_pdf_transform} ergibt dann
\begin{align}
\begin{split}
p_U(u)
& = 1_{\mathcal{U}_1}(u) \frac{1}{|f'_1(f_1^{-1}(u))|}p_\zeta\left(f_1^{-1} (u)\right)
  + 1_{\mathcal{U}_2}(u) \frac{1}{|f'_2(f_2^{-1}(u))|}p_\zeta\left(f_2^{-1} (u)\right) \\
& = \frac{1}{|2(-\sqrt{u})|}\frac{1}{\sqrt{2\pi}}\exp\left(-\frac{1}{2}(-\sqrt{u})^2\right)
  + \frac{1}{|2( \sqrt{u})|}\frac{1}{\sqrt{2\pi}}\exp\left(-\frac{1}{2}( \sqrt{u})^2\right) \\
& = \frac{1}{2\sqrt{u}}\frac{1}{\sqrt{2\pi}}\exp\left(-\frac{1}{2}u\right)
  + \frac{1}{2\sqrt{u}}\frac{1}{\sqrt{2\pi}}\exp\left(-\frac{1}{2}u\right)\\
& = \frac{1}{\sqrt{2\pi}}\frac{1}{\sqrt{u}}\exp\left(-\frac{1}{2}u\right).
\end{split}
\end{align}
Andererseits gilt, dass mit $\Gamma\left(\frac{1}{2}\right) = \sqrt{\pi}$, die PDF einer $\chi^2$-Zufallsvariable $U$ mit $n = 1$ durch
\begin{equation}
\frac{1}{\Gamma\left(\frac{1}{2}\right)2^{\frac{1}{2}}} u^{\frac{1}{2}-1}\exp\left(-\frac{1}{2}u\right)
= \frac{1}{\sqrt{2\pi}}\frac{1}{\sqrt{u}}\exp\left(-\frac{1}{2}u\right)
\end{equation}
gegeben ist. Also gilt, dass wenn $Z \sim N(0,1)$ ist, dann ist $U := Z^2 \sim \chi^2(1)$.
:::

Wichtige Anwendungsfälle sind die $U$-Konfidenzintervallstatistik sowie die
im folgenden eingeführten $t$- und $f$-Zufallsvariablen. Wir visualisieren 
@thm-chi2-transformation exemplarisch in @fig-chi2-transform.

```{r, echo = F, eval = F}
pdf(file = "./_figures/209-chi2-transform.pdf", width = 10, height = 5)                                                                         
library(latex2exp)
par(                                                                    
family     = "sans",                                                  
mfcol      = c(1,2),                                                 
pty        = "m",                                                     
bty        = "l",                                                     
lwd        = 1,                                                       
las        = 1,                                                      
mgp        = c(2,1,0),                                               
xaxs         = "i",                                                   
yaxs         = "i",                                                   
font.main  = 1,                                                       
cex        = 1.2,
cex.main   = 1.3)                                                      

# Z sample
n           = 1e5                                                                # number of samples
Z           = rnorm(n, 0 ,1)                                                     # n samples of Z \sim N(0,1)
z_min       = -5                                                                 # minimum z-value
z_max       = 5                                                                  # maximum z-value
z_res       = 1e3                                                                # z-space resolution
z           = seq(z_min, z_max, len = z_res)                                     # z-space
p_Z         = dnorm(z, 0, 1)                                                     # z density

# histogram
hist(
Z,                                                                         
breaks = 50,                                                                
col   = "gray90",                                                           
prob  = TRUE,                                                               
xlim  = c(-5, 10),                                                         
ylim  = c(0,.42),                                                          
xlab  = "z",                                                                
ylab  = "",                                                                 
main  = TeX("$Z \\sim N(0,1)$"))

# density
lines(
z,                                                                          
p_Z,                                                                        
lwd   = 2,                                                                 
col   = "darkorange")                                                      

# Transformation der N(0,1) sample
U           = Z^2                                                                # vector arithmetic
u_min       = -5                                                                 # minimum u-value
u_max       = 10                                                                 # maximum u-value
u_res       = 1e3                                                                # u-space resolution
u           = seq(u_min, u_max, len = u_res)                                     # u-space
p_U         = dchisq(u,1)                                                        # Chi^2 density chi^2(u;1)


# histogram
hist(
U,                                                                         
breaks= 100,                                                                
col   = "gray90",                                                           
prob  = TRUE,                                                               
xlim  = c(-5, 10),                                                         
ylim  = c(0,1),                                                           
xlab  = "x",                                                                
ylab  = "",                                                                 
main  = TeX("$U = Z^2 \\sim \\chi^2(1)$"))                                 

# density
lines(
u,                                                                         
p_U,                                                                        
lwd   = 2,                                                                  
col   = "darkorange")                                                       
dev.off()                                                                     
```
![$\chi^2$-Transformation normalverteilter Zufallsvariablen.](./_figures/209-chi2-transform){#fig-chi2-transform fig-align="center" width=100%}


## $T$-Transformation {#sec-t-transformation}

Das in diesem Abschnitt betrachtete Theorem geht auf @student1908 zurück und ist das 
zentrale und stilprägende Resultat der Entwicklung der Frequentistischen Inferenz 
in der ersten Hälfte der 20. Jahrhunderts. @hald2007 und @zabell2008 und geben 
hierzu einen historischen Überblick. Das zentrale @thm-t-transformation besagt dabei, 
dass die Zufallsvariable, die sich durch Division einer standardnormalverteilten 
Zufallsvariable durch die Quadratwurzel einer $\chi^2$-verteilten Zufallsvariable 
geteilt durch ein $n$, ergibt, eine $t$-verteilte Zufallsvariable ist. Dabei ist
eine $t$-verteilte Zufallsvariable wie folgt definiert. 

:::{#def-t-zufallsvariable}
## $t$-Zufallsvariable
$T$ sei eine Zufallsvariable mit Ergebnisraum $\mathbb{R}$ und WDF
\begin{equation}
p : \mathbb{R} \to \mathbb{R}_{>0}, t \mapsto p(t)
:= \frac{\Gamma\left(\frac{n+1}{2}\right)}{\sqrt{n\pi}\Gamma\left(\frac{n}{2}\right)}
\left(1 + \frac{t^2}{n} \right)^{-\frac{n+1}{2}},
\end{equation}
wobei $\Gamma$ die Gammafunktion bezeichne. Dann sagen wir, dass $T$ einer
$t$-Verteilung mit Freiheitsgradparameter $n$ unterliegt und nennen $T$ eine $t$-Zufallsvariable
mit Freiheitsgradparameter $n$. Wir kürzen dies mit $T \sim t(n)$ ab. Die WDF einer
$t$-Zufallsvariable bezeichnen wir mit
\begin{equation}
T(t;n) := \frac{\Gamma\left(\frac{n+1}{2}\right)}{\sqrt{n\pi}\Gamma\left(\frac{n}{2}\right)}
\left(1 + \frac{t^2}{n} \right)^{-\frac{n+1}{2}}.
\end{equation}
:::

In @fig-t-wdf visualisieren wir exemplarisch einige WDFen von $t$-Zufallsvariablen. 
Wir beobachten, dass die $t$-Verteilung immer um $0$ symmetrisch ist und ein 
steigendes $n$ Wahrscheinlichkeitsmasse aus den Ausläufen zum Zentrum verschiebt.
Wir merken an, dass ab etwa $n = 30$ gilt, dass $T(t;n) \approx N(0,1)$.

```{r, echo = F, eval = F}
pdf(file  = "./_figures/209-t-wdf.pdf", width = 6, height = 5)                                                                         
par(                                                                    
family     = "sans",                                                  
pty        = "m",                                                     
bty        = "l",                                                     
lwd        = 1,                                                       
las        = 1,                                                       
mgp        = c(2,1,0),                                                
xaxs       = "i",                                                    
yaxs       = "i",                                                     
font.main  = 1,                                                       
cex        = 1.1,
cex.main   = 1.4)

# t space
t_min   = -5                                                                     # minimum t-value
t_max   = 5                                                                      # maximum t-value
t_res   = 1e3                                                                    # t-space resolution
t       = seq(t_min,t_max, len = t_res)                                          # t-space

# parameters of interest
n       = c(2,3,5,10,30)                                                        # degrees of freedom

# plotting
matplot(
t,
matrix(
c(dt(t,n[1]),
dt(t,n[2]),
dt(t,n[3]),
dt(t,n[4]),
dt(t,n[5])),
ncol = 5),
type         = "l",                                                      
lty          = 1,                                                          
lwd          = 2,                                                         
col          = c("gray90","gray70", "gray50", "gray30", "gray10"),       
ylim         = c(0,.4),                                                   
xlim         = c(t_min,t_max),                                            
ylab         = " ",                                                       
xlab         = "t",                                                       
main         = TeX("$\\T(t;n)$"))                                         

legend(
2,                                                                         
.4,                                                                       
c("n = 2", "n = 3", "n = 5", "n = 10", "n = 30"),                         
lty         = 1,                                                          
lwd         = 2,                                                          
col         =  c("gray90","gray70", "gray50", "gray30", "gray10"),        
bty         = "n",                                                       
cex         = 1,                                                        
y.intersp   = 1)                                                        
dev.off()                                                                   
```

![WDFen von $T$-Zufallsvariablen.](./_figures/209-t-wdf){#fig-t-wdf fig-align="center" width=60%}

:::{#thm-t-transformation}
## $T$-Transformation
$Z \sim N(0,1)$ sei eine standarnormalverteilte Zufallsvariable, $U \sim \chi^2(n)$ 
sei eine $\chi^2$-Zufallsvariable mit Freiheitsgradparameter $n$, und $Z$ und $U$ seien
unabhängig. Dann ist die Zufallsvariable
\begin{equation}
T := \frac{Z}{\sqrt{U/n}}
\end{equation}
eine $t$-verteilte Zufallsvariable mit Freiheitsgradparameter $n$, es gilt also $T \sim t(n)$.
:::

:::{.proof}
Wir halten zunächst fest, dass die zweidimensionale WDF der gemeinsamen
(unabhängigen) Verteilung von $Z$ und $U$ durch
\begin{equation}
p_{Z,U}(z,u)
=
\frac{1}{\sqrt{2\pi}}\exp\left(-\frac{1}{2}z^2\right)
\frac{1}{\Gamma(\frac{n}{2})2^{\frac{n}{2}}}u^{\frac{n}{2}-1} \exp\left(-\frac{1}{2}u\right).
\end{equation}
gegeben ist. Wir betrachten dann die multivariate vektorwertige Abbildung
\begin{equation}
f : \mathbb{R}^2 \to \mathbb{R}^2,
(z,u)
\mapsto
f(z,u)
:=
\left(\frac{z}{\sqrt{u/n}},u\right)
=:
(t,w)
\end{equation}
und benutzen das multivariate WDF Transformationstheorem für bijektive Abbildungen
um die WDF von $(t,w)$ herzuleiten. Dazu erinnern wir uns, dass wenn $\xi$ ein
$n$-dimensionaler Zufallsvektor mit WDF $p_\xi$ und $\upsilon := f(\xi)$ für eine
differenzierbare und bijektive Abbildung $f : \mathbb{R}^n \to \mathbb{R}^n$ ist,
die WDF des Zufallsvektors $\upsilon$ durch
\begin{equation}\label{eq:pdftmv}
p_\upsilon : \mathbb{R}^n \to \mathbb{R}_{\ge 0},
y \mapsto p_\upsilon(y) :=
\frac{1}{|J^f\left(f^{-1}(y)\right)|}p_\xi\left(f^{-1}(y)\right)
\end{equation}
gegeben ist. Für die im vorliegenden Fall betrachtete Abbildung halten wir zunächst fest, dass
\begin{equation}
f^{-1}:\mathbb{R}^2 \to \mathbb{R}^2,
(t,w)
\mapsto
f^{-1}
(t,w)
:=\left(\sqrt{w/n}t, w\right).
\end{equation}
Dies ergibt sich direkt aus
\begin{equation}
f^{-1}(f(z,u))
=
f^{-1}\left(\frac{z}{\sqrt{u/n}},u\right)
=
\left(\frac{\sqrt{u/n}z}{\sqrt{u/n}}, u \right)
=
(z,u)
\mbox{ für alle }
(z,u)
\in \mathbb{R}^2.
\end{equation}
Wir halten dann fest, dass die Determinante der Jacobi-Matrix von $f$ an der Stelle $(z,u)$ durch
\begin{equation}
|J^f(z,u)|
=
\begin{vmatrix}
  \frac{\partial}{\partial z} \left(\frac{z}{\sqrt{u/n}}\right)
& \frac{\partial}{\partial u} \left(\frac{z}{\sqrt{u/n}}\right) \\
  \frac{\partial}{\partial z} u
& \frac{\partial}{\partial u} u\\
\end{vmatrix}
= \left(\frac{v}{n}\right)^{-1/2},
\end{equation}
gegeben ist, sodass folgt, dass
\begin{equation}
\frac{1}{|J^f\left(f^{-1}(z,u)\right)|}
= \left(\frac{w}{n}\right)^{1/2}.
\end{equation}
Einsetzen in Gleichung \eqref{eq:pdftmv} ergibt dann
\begin{equation}
p_{T,W}(t,w) = \left(\frac{w}{n}\right)^{1/2}p_{Z,V}\left(\sqrt{w/n}t,w\right),
\end{equation}
Es folgt also
\begin{align}
\begin{split}
p_T(t)
& =
\int_0^\infty  p_{T,W}(t,w)
\,dw 													\\
& =
\int_0^\infty
\left(\frac{w}{n}\right)^{1/2}
p_{Z,V}\left(\sqrt{w/n}t,w\right)
\,dw  \\
& =
\int_0^\infty
\frac{1}{\sqrt{2\pi}}\exp\left(-\frac{1}{2}(\sqrt{w/n}t)^2\right)
\frac{1}{\Gamma(\frac{n}{2})2^{\frac{n}{2}}}w^{\frac{n}{2}-1} \exp\left(-\frac{1}{2}w\right)
\left(\frac{w}{n}\right)^{1/2}
\,dw \\
& =
\frac{1}{\sqrt{2\pi}}\frac{1}{\Gamma(\frac{n}{2})2^{\frac{n}{2}}n^{\frac{1}{2}}}
\int_0^\infty
\exp\left(-\frac{1}{2}\frac{w}{n}t^2\right)
w^{\frac{n}{2}-1} \exp\left(-\frac{1}{2}w\right)w^{1/2}
\,dw \\
& =
\frac{1}{\sqrt{2\pi}}\frac{1}{\Gamma(\frac{n}{2})2^{\frac{n}{2}}n^{\frac{1}{2}}}
\int_0^\infty
\exp\left(-\frac{1}{2}\frac{w}{n}t^2 -\frac{1}{2}w\right)
w^{\frac{n}{2}-1} w^{\frac{1}{2}}
\,dw \\
& =
\frac{1}{\sqrt{2\pi}}\frac{1}{\Gamma(\frac{n}{2})2^{\frac{n}{2}}n^{\frac{1}{2}}}
\int_0^\infty
\exp\left(-\frac{1}{2}\left(\frac{w}{n}t^2 + w\right)\right)
w^{\frac{n + 1}{2}-1}
\,dw \\
& =
\frac{1}{\sqrt{2\pi}}\frac{1}{\Gamma(\frac{n}{2})2^{\frac{n}{2}}n^{\frac{1}{2}}}
\int_0^\infty
\exp\left(-\frac{1}{2}\left(1 + \frac{t^2}{n}\right)\right)
w^{\frac{n + 1}{2}-1}
\,dw \\
\end{split}
\end{align}
Wir stellen dann fest, dass der Integrand auf der linken Seite der obigen Gleichung
dem Kern einer Gamma WDF mit Parametern  $\alpha = \frac{n+1}{2}$ und
$\beta = \frac{2}{1+\frac{t^2}{n}}$ entspricht, wie man leicht einsieht:
\begin{align*}
\Gamma(w;\alpha,\beta)
= \frac{1}{\Gamma(\alpha)\beta^{\alpha}}w^{\alpha-1}\exp\left(-\frac{w}{\beta}\right) & \\
\Rightarrow
\Gamma\left(w;\frac{n+1}{2},\frac{2}{1+\frac{t^2}{n}}\right)
& = \frac{1}{\Gamma(\frac{n+1}{2})\left(\frac{2}{1+\frac{t^2}{n}}\right)^{\frac{n+1}{2}}}
w^{\frac{n+1}{2}-1}\exp\left(-\frac{w}{\frac{2}{1+\frac{t^2}{n}}}\right) \\
& = \frac{1}{\Gamma( \frac{n+1}{2})\left(\frac{2}{1+\frac{t^2}{n}}\right)^{ \frac{n+1}{2}}}
\exp\left(-\frac{1}{2}\left(1 + \frac{t^2}{n}\right)\right) w^{\frac{n+1}{2}-1}.
\end{align*}
Es ergibt sich also
\begin{equation}
p_T(t)
=
\frac{1}{\sqrt{2\pi}}\frac{1}{\Gamma(\frac{n}{2})2^{\frac{n}{2}}n^{\frac{1}{2}}}
\int_0^\infty
\Gamma\left(w;\frac{n+1}{2},\frac{2}{1+\frac{t^2}{n}}\right)
\,dw .
\end{equation}
Schließlich stellen wir fest, dass der Integralterm in obiger Gleichung dem
Normalisierungsterm einer Gamma WDF entspricht. Abschließend ergibt sich also
\begin{equation}
p_T(t) =
\frac{1}{\sqrt{2\pi}}\frac{1}{\Gamma(\frac{n}{2})2^{\frac{n}{2}}n^{\frac{1}{2}}}
\Gamma\left(\frac{n+1}{2}\right)\left(\frac{2}{1 + \frac{t^2}{n}} \right)^{\frac{n+1}{2}}.
\end{equation}
Die Verteilung von $Z/\sqrt{U/n}$ hat also die WDF einer $t$-Zufallsvariable.
:::

Wichtige Anwendungsfälle sind die $T$-Konfidenzintervallstatistik sowie die 
$T$-Teststatistiken der Theorie von Hypothesentests im Kontext des Allgemeinen 
Linearen Modells. Wir visualisieren @thm-t-transformation exemplarisch in @fig-t-transform.

```{r, eval = F, echo = F}
pdf(file = "./_figures/209-t-transform.pdf", width = 6, height = 2)                                                                        
library(latex2exp)
par(                                                                    
family     = "sans",                                                  
mfcol      = c(1,3),                                                  
pty        = "m",                                                     
bty        = "l",                                                     
lwd        = .5,                                                       
las        = 1,                                                       
mgp        = c(2,1,0),                                                
xaxs       = "i",                                                     
yaxs       = "i",                                                     
font.main  = 1,                                                      
cex        = 0.5,
cex.main   = 1.1)

# Z sample
n           = 1e4                                                                # number of samples
Z           = rnorm(n, 0 ,1)                                                     # n samples of Z \sim N(0,1)
z_min       = -5                                                                 # minimum z-value
z_max       = 5                                                                  # maximum z-value
z_res       = 1e3                                                                # z-space resolution
z           = seq(z_min, z_max, len = z_res)                                     # z-space
p_Z         = dnorm(z, 0, 1)                                                     # z density

# histogram
hist(
Z,                                                                         
breaks = 50,                                                               
col   = "gray90",                                                           
prob  = TRUE,                                                               
xlim  = c(-5, 5),                                                           
ylim  = c(0,.42),                                                           
xlab  = "z",                                                                
ylab  = "",                                                                 
main  = TeX("$Z \\sim N(0,1)$"))                                             

# density
lines(
z,                                                                          
p_Z,                                                                       
lwd   = 2,                                                                  
col   = "darkorange")                                                       

# chi^2 sample
df          = 3                                                                  # degrees of freedom
U           = rchisq(n,df)                                                       # n samples of U \sim \chi^2(3)
u_min       = 1e-5                                                               # minimum z-value
u_max       = 10                                                                 # maximum z-value
u_res       = 1e3                                                                # u-space resolution
u           = seq(u_min, u_max, len = u_res)                                     # u-space
p_U         = dchisq(u,df)                                                       # u density

# histogram
hist(
U,                                                                          
breaks= 100,                                                                
col   = "gray90",                                                           
prob  = TRUE,                                                               
xlim  = c(0, 10),                                                           
ylim  = c(0,0.3),                                                           
xlab  = "u",                                                                
ylab  = "",                                                                 
main  = TeX("$U \\sim \\chi^2(3)$"))                                         

# density
lines(
u,                                                                          
p_U,                                                                       
lwd   = 2,                                                                  
col   = "darkorange")                                                       

# T-transformation
Tee         = Z/(sqrt(U/df))                                                     # element-wise vector arithmetic
Tee         = Tee[!abs(Tee) > 10]                                                # mildly censored sample for good histogram performance
t_min       = -4                                                                 # minimum t-value
t_max       = 4                                                                  # maximum t-value
t_res       = 1e3                                                                # t-space resolution
t           = seq(z_min, z_max, len = z_res)                                     # t-space
p_T         = dt(z,df)                                                           # t density

# histogram
hist(
Tee,                                                                        
breaks      = 100,                                                                
col         = "gray90",                                                           
prob        = TRUE,                                                               
xlim        = c(t_min, t_max),                                                     
ylim        = c(0,0.4),                                                           
xlab        = "t",                                                                
ylab        = "",                                                                 
main        = TeX("$T = Z/\\sqrt{U/n}\\sim \\t(3)$"))                        
 
# density
lines(
t,                                                                          
p_T,                                                                       
lwd         = 2,                                                                  
col         = "darkorange")                                                       
dev.off()                                                                 
```

![$T$-Transformation normalverteilter Zufallsvariablen.](./_figures/209-t-transform){#fig-t-transform fig-align="center" width=100%}

## Nichtzentrale $T$-Transformation {#sec-nichtzentrale-t-transformation}

In diesem Abschnitt betrachten wir den Fall, dass der Erwartungswertparameter
der Zählervariable der in @thm-t-transformation betrachteten Zufallsvariable $T$
von Null verschieden ist, dass es sich bei der Zählervariable also nicht um eine
nach $N(0,1)$, sondern eine nach $N(\mu,1)$ verteilte Zufallsvariable für ein 
beliebiges $\mu \in \mathbb{R}$ handelt. Die so entstehende Zufallsvariable $T$
folgt dann einer sogenannten *nichtzentralen-t-Verteilung*. Eine frühe ausführliche
Diskussion dieser Verteilung findet sich zum Beispiel in @johnson1940. Eine entsprechende
nichtzentralen-$t$-verteilte Zufallsvariable ist wie folgt definiert (vgl. @lehmann1986).

:::{#def-nichtzentrale-$t$-zufallsvariable}
## Nichtzentrale $t$-Zufallsvariable
$T$ sei eine Zufallsvariable mit Ergebnisraum $\mathbb{R}$ und WDF
\begin{multline}
p : \mathbb{R} \to \mathbb{R}_{>0}, t \mapsto p(t) :=
\frac{1}{2^{\frac{n-1}{2}}\Gamma\left(\frac{n}{2} \right)(n \pi)^{\frac{1}{2}}} \\
\times \int_{0}^\infty \tau^{\frac{n-1}{2}} \exp\left(-\frac{\tau}{2}\right)
\exp\left(-\frac{1}{2}\left(t \left(\frac{\tau}{n}\right)^{\frac{1}{2}} - \delta \right)^2 \right)\,d\tau.
\end{multline}
Dann sagen wir, dass $T$ einer nichtzentralen $t$-Verteilung mit 
Nichtzentralitätsparameter $\delta$ und Freiheitsgradparameter $n$ unterliegt 
und nennen $T$ eine *nichtzentrale $t$-Zufallsvariable mit Nichtzentralitätsparameter $\delta$ und Freiheitsgradparameter $n$*. Wir kürzen dies mit $t(\delta, n)$ ab. 
Die WDF einer nichtzentralen $t$-Zufallsvariable bezeichnen wir mit
$t(T;\delta,n)$. Die KVF und inverse KVF einer nichtzentralen $t$-Zufallsvariable
bezeichnen wir mit $\Psi(\cdot; \delta, n)$ und $\Psi^{-1}(\cdot; \delta, n)$, respektive.
:::

Ohne Beweis merken wir an, dass eine nichtzentrale $t$-Zufallsvariable mit 
$\delta = 0$ einer $t$-Zufallsvariable enstpricht, es gelten also
\begin{equation}
t(T;0,n) = t(T;n)
\end{equation}
sowie 
\begin{equation}
\Psi(T;0,n) = \Psi(T;n)  \mbox{ und } \Psi^{-1}(T;0,n) = \Psi^{-1}(T;n).
\end{equation}

In @fig-nichtzentrale-t-wdf visualisieren wir exemplarisch einige WDFen von nichtzentralen 
$t$-Zufallsvariablen. Wir beobachten, dass ein positiver Nichtzentralitätsparameter
$\delta$ die Verteilung nach rechts verschiebt und die Verteilungen mit steigendem
Freiheitsgradparameter $\delta$ sich entsprechend lokalisierten Normalverteilungen mit
Varianzparameter 1 annähern. Man beachte auch die Nichtsymmetrie der WDFen für 
kleine Freiheitsgradparameter bei von Null verschiedenem positivem Nichtzentralitätsparameter. 

```{r, echo = F, eval = F}
options(warn=-1)                                                                # warning off
t_min     = -5                                                                  # Minimum T-Wert
t_max     = 30                                                                  # Maximum T-Wert
t_res     = 1e3                                                                 # T-Wert Auflösung
t         = seq(t_min, t_max, len = t_res)                                      # T-Raum
delta     = c(0,5,15)                                                           # Nichtzentralitätsparameter
n         = c(5, 30)                                                            # Freiheitsgrade
p         = cbind(
            matrix(dt(t, n[1], delta[1]),nrow=length(t)),
            matrix(dt(t, n[2], delta[1]),nrow=length(t)),
            matrix(dt(t, n[1], delta[2]),nrow=length(t)),
            matrix(dt(t, n[2], delta[2]),nrow=length(t)),
            matrix(dt(t, n[1], delta[3]),nrow=length(t)),
            matrix(dt(t, n[2], delta[3]),nrow=length(t)))

# Visualisierung
pdf(
file        = "./_figures/209-nichtzentrale-t-wdf.pdf",
width       = 7,
height      = 4.5)
library(latex2exp)
par(
family      = "sans",
pty         = "m",
bty         = "l",
lwd         = 1,
las         = 1,
mgp         = c(2,1,0),
xaxs        = "i",
yaxs        = "i",
font.main   = 1,
cex         = 1,
cex.main    = 1.2)
matplot(
t,
p,
type        = "l",
lty         = c(1,2,1,2,1,2),
col         = c("gray10", "gray10", "gray50", "gray50", "gray70", "gray70"),
lwd         = 2,
xlab        = "T",
ylab        = "",
ylim        = c(0,.4),
main        = TeX("$t(T;\\delta,n)$"))
legend(
18,
.4,
c(TeX("$\\delta = 0 , \\,\\,\\, n = 5$"),
  TeX("$\\delta = 0 , \\,\\,\\, n = 30$"),
  TeX("$\\delta = 5 , \\,\\,\\, n = 5$"),
  TeX("$\\delta = 5 , \\,\\,\\, n = 30$"),
  TeX("$\\delta = 15, \\, n = 5$"),
  TeX("$\\delta = 15, \\, n = 30$")),
lty         = c(1,2,1,2,1,2),
col         = c("gray10", "gray10", "gray50", "gray50", "gray70", "gray70"),
lwd         = 2,
bty         = "n",
seg.len     = 1.75)
dev.off()
```

![WDFen von Nichtzentralen-$T$-Zufallsvariablen.](./_figures/209-nichtzentrale-t-wdf){#fig-nichtzentrale-t-wdf fig-align="center" width=80%}

Eine nichtzentrale $t$-Zufallsvariable ist das Resultat einer nichtzentralen $T$-Transformation, wie folgendes Theorem besagt.

:::{#thm-nichtzentrale-t-transformation}
## Nichtzentrale T-Transformation
$\upsilon \sim N(\mu,1)$ sei eine normalverteilte Zufallsvariable, $U \sim \chi^2(n)$
sei eine $\chi^2$ Zufallsvariable mit Freiheitsgradparameter $n$, und $\upsilon$ und
$U$ seien unabhängige Zufallsvariablen. Dann ist die Zufallsvariable
\begin{equation}
T := \frac{\upsilon}{\sqrt{U/n}}
\end{equation}
eine nichtzentrale $t$-Zufallsvariable mit Nichtzentralitätsparameter $\mu$ und
Freiheitsgradparameter $n$, also $T \sim t(\mu,n)$.
:::

Wir verzichten auf einen Beweis. Wichtige Anwendungsfälle sind die Testgütefunktionen
der T-Test Varianten im Kontext des Allgemeinen Linearen Modells. Wir visualisieren @thm-nichtzentrale-t-transformation exemplarisch in @fig-nichtzentrale-t-transformation.

```{r, echo = F, eval = F}
pdf(
file        = "./_figures/209-nichtzentrale-t-transformation.pdf",
width       = 7,
height      = 3)
par(
family      = "sans",
mfcol       = c(1,3),
pty         = "m",
bty         = "l",
lwd         = 1,
las         = 1,
mgp         = c(2,1,0),
xaxs        = "i",
yaxs        = "i",
font.main   = 1,
cex.main    = 1.2)

# simulation parameters
mu          = 5                                                                  # expectation parameter
n           = 5                                                                  # degrees of freedom parameter
ns          = 1e5                                                                # number of samples


# X sample
X           = rnorm(ns,mu,1)                                                     # ns samples of X \sim N(0,1)
x_min       = 0                                                                  # minimum x-value
x_max       = 10                                                                 # maximum x-value
x_res       = 1e3                                                                # x-space resolution
x           = seq(x_min, x_max, len = x_res)                                     # x-space
p_X         = dnorm(x,mu, 1)                                                     # x density

# histogram and density
hist(
X,
breaks      = 50,
col         = "gray90",
prob        = TRUE,
xlim        = c(x_min,x_max),
ylim        = c(0,.5),
xlab        = "x",
ylab        =  "",
main        = TeX("$\\upsilon \\sim N(5,1)$"))
lines(
x,
p_X,
lwd         = 2,
col         = "darkorange")

# chi^2 sample
U           = rchisq(ns,n)                                                       # ns samples of U \sim \chi^2(n)
u_min       = 1e-5                                                               # minimum z-value
u_max       = 20                                                                 # maximum z-value
u_res       = 1e3                                                                # u-space resolution
u           = seq(u_min, u_max, len = u_res)                                     # u-space
p_U         = dchisq(u,n)                                                        # u density

# histogram and density
hist(
U,
breaks      = 100,
col         = "gray90",
prob        = TRUE,
xlim        = c(u_min, u_max),
ylim        = c(0,0.2),
xlab        = "u",
ylab        = "",
main        = TeX("$U \\sim \\chi^2(5)$"))
lines(
u,
p_U,
lwd   = 2,
col   = "darkorange")

# Noncentral T-transformation
Tee         = X/(sqrt(U/n))                                                      # element-wise vector arithmetic
Tee         = Tee[!abs(Tee) > 30]                                                # mildly censored sample for good histogram performance
t_min       = 0                                                                  # minimum t-value
t_max       = 20                                                                 # maximum t-value
t_res       = 1e3                                                                # t-space resolution
t           = seq(t_min,t_max,len = t_res)                                       # t-space
p_T         = dt(t,n,mu)                                                         # t density


# histogram and density
hist(
Tee,
breaks      = 100,
col         = "gray90",
prob        = TRUE,
xlim        = c(t_min, t_max),
ylim        = c(0,0.3),
xlab        = "t",
ylab        = "",
main        = TeX("$T = \\upsilon/\\sqrt{U/n} \\sim \\t(5,5)$"))
lines(
t,
p_T,
lwd         = 2,
col         = "darkorange")
dev.off()
```

![Nichtzentrale $T$-Transformation normalverteilter Zufallsvariablen.](./_figures/209-nichtzentrale-t-transformation){#fig-nichtzentrale-t-transformation fig-align="center" width=100%}

## $F$-Transformation


Das in diesem Abschnitt zentrale @thm-f-transformation besagt, dass die Zufallsvariable, 
die sich durch Division zweier $\chi^2$ verteilter Zufallsvariablen, jeweils geteilt
durch ihre jeweiligen Freiheitsgradparameter, eine $F$-verteilte Zufallsvariable ist.
Dabei ist eine $F$-verteilte Zufallsvariable wie folgt definiert.

:::{#def-f-zufallsvariable}
## $f$-Zufallsvariable
$F$ sei eine Zufallsvariable mit Ergebnisraum $\mathbb{R}_{>0}$ und WDF
\begin{equation}
p_F : \mathbb{R} \to \mathbb{R}_{>0}, f \mapsto p_F(f)
:= m^{\frac{m}{2}}n^{\frac{n}{2}}
   \frac{\Gamma\left(\frac{m+n}{2}\right)}{\Gamma\left(\frac{m}{2}\right)\Gamma\left(\frac{n}{2}\right)}
   \frac{f^{\frac{m}{2}-1}}{\left(1 + \frac{m}{n}f \right)^{\frac{m+n}{2}}},
\end{equation}
wobei $\Gamma$ die Gammafunktion bezeichne. Dann sagen wir, dass $F$ einer
$f$-Verteilung mit Freiheitsgradparametern $n,m$ unterliegt und nennen $F$ eine
$f$-Zufallsvariable mit Freiheitsgradparametern $n,m$. Wir kürzen dies mit $F \sim f(n,m)$ ab.
Die WDF einer $f$-Zufallsvariable bezeichnen wir mit
\begin{equation}
F(f;n,m)
:= m^{\frac{m}{2}}n^{\frac{n}{2}}
   \frac{\Gamma\left(\frac{m+n}{2}\right)}{\Gamma\left(\frac{m}{2}\right)\Gamma\left(\frac{n}{2}\right)}
   \frac{f^{\frac{m}{2}-1}}{\left(1 + \frac{m}{n}f \right)^{\frac{m+n}{2}}}.
\end{equation}
:::

In @fig-f-wdf visualisieren wir exemplarisch einige WDFen von $f$-Zufallsvariablen.
Wir beobachten, dass die Form der WDFen zunächt primär durch den Freiheitsgradparameter
$n$ und dann sekundär durch den Freiheitsgradparameter $m$ bestimmt werden.

```{r, echo = F, eval = F}
pdf(file = "./_figures/209-f-wdf.pdf", width = 6, height = 5) 
par(                                                                    
family     = "sans",                                                 
pty        = "m",                                                     
bty        = "l",                                                    
lwd        = 1,                                                       
las        = 1,                                                       
mgp        = c(2,1,0),                                                
xaxs       = "i",                                                   
yaxs       = "i",                                      
font.main  = 1,                                                       
cex.main   = 1.4)

# f space
f_min   = 0                                                                     # minimum f-value
f_max   = 4                                                                     # maximum f-value
f_res   = 1e3                                                                   # f-space resolution
f        = seq(f_min, f_max, len = f_res)                                        # f-space

# parameters of interest
n       = c(2,2 ,5,5 ,10,10)                                                        # degrees of freedom
m       = c(2,10,2,10,2 ,10)                                                        # degrees of freedom

# plotting
matplot(
f,
matrix(
c(df(f,n[1],m[1]),
df(f,n[2],m[2]),
df(f,n[3],m[3]),
df(f,n[4],m[4]),
df(f,n[5],m[5]),
df(f,n[6],m[6])),
ncol = 6),
type         = "l",                                                      
lty          = c(1,2,1,2,1,2),                                            
lwd          = 2,                                                         
col          = c("gray90","gray70", "gray50", "gray30", "gray10"),      
ylim         = c(0,1),                                                    
xlim         = c(f_min,f_max),                                            
ylab         = " ",                                                       
xlab         = "f",                                                       
main         = TeX("$F(f;n,m)$"))                                        

legend(
2.40,                                                                        
1,                                                                       
c("n = 2,  m = 2",
"n = 2,  m = 10",
"n = 5,  m = 2",
"n = 5,  m = 10",
"n = 10, m = 5",
"n = 10, m = 10"),                                                      
lty         = c(1,2,1,2,1,2),                                             
lwd         = 2,                                                          
col         = c("gray90","gray70", "gray50", "gray30", "gray10"),       
bty         = "n",                                                        
cex         = 1,                                                        
y.intersp   = 1)                                                        
dev.off()                                                                  
```


![WDFen von $f$-verteilten Zufallsvariablen.](./_figures/209-f-wdf){#fig-f-wdf fig-align="center" width=60%}

:::{#thm-f-transformation}
## $F$-Transformation
$V \sim \chi^2(n)$ und $W \sim \chi^2(m)$ seien zwei unabhängige
$\chi^2$-Zufallfsvariablen mit Freiheitsgradparametern $n$ und $m$, respektive.
Dann ist die Zufallsvariable
\begin{equation}
F := \frac{V/n}{W/m}
\end{equation}
eine $f$-verteilte Zufallsvariable mit Freiheitsgradparametern $n,m$, es gilt also $F \sim f(n,m)$.
:::

Das Theorem kann bewiesen werden, in dem man zunächst ein Transformationstheorem
für Quotienten von Zufallsvariablen mithilfe von @thm-transformation-eines-zufallsvektors
und Marginalisierung herleitet und dieses Theorem dann auf die WDF von $\chi^2$-verteilten
Zufallsvariablen anwendet. Wir visualisieren @thm-f-transformation exemplarisch in @fig-f-transform.
Wichtige Anwendungsfälle von @thm-f-transformation sind die im Rahmen der
Theorie des Allgemeinen Linearen Modells betrachteten $F$-Statistiken.


```{r, echo = F, eval = F}
pdf(file = "./_figures/209-f-transform.pdf", width = 12, height = 4)                                                                       
par(                                                                    
family     = "sans",                                                  
mfcol      = c(1,3),                                                  
pty        = "m",                                                     
bty        = "l",                                                     
lwd        = 1,                                                       
las        = 1,                                                       
mgp        = c(2,1,0),                                                
xaxs         = "i",                                                   
yaxs         = "i",                                                  
font.main  = 1,                                                       
cex        = 1.2,
cex.main   = 1)

# chi^2 samples
n           = 5
m           = 10
nsamp       = 1e4                                                                # number of samples
V           = rchisq(nsamp,n)                                                    # nsamp samples of V \sim \chi^2(n)
W           = rchisq(nsamp,m)                                                    # nsamp samples of W \sim \chi^2(m)
v_min       = 0                                                                  # minimum chi^2-value
v_max       = 25                                                                 # maximum chi^2-value
v_res       = 1e3                                                                # chi^2-space resolution
v           = seq(v_min, v_max, len = v_res)                                     # chi^2-space
w           = v                                                                  # chi^2-space
p_V         = dchisq(v,n)                                                        # chi^2(n) density
p_W         = dchisq(w,m)                                                        # chi^2(m) density

# V histogram
hist(
V,                                                                          
breaks = 50,                                                                
col   = "gray90",                                                           
prob  = TRUE,                                                               
xlim  = c(v_min,v_max),                                                     
ylim  = c(0,.2),                                                            
xlab  = "v",                                                                
ylab  = "",                                                                
main  = TeX("$V \\sim \\chi^2(5)$")) 

# density
lines(
v,                                                                          
p_V,                                                                        
lwd   = 2,                                                                  
col   = "darkorange")                                                       

# W histogram
hist(
W,                                                                          
breaks = 50,                                                                
col   = "gray90",                                                           
prob  = TRUE,                                                               
xlim  = c(v_min,v_max),                                                     
ylim  = c(0,.2),                                                            
xlab  = "w",                                                                
ylab  = "",                                                                  
main  = TeX("$W \\sim \\chi^2(10)$"))                                       

# density
lines(
w,                                                                         
p_W,                                                                        
lwd   = 2,                                                                  
col   = "darkorange")                                                       

# F-transformation
Eff         = (V/n)/(W/m)                                                        # element-wise vector arithmetic
f_min       = 0                                                                  # minimum t-value
f_max       = 6                                                                  # maximum t-value
f_res       = 1e3                                                                # t-space resolution
f           = seq(f_min, f_max, len = f_res)                                     # t-space
p_F         = df(f,n,m)                                                          # t density

# histogram
hist(
Eff,                                                                       
breaks= 100,                                                                
col   = "gray90",                                                           
prob  = TRUE,                                                               
xlim  = c(f_min, f_max),                                                    
ylim  = c(0,.8),                                                            
xlab  = "f",                                                                
ylab  = "",                                                                 
main  = TeX("$F = \\frac{V/n}{W/m}\\sim \\F(5,10)$"))

# density
lines(
f,                                                                          
p_F,                                                                       
lwd   = 2,                                                                  
col   = "darkorange")                                                       
dev.off()                                                                
```

![$F$-Transformation normalverteilter Zufallsvariablen.](./_figures/209-f-transform){#fig-f-transform fig-align="center" width=100%}

##  Selbstkontrollfragen

1. Erläutern Sie die Bedeutung der in diesem Abschnitt betrachteten Transformationen von normalverteilten Zufallsvariablen für die Frequentistische Inferenz.
1. Geben Sie das Theorem zur Summentransformation wieder.
1. Geben Sie das Theorem zur Mittelwerttransformation wieder.
1. Geben Sie das Theorem zur $Z$-Transformation wieder.
1. Geben Sie das Theorem zur $\chi^2$-Transformation wieder.
1. Beschreiben Sie die WDF der $t$-Verteilung in Abhängigkeit ihrer Freiheitsgradparameter.
1. Geben Sie das Theorem zur $T$-Transformation wieder.
1. Geben Sie das Theorem zur $F$-Transformation wieder.

