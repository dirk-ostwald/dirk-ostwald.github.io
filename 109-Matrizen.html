<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="de" xml:lang="de"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>9&nbsp; Matrizen – Probabilistische Datenwissenschaft für die Psychologie</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./110-Deskriptivstatistiken.html" rel="next">
<link href="./108-Vektoren.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-ca3ba20d3bce705d7fcc85d020c3372b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Keine Treffer",
    "search-matching-documents-text": "Treffer",
    "search-copy-link-title": "Link in die Suche kopieren",
    "search-hide-matches-text": "Zusätzliche Treffer verbergen",
    "search-more-match-text": "weitere Treffer in diesem Dokument",
    "search-more-matches-text": "weitere Treffer in diesem Dokument",
    "search-clear-button-title": "Zurücksetzen",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Abbrechen",
    "search-submit-button-title": "Abschicken",
    "search-label": "Suchen"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Probabilistische Datenwissenschaft für die Psychologie</span>
    </a>
  </div>
        <div class="quarto-navbar-tools tools-end">
    <a href="https://github.com/dirk-ostwald/dirk-ostwald.github.io/tree/gh-pages" title="Quellcode" class="quarto-navigation-tool px-1" aria-label="Quellcode"><i class="bi bi-github"></i></a>
    <a href="./Probabilistische-Datenwissenschaft-für-die-Psychologie.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
</div>
          <div id="quarto-search" class="" title="Suchen"></div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Seitenleiste umschalten" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./100-Mathematische-Grundlagen.html">Mathematische Grundlagen</a></li><li class="breadcrumb-item"><a href="./109-Matrizen.html"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Matrizen</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Seitenleiste umschalten" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Willkommen</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./100-Mathematische-Grundlagen.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Mathematische Grundlagen</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Abschnitt umschalten">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./101-Sprache-und-Logik.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Sprache und Logik</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./102-Mengen.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Mengen</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./103-Summen-Produkte-Potenzen.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Summen, Produkte, Potenzen</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./104-Funktionen.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Funktionen</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./105-Folgen-Grenzwerte-Stetigkeit.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Folgen, Grenzwerte, Stetigkeit</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./106-Differentialrechnung.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Differentialrechnung</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./107-Integralrechnung.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Integralrechnung</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./108-Vektoren.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Vektoren</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./109-Matrizen.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Matrizen</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./110-Deskriptivstatistiken.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Deskriptivstatistiken</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Referenzen.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Referenzen</span></a>
  </div>
</li>
    </ul>
    </div>
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Inhaltsverzeichnis</h2>
   
  <ul>
  <li><a href="#sec-matrix-definition" id="toc-sec-matrix-definition" class="nav-link active" data-scroll-target="#sec-matrix-definition"><span class="header-section-number">9.1</span> Definition</a></li>
  <li><a href="#sec-grundlegende-matrixoperationen" id="toc-sec-grundlegende-matrixoperationen" class="nav-link" data-scroll-target="#sec-grundlegende-matrixoperationen"><span class="header-section-number">9.2</span> Grundlegende Matrixoperationen</a>
  <ul class="collapse">
  <li><a href="#matrixaddition" id="toc-matrixaddition" class="nav-link" data-scroll-target="#matrixaddition"><span class="header-section-number">9.2.1</span> Matrixaddition</a></li>
  <li><a href="#matrixsubtraktion" id="toc-matrixsubtraktion" class="nav-link" data-scroll-target="#matrixsubtraktion"><span class="header-section-number">9.2.2</span> Matrixsubtraktion</a></li>
  <li><a href="#skalarmultiplikation" id="toc-skalarmultiplikation" class="nav-link" data-scroll-target="#skalarmultiplikation"><span class="header-section-number">9.2.3</span> Skalarmultiplikation</a></li>
  <li><a href="#matrixtransposition" id="toc-matrixtransposition" class="nav-link" data-scroll-target="#matrixtransposition"><span class="header-section-number">9.2.4</span> Matrixtransposition</a></li>
  </ul></li>
  <li><a href="#sec-matrixmultiplikation" id="toc-sec-matrixmultiplikation" class="nav-link" data-scroll-target="#sec-matrixmultiplikation"><span class="header-section-number">9.3</span> Matrixmultiplikation</a>
  <ul class="collapse">
  <li><a href="#rechenregeln-der-matrixmultiplikation" id="toc-rechenregeln-der-matrixmultiplikation" class="nav-link" data-scroll-target="#rechenregeln-der-matrixmultiplikation"><span class="header-section-number">9.3.1</span> Rechenregeln der Matrixmultiplikation</a></li>
  </ul></li>
  <li><a href="#sec-matrixinversion" id="toc-sec-matrixinversion" class="nav-link" data-scroll-target="#sec-matrixinversion"><span class="header-section-number">9.4</span> Matrixinversion</a></li>
  <li><a href="#sec-determinanten" id="toc-sec-determinanten" class="nav-link" data-scroll-target="#sec-determinanten"><span class="header-section-number">9.5</span> Determinanten</a></li>
  <li><a href="#sec-spezielle-matrizen" id="toc-sec-spezielle-matrizen" class="nav-link" data-scroll-target="#sec-spezielle-matrizen"><span class="header-section-number">9.6</span> Spezielle Matrizen</a>
  <ul class="collapse">
  <li><a href="#einheitsmatrizen" id="toc-einheitsmatrizen" class="nav-link" data-scroll-target="#einheitsmatrizen"><span class="header-section-number">9.6.1</span> Einheitsmatrizen</a></li>
  <li><a href="#einsmatrizen-und-nullmatrizen" id="toc-einsmatrizen-und-nullmatrizen" class="nav-link" data-scroll-target="#einsmatrizen-und-nullmatrizen"><span class="header-section-number">9.6.2</span> Einsmatrizen und Nullmatrizen</a></li>
  <li><a href="#diagonalmatrizen" id="toc-diagonalmatrizen" class="nav-link" data-scroll-target="#diagonalmatrizen"><span class="header-section-number">9.6.3</span> Diagonalmatrizen</a></li>
  <li><a href="#symmetrische-matrizen" id="toc-symmetrische-matrizen" class="nav-link" data-scroll-target="#symmetrische-matrizen"><span class="header-section-number">9.6.4</span> Symmetrische Matrizen</a></li>
  <li><a href="#orthogonale-matrizen" id="toc-orthogonale-matrizen" class="nav-link" data-scroll-target="#orthogonale-matrizen"><span class="header-section-number">9.6.5</span> Orthogonale Matrizen</a></li>
  <li><a href="#positiv-definite-matrizen" id="toc-positiv-definite-matrizen" class="nav-link" data-scroll-target="#positiv-definite-matrizen"><span class="header-section-number">9.6.6</span> Positiv-definite Matrizen</a></li>
  </ul></li>
  <li><a href="#literaturhinweise" id="toc-literaturhinweise" class="nav-link" data-scroll-target="#literaturhinweise"><span class="header-section-number">9.7</span> Literaturhinweise</a></li>
  <li><a href="#selbstkontrollfragen" id="toc-selbstkontrollfragen" class="nav-link" data-scroll-target="#selbstkontrollfragen"><span class="header-section-number">9.8</span> Selbstkontrollfragen</a></li>
  <li><a href="#sec-eigenanalyse" id="toc-sec-eigenanalyse" class="nav-link" data-scroll-target="#sec-eigenanalyse"><span class="header-section-number">9.9</span> Eigenanalyse</a></li>
  <li><a href="#eigenvektoren-und-eigenwerte" id="toc-eigenvektoren-und-eigenwerte" class="nav-link" data-scroll-target="#eigenvektoren-und-eigenwerte"><span class="header-section-number">9.10</span> Eigenvektoren und Eigenwerte</a>
  <ul class="collapse">
  <li><a href="#beispiel" id="toc-beispiel" class="nav-link" data-scroll-target="#beispiel">Beispiel</a></li>
  <li><a href="#bestimmung-von-eigenwerten-und-eigenvektoren" id="toc-bestimmung-von-eigenwerten-und-eigenvektoren" class="nav-link" data-scroll-target="#bestimmung-von-eigenwerten-und-eigenvektoren">Bestimmung von Eigenwerten und Eigenvektoren</a></li>
  <li><a href="#beispiel-1" id="toc-beispiel-1" class="nav-link" data-scroll-target="#beispiel-1">Beispiel</a></li>
  </ul></li>
  <li><a href="#sec-orthonormalzerlegung" id="toc-sec-orthonormalzerlegung" class="nav-link" data-scroll-target="#sec-orthonormalzerlegung"><span class="header-section-number">9.11</span> Orthonormalzerlegung</a>
  <ul class="collapse">
  <li><a href="#symmetrische-quadratwurzel-einer-matrix" id="toc-symmetrische-quadratwurzel-einer-matrix" class="nav-link" data-scroll-target="#symmetrische-quadratwurzel-einer-matrix">Symmetrische Quadratwurzel einer Matrix</a></li>
  </ul></li>
  <li><a href="#sec-singulärwertzerlegung" id="toc-sec-singulärwertzerlegung" class="nav-link" data-scroll-target="#sec-singulärwertzerlegung"><span class="header-section-number">9.12</span> Singulärwertzerlegung</a></li>
  <li><a href="#literaturhinweise-1" id="toc-literaturhinweise-1" class="nav-link" data-scroll-target="#literaturhinweise-1"><span class="header-section-number">9.13</span> Literaturhinweise</a></li>
  <li><a href="#selbstkontrollfragen-1" id="toc-selbstkontrollfragen-1" class="nav-link" data-scroll-target="#selbstkontrollfragen-1"><span class="header-section-number">9.14</span> Selbstkontrollfragen</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/dirk-ostwald/dirk-ostwald.github.io/tree/gh-pages/edit/main/109-Matrizen.qmd" class="toc-action"><i class="bi bi-github"></i>Seite editieren</a></li></ul></div></nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./100-Mathematische-Grundlagen.html">Mathematische Grundlagen</a></li><li class="breadcrumb-item"><a href="./109-Matrizen.html"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Matrizen</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-matrizen" class="quarto-section-identifier"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Matrizen</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Matrizen sind die Worte der Sprache der modernen Datenanalyse. Ein Verständnis moderner datenanalytischer Verfahren und ihrer Implementation ist ohne ein Grundverständnis des Matrixbegriffs und ein Wissen um die grundlegenden Matrixoperationen nicht möglich. Matrizen können dabei sehr unterschiedliche Rollen spielen. So können Matrizen zum Beispiel Daten, experimentelle Designs und Modellparameter repräsentieren. Im Kontext der Linearen Algebra dienen Matrizen zur Repräsentation linearer Abbildungen und von Vektorräumen, hier werden Vektoren dann als spezielle Matrizen aufgefasst.</p>
<p>In diesem Kapitel geben wir eine Einführung zum Umgang mit Matrizen, wobei wir auf abstrakte Begrifflichkeiten der Linearen Algebra im Wesentlichen verzichten. Wir führen zunächst den Matrixbegriff ein und diskutieren dann mit der Matrixaddition, Matrixsubtraktion, Skalarmultiplikation und der Matrixtransposition erste grundlegende Matrixoperationen (<a href="#sec-matrix-definition" class="quarto-xref"><span>Kapitel 9.1</span></a> und <a href="#sec-grundlegende-matrixoperationen" class="quarto-xref"><span>Kapitel 9.2</span></a>). Wir führen dann die zentralen Begriffe der Matrixmultiplikation und der Matrixinversion ein (<a href="#sec-matrixmultiplikation" class="quarto-xref"><span>Kapitel 9.3</span></a> und <a href="#sec-matrixinversion" class="quarto-xref"><span>Kapitel 9.4</span></a>). Mit der Matrixdeterminante diskutieren wir dann in <a href="#sec-determinanten" class="quarto-xref"><span>Kapitel 9.5</span></a> eine erste Maßzahl zur Beschreibung von Matrizen. Wir schließen in <a href="#sec-spezielle-matrizen" class="quarto-xref"><span>Kapitel 9.6</span></a> mit einer Übersicht zu besonders häufig auftretenden Matrizen.</p>
<section id="sec-matrix-definition" class="level2" data-number="9.1">
<h2 data-number="9.1" class="anchored" data-anchor-id="sec-matrix-definition"><span class="header-section-number">9.1</span> Definition</h2>
<p>Wir beginnen mit der Definition einer Matrix.</p>
<div id="def-matrix" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 9.1</strong></span> Eine Matrix ist eine rechteckige Anordnung von Zahlen, die wie folgt bezeichnet wird <span class="math display">\[\begin{equation}
A := \begin{pmatrix}
a_{11} &amp; a_{12} &amp; \cdots &amp; a_{1m} \\
a_{21} &amp; a_{22} &amp; \cdots &amp; a_{2m} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
a_{n1} &amp; a_{n2} &amp; \cdots &amp; a_{nm}
\end{pmatrix}
:= {(a_{ij})}_{1\le i\le n,\, 1\le j\le m}.
\end{equation}\]</span></p>
</div>
<p>Matrizen bestehen aus <em>Zeilen (rows)</em> und <em>Spalten (columns)</em>. Die Matrixeinträge <span class="math inline">\(a_{ij}\)</span> werden mit einem <em>Zeilenindex</em> <span class="math inline">\(i\)</span> und einem <em>Spaltenindex</em> <span class="math inline">\(j\)</span> indiziert. Zum Beispiel gilt für <span class="math display">\[\begin{equation}
A:=\begin{pmatrix}
2 &amp; 7 &amp; 5 &amp; 2 \\
8 &amp; 2 &amp; 5 &amp; 6 \\
6 &amp; 4 &amp; 0 &amp; 9 \\
9 &amp; 2 &amp; 1 &amp; 2
\end{pmatrix},
\end{equation}\]</span> dass <span class="math inline">\(a_{32} = 4\)</span>. Die <em>Größe</em> oder <em>Dimension</em> einer Matrix ergibt sich aus der Anzahl ihrer Zeilen <span class="math inline">\(n \in \mathbb{N}\)</span> und Spalten <span class="math inline">\(m \in \mathbb{N}\)</span>. Matrizen mit <span class="math inline">\(n = m\)</span> heißen <em>quadratische Matrizen</em>.</p>
<p>In der Folge benötigen wir nur Matrizen mit reellen Einträgen, also <span class="math inline">\(a_{ij} \in \mathbb{R}\)</span> für alle <span class="math inline">\(i = 1,...,n\)</span> und <span class="math inline">\(j = 1,...,m\)</span>. Wir nennen die Matrizen mit reellen Einträge <em>reelle Matrizen</em> und bezeichnen die Menge der reellen Matrizen mit <span class="math inline">\(n\)</span> Zeilen und <span class="math inline">\(m\)</span> Spalten mit <span class="math inline">\(\mathbb{R}^{n \times m}\)</span>. An dem Ausdruck <span class="math display">\[\begin{equation}
A \in \mathbb{R}^{n\times m}
\end{equation}\]</span> können wir also ablesen, dass <span class="math inline">\(A\)</span> eine reelle Matrix mit <span class="math inline">\(n\)</span> Zeilen und <span class="math inline">\(m\)</span> Spalten ist. Wir identifizieren dabei die Menge <span class="math inline">\(\mathbb{R}^{1 \times 1}\)</span> mit der Menge <span class="math inline">\(\mathbb{R}\)</span>, die Menge <span class="math inline">\(\mathbb{R}^{n \times 1}\)</span> mit der Menge <span class="math inline">\(\mathbb{R}^n\)</span>. Reelle Matrizen mit einer Spalte und <span class="math inline">\(n\)</span> Zeilen entsprechen also <span class="math inline">\(n\)</span>-dimensionalen reellen Vektoren und reelle Matrizen mit einer Spalte und einer Zeile entsprechen reellen Zahlen.</p>
<p><strong>Definition von Matrizen in R</strong></p>
<p>In <strong>R</strong> werden Matrizen definiert, indem <strong>R</strong> Vektoren mithilfe der <code>matrix()</code> Funktion in die Repräsentation einer mathematischen Matrix transformiert werden. Die Einträge eines <strong>R</strong> Vektors werden dabei anhand der spezifizierten Zeilenanzahl <code>nrow</code> anhand ihrer Gesamtanzahl auf die Matrix verteilt. Wollen wir beispielsweise die Matrix <span class="math display">\[\begin{equation}
A :=
\begin{pmatrix}
2 &amp; 3 &amp; 0 \\
1 &amp; 6 &amp; 5
\end{pmatrix}
\end{equation}\]</span> in <strong>R</strong> definieren, so ergibt sich</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1"></a><span class="co"># Spaltenweise Definition von A (R default)</span></span>
<span id="cb1-2"><a href="#cb1-2"></a>A <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">3</span>,<span class="dv">6</span>,<span class="dv">0</span>,<span class="dv">5</span>), <span class="at">nrow =</span> <span class="dv">2</span>)</span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="fu">print</span>(A)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     [,1] [,2] [,3]
[1,]    2    3    0
[2,]    1    6    5</code></pre>
</div>
</div>
<p><strong>R</strong> folgt hier per default einer sogenannten <em>column-major-order</em>, das heißt, die Elemente des <strong>R</strong> Vektors <code>c(2,1,3,6,0,5)</code> werden der Reihe nach von oben nach unten in die Spalten der Matrix von links nach rechts überführt. Einen etwas klareren Zusammenhang zwischen dem visuellen Layout des <strong>R</strong> Codes und der resultierenden Matrix erhält man, indem man den <strong>R</strong> Vektor mithilfe von Zeilenumbrüchen anhand des intendierten Matrixlayouts formatiert und dann die column-major-order mithilfe des Arguments <code>byrow = TRUE</code> zu einer <em>row-major-order</em> umstellt. Es wird dann zunächst die erste Zeile der Matrix von links nach rechts mit den Elementen des <strong>R</strong> Vektors gefüllt wird und dann die zweite Zeile usw. bis alle Elemente des Vektors auf die Matrix verteilt sind.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1"></a><span class="co"># Reihenweise Definition von A (R default)</span></span>
<span id="cb3-2"><a href="#cb3-2"></a>A <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">0</span>,</span>
<span id="cb3-3"><a href="#cb3-3"></a>             <span class="dv">1</span>,<span class="dv">6</span>,<span class="dv">5</span>),</span>
<span id="cb3-4"><a href="#cb3-4"></a>             <span class="at">nrow =</span> <span class="dv">2</span>,</span>
<span id="cb3-5"><a href="#cb3-5"></a>             <span class="at">byrow =</span> <span class="cn">TRUE</span>)</span>
<span id="cb3-6"><a href="#cb3-6"></a><span class="fu">print</span>(A)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     [,1] [,2] [,3]
[1,]    2    3    0
[2,]    1    6    5</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1"></a><span class="co"># Zeilenweise Definition von B</span></span>
<span id="cb5-2"><a href="#cb5-2"></a>B <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">1</span>,<span class="dv">0</span>,</span>
<span id="cb5-3"><a href="#cb5-3"></a>            <span class="sc">-</span><span class="dv">4</span>,<span class="dv">2</span>,<span class="dv">0</span>), </span>
<span id="cb5-4"><a href="#cb5-4"></a>            <span class="at">nrow =</span> <span class="dv">2</span>, </span>
<span id="cb5-5"><a href="#cb5-5"></a>            <span class="at">byrow =</span> <span class="cn">TRUE</span>)</span>
<span id="cb5-6"><a href="#cb5-6"></a><span class="fu">print</span>(B)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     [,1] [,2] [,3]
[1,]    4    1    0
[2,]   -4    2    0</code></pre>
</div>
</div>
</section>
<section id="sec-grundlegende-matrixoperationen" class="level2" data-number="9.2">
<h2 data-number="9.2" class="anchored" data-anchor-id="sec-grundlegende-matrixoperationen"><span class="header-section-number">9.2</span> Grundlegende Matrixoperationen</h2>
<p>Man kann mit Matrizen rechnen. Dabei sind folgende Matrixoperationen grundlegend:</p>
<ul>
<li>Die Addition von Matrizen gleicher Größe, genannt <em>Matrixaddition</em>,</li>
<li>die Subtraktion von Matrizen gleicher Größe, genannt <em>Matrixsubtraktion</em>,</li>
<li>die Multiplikation einer Matrix mit einem Skalar, genannt <em>Skalarmultiplikation</em>,</li>
<li>das Vertauschen der Zeilen- und Spalten einer Matrix, genannt <em>Matrixtransposition</em>.</li>
</ul>
<p>Wir führen diese Operationen in der Folge in Operatorform, also als Funktionen ein. Dies dient insbesondere dazu, bei jeder Operation mit Hilfe ihrer Definitionsmenge zu betonen, von welcher Art die Objekte der jeweiligen Operation sind und mithilfe ihrer Bildmenge zu betonen, von welcher Art das Resultat der jeweiligen Operation ist.</p>
<section id="matrixaddition" class="level3" data-number="9.2.1">
<h3 data-number="9.2.1" class="anchored" data-anchor-id="matrixaddition"><span class="header-section-number">9.2.1</span> Matrixaddition</h3>
<div id="def-Matrixaddition" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 9.2</strong></span> Es seien <span class="math inline">\(A,B\in \mathbb{R}^{n\times m}\)</span>. Dann ist die <em>Addition</em> von <span class="math inline">\(A\)</span> und <span class="math inline">\(B\)</span> definiert als die Abbildung <span class="math display">\[\begin{equation}
+ : \mathbb{R}^{n\times m} \times \mathbb{R}^{n\times m} \to \mathbb{R}^{n \times m}, \,
(A,B) \mapsto +(A,B) := A + B
\end{equation}\]</span> mit <span class="math display">\[\begin{align}
\begin{split}
A + B
&amp; =
\begin{pmatrix}
a_{11} &amp; a_{12} &amp; \cdots &amp; a_{1m} \\
a_{21} &amp; a_{22} &amp; \cdots &amp; a_{2m} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
a_{n1} &amp; a_{n2} &amp; \cdots &amp; a_{nm}
\end{pmatrix}
+
\begin{pmatrix}
b_{11} &amp; b_{12} &amp; \cdots &amp; b_{1m} \\
b_{21} &amp; b_{22} &amp; \cdots &amp; b_{2m} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
b_{n1} &amp; b_{n2} &amp; \cdots &amp; b_{nm}
\end{pmatrix}
\\
&amp;
:=
\begin{pmatrix}
a_{11} + b_{11} &amp; a_{12} + b_{12} &amp; \cdots &amp; a_{1m} + b_{1m} \\
a_{21} + b_{21} &amp; a_{22} + b_{22} &amp; \cdots &amp; a_{2m} + b_{2m} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
a_{n1} + b_{n1} &amp; a_{n2} + b_{n2} &amp; \cdots &amp; a_{nm} + b_{nm}
\end{pmatrix}.
\end{split}
\end{align}\]</span></p>
</div>
<p>Die Definition der Matrixaddition legt insbesondere fest, dass nur Matrizen gleicher Größe addiert werden können und dass die Operation der Matrixaddition elementweise definiert ist.</p>
<p><strong>Beispiel</strong></p>
<p>Es seien <span class="math inline">\(A,B\in \mathbb{R}^{2\times 3}\)</span> definiert als <span class="math display">\[\begin{equation}
A:=\begin{pmatrix}
2 &amp; -3 &amp; 0\\
1 &amp;  6 &amp; 5\\
\end{pmatrix}
\mbox{ und }
B := \begin{pmatrix}
4 &amp; 1 &amp; 0\\
-4 &amp; 2 &amp; 0\\
\end{pmatrix}.
\end{equation}\]</span> Da <span class="math inline">\(A\)</span> und <span class="math inline">\(B\)</span> gleich groß sind, können wir sie addieren <span class="math display">\[\begin{align}
\begin{split}
C
= A+B
&amp; =
\begin{pmatrix}
2 &amp; -3 &amp; 0\\
1 &amp;  6 &amp; 5\\
\end{pmatrix}
+
\begin{pmatrix}
4 &amp; 1 &amp; 0\\
-4 &amp; 2 &amp; 0\\
\end{pmatrix}\\
&amp; =
\begin{pmatrix}
2 + 4 &amp; -3 + 1 &amp; 0 + 0\\
1 - 4 &amp;  6 + 2 &amp; 5 + 0\\
\end{pmatrix}\\
&amp; =
\begin{pmatrix}
6 &amp; -2 &amp; 0\\
-3 &amp;  8 &amp; 5 \\
\end{pmatrix}.
\end{split}
\end{align}\]</span></p>
<p>In <strong>R</strong> führt man obige Rechnung wie folgt aus.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1"></a><span class="co"># Definition</span></span>
<span id="cb7-2"><a href="#cb7-2"></a>A <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">2</span>, <span class="sc">-</span><span class="dv">3</span>, <span class="dv">0</span>,</span>
<span id="cb7-3"><a href="#cb7-3"></a>             <span class="dv">1</span>,  <span class="dv">6</span>, <span class="dv">5</span>),</span>
<span id="cb7-4"><a href="#cb7-4"></a>             <span class="at">nrow  =</span> <span class="dv">2</span>,</span>
<span id="cb7-5"><a href="#cb7-5"></a>             <span class="at">byrow =</span> <span class="cn">TRUE</span>)</span>
<span id="cb7-6"><a href="#cb7-6"></a>B <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">c</span>( <span class="dv">4</span>, <span class="dv">1</span>, <span class="dv">0</span>,</span>
<span id="cb7-7"><a href="#cb7-7"></a>             <span class="sc">-</span><span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">0</span>),</span>
<span id="cb7-8"><a href="#cb7-8"></a>              <span class="at">nrow =</span> <span class="dv">2</span>,</span>
<span id="cb7-9"><a href="#cb7-9"></a>             <span class="at">byrow =</span> <span class="cn">TRUE</span>)</span>
<span id="cb7-10"><a href="#cb7-10"></a></span>
<span id="cb7-11"><a href="#cb7-11"></a><span class="co"># Addition</span></span>
<span id="cb7-12"><a href="#cb7-12"></a>C <span class="ot">=</span> A <span class="sc">+</span> B</span>
<span id="cb7-13"><a href="#cb7-13"></a><span class="fu">print</span>(C)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     [,1] [,2] [,3]
[1,]    6   -2    0
[2,]   -3    8    5</code></pre>
</div>
</div>
</section>
<section id="matrixsubtraktion" class="level3" data-number="9.2.2">
<h3 data-number="9.2.2" class="anchored" data-anchor-id="matrixsubtraktion"><span class="header-section-number">9.2.2</span> Matrixsubtraktion</h3>
<p>Die Subtraktion von Matrizen gleicher Größe ist analog zur Addition definiert.</p>
<div id="def-matrixsubtraktion" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 9.3 (Matrixsubtraktion)</strong></span> Es seien <span class="math inline">\(A,B\in \mathbb{R}^{n\times m}\)</span>. Dann ist die <em>Subtraktion</em> von <span class="math inline">\(A\)</span> und <span class="math inline">\(B\)</span> definiert als die Abbildung <span class="math display">\[\begin{equation}
- : \mathbb{R}^{n\times m} \times \mathbb{R}^{n\times m} \to \mathbb{R}^{n\times m}, \,
(A,B) \mapsto -(A,B) := A - B
\end{equation}\]</span> mit <span class="math display">\[\begin{align}
\begin{split}
A - B
&amp; =
\begin{pmatrix}
a_{11} &amp; a_{12} &amp; \cdots &amp; a_{1m} \\
a_{21} &amp; a_{22} &amp; \cdots &amp; a_{2m} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
a_{n1} &amp; a_{n2} &amp; \cdots &amp; a_{nm}
\end{pmatrix}
-
\begin{pmatrix}
b_{11} &amp; b_{12} &amp; \cdots &amp; b_{1m} \\
b_{21} &amp; b_{22} &amp; \cdots &amp; b_{2m} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
b_{n1} &amp; b_{n2} &amp; \cdots &amp; b_{nm}
\end{pmatrix}
\\
&amp;
:=
\begin{pmatrix}
a_{11} - b_{11} &amp; a_{12} - b_{12} &amp; \cdots &amp; a_{1m} - b_{1m} \\
a_{21} - b_{21} &amp; a_{22} - b_{22} &amp; \cdots &amp; a_{2m} - b_{2m} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
a_{n1} - b_{n1} &amp; a_{n2} - b_{n2} &amp; \cdots &amp; a_{nm} - b_{nm}
\end{pmatrix}.
\end{split}
\end{align}\]</span></p>
</div>
<p>Wie bei der Matrixaddition legt die Definition der Matrixsubtraktion fest, dass nur Matrizen gleicher Größe voneinander subtrahiert werden können und dass die Subktration zweier gleich großer Matrizen elementweise definiert ist.</p>
<p><strong>Beispiel</strong></p>
<p>Wir können die im Beispiel zur Matrixaddition definierten Matrizen <span class="math inline">\(A\)</span> und <span class="math inline">\(B\)</span> auch voneinander subtrahieren, <span class="math display">\[\begin{align}
\begin{split}
D
= A-B
&amp; =
\begin{pmatrix}
2 &amp; -3 &amp; 0\\
1 &amp;  6 &amp; 5\\
\end{pmatrix}
-
\begin{pmatrix}
4 &amp; 1 &amp; 0\\
-4 &amp; 2 &amp; 0\\
\end{pmatrix}\\
&amp; =
\begin{pmatrix}
2 - 4 &amp; -3 - 1 &amp; 0 - 0\\
1 + 4 &amp;  6 - 2 &amp; 5 - 0\\
\end{pmatrix}\\
&amp; =
\begin{pmatrix}
-2 &amp; -4 &amp; 0\\
5 &amp;  4 &amp; 5 \\
\end{pmatrix}.
\end{split}
\end{align}\]</span></p>
<p>In <strong>R</strong> führt man diese Rechnung wie folgt aus.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1"></a><span class="co"># Subtraktion</span></span>
<span id="cb9-2"><a href="#cb9-2"></a>D <span class="ot">=</span> A <span class="sc">-</span> B</span>
<span id="cb9-3"><a href="#cb9-3"></a><span class="fu">print</span>(D)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     [,1] [,2] [,3]
[1,]   -2   -4    0
[2,]    5    4    5</code></pre>
</div>
</div>
</section>
<section id="skalarmultiplikation" class="level3" data-number="9.2.3">
<h3 data-number="9.2.3" class="anchored" data-anchor-id="skalarmultiplikation"><span class="header-section-number">9.2.3</span> Skalarmultiplikation</h3>
<p>Die <em>Skalarmultiplikation</em> einer Matrix bezeichnet die Multiplikation eines Skalars mit einer Matrix.</p>
<div id="def-skalarmultiplikation" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 9.4 (Skalarmultiplikation)</strong></span> Es sei <span class="math inline">\(c \in \mathbb{R}\)</span> ein Skalar und <span class="math inline">\(A \in \mathbb{R}^{n\times m}\)</span>. Dann ist die <em>Skalarmultiplikation</em> von <span class="math inline">\(c\)</span> und <span class="math inline">\(A\)</span> definiert als die Abbildung <span class="math display">\[\begin{equation}
\cdot : \mathbb{R} \times \mathbb{R}^{n\times m} \to \mathbb{R}^{n\times m}, \,
(c,A) \mapsto \cdot (c,A) := cA
\end{equation}\]</span> mit <span class="math display">\[\begin{align}
\begin{split}
cA
=
c
\begin{pmatrix}
a_{11} &amp; a_{12} &amp; \cdots &amp; a_{1m} \\
a_{21} &amp; a_{22} &amp; \cdots &amp; a_{2m} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
a_{n1} &amp; a_{n2} &amp; \cdots &amp; a_{nm}
\end{pmatrix}
:=
\begin{pmatrix}
ca_{11} &amp; ca_{12} &amp; \cdots &amp; ca_{1m}  \\
ca_{21} &amp; ca_{22} &amp; \cdots &amp; ca_{2m}  \\
\vdots  &amp; \vdots  &amp; \ddots &amp; \vdots    \\
ca_{n1} &amp; ca_{n2} &amp; \cdots &amp; ca_{nm}
\end{pmatrix}.
\end{split}
\end{align}\]</span></p>
</div>
<p>Die Skalarmultiplikation ist mit dieser Definition also elementweise definiert.</p>
<p><strong>Beispiel</strong></p>
<p>Es seien <span class="math inline">\(c:=-3\)</span> und <span class="math inline">\(A\in \mathbb{R}^{4\times 3}\)</span> definiert als</p>
<p><span class="math display">\[\begin{equation}
A := \begin{pmatrix}
3 &amp; 1 &amp; 1\\
5 &amp; 2 &amp; 5\\
2 &amp; 7 &amp; 1\\
3 &amp; 4 &amp; 2
\end{pmatrix}.
\end{equation}\]</span> Dann ergibt sich <span class="math display">\[\begin{align}
\begin{split}
B :=
cA
= -3\begin{pmatrix}
3 &amp; 1 &amp; 1\\
5 &amp; 2 &amp; 5\\
2 &amp; 7 &amp; 1\\
3 &amp; 4 &amp; 2
\end{pmatrix}
= \begin{pmatrix}
-3\cdot3 &amp; -3\cdot1 &amp; -3\cdot1\\
-3\cdot5 &amp; -3\cdot2 &amp; -3\cdot5\\
-3\cdot2 &amp; -3\cdot7 &amp; -3\cdot1\\
-3\cdot3 &amp; -3\cdot4 &amp; -3\cdot2
\end{pmatrix}
= \begin{pmatrix}
-9  &amp;  -3 &amp; -3  \\
-15 &amp;  -6 &amp; -15 \\
-6  &amp; -21 &amp; -3  \\
-9  &amp; -12 &amp; -6
\end{pmatrix}.
\end{split}
\end{align}\]</span></p>
<p>In <strong>R</strong> führt man diese Skalarmultiplikation aus wie folgt. </p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1"></a><span class="co"># Definitionen</span></span>
<span id="cb11-2"><a href="#cb11-2"></a>A <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">3</span>,<span class="dv">1</span>,<span class="dv">1</span>,</span>
<span id="cb11-3"><a href="#cb11-3"></a>             <span class="dv">5</span>,<span class="dv">2</span>,<span class="dv">5</span>,</span>
<span id="cb11-4"><a href="#cb11-4"></a>             <span class="dv">2</span>,<span class="dv">7</span>,<span class="dv">1</span>,</span>
<span id="cb11-5"><a href="#cb11-5"></a>             <span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">2</span>),</span>
<span id="cb11-6"><a href="#cb11-6"></a>           <span class="at">nrow =</span> <span class="dv">4</span>,</span>
<span id="cb11-7"><a href="#cb11-7"></a>           <span class="at">byrow =</span> <span class="cn">TRUE</span>)</span>
<span id="cb11-8"><a href="#cb11-8"></a>c <span class="ot">=</span> <span class="sc">-</span><span class="dv">3</span></span>
<span id="cb11-9"><a href="#cb11-9"></a></span>
<span id="cb11-10"><a href="#cb11-10"></a><span class="co"># Skalarmultiplikation</span></span>
<span id="cb11-11"><a href="#cb11-11"></a>B <span class="ot">=</span> c<span class="sc">*</span>A</span>
<span id="cb11-12"><a href="#cb11-12"></a><span class="fu">print</span>(B)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     [,1] [,2] [,3]
[1,]   -9   -3   -3
[2,]  -15   -6  -15
[3,]   -6  -21   -3
[4,]   -9  -12   -6</code></pre>
</div>
</div>
<p>Mithilfe der Definition von Matrixaddition und Skalarmultiplikation ist es möglich, einen Vektorraum zu definieren, dessen Elemente die reellen Matrizen sind. Insbesondere legt diese Definition auch die Rechenregeln beim Umgang mit Matrixaddition und Skalarmultiplikation fest.</p>
<div id="thm-vektorraum-der-reellwertigen-Matrizen" class="theorem">
<p><span class="theorem-title"><strong>Theorem 9.1 (Vektorraum der reellwertigen Matrizen)</strong></span> Das Tripel <span class="math inline">\((\mathbb{R}^{n \times m}, +, \cdot)\)</span> mit der oben definierten Matrixaddition und Skalarmultiplikation ist ein Vektorraum. Insbesondere gelten damit für <span class="math inline">\(A,B,C\in \mathbb{R}^{n \times m}\)</span> und <span class="math inline">\(r,s,t\in \mathbb{R}\)</span> folgende Rechenregeln:</p>
<ol type="1">
<li>Kommutativität der Addition: <span class="math inline">\(A + B = B + A\)</span>.</li>
<li>Assoziativität der Addition: <span class="math inline">\((A + B) + C = A + (B + C)\)</span>.</li>
<li>Existenz eines neutralen Elements der Addition: <span class="math inline">\(\exists\, 0 \in \mathbb{R}^{n \times m}\)</span> mit <span class="math inline">\(A + 0 = 0 + A = A\)</span>.</li>
<li>Existenz inverser Elemente der Addition: <span class="math inline">\(\forall A\,\exists -A \in \mathbb{R}^{n \times m}\)</span> mit <span class="math inline">\(A + (-A) = 0\)</span>.</li>
<li>Existenz eines neutralen Elements der Skalarmultiplikation: <span class="math inline">\(\exists\, 1 \in \mathbb{R}\)</span> mit <span class="math inline">\(1 \cdot A = A\)</span>.</li>
<li>Assoziativität der Skalarmultiplikation: <span class="math inline">\(r \cdot (s \cdot t) = (r \cdot s)\cdot t\)</span>.</li>
<li>Distributivität hinsichtlich der Matrixaddition: <span class="math inline">\(r\cdot (A + B) = r\cdot A + r\cdot B\)</span>.</li>
<li>Distributivität hinsichtlich der Skalaraddition: <span class="math inline">\((r + s)\cdot A = r\cdot A + s\cdot A\)</span>.</li>
</ol>
</div>
<p>Wir verzichten auf einen Beweis, der sich mit einigem Notationsaufwand direkt aus dem elementweisen Charakter von Matrixaddition und Skalarmultiplikation sowie den aus dem Umgang mit den reellen Zahlen bekannten Rechenregeln ergibt. Das im Theorem erwähnte neutrale Element der Addition wird <em>Nullmatrix</em> genannt, wir werden dazu später eine allgemeine Notation einführen. Die inversen Elemente der Addition sind durch <span class="math display">\[\begin{equation}
-A := (-a_{ij})_{1\le i \le n, 1 \le j \le m}
\end{equation}\]</span> gegeben und erlauben es, die Matrixsubtraktion als Spezialfall der Matrixaddition zu betrachten.</p>
</section>
<section id="matrixtransposition" class="level3" data-number="9.2.4">
<h3 data-number="9.2.4" class="anchored" data-anchor-id="matrixtransposition"><span class="header-section-number">9.2.4</span> Matrixtransposition</h3>
<p>Eine weitere häufig auftretende grundlegende Matrixoperation ist das Vertauschen der Zeilen- und Spaltenanordnung einer Matrix, genannt <em>Matrixtransposition</em>.</p>
<div id="def-matrixtransposition" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 9.5 (Matrixtransposition)</strong></span> Es sei <span class="math inline">\(A \in \mathbb{R}^{n\times m}\)</span>. Dann ist die <em>Transposition</em> von <span class="math inline">\(A\)</span> definiert als die Abbildung <span class="math display">\[\begin{equation}
\cdot^{T} : \mathbb{R}^{n\times m} \to \mathbb{R}^{m \times n}, \,
A \mapsto \cdot^{T}(A) := A^T
\end{equation}\]</span> mit <span class="math display">\[\begin{align}
\begin{split}
A^T
=
\begin{pmatrix}
a_{11} &amp; a_{12} &amp; \cdots &amp; a_{1m} \\
a_{21} &amp; a_{22} &amp; \cdots &amp; a_{2m} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
a_{n1} &amp; a_{n2} &amp; \cdots &amp; a_{nm}
\end{pmatrix}^T
:=
\begin{pmatrix}
a_{11} &amp; a_{21} &amp; \cdots &amp; a_{n1} \\
a_{12} &amp; a_{22} &amp; \cdots &amp; a_{n2} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
a_{1m} &amp; a_{2m} &amp; \cdots &amp; a_{nm}
\end{pmatrix}.
\end{split}
\end{align}\]</span></p>
</div>
<p>Für <span class="math inline">\(A \in \mathbb{R}^{n \times m}\)</span> gilt damit also immer <span class="math inline">\(A^T \in \mathbb{R}^{m \times n}\)</span>. Weiterhin gelten folgende Rechenregeln der Matrixtransposition, wie man sich an Beispielen klar macht:</p>
<ol type="1">
<li>Für <span class="math inline">\(A \in \mathbb{R}^{1 \times 1}\)</span> gilt <span class="math display">\[\begin{equation}
A^T = A.
\end{equation}\]</span></li>
<li>Es gilt <span class="math display">\[\begin{equation}
\left(A^T\right)^T = A.
\end{equation}\]</span></li>
<li>Es gilt <span class="math display">\[\begin{equation}
\left(a_{ii}\right)_{1 \le i \le \mbox{min}(n,m)} = \left(a_{ii}\right)^T_{1 \le i \le \mbox{min}(n,m)}.
\end{equation}\]</span></li>
</ol>
<p>Letztere Eigenschaft der Transposition besagt, dass die Elemente auf der Hauptdiagonalen einer Matrix bei Transposition unberührt bleiben.</p>
<p><strong>Beispiel</strong></p>
<p>Es sei <span class="math inline">\(A \in \mathbb{R}^{2 \times 3}\)</span> definiert durch <span class="math display">\[\begin{equation}
A:=\begin{pmatrix}
2 &amp; 3 &amp; 0 \\
1 &amp; 6 &amp; 5 \\
\end{pmatrix},
\end{equation}\]</span> Dann gilt <span class="math inline">\(A^T \in \mathbb{R}^{3 \times 2}\)</span> und speziell <span class="math display">\[\begin{equation}
A^{T} :=
\begin{pmatrix}
2  &amp; 1 \\
3  &amp; 6 \\
0  &amp; 5 \\
\end{pmatrix}.
\end{equation}\]</span> Weiterhin gilt offenbar <span class="math inline">\(\min(m,n) = 2\)</span> und folglich <span class="math display">\[\begin{equation}
(a_{11}) = \left(a_{11}\right)^T
\mbox{ und }
(a_{22}) = \left(a_{22}\right)^T.
\end{equation}\]</span> In <strong>R</strong> führt man die Transposition einer Matrix wie folgt durch.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1"></a><span class="co"># Definition</span></span>
<span id="cb13-2"><a href="#cb13-2"></a>A <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">0</span>,</span>
<span id="cb13-3"><a href="#cb13-3"></a>             <span class="dv">1</span>,<span class="dv">6</span>,<span class="dv">5</span>),</span>
<span id="cb13-4"><a href="#cb13-4"></a>           <span class="at">nrow =</span> <span class="dv">2</span>,</span>
<span id="cb13-5"><a href="#cb13-5"></a>           <span class="at">byrow =</span> <span class="cn">TRUE</span>)</span>
<span id="cb13-6"><a href="#cb13-6"></a><span class="fu">print</span>(A)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     [,1] [,2] [,3]
[1,]    2    3    0
[2,]    1    6    5</code></pre>
</div>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1"></a><span class="co"># Transposition</span></span>
<span id="cb15-2"><a href="#cb15-2"></a>AT <span class="ot">=</span> <span class="fu">t</span>(A)</span>
<span id="cb15-3"><a href="#cb15-3"></a><span class="fu">print</span>(AT)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     [,1] [,2]
[1,]    2    1
[2,]    3    6
[3,]    0    5</code></pre>
</div>
</div>
<p>Schließlich gelten in der Verbindung mit der Matrixaddition, Matrixsubtraktion und der Skalarmultiplikation folgende Rechenregeln, wie man sich an Beispielen klar macht:</p>
<ol type="1">
<li>Für <span class="math inline">\(A,B\in \mathbb{R}^{n \times m}\)</span> gilt <span class="math display">\[\begin{equation}
(A+B)^T = A^T + B^T.
\end{equation}\]</span></li>
<li>Für <span class="math inline">\(A,B\in \mathbb{R}^{n \times m}\)</span> gilt <span class="math display">\[\begin{equation}
(A-B)^T = A^T - B^T.
\end{equation}\]</span></li>
<li>Für <span class="math inline">\(c\in \mathbb{R}\)</span> und <span class="math inline">\(A \in \mathbb{R}^{n \times m}\)</span> gilt <span class="math display">\[\begin{equation}
(cA)^T = cA^T.
\end{equation}\]</span></li>
</ol>
</section>
</section>
<section id="sec-matrixmultiplikation" class="level2" data-number="9.3">
<h2 data-number="9.3" class="anchored" data-anchor-id="sec-matrixmultiplikation"><span class="header-section-number">9.3</span> Matrixmultiplikation</h2>
<p>Die Matrixmultiplikation ist die zentrale Operation beim Rechnen mit Matrizen. Sie ist definiert wie folgt.</p>
<div id="def-matrixmultiplikation" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 9.6 (Matrixmultiplikation)</strong></span> Es seien <span class="math inline">\(A\in \mathbb{R}^{n \times m}\)</span> und <span class="math inline">\(B \in \mathbb{R}^{m \times k}\)</span>. Dann ist die <em>Matrixmultiplikation</em> von <span class="math inline">\(A\)</span> und <span class="math inline">\(B\)</span> definiert als die Abbildung <span class="math display">\[\begin{equation}
\cdot : \mathbb{R}^{n\times m} \times \mathbb{R}^{m\times k} \to \mathbb{R}^{n \times k}, \,
(A,B) \mapsto \cdot(A,B) := AB
\end{equation}\]</span> mit <span class="math display">\[\begin{align}
\begin{split}
AB
&amp; =
\begin{pmatrix}
a_{11} &amp; a_{12} &amp; \cdots &amp; a_{1m} \\
a_{21} &amp; a_{22} &amp; \cdots &amp; a_{2m} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
a_{n1} &amp; a_{n2} &amp; \cdots &amp; a_{nm}
\end{pmatrix}
\begin{pmatrix}
b_{11} &amp; b_{12} &amp; \cdots &amp; b_{1k} \\
b_{21} &amp; b_{22} &amp; \cdots &amp; b_{2k} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
b_{m1} &amp; b_{m2} &amp; \cdots &amp; b_{mk}
\end{pmatrix}
\\
&amp;
:=
\begin{pmatrix}
\sum_{i=1}^m a_{1i}b_{i1} &amp; \sum_{i=1}^m a_{1i}b_{i2} &amp; \cdots &amp; \sum_{i=1}^m a_{1i}b_{ik}  \\
\sum_{i=1}^m a_{2i}b_{i1} &amp; \sum_{i=1}^m a_{2i}b_{i2} &amp; \cdots &amp; \sum_{i=1}^m a_{2i}b_{ik}  \\
\vdots                    &amp; \vdots                    &amp; \ddots &amp; \vdots                     \\
\sum_{i=1}^m a_{ni}b_{i1} &amp; \sum_{i=1}^m a_{ni}b_{i2} &amp; \cdots &amp; \sum_{i=1}^m a_{ni}b_{ik}
\end{pmatrix}
\\
&amp;
= \left(\sum_{i=1}^m a_{ji}b_{il} \right)_{1 \le j \le n, 1 \le l \le k}
\end{split}
\end{align}\]</span></p>
</div>
<p>Das Matrixprodukt <span class="math inline">\(AB\)</span> ist also nur dann definiert, wenn <span class="math inline">\(A\)</span> genau so viele Spalten hat wie <span class="math inline">\(B\)</span> Zeilen hat. Informell gilt für die beteiligten Matrixgrößen dabei die Merkregel <span class="math display">\[\begin{equation}
(n \times m)(m \times k) = (n \times k).
\end{equation}\]</span> Der Eintrag <span class="math inline">\((AB)_{ij}\)</span> in <span class="math inline">\(AB\)</span> entspricht der Summe der multiplizierten <span class="math inline">\(i\)</span>ten Zeile von <span class="math inline">\(A\)</span> und <span class="math inline">\(j\)</span>ten Spalte von <span class="math inline">\(B\)</span>. Zum Berechnen von <span class="math inline">\((AB)_{ij}\)</span> geht man für <span class="math inline">\(i = 1,...,n\)</span> und <span class="math inline">\(j = 1,...,k\)</span> also in Gedanken wie folgt vor:</p>
<ol type="1">
<li>Man legt die Tranposition der <span class="math inline">\(i\)</span>ten Zeile von <span class="math inline">\(A\)</span> über die <span class="math inline">\(j\)</span>te Spalte von <span class="math inline">\(B\)</span>.</li>
<li>Weil <span class="math inline">\(A\)</span> genau <span class="math inline">\(m\)</span> Spalten hat und <span class="math inline">\(B\)</span> genau <span class="math inline">\(m\)</span> Zeilen hat, gibt es dann zu jedem Element der Zeile aus <span class="math inline">\(A\)</span> ein korrespondierendes Element in der Spalte von <span class="math inline">\(B\)</span>.</li>
<li>Man multipliziert die korrespondierenden Elemente miteinander.</li>
<li>Die Summe dieser Produkte ist dann der Eintrag mit Index <span class="math inline">\(ij\)</span> in <span class="math inline">\(AB\)</span>.</li>
</ol>
<p><strong>Beispiel</strong></p>
<p><span class="math inline">\(A\in \mathbb{R}^{2\times 3}\)</span> und <span class="math inline">\(B\in \mathbb{R}^{3\times 2}\)</span> seien definiert als <span class="math display">\[\begin{equation}
A := \begin{pmatrix}
2 &amp; -3 &amp;  0   \\
1 &amp;  6 &amp;  5
\end{pmatrix}
\mbox{ und }
B := \begin{pmatrix}
4 &amp; 2  \\
-1 &amp; 0  \\
1 &amp; 3
\end{pmatrix}.
\end{equation}\]</span> Wir wollen <span class="math inline">\(C := AB\)</span> und <span class="math inline">\(D := BA\)</span> berechnen. Mit <span class="math inline">\(n = 2, m = 3\)</span> und <span class="math inline">\(k = 2\)</span> wissen wir schon, dass <span class="math inline">\(C \in \mathbb{R}^{2 \times 2}\)</span> und <span class="math inline">\(D \in \mathbb{R}^{3 \times 3}\)</span>, weil <span class="math display">\[\begin{equation}
(2 \times 3)(3 \times 2) = (2 \times 2)
\end{equation}\]</span> und <span class="math display">\[\begin{equation}
(3 \times 2)(2 \times 3) = (3 \times 3).
\end{equation}\]</span> Es gilt hier also sicher <span class="math inline">\(AB \neq BA\)</span>. Für <span class="math inline">\(C\)</span> ergibt sich dann <span class="math display">\[\begin{align}
\begin{split}
C
&amp; = AB
\\
&amp; = \begin{pmatrix}
2 &amp; -3 &amp; 0 \\
1 &amp;  6 &amp; 5 \\
\end{pmatrix}
\begin{pmatrix}
4  &amp; 2 \\
-1 &amp; 0 \\
1  &amp; 3
\end{pmatrix}
\\
&amp; =
\begin{pmatrix}
2\cdot 4 + (-3)\cdot (-1) + 0\cdot 1 &amp; 2\cdot 2 + (-3)\cdot 0 + 0\cdot 3 \\
1\cdot 4 +    6\cdot (-1) + 5\cdot 1 &amp; 1\cdot 2 +  6\cdot 0 + 5\cdot 3 \\
\end{pmatrix}
\\
&amp; =
\begin{pmatrix}
8 + 3 + 0 &amp; 4 + 0 + 0 \\
4 - 6 + 5 &amp; 2 + 0 + 15 \\
\end{pmatrix}
\\
&amp; =
\begin{pmatrix}
11 &amp; 4 \\
3 &amp; 17 \\
\end{pmatrix}.
\end{split}
\end{align}\]</span></p>
<p>In <strong>R</strong> nutzt man für die Matrixmultiplikation den <code>%*%</code> Operator.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1"></a><span class="co"># Definitionen</span></span>
<span id="cb17-2"><a href="#cb17-2"></a>A <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">2</span>,<span class="sc">-</span><span class="dv">3</span>,<span class="dv">0</span>,</span>
<span id="cb17-3"><a href="#cb17-3"></a>             <span class="dv">1</span>, <span class="dv">6</span>,<span class="dv">5</span>),</span>
<span id="cb17-4"><a href="#cb17-4"></a>           <span class="at">nrow  =</span> <span class="dv">2</span>,</span>
<span id="cb17-5"><a href="#cb17-5"></a>           <span class="at">byrow =</span> <span class="cn">TRUE</span>)</span>
<span id="cb17-6"><a href="#cb17-6"></a>B <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">c</span>( <span class="dv">4</span>,<span class="dv">2</span>,</span>
<span id="cb17-7"><a href="#cb17-7"></a>             <span class="sc">-</span><span class="dv">1</span>,<span class="dv">0</span>,</span>
<span id="cb17-8"><a href="#cb17-8"></a>              <span class="dv">1</span>,<span class="dv">3</span>),</span>
<span id="cb17-9"><a href="#cb17-9"></a>           <span class="at">nrow  =</span> <span class="dv">3</span>,</span>
<span id="cb17-10"><a href="#cb17-10"></a>           <span class="at">byrow =</span> <span class="cn">TRUE</span>)</span>
<span id="cb17-11"><a href="#cb17-11"></a></span>
<span id="cb17-12"><a href="#cb17-12"></a><span class="co"># Matrixmultiplikation</span></span>
<span id="cb17-13"><a href="#cb17-13"></a>C <span class="ot">=</span> A <span class="sc">%*%</span> B</span>
<span id="cb17-14"><a href="#cb17-14"></a><span class="fu">print</span>(C)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     [,1] [,2]
[1,]   11    4
[2,]    3   17</code></pre>
</div>
</div>
<p>Für <span class="math inline">\(D\)</span> ergibt sich weiterhin <span class="math display">\[\begin{align}
\begin{split}
D
&amp; = BA
\\
&amp; =
\begin{pmatrix}
4  &amp; 2 \\
-1 &amp; 0 \\
1  &amp; 3
\end{pmatrix}
\begin{pmatrix}
2 &amp; -3 &amp; 0 \\
1 &amp;  6 &amp; 5 \\
\end{pmatrix}
\\
&amp; =
\begin{pmatrix}
  4    \cdot   2  + 2 \cdot 1
&amp; 4    \cdot (-3) + 2 \cdot 6
&amp; 4    \cdot   0  + 2 \cdot 5
\\
  (-1) \cdot  2  + 0 \cdot 1
&amp; (-1) \cdot(-3) + 0 \cdot 6
&amp; (-1) \cdot  0  + 0 \cdot 5
\\
  1    \cdot  2  + 3 \cdot 1
&amp; 1    \cdot(-3) + 3 \cdot 6
&amp; 1    \cdot  0  + 3 \cdot 5
\end{pmatrix}
\\
&amp; =
\begin{pmatrix}
    8 + 2
&amp; -12 + 12
&amp;   0 + 5
\\
   -2 + 0
&amp;   3 + 0
&amp;   0 + 0
\\
    2 + 3
&amp;  -3 + 18
&amp;   0 + 15
\end{pmatrix}
\\
&amp; =
\begin{pmatrix}
  10
&amp;  0
&amp; 10
\\
  -2
&amp;  3
&amp;  0
\\
   5
&amp; 15
&amp; 15
\\
\end{pmatrix}
\end{split}
\end{align}\]</span></p>
<p>In <strong>R</strong> überprüft man diese Rechnung wie folgt.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1"></a><span class="co"># Definitionen</span></span>
<span id="cb19-2"><a href="#cb19-2"></a>A <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">2</span>,<span class="sc">-</span><span class="dv">3</span>,<span class="dv">0</span>,</span>
<span id="cb19-3"><a href="#cb19-3"></a>             <span class="dv">1</span>, <span class="dv">6</span>,<span class="dv">5</span>),</span>
<span id="cb19-4"><a href="#cb19-4"></a>           <span class="at">nrow  =</span> <span class="dv">2</span>,</span>
<span id="cb19-5"><a href="#cb19-5"></a>           <span class="at">byrow =</span> <span class="cn">TRUE</span>)</span>
<span id="cb19-6"><a href="#cb19-6"></a>B <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">c</span>( <span class="dv">4</span>,<span class="dv">2</span>,</span>
<span id="cb19-7"><a href="#cb19-7"></a>             <span class="sc">-</span><span class="dv">1</span>,<span class="dv">0</span>,</span>
<span id="cb19-8"><a href="#cb19-8"></a>              <span class="dv">1</span>,<span class="dv">3</span>),</span>
<span id="cb19-9"><a href="#cb19-9"></a>           <span class="at">nrow  =</span> <span class="dv">3</span>,</span>
<span id="cb19-10"><a href="#cb19-10"></a>           <span class="at">byrow =</span> <span class="cn">TRUE</span>)</span>
<span id="cb19-11"><a href="#cb19-11"></a></span>
<span id="cb19-12"><a href="#cb19-12"></a><span class="co"># Matrixmultiplikation</span></span>
<span id="cb19-13"><a href="#cb19-13"></a>D <span class="ot">=</span> B <span class="sc">%*%</span> A</span>
<span id="cb19-14"><a href="#cb19-14"></a><span class="fu">print</span>(D)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     [,1] [,2] [,3]
[1,]   10    0   10
[2,]   -2    3    0
[3,]    5   15   15</code></pre>
</div>
</div>
<p>Ist allerdings eine Matrixmultiplikation aufgrund nicht-adäquater Matrizengrößen nicht definiert, so lässt sich diese auch nicht numerisch auswerten.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1"></a><span class="co"># Beispiel für eine undefinierte Matrixmultipliation</span></span>
<span id="cb21-2"><a href="#cb21-2"></a>E <span class="ot">=</span> <span class="fu">t</span>(A) <span class="sc">%*%</span> B      <span class="co"># (3 x 2)(3 x 2)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<pre><code>Error in t(A) %*% B: non-conformable arguments</code></pre>
</div>
</div>
<p>Folgendes Theorem, das wir nicht beweisen wollen, stellt den Bezug zwischen dem Skalarprodukt zweier Vektoren und der Multiplikation zweier Matrizen her. Dieser ergibt sich im Wesentlichen durch die Identifikation von <span class="math inline">\(\mathbb{R}^{n}\)</span> und <span class="math inline">\(\mathbb{R}^{n \times 1}\)</span> und der Tatsache, dass nach Definition der Eintrag <span class="math inline">\((AB)_{ij}\)</span> im Produkt von <span class="math inline">\(A \in \mathbb{R}^{n \times m}\)</span> und <span class="math inline">\(B \in \mathbb{R}^{m \times k}\)</span> dem Vektorskalarprodukt der <span class="math inline">\(i\)</span>ten Spalte von <span class="math inline">\(A^T\)</span> und der <span class="math inline">\(j\)</span>ten Spalte von <span class="math inline">\(B\)</span> entspricht.</p>
<div id="thm-matrixmultiplikation-skalarprodukt" class="theorem">
<p><span class="theorem-title"><strong>Theorem 9.2 (Matrixmultiplikation und Vektorskalarprodukt)</strong></span> Es seien <span class="math inline">\(x,y \in \mathbb{R}^n\)</span>. Dann gilt <span class="math display">\[\begin{equation}
\langle x,y \rangle = x^Ty.
\end{equation}\]</span> Weiterhin seien für <span class="math inline">\(A \in \mathbb{R}^{n\times m}\)</span> für <span class="math inline">\(i = 1,...,n\)</span> <span class="math display">\[\begin{equation}
\bar{a}_i := (a_{ji})_{1 \le j \le m} \in \mathbb{R}^m
\end{equation}\]</span> die Spalten von <span class="math inline">\(A^T\)</span> und für <span class="math inline">\(B \in \mathbb{R}^{m \times k}\)</span> für <span class="math inline">\(i = 1,...,k\)</span> <span class="math display">\[\begin{equation}
\bar{b}_j := (b_{ij})_{1 \le j \le m} \in \mathbb{R}^m
\end{equation}\]</span> die Spalten von <span class="math inline">\(B\)</span>, also <span class="math display">\[\begin{equation}
A^T =
\begin{pmatrix}
\bar{a}_1 &amp; \bar{a}_2 &amp; \cdots &amp; \bar{a}_n
\end{pmatrix}
\in \mathbb{R}^{m \times n}
\mbox{ und }
B =
\begin{pmatrix}
\bar{b}_1 &amp; \bar{b}_2 &amp; \cdots &amp; \bar{b}_k
\end{pmatrix}
\in \mathbb{R}^{m \times k}.
\end{equation}\]</span> Dann gilt <span class="math display">\[\begin{equation}
AB = \left(\langle \bar{a}_i,\bar{b}_j \rangle \right)_{1 \le i \le n, 1 \le j \le k}.
\end{equation}\]</span></p>
</div>
<section id="rechenregeln-der-matrixmultiplikation" class="level3" data-number="9.3.1">
<h3 data-number="9.3.1" class="anchored" data-anchor-id="rechenregeln-der-matrixmultiplikation"><span class="header-section-number">9.3.1</span> Rechenregeln der Matrixmultiplikation</h3>
<p>Im Folgenden stellen wir einige grundlegende Rechenregeln der Matrixmultiplikation, insbesondere auch in Kombination mit anderen Matrixoperationen zusammen.</p>
<p>Für Beweise der folgenden zwei Theoreme zur Assoziativität und Distributivität, die sich im Wesentlichen mit den entsprechenden Rechenregeln für Summen und Produkte der reellen Zahlen ergeben, verweisen wir auf die weiterführende Literatur.</p>
<div id="thm-assoziativität" class="theorem">
<p><span class="theorem-title"><strong>Theorem 9.3 (Assoziativität)</strong></span> Es seien <span class="math inline">\(A \in \mathbb{R}^{n \times m}\)</span>, <span class="math inline">\(B \in \mathbb{R}^{m \times k}\)</span>, <span class="math inline">\(C \in \mathbb{R}^{k \times p}\)</span> und <span class="math inline">\(c \in \mathbb{R}\)</span>. Dann gelten</p>
<ol type="1">
<li>Die Multiplikation von Matrizen ist assoziativ, es gilt <span class="math display">\[\begin{equation}
A(BC) = (AB)C.
\end{equation}\]</span></li>
<li>Die Kombination von Matrizenmultiplikation und Skalarmultiplikation ist assoziativ, <span class="math display">\[\begin{equation}
c(AB) = (cA)B = A(cB).
\end{equation}\]</span></li>
</ol>
</div>
<p>Die Assoziativität von Matrizenmultiplikation und Skalarmultiplikation erkennt man leicht bei Betrachtung des <span class="math inline">\(j,l\)</span>ten Elements von <span class="math inline">\(c(AB), (cA)B\)</span> und <span class="math inline">\(A(cB)\)</span> anhand von <span class="math display">\[\begin{equation}
c\left(\sum_{i = 1}^m a_{ji}b_{il}\right)
= \sum_{i = 1}^m \left(c a_{ji}\right) b_{il}  
= \sum_{i = 1}^m a_{ji}\left(c b_{il}\right).
\end{equation}\]</span></p>
<div id="thm-distributivität" class="theorem">
<p><span class="theorem-title"><strong>Theorem 9.4 (Distributivität)</strong></span> Es seien <span class="math inline">\(A \in \mathbb{R}^{n \times m}\)</span>, <span class="math inline">\(B \in \mathbb{R}^{n \times m}\)</span>, <span class="math inline">\(C \in \mathbb{R}^{m \times p}\)</span>. Dann gelten <span class="math display">\[\begin{equation}
(A + B)C = AC + BC
\end{equation}\]</span> und <span class="math display">\[\begin{equation}
C^T(A + B) = C^TA + C^TB
\end{equation}\]</span></p>
</div>
<p>Im Gegensatz zur Kommutativität der Multiplikation reeller Zahlen ist die Matrixmultiplikation im Allgemeinen nicht kommutativ.</p>
<div id="thm-nichtkommutativität" class="theorem">
<p><span class="theorem-title"><strong>Theorem 9.5 (Nichtkommutativität)</strong></span> Es seien <span class="math inline">\(A \in \mathbb{R}^{n \times m}\)</span> und <span class="math inline">\(B \in \mathbb{R}^{m \times p}\)</span>. Dann gilt im Allgemeinen <span class="math display">\[\begin{equation}
AB \neq BA.
\end{equation}\]</span></p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Beweis</em>. </span>Im Fall <span class="math inline">\(p \neq n\)</span> ist <span class="math inline">\(BA\)</span> nicht definiert, wir betrachten also nur den Fall <span class="math inline">\(p = n\)</span>. Wir zeigen durch Angabe eines Gegenbeispiels mit <span class="math inline">\(A,B\in \mathbb{R}^{2 \times n}\)</span>, dass im Allgemeinen <span class="math inline">\(AB = BA\)</span> <em>nicht</em> gilt. Es seien <span class="math display">\[\begin{equation}
A := \begin{pmatrix} 0 &amp; 1 \\ 0 &amp; 0 \end{pmatrix}
\mbox{ und }
B := \begin{pmatrix} 0 &amp; 0 \\ 1 &amp; 0 \end{pmatrix}.
\end{equation}\]</span> Dann gilt <span class="math display">\[\begin{equation}
AB
=
\begin{pmatrix} 0 &amp; 1 \\ 0 &amp; 0 \end{pmatrix}
\begin{pmatrix} 0 &amp; 0 \\ 1 &amp; 0 \end{pmatrix}
=
\begin{pmatrix} 1 &amp; 0 \\ 0 &amp; 0 \end{pmatrix}
\neq
\begin{pmatrix} 0 &amp; 0 \\ 0 &amp; 1 \end{pmatrix}
=
\begin{pmatrix} 0 &amp; 0 \\ 1 &amp; 0 \end{pmatrix}
\begin{pmatrix} 0 &amp; 1 \\ 0 &amp; 0 \end{pmatrix}
=
BA.
\end{equation}\]</span></p>
</div>
<div id="thm-matrixmultiplikation-transposition" class="theorem">
<p><span class="theorem-title"><strong>Theorem 9.6 (Kombination von Matrixmultiplikation und Transposition)</strong></span> Es seien <span class="math inline">\(A \in \mathbb{R}^{m \times n}\)</span> und <span class="math inline">\(B \in \mathbb{R}^{n \times k}\)</span>. Dann gilt <span class="math display">\[\begin{equation}
(AB)^T = B^TA^T.
\end{equation}\]</span></p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Beweis</em>. </span>Ein Beweis ergibt sich wie folgt <span class="math display">\[\begin{align}
\begin{split}
(AB)^T
&amp; = \left(\left(\sum_{i=1}^m a_{ji}b_{il} \right)_{1 \le j \le n, 1 \le l \le k}\right)^T \\
&amp; = \left(\sum_{i=1}^m a_{ij}b_{li} \right)_{1 \le i \le k, 1 \le j \le n}  \\
&amp; = \left(\sum_{i=1}^m b_{li}a_{ij} \right)_{1 \le j \le k, 1 \le l \le n}  \\
&amp; = B^TA^T.
\end{split}
\end{align}\]</span></p>
</div>
</section>
</section>
<section id="sec-matrixinversion" class="level2" data-number="9.4">
<h2 data-number="9.4" class="anchored" data-anchor-id="sec-matrixinversion"><span class="header-section-number">9.4</span> Matrixinversion</h2>
<p>Um den Begriff der inversen Matrix zu motivieren, betrachten wir zunächst das Problem des <em>Lösens eines linearen Gleichungssystems</em>. Dazu seien <span class="math inline">\(A\in \mathbb{R}^{n \times n},\, x \in \mathbb{R}^n\)</span> und <span class="math inline">\(b \in \mathbb{R}^n\)</span> und es gelte <span class="math display">\[\begin{equation}
Ax = b.
\end{equation}\]</span> <span class="math inline">\(A\)</span> und <span class="math inline">\(b\)</span> seien als bekannt vorausgesetzt, <span class="math inline">\(x\)</span> sei unbekannt. Konkret seien beispielsweise <span class="math display">\[\begin{equation}
A := \begin{pmatrix} 1 &amp; 2 \\ 3 &amp; 4 \end{pmatrix} \mbox{ und }b := \begin{pmatrix}  5 \\ 11 \end{pmatrix}.
\end{equation}\]</span></p>
<p>Dann liegt folgendes lineares Gleichungssystem mit zwei Gleichungen und zwei Unbekannten vor: <span class="math display">\[\begin{equation}
Ax = b
\Leftrightarrow
\begin{pmatrix}
1 &amp; 2 \\
3 &amp; 4
\end{pmatrix}
\begin{pmatrix}
x_1 \\
x_2
\end{pmatrix}
= \begin{pmatrix}
5 \\
11
\end{pmatrix}
\Leftrightarrow
\begin{matrix}
1x_1 + 2x_2 &amp; = 5 \\
3x_1 + 4x_2 &amp; = 11
\end{matrix}.
\end{equation}\]</span></p>
<p>Ziel des Lösens von linearen Gleichungssystemen ist bekanntlich, herauszufinden, für welche <span class="math inline">\(x\)</span> das Gleichungssystem erfüllt ist. Um in diesem Kontext den Begriff der inversen Matrix von <span class="math inline">\(A\)</span> einzuführen, vereinfachen wir die Situation weiter. Wir nehmen an, dass <span class="math inline">\(A = a\)</span> eine <span class="math inline">\(1 \times 1\)</span> Matrix, also ein Skalar, sei und ebenso <span class="math inline">\(x\)</span> und <span class="math inline">\(b\)</span>, dass wir also für <span class="math inline">\(a,x,b \in \mathbb{R}\)</span> die Gleichung <span class="math display">\[\begin{equation}
ax = b
\end{equation}\]</span> haben. Um diese Gleichung nach <span class="math inline">\(x\)</span> aufzulösen würde man natürlich beide Seiten der Gleichung mit dem <em>multiplikativem Inversen</em> von <span class="math inline">\(a\)</span> multiplizieren, wobei das <em>multiplikative Inverse</em> von <span class="math inline">\(a\)</span> den Wert bezeichnet, der mit <span class="math inline">\(a\)</span> multipliziert <span class="math inline">\(1\)</span> ergibt. Dieser ist bekanntlich durch <span class="math display">\[\begin{equation}
a^{-1} = \frac{1}{a}
\end{equation}\]</span> gegeben. Dann würde gelten <span class="math display">\[\begin{equation}
ax = b \Leftrightarrow a^{-1}ax = a^{-1}b \Leftrightarrow 1 \cdot x = a^{-1}b \Leftrightarrow x = \frac{b}{a}.
\end{equation}\]</span> Ganz konkret etwa <span class="math display">\[\begin{equation}
2x = 6 \Leftrightarrow 2^{-1} 2x = 2^{-1}6 \Leftrightarrow \frac{1}{2}2x = \frac{1}{2}6 \Leftrightarrow x = 3.
\end{equation}\]</span> Analog zu dem Fall, dass die Matrizen in <span class="math inline">\(Ax = b\)</span> allesamt Skalare sind, möchte man im Fall eines linearen Gleichungssystems beide Seiten der Gleichung mit dem <em>multiplikativen Inversen</em> <span class="math inline">\(A^{-1}\)</span> von <span class="math inline">\(A\)</span> multiplizieren können, sodass eine Gleichung der Form <span class="math display">\[\begin{equation}
A^{-1}A = "1".
\end{equation}\]</span> resultiert. Dann hätte man nämlich <span class="math display">\[\begin{equation}
Ax = b \Leftrightarrow A^{-1}Ax = A^{-1}b \Leftrightarrow x = A^{-1}b.
\end{equation}\]</span> Diese intuitive Idee des multiplikativen Inversen einer Matrix <span class="math inline">\(A\)</span> wird im Folgenden unter dem Begriff der <em>inversen Matrix</em> formalisiert. Dazu benötigen wir zunächst den Begriff der <em>Einheitsmatrix</em>.</p>
<div id="def-einheitsmatrix" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 9.7 (Einheitsmatrix)</strong></span> Die Matrix <span class="math display">\[\begin{equation}
I_n
:= (a_{ij})_{1\le i \le n, 1 \le j \le n}  \in \mathbb{R}^{n \times n}
:=
\begin{pmatrix}
1      &amp; 0      &amp; \cdots &amp; 0       \\
0      &amp; 1      &amp; \cdots &amp; 0       \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots  \\
0      &amp; 0      &amp; \cdots &amp; 1       \\
\end{pmatrix}
\end{equation}\]</span> mit <span class="math inline">\(a_{ij} = 1\)</span> für <span class="math inline">\(i = j\)</span> und <span class="math inline">\(a_{ij} = 0\)</span> für <span class="math inline">\(i \neq j\)</span> heißt <em><span class="math inline">\(n\)</span>-dimensionale Einheitsmatrix</em>.</p>
</div>
<p>In <strong>R</strong> wird <span class="math inline">\(I_n\)</span> mit dem Befehl <code>diag(n)</code> erzeugt. Die Einheitsmatrix ist für die Matrixmultiplikation das Analog zur 1 bei der Multiplikation reeller Zahlen. Das ist die Aussage folgenden Theorems.</p>
<div id="thm-neutrales-element-der-matrixmultiplikation" class="theorem">
<p><span class="theorem-title"><strong>Theorem 9.7 (Neutrales Element der Matrixmultiplikation)</strong></span> <span class="math inline">\(I_n\)</span> ist das neutrale Element der Matrixmultiplikation, das heißt es gilt für <span class="math inline">\(A \in \mathbb{R}^{n \times m}\)</span>, dass <span class="math display">\[\begin{equation}
I_nA = A \mbox{ und } AI_m = A.
\end{equation}\]</span></p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Beweis</em>. </span>Es sei <span class="math inline">\(B = (b_{ij}) = I_nA \in \mathbb{R}^{n\times m}\)</span>. Dann gilt für alle <span class="math inline">\(1 \le i \le n\)</span> und alle <span class="math inline">\(1 \le j \le n\)</span> <span class="math display">\[\begin{equation}
d_{ij}
= 0 \cdot a_{1j}
+ 0 \cdot a_{2j}
+ \cdots
+ 0 \cdot a_{i-1,j}
+ 1 \cdot a_{ij}
+ \cdots
+ 0 \cdot a_{i+1,j}
+ 0 \cdot a_{nj}
= a_{ij}.
\end{equation}\]</span> Analog zeigt man dies für <span class="math inline">\(AI_m\)</span>.</p>
</div>
<p>Mit dem Begriff der Einheitsmatrix können wir jetzt die Begriffe der inversen Matrix und der invertierbaren Matrix definieren:</p>
<div id="def-invertierbare-matrix-und-inverse-matrix" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 9.8 (Invertierbare Matrix und inverse Matrix)</strong></span> Eine quadratische Matrix <span class="math inline">\(A \in \mathbb{R}^{n \times n}\)</span> heißt <em>invertierbar</em>, wenn es eine quadratische Matrix <span class="math inline">\(A^{-1} \in \mathbb{R}^{n \times n}\)</span> gibt, so dass <span class="math display">\[\begin{equation}
A^{-1}A = AA^{-1} = I_n
\end{equation}\]</span> ist. Die Matrix <span class="math inline">\(A^{-1}\)</span> heißt die <em>inverse Matrix von <span class="math inline">\(A\)</span></em>.</p>
</div>
<p>Man beachte, dass sich die Begriffe der inversen Matrix und der Invertierbarkeit <em>nur</em> auf quadratische Matrizen beziehen. Insbesondere können quadratische Matrizen invertierbar sein, müssen es aber nicht sein (lineare Gleichungssysteme können also Lösungen haben, müssen es aber nicht). Nicht invertierbare Matrizen nennt man auch <em>singuläre</em> Matrizen, invertierbare Matrizen manchmal auch <em>nicht-singuläre</em> Matrizen. Schließlich beachte man, dass <a href="#def-invertierbare-matrix-und-inverse-matrix" class="quarto-xref">Definition&nbsp;<span>9.8</span></a> lediglich aussagt, was eine inverse Matrix ist, aber nicht wie man sie berechnet.</p>
<p><strong>Beispiel für eine invertierbare Matrix</strong></p>
<p>Die Matrix <span class="math display">\[\begin{equation}
A := \begin{pmatrix} 2.0 &amp; 1.0 \\ 3.0 &amp; 4.0 \end{pmatrix}
\end{equation}\]</span> ist invertierbar und ihre inverse Matrix ist gegeben durch <span class="math display">\[\begin{equation}
A^{-1} = \begin{pmatrix} 0.8 &amp; -0.2 \\  -0.6 &amp; 0.4 \end{pmatrix},
\end{equation}\]</span> denn <span class="math display">\[\begin{equation}
\begin{pmatrix} 2.0 &amp;  1.0 \\   3.0 &amp; 4.0 \end{pmatrix}
\begin{pmatrix} 0.8 &amp; -0.2 \\  -0.6 &amp; 0.4 \end{pmatrix}
=
\begin{pmatrix} 1 &amp; 0 \\ 0 &amp; 1 \end{pmatrix}
=
\begin{pmatrix} 0.8 &amp; -0.2  \\  -0.6 &amp; 0.4 \end{pmatrix}
\begin{pmatrix} 2.0 &amp;  1.0  \\   3.0 &amp; 4.0 \end{pmatrix},
\end{equation}\]</span> wovon man sich durch Nachrechnen überzeugt.</p>
<p><strong>Beispiel für eine nicht-invertierbare Matrix</strong></p>
<p>Die Matrix <span class="math display">\[\begin{equation}
B := \begin{pmatrix} 1 &amp; 0 \\ 0 &amp; 0 \end{pmatrix}
\end{equation}\]</span> ist nicht invertierbar, denn wäre <span class="math inline">\(B\)</span> invertierbar, dann gäbe es <span class="math display">\[\begin{equation}
\begin{pmatrix} a &amp; b \\ c &amp; d \end{pmatrix}
\end{equation}\]</span> mit <span class="math display">\[\begin{equation}
\begin{pmatrix} 1 &amp; 0 \\ 0 &amp; 0 \end{pmatrix}
\begin{pmatrix} a &amp; b \\ c &amp; d \end{pmatrix}
=
\begin{pmatrix} a &amp; b \\ 0 &amp; 0 \end{pmatrix}
=
\begin{pmatrix} 1 &amp; 0 \\ 0 &amp; 1 \end{pmatrix}.
\end{equation}\]</span> Das würde aber bedeuten, dass <span class="math inline">\(0 = 1\)</span> in <span class="math inline">\(\mathbb{R}\)</span> und das ist ein Widerspruch. Also kann <span class="math inline">\(B\)</span> nicht invertierbar sein.</p>
<p><strong>Zum Berechnen inverser Matrizen</strong></p>
<p><span class="math inline">\(2 \times 2\)</span> bis etwa <span class="math inline">\(5 \times 5\)</span> Matrizen kann man prinzipiell per Hand invertieren, dazu stellt die Lineare Algebra verschiedene Verfahren bereit. Wir wollen hier auf eine Einführung in die Matrizeninvertierung per Hand verzichten, da in der Anwendung Matrizen standardmäßig numerisch invertiert werden. Die numerische Matrixinversion ist dann auch ein großes Feld der Forschung zur Numerischen Mathematik, die eine Vielzahl von Algorithmen zu diesem Zweck bereitstellt. In <strong>R</strong> werden Matrizen per default mit der Funktion <code>solve()</code>, in Anlehnung an das Lösen linearer Gleichungssysteme, invertiert. Für das obige Beispiel einer invertierbaren Matrix ergibt sich dabei folgender <strong>R</strong> Code.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1"></a><span class="co"># Definition</span></span>
<span id="cb23-2"><a href="#cb23-2"></a>A <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">1</span>,</span>
<span id="cb23-3"><a href="#cb23-3"></a>             <span class="dv">3</span>,<span class="dv">4</span>),</span>
<span id="cb23-4"><a href="#cb23-4"></a>           <span class="at">nrow  =</span> <span class="dv">2</span>,</span>
<span id="cb23-5"><a href="#cb23-5"></a>           <span class="at">byrow =</span> <span class="cn">TRUE</span>)</span>
<span id="cb23-6"><a href="#cb23-6"></a></span>
<span id="cb23-7"><a href="#cb23-7"></a><span class="co"># Berechnen von A^{-1}</span></span>
<span id="cb23-8"><a href="#cb23-8"></a><span class="fu">print</span>(<span class="fu">solve</span>(A))</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     [,1] [,2]
[1,]  0.8 -0.2
[2,] -0.6  0.4</code></pre>
</div>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1"></a><span class="co"># Überprüfen der Eigenschaften einer inversen Matrix</span></span>
<span id="cb25-2"><a href="#cb25-2"></a><span class="fu">print</span>(<span class="fu">solve</span>(A) <span class="sc">%*%</span> A)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     [,1] [,2]
[1,]    1    0
[2,]    0    1</code></pre>
</div>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1"></a><span class="co"># Bei der umgekehrten Berechnung ergebn sich kleine Rundungsfehler</span></span>
<span id="cb27-2"><a href="#cb27-2"></a><span class="fu">print</span>(A <span class="sc">%*%</span> <span class="fu">solve</span>(A))</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     [,1]          [,2]
[1,]    1 -5.551115e-17
[2,]    0  1.000000e+00</code></pre>
</div>
</div>
<p>Nicht-invertierbare Matrizen sind dabei natürlich auch numerisch nicht-invertierbar, wie folgende Fehlermeldung in <strong>R</strong> bezüglich obigen Beispiels einer nicht-invertierbaren Matrix demonstriert.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1"></a>B <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">0</span>,</span>
<span id="cb29-2"><a href="#cb29-2"></a>             <span class="dv">0</span>,<span class="dv">0</span>),</span>
<span id="cb29-3"><a href="#cb29-3"></a>           <span class="at">nrow  =</span> <span class="dv">2</span>,</span>
<span id="cb29-4"><a href="#cb29-4"></a>           <span class="at">byrow =</span> <span class="dv">2</span>)</span>
<span id="cb29-5"><a href="#cb29-5"></a><span class="fu">solve</span>(B)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<pre><code>Error in solve.default(B): Lapack routine dgesv: system is exactly singular: U[2,2] = 0</code></pre>
</div>
</div>
</section>
<section id="sec-determinanten" class="level2" data-number="9.5">
<h2 data-number="9.5" class="anchored" data-anchor-id="sec-determinanten"><span class="header-section-number">9.5</span> Determinanten</h2>
<p>Die Determinante ist eine vielseitig einsetzbare Maßzahl einer quadratischen Matrix. Für das Verständnis der <em>Eigenanalyse</em> und der <em>Matrixzerlegung</em> ist der Begriff der Determinante im Kontext des <em>charakteristischen Polynoms</em> grundlegend.</p>
<p>Allgemein ist eine Determinante eine nichtlineare Abbildung der Form <span class="math display">\[\begin{equation}
\lvert \cdot \rvert: \mathbb{R}^{n \times n} \to \mathbb{R}, A \mapsto \lvert A \rvert,
\end{equation}\]</span> das heißt, eine Determinante ordnet einer quadratischen Matrix <span class="math inline">\(A\)</span> die reelle Zahl <span class="math inline">\(\lvert A \rvert\)</span> zu. Die Zahl <span class="math inline">\(\lvert A \rvert\)</span> wird dabei rekursiv anhand folgender Definition bestimmt.</p>
<div id="def-Determinante" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 9.9 (Determinante)</strong></span> Für <span class="math inline">\(A = (a_{ij})_{1 \le i,j \le n} \in \mathbb{R}^{n \times n}\)</span> mit <span class="math inline">\(n&gt;1\)</span> sei <span class="math inline">\(A_{ij} \in \mathbb{R}^{n-1 \times n-1}\)</span> die Matrix, die aus <span class="math inline">\(A\)</span> durch Entfernen der <span class="math inline">\(i\)</span>ten Zeile und der <span class="math inline">\(j\)</span>ten Spalte entsteht. Dann heißt die Zahl <span class="math display">\[\begin{align}
\lvert A \rvert &amp; := a_{11} \quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad   \mbox{ für } n = 1\\
\lvert A \rvert &amp; := \sum_{j = 1}^n a_{1j}(-1)^{1+j} \det\left(A_{1j}\right)               \mbox{ für } n &gt; 1
\end{align}\]</span> die <em>Determinante von <span class="math inline">\(A\)</span></em>.</p>
</div>
<p>Die Definition führt die Bestimmung der Determinante einer quadratischen Matrix also sukzessive durch Streichen von Zeilen und Spalten auf die Determinante einer <span class="math inline">\(1 \times 1\)</span> Matrix zurück, die durch ihr einziges Element gegeben ist. Für <span class="math display">\[\begin{equation}
A :=
\begin{pmatrix}
1 &amp; 2 &amp; 3 \\
4 &amp; 5 &amp; 6 \\
7 &amp; 8 &amp; 9 \\
\end{pmatrix}
\in \mathbb{R}^{3 \times 3}
\end{equation}\]</span> ergeben sich dabei zum Beispiel folgende Matrizen der Form <span class="math inline">\(A_{ij} \in \mathbb{R}^{3-1 \times 3-1}\)</span>: <span class="math display">\[\begin{equation}
A_{11}
=
\begin{pmatrix}
5 &amp; 6 \\
8 &amp; 9 \\
\end{pmatrix},
A_{12}
=
\begin{pmatrix}
4 &amp; 6 \\
7 &amp; 9 \\
\end{pmatrix},
A_{21}
=
\begin{pmatrix}
2 &amp; 3 \\
8 &amp; 9 \\
\end{pmatrix},
A_{22}
=
\begin{pmatrix}
1 &amp; 3 \\
7 &amp; 9 \\
\end{pmatrix}.
\end{equation}\]</span></p>
<p>Für die Berechnung der Determinanten von zwei- und dreidimensionalen quadratischen Matrizen gibt es direkte, nicht-rekursive Rechenregeln, die in folgendem Theorem festgehalten sind.</p>
<div id="thm-determinanten-von-zwei-und-dreidimensionalen-matrizen" class="theorem">
<p><span class="theorem-title"><strong>Theorem 9.8 (Determinanten von zwei- und dreidimensionalen Matrizen)</strong></span> <span class="math inline">\(\quad\)</span></p>
<p>Es sei <span class="math inline">\(A = (a_{ij})_{1 \le i,j \le 2} \in \mathbb{R}^{2 \times 2}\)</span>. Dann gilt <span class="math display">\[\begin{equation}
\lvert A \rvert = a_{11}a_{22} - a_{12}a_{21}.
\end{equation}\]</span> Es sei <span class="math inline">\(A = (a_{ij})_{1 \le i,j \le 3} \in \mathbb{R}^{3 \times 3}\)</span>. Dann gilt <span class="math display">\[\begin{equation}
\lvert A \rvert= a_{11}a_{22}a_{33} + a_{12}a_{23}a_{31} + a_{13}a_{21}a_{32} - a_{12}a_{21}a_{33} - a_{11}a_{23}a_{32} - a_{13}a_{22}a_{31}.
\end{equation}\]</span></p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Beweis</em>. </span>Für <span class="math inline">\(A \in \mathbb{R}^{2 \times 2}\)</span> gilt nach Definition <span class="math display">\[\begin{align}
\begin{split}
\lvert A \rvert
&amp; = \sum_{j = 1}^n a_{1j}(-1)^{1+j} |A_{1j}| \\
&amp; = a_{11}(-1)^{1 + 1}|A_{11}| + a_{12}(-1)^{1 + 2}|A_{12}| \\
&amp; = a_{11}|(a_{22})| - a_{12}|(a_{21})| \\
&amp; = a_{11}a_{22} - a_{12}a_{21}. \\
\end{split}
\end{align}\]</span> Für <span class="math inline">\(A \in \mathbb{R}^{3 \times 3}\)</span> gilt nach Definition und mit der Formel für Determinanten von <span class="math inline">\(2 \times 2\)</span> Matrizen <span class="math display">\[\begin{align}
\begin{split}
\lvert A \rvert
&amp; = \sum_{j = 1}^n a_{1j}(-1)^{1+j} |(A_{1j}| \\
&amp; =   a_{11}(-1)^{1+1} |A_{1j}| + a_{12}(-1)^{1+2} |A_{12}| +  a_{13}(-1)^{1+3}|A_{13}| \\
&amp; =   a_{11}|A_{11}| - a_{12}|A_{12}| + a_{13}|A_{13}| \\
&amp; =   a_{11}\left\vert\begin{pmatrix} a_{22} &amp; a_{23} \\ a_{32} &amp; a_{33}\end{pmatrix}\right\vert
    - a_{12}\left\vert\begin{pmatrix} a_{21} &amp; a_{23} \\ a_{31} &amp; a_{33}\end{pmatrix}\right\vert
    + a_{13}\left\vert\begin{pmatrix} a_{21} &amp; a_{22} \\ a_{31} &amp; a_{32}\end{pmatrix}\right\vert \\
&amp; =   a_{11}(a_{22}a_{33} - a_{23}a_{32})
    - a_{12}(a_{21}a_{33} - a_{23}a_{31})
    + a_{13}(a_{21}a_{32} - a_{22}a_{31}) \\
&amp; =   a_{11}a_{22}a_{33} - a_{11}a_{23}a_{32}
    - a_{12}a_{21}a_{33} + a_{12}a_{23}a_{31}
    + a_{13}a_{21}a_{32} - a_{13}a_{22}a_{31} \\
&amp; =   a_{11}a_{22}a_{33} + a_{12}a_{23}a_{31} + a_{13}a_{21}a_{32}
    - a_{12}a_{21}a_{33} - a_{11}a_{23}a_{32} - a_{13}a_{22}a_{31}.
\end{split}
\end{align}\]</span></p>
</div>
<p>Für die Bestimmung der Determinanten von <span class="math inline">\(2 \times 2\)</span> und <span class="math inline">\(3 \times 3\)</span> Matrizen gilt somit die sogennante <em>Sarrusche Merkregel</em>: <span class="math display">\[\begin{equation*}
\mbox{``Summe der Produkte auf den Diagonalen minus Summe der Produkte auf den Gegendiagonalen.''}
\end{equation*}\]</span> Dabei bezieht sich die Merkregeln bei <span class="math inline">\(3 \times 3\)</span> Matrizen auf das Schema <span class="math display">\[\begin{equation}
\begin{pmatrix}
a_{11} &amp; a_{12} &amp; a_{13} &amp; \vert &amp; a_{11} &amp; a_{12} \\
a_{21} &amp; a_{22} &amp; a_{23} &amp; \vert &amp; a_{21} &amp; a_{22} \\
a_{31} &amp; a_{32} &amp; a_{33} &amp; \vert &amp; a_{31} &amp; a_{32}
\end{pmatrix}.
\end{equation}\]</span></p>
<p><strong>Beispiele für Determinanten von <span class="math inline">\(2 \times 2\)</span> und <span class="math inline">\(3 \times 3\)</span> Matrizen</strong></p>
<p>Es seien <span class="math display">\[\begin{equation}
A :=
\begin{pmatrix}
2 &amp; 1 \\
3 &amp; 4
\end{pmatrix},
B :=
\begin{pmatrix}
1 &amp; 0 \\
0 &amp; 0
\end{pmatrix}
\mbox{ und }
C :=
\begin{pmatrix}
2 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 3
\end{pmatrix}
\end{equation}\]</span> Dann ergeben sich <span class="math display">\[\begin{equation}
\lvert A \rvert
= 2 \cdot 4 - 1 \cdot 3 = 8 - 3 = 5
\end{equation}\]</span> und <span class="math display">\[\begin{equation}
\lvert B \rvert
= 1 \cdot 0 - 0 \cdot 0 = 0 - 0 = 0
\end{equation}\]</span> und <span class="math display">\[\begin{equation}
\lvert C \rvert
= 2 \cdot 1 \cdot 3  + 0 \cdot 0 \cdot 0 + 0 \cdot 0 \cdot 0 - 0 \cdot 0 \cdot 3 - 0 \cdot 0 \cdot 0  - 0 \cdot 1 \cdot 0
= 2 \cdot 1 \cdot 3
= 6.
\end{equation}\]</span></p>
<p>In <strong>R</strong> rechnet man dies mithilfe der <code>det()</code> Funktion wie folgt nach.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1"></a><span class="co"># Matrixdefinition und Determinantenberechnung</span></span>
<span id="cb31-2"><a href="#cb31-2"></a>A <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">1</span>,</span>
<span id="cb31-3"><a href="#cb31-3"></a>             <span class="dv">3</span>,<span class="dv">4</span>),</span>
<span id="cb31-4"><a href="#cb31-4"></a>           <span class="at">nrow =</span> <span class="dv">2</span>,</span>
<span id="cb31-5"><a href="#cb31-5"></a>           <span class="at">byrow =</span> <span class="cn">TRUE</span>)</span>
<span id="cb31-6"><a href="#cb31-6"></a><span class="fu">det</span>(A)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 5</code></pre>
</div>
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1"></a><span class="co"># Matrixdefinition und Determinantenberechnung</span></span>
<span id="cb33-2"><a href="#cb33-2"></a>B <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">0</span>,</span>
<span id="cb33-3"><a href="#cb33-3"></a>             <span class="dv">0</span>,<span class="dv">0</span>),</span>
<span id="cb33-4"><a href="#cb33-4"></a>           <span class="at">nrow =</span> <span class="dv">2</span>,</span>
<span id="cb33-5"><a href="#cb33-5"></a>           <span class="at">byrow =</span> <span class="cn">TRUE</span>)</span>
<span id="cb33-6"><a href="#cb33-6"></a><span class="fu">det</span>(B)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0</code></pre>
</div>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1"></a><span class="co"># Matrixdefinition und Determinantenberechnung</span></span>
<span id="cb35-2"><a href="#cb35-2"></a>C <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">0</span>,<span class="dv">0</span>,</span>
<span id="cb35-3"><a href="#cb35-3"></a>             <span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>,</span>
<span id="cb35-4"><a href="#cb35-4"></a>             <span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">3</span>),</span>
<span id="cb35-5"><a href="#cb35-5"></a>           <span class="at">nrow =</span> <span class="dv">3</span>,</span>
<span id="cb35-6"><a href="#cb35-6"></a>           <span class="at">byrow =</span> <span class="cn">TRUE</span>)</span>
<span id="cb35-7"><a href="#cb35-7"></a><span class="fu">det</span>(C)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 6</code></pre>
</div>
</div>
<p>Für Determinanten bestehen zahlreiche Rechenregeln im Zusammenspiel mit Matrixmultiplikation und Matrixinversion. Ohne Beweis stellen wir diese in folgendem Theorem zusammen.</p>
<div id="thm-rechenregeln-für-determinanten" class="theorem">
<p><span class="theorem-title"><strong>Theorem 9.9 (Rechenregeln für Determinanten)</strong></span> <span class="math inline">\(\quad\)</span></p>
<p>(Determinantenmultiplikationssatz). Für <span class="math inline">\(A,B \in \mathbb{R}^{n \times n}\)</span> gilt <span class="math display">\[\begin{equation}
|AB| = \lvert A \rvert\lvert B \rvert.
\end{equation}\]</span> (Transposition). Für <span class="math inline">\(A \in \mathbb{R}^{n \times n}\)</span> gilt <span class="math display">\[\begin{equation}
\lvert A \rvert = \left\vert A^T \right\vert.
\end{equation}\]</span> (Inversion). Für eine invertierbare Matrix <span class="math inline">\(A \in \mathbb{R}^{n \times n}\)</span> gilt <span class="math display">\[\begin{equation}
\left\vert A^{-1}\right\vert = \frac{1}{\lvert A \rvert}.
\end{equation}\]</span> (Dreiecksmatrizen). Für Matrizen <span class="math inline">\(A = (a_{ij})_{1 \le i,j\le n} \in \mathbb{R}^{n \times n}\)</span> mit <span class="math inline">\(a_{ij} = 0\)</span> für <span class="math inline">\(i &gt; j\)</span> oder <span class="math inline">\(a_{ij} = 0\)</span> <span class="math inline">\(j &gt; i\)</span> gilt <span class="math display">\[\begin{equation}
\lvert A \rvert = \prod_{i=1}^n a_{ii}.
\end{equation}\]</span></p>
</div>
<p>Folgendes sehr tiefgehendes Theorem, welches wir nicht vollständig beweisen wollen, gibt eine Möglichkeit an, anhand der Determinante einer quadratischen Matrix zu bestimmen, ob sie invertierbar ist.</p>
<div id="thm-invertierbarkeit-und-determinante" class="theorem">
<p><span class="theorem-title"><strong>Theorem 9.10</strong></span> <span class="math inline">\(A \in \mathbb{R}^{n \times n}\)</span> ist dann und nur dann invertierbar, wenn gilt, dass <span class="math inline">\(\lvert A \rvert \neq 0\)</span>. Es gilt also <span class="math display">\[\begin{equation}
A \mbox{ ist invertierbar} \Leftrightarrow \lvert A \rvert \neq 0
\mbox{ und }
A \mbox{ ist nicht invertierbar} \Leftrightarrow \lvert A \rvert = 0.
\end{equation}\]</span></p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Beweis</em>. </span>Wir deuten einen Beweis lediglich an und zeigen, dass aus der Invertierbarkeit von <span class="math inline">\(A\)</span> folgt, dass <span class="math inline">\(\lvert A \rvert\)</span> nicht gleich Null sein kann. Nehmen wir also an, dass <span class="math inline">\(A\)</span> invertierbar ist. Dann gibt es eine Matrix <span class="math inline">\(B\)</span> mit <span class="math inline">\(AB = I_n\)</span> und mit dem Determinantenmultiplikationssatz folgt <span class="math display">\[\begin{equation}
\lvert AB \rvert = \lvert A \rvert\lvert B \rvert= |I_n| = 1.
\end{equation}\]</span> Also kann <span class="math inline">\(\lvert A \rvert = 0\)</span> nicht gelten, denn sonst wäre <span class="math inline">\(0 = 1\)</span>.</p>
</div>
<p><strong>Visuelle Intuition</strong></p>
<p>Der abstrakte Begriff der Determinante einer quadratischen Matrix kann mithilfe des Vektorraumbegriffs etwas veranschaulicht werden. Dazu seien <span class="math inline">\(a_1,...,a_n \in \mathbb{R}^n\)</span> die Spalten von <span class="math inline">\(A \in \mathbb{R}^{n \times n}\)</span>. Dann gilt (wie wir nicht beweisen wollen), dass <span class="math inline">\(\lvert A \rvert\)</span> dem signierten Volumen des von <span class="math inline">\(a_1,...,a_n\in \mathbb{R}^n\)</span> aufgespannten Parallelotops entspricht. Um dies visuell zu veranschaulichen betrachten wir die Matrizen <span class="math display">\[\begin{equation}
A_1 =
\begin{pmatrix}
3 &amp; 1 \\
1 &amp; 2
\end{pmatrix},
A_2 =
\begin{pmatrix}
2 &amp; 0 \\
0 &amp; 2
\end{pmatrix},
A_3 =
\begin{pmatrix}
2 &amp; 2 \\
2 &amp; 2
\end{pmatrix}
\end{equation}\]</span> mit den jeweiligen Determinanten <span class="math display">\[\begin{equation}
\lvert A_1 \rvert = 3\cdot 2 - 1 \cdot 1 = 5, \quad
\lvert A_2 \rvert= 2\cdot 2 - 0 \cdot 0 = 4, \quad
\lvert A_3 \rvert = 2\cdot 2 - 2 \cdot 2 = 0.
\end{equation}\]</span></p>
<p><a href="#fig-determinanten" class="quarto-xref">Abbildung&nbsp;<span>9.1</span></a> visualisiert die entsprechende Intuition.</p>
<div id="fig-determinanten" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-determinanten-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./_figures/109-determinanten.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-determinanten-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Abbildung&nbsp;9.1: Determinanten als Parallelotopvolumina.
</figcaption>
</figure>
</div>
</section>
<section id="sec-spezielle-matrizen" class="level2" data-number="9.6">
<h2 data-number="9.6" class="anchored" data-anchor-id="sec-spezielle-matrizen"><span class="header-section-number">9.6</span> Spezielle Matrizen</h2>
<p>In dieser Sektion stellen wir einige häufig auftretende Typen von Matrizen und ihre Eigenschaften zusammen. Zum Beweis der allermeisten Eigenschaften verweisen wir dabei auf die weiterführende Literatur.</p>
<section id="einheitsmatrizen" class="level3" data-number="9.6.1">
<h3 data-number="9.6.1" class="anchored" data-anchor-id="einheitsmatrizen"><span class="header-section-number">9.6.1</span> Einheitsmatrizen</h3>
<p>Die Einheitsmatrix und die Einheitsvektoren haben wir bereits kennengelernt. Wir fassen sie hier noch einmal in einer gemeinsamen Definition zusammen.</p>
<div id="def-einheitsmatrizen-und-einheitsvektoren" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 9.10 (Einheitsmatrix und Einheitsvektoren)</strong></span> Wir bezeichnen die <em>Einheitsmatrix</em> mit <span class="math display">\[\begin{equation}
I_{n} := (i_{jk})_{1 \le j \le n, 1 \le k \le n} \in \mathbb{R}^{n \times n} \mbox{ mit } i_{jk} = 1 \mbox{ für } j = k \mbox{ und } i_{jk} = 0 \mbox{ für } j \neq k.
\end{equation}\]</span> Wir bezeichnen die <em>Einheitsvektoren</em> <span class="math inline">\(e_i, i = 1,...,n\)</span> mit <span class="math display">\[\begin{equation}
e_{i} := (e_{{i}_j})_{1 \le j \le n} \in \mathbb{R}^{n} \mbox{ mit } e_{{i}_j} = 1 \mbox{ für } i = j \mbox{ und } e_{{i}_j} = 0 \mbox{ für } i \neq j.
\end{equation}\]</span></p>
</div>
<p>Die Einheitsmatrix <span class="math inline">\(I_n\)</span> besteht nur aus Nullen und Diagonalelementen gleich Eins, die Einheitsvektoren bestehen nur aus Nullen und einer Eins in der jeweils indizierten Komponente. Es gilt <span class="math display">\[\begin{equation}
I_n = \begin{pmatrix} e_1 &amp; \cdots &amp; e_n \end{pmatrix}
\in \mathbb{R}^{n \times n}
\end{equation}\]</span> Für <span class="math inline">\(n = 3\)</span> gilt also zum Beispiel <span class="math display">\[\begin{equation}
I_3 =
\begin{pmatrix}
1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 1
\end{pmatrix}
\mbox{ und }
e_1 = \begin{pmatrix} 1 \\ 0 \\ 0 \end{pmatrix},
e_2 = \begin{pmatrix} 0 \\ 1 \\ 0 \end{pmatrix},
e_3 = \begin{pmatrix} 0 \\ 0 \\ 1 \end{pmatrix}.
\end{equation}\]</span> Weiterhin gelten für die Einheitsvektoren bekanntlich für <span class="math inline">\(1 \le i,j \le n\)</span> <span class="math display">\[\begin{equation}
e^T_ie_j = 0 \mbox{ für } i \neq j,  e^T_ie_i = 1 \mbox{ und } e^T_iv = v^Te_i = v_i \mbox{ für } v \in \mathbb{R}^n.
\end{equation}\]</span></p>
</section>
<section id="einsmatrizen-und-nullmatrizen" class="level3" data-number="9.6.2">
<h3 data-number="9.6.2" class="anchored" data-anchor-id="einsmatrizen-und-nullmatrizen"><span class="header-section-number">9.6.2</span> Einsmatrizen und Nullmatrizen</h3>
<div id="def-nullmatrizen-nullvektoren-einsmatrizen-einsvektoren" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 9.11 (Nullmatrizen, Nullvektoren, Einsmatrizen, Einsvektoren)</strong></span> Wir bezeichnen <em>Nullmatrizen</em> und <em>Nullvektoren</em> mit <span class="math display">\[\begin{equation}
0_{nm} := (0)_{1 \le i \le m, 1 \le j \le n} \in \mathbb{R}^{n \times m}
\mbox{ und }
0_{n} := (0)_{1 \le i \le n} \in \mathbb{R}^{n}.
\end{equation}\]</span> Wir bezeichnen <em>Einsmatrizen</em> und <em>Einsvektoren</em> mit <span class="math display">\[\begin{equation}
1_{nm} := (1)_{1 \le i \le n, 1 \le j \le m} \in \mathbb{R}^{n \times m}
\mbox{ und }
1_n := (1)_{1 \le i \le n} \in \mathbb{R}^n.
\end{equation}\]</span></p>
</div>
<p><span class="math inline">\(0_{nm}\)</span> und <span class="math inline">\(0_{n}\)</span> bestehen also nur aus Nullen und <span class="math inline">\(1_{nm}\)</span> und <span class="math inline">\(1_{n}\)</span> bestehen nur aus Einsen. Es gilt also beispielsweise <span class="math display">\[\begin{equation}
0_{32} = \begin{pmatrix} 0 &amp; 0 \\ 0 &amp; 0 \\ 0 &amp; 0 \end{pmatrix},
0_{3}  = \begin{pmatrix} 0  \\ 0  \\ 0  \end{pmatrix},
1_{32} = \begin{pmatrix} 1 &amp; 1 \\ 1 &amp; 1 \\ 1 &amp; 1 \end{pmatrix} \mbox{ und }
1_{3}  = \begin{pmatrix} 1  \\ 1  \\ 1  \end{pmatrix}.
\end{equation}\]</span> Weiterhin gelten zum Beispiel <span class="math display">\[\begin{equation}
0_n0_n^T = 0_{nn} \mbox{ und } 1_n1_n^T = 1_{nn},
\end{equation}\]</span> wovon man sich durch Nachrechnen überzeugt.</p>
</section>
<section id="diagonalmatrizen" class="level3" data-number="9.6.3">
<h3 data-number="9.6.3" class="anchored" data-anchor-id="diagonalmatrizen"><span class="header-section-number">9.6.3</span> Diagonalmatrizen</h3>
<div id="def-diagonalmatrix" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 9.12 (Diagonalmatrix)</strong></span> Eine Matrix <span class="math inline">\(D \in \mathbb{R}^{n \times m}\)</span> heißt <em>Diagonalmatrix</em>, wenn <span class="math inline">\(d_{ij} = 0\)</span> für <span class="math inline">\(1 \le i \le n, 1 \le j \le m\)</span> mit <span class="math inline">\(i \neq j\)</span>.</p>
</div>
<p>Eine quadratische Diagonalmatrix <span class="math inline">\(D\in \mathbb{R}^{n \times n}\)</span> mit den Diagonalelementen <span class="math inline">\(d_1,...,d_n \in \mathbb{R}\)</span> schreibt man auch als <span class="math display">\[\begin{equation}
D = \mbox{diag}(d_1,...,d_n).
\end{equation}\]</span> Zum Beispiel gelten <span class="math display">\[\begin{equation}
D
:= \mbox{diag}(1,2,3)
= \begin{pmatrix}
1 &amp; 0 &amp; 0 \\
0 &amp; 2 &amp; 0 \\
0 &amp; 0 &amp; 3
\end{pmatrix}
\end{equation}\]</span> und für <span class="math inline">\(\sigma^2 \in \mathbb{R}\)</span> <span class="math display">\[\begin{equation}
\Sigma
= \mbox{diag}(\sigma^2,\sigma^2,\sigma^2)
= \begin{pmatrix}
\sigma^2 &amp; 0 &amp; 0 \\
0 &amp; \sigma^2 &amp; 0 \\
0 &amp; 0 &amp; \sigma^2
\end{pmatrix}
= \sigma^2I_3.
\end{equation}\]</span></p>
<p>In folgendem Theorem stellen wir einige wichtige Eigenschaften von quadratischen Diagonalmatrizen zusammen.</p>
<div id="thm-diagonalmatrix" class="theorem">
<p><span class="theorem-title"><strong>Theorem 9.11 (Eigenschaften quadratischer Diagonalmatrizen)</strong></span> <span class="math inline">\(\quad\)</span></p>
<p>(Determinante.) <span class="math inline">\(D := \mbox{diag}(d_1,...,d_n) \in \mathbb{R}^{n \times n}\)</span> sei eine quadratische Diagonalmatrix. Dann gilt <span class="math display">\[\begin{equation}
|D| = \prod_{i=1}^n d_i.
\end{equation}\]</span></p>
</div>
</section>
<section id="symmetrische-matrizen" class="level3" data-number="9.6.4">
<h3 data-number="9.6.4" class="anchored" data-anchor-id="symmetrische-matrizen"><span class="header-section-number">9.6.4</span> Symmetrische Matrizen</h3>
<p>Symmetrische Matrizen sind quadratische Matrizen, die bei Transposition unverändert bleiben:</p>
<div id="def-symmetrische-matrix" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 9.13</strong></span> Eine Matrix <span class="math inline">\(S \in \mathbb{R}^{n \times n}\)</span> heißt <em>symmetrisch</em>, wenn <span class="math inline">\(S^T = S\)</span>.</p>
</div>
<p>Ein Beispiel für eine symmetrische Matrix ist <span class="math display">\[\begin{equation}
S :=
\begin{pmatrix}
1 &amp; 2 &amp; 3 \\
2 &amp; 1 &amp; 2 \\
3 &amp; 2 &amp; 1
\end{pmatrix}.
\end{equation}\]</span></p>
<p>In folgendem Theorem stellen wir einige wichtige Eigenschaften symmetrischer Matrizen zusammen.</p>
<div id="thm-symmetrische-matrix" class="theorem">
<p><span class="theorem-title"><strong>Theorem 9.12 (Eigenschaften symmetrischer Matrizen)</strong></span> <span class="math inline">\(\quad\)</span></p>
<p>(Summation.) <span class="math inline">\(S_1 \in \mathbb{R}^{n \times n}\)</span> und <span class="math inline">\(S_2 \in \mathbb{R}^{n \times n}\)</span> seien symmetrische Matrizen. Dann gilt <span class="math display">\[\begin{equation}
S_1 + S_2 = (S_1 + S_2)^T.
\end{equation}\]</span> (Inverse.) <span class="math inline">\(S\)</span> sei eine invertierbare symmetrische Matrix und <span class="math inline">\(S^{-1}\)</span> ihre Inverse. Dann ist auch <span class="math inline">\(S^{-1}\)</span> eine symmetrische Matrix, das heißt es gilt <span class="math display">\[\begin{equation}
\left(S^{-1}\right)^T = S^{-1}.
\end{equation}\]</span></p>
</div>
</section>
<section id="orthogonale-matrizen" class="level3" data-number="9.6.5">
<h3 data-number="9.6.5" class="anchored" data-anchor-id="orthogonale-matrizen"><span class="header-section-number">9.6.5</span> Orthogonale Matrizen</h3>
<div id="def-orthogonale-matrix" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 9.14</strong></span> Eine Matrix <span class="math inline">\(Q \in \mathbb{R}^{n \times n}\)</span> heißt <em>orthogonal</em>, wenn <span class="math inline">\(Q^TQ = I_n\)</span>.</p>
</div>
<p>Die Spalten einer orthogonalen Matrix sind also paarweise orthogonal, es gilt für <span class="math display">\[\begin{equation}
Q = \begin{pmatrix} q_1 &amp; \cdots &amp; q_n \end{pmatrix} \mbox{ mit } q_i \in \mathbb{R}^n \mbox{ für } 1 \le i \le n,
\end{equation}\]</span> dass <span class="math display">\[\begin{equation}
q_i^Tq_j = 0 \mbox{ für } i \neq j \mbox{ und }  q_i^Tq_j = 1 \mbox{ für } i = j \mbox{ mit } 1 \le i,j \le n.
\end{equation}\]</span></p>
<div id="thm-orthogonale-matrizen" class="theorem">
<p><span class="theorem-title"><strong>Theorem 9.13 (Eigenschaften orthogonaler Matrizen)</strong></span> <span class="math inline">\(Q \in \mathbb{R}^{n \times n}\)</span> sei eine orthogonale Matrix. Dann gelten folgende Eigenschaften von <span class="math inline">\(Q\)</span>. <span class="math inline">\(\quad\)</span></p>
<p>(Inverse.) Die Inverse von <span class="math inline">\(Q\)</span> ist <span class="math inline">\(Q^T\)</span>, es gilt<br>
<span class="math display">\[\begin{equation}
Q^{-1} = Q^T.
\end{equation}\]</span> (Transposition) Die Zeilen von <span class="math inline">\(Q\)</span> sind orthonormal, es gilt <span class="math display">\[\begin{equation}
QQ^T = I_n
\end{equation}\]</span></p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Beweis</em>. </span>(Inverse) Unter der Annahme, dass <span class="math inline">\(Q^{-1}\)</span> existiert, gilt <span class="math display">\[\begin{equation}
Q^TQ = I_n \Leftrightarrow Q^TQQ^{-1} = I_nQ^{-1} \Leftrightarrow  Q^{-1} = Q^T.
\end{equation}\]</span> (Transposition) Es gilt <span class="math display">\[\begin{equation}
Q^TQ = I_n \Leftrightarrow QQ^TQ = QI_n \Leftrightarrow  QQ^TQQ^T = QQ^T \Leftrightarrow  QQ^T = I_n.
\end{equation}\]</span></p>
</div>
</section>
<section id="positiv-definite-matrizen" class="level3" data-number="9.6.6">
<h3 data-number="9.6.6" class="anchored" data-anchor-id="positiv-definite-matrizen"><span class="header-section-number">9.6.6</span> Positiv-definite Matrizen</h3>
<p>Positiv-definite Matrizen sind für die probabilistiche Modellbildung unter Verwendung multivariater Normalverteilungen zentral.</p>
<div id="def-positiv-definite-matrix" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 9.15</strong></span> Eine quadratische Matrix <span class="math inline">\(C \in \mathbb{R}^{n \times n}\)</span> heißt positiv-definit (<span class="math inline">\(\mbox{p.d.}\)</span>), wenn</p>
<ul>
<li><span class="math inline">\(C\)</span> eine symmetrische Matrix ist und</li>
<li>für alle <span class="math inline">\(x \in \mathbb{R}^n, x \neq 0_n\)</span> gilt, dass <span class="math inline">\(x^TCx &gt; 0\)</span> ist.</li>
</ul>
</div>
<p>In folgendem Theorem stellen wir einige wichtige Eigenschaften positiv-definiter Matrizen zusammen.</p>
<div id="thm-positiv-definite-matrix" class="theorem">
<p><span class="theorem-title"><strong>Theorem 9.14 (Eigenschaften positiv-definiter Matrizen)</strong></span> <span class="math inline">\(\quad\)</span></p>
<p>(Inverse.) <span class="math inline">\(C \in \mathbb{R}^{n \times n}\)</span> sei eine positiv-definite Matrix. Dann gilt, dass <span class="math inline">\(C^{-1}\)</span> existiert und ebenfalls positiv-definit ist.</p>
</div>
</section>
</section>
<section id="literaturhinweise" class="level2" data-number="9.7">
<h2 data-number="9.7" class="anchored" data-anchor-id="literaturhinweise"><span class="header-section-number">9.7</span> Literaturhinweise</h2>
<p><span class="citation" data-cites="searle1982">Searle (<a href="#ref-searle1982" role="doc-biblioref">1982</a>)</span> gibt eine umfassende Einführung in die Matrixtheorie vor dem Hintergrund der probabilistischen Datenanalyse, <span class="citation" data-cites="strang2009">Strang (<a href="#ref-strang2009" role="doc-biblioref">2009</a>)</span> gibt ein umfassende Einführung in die Matrixtheorie im Kontext der linearen Algebra. In ihrer modernen Inkarnation tauchen Matrizen als algebraische Objekte wohl zunächst in den Arbeiten von Arthur Caley (1821-1895) auf, siehe zum Beispiel <span class="citation" data-cites="caley1858">Caley (<a href="#ref-caley1858" role="doc-biblioref">1858</a>)</span>.</p>
</section>
<section id="selbstkontrollfragen" class="level2" data-number="9.8">
<h2 data-number="9.8" class="anchored" data-anchor-id="selbstkontrollfragen"><span class="header-section-number">9.8</span> Selbstkontrollfragen</h2>
<ol type="1">
<li>Geben Sie die Definition einer Matrix wieder.</li>
<li>Nennen Sie sechs Matrixoperationen.</li>
<li>Geben Sie die Definitionen der Matrixaddition und der Matrixsubtraktion wieder.</li>
<li>Geben Sie die Definition der Skalarmultiplikation für Matrizen wieder.</li>
<li>Geben Sie die Definition der Matrixtransposition wieder.</li>
<li>Es seien <span class="math display">\[\begin{equation}
A :=
\begin{pmatrix}
1 &amp; 2 \\
2 &amp; 1
\end{pmatrix},
B :=
\begin{pmatrix}
3 &amp; 0 \\
1 &amp; 2
\end{pmatrix}
\mbox{ und }
c := 2.
\end{equation}\]</span> Berechnen Sie <span class="math display">\[\begin{equation}
D := c\left(A - B^T\right)
\mbox{ und }
E := \left(cA\right)^T + B.
\end{equation}\]</span></li>
<li>Geben Sie die Definition der Matrixmultiplikation wieder.</li>
<li>Es seien <span class="math inline">\(A \in \mathbb{R}^{3 \times 2}, B \in \mathbb{R}^{2\times 4}\)</span> und <span class="math inline">\(C \in \mathbb{R}^{3 \times 4}\)</span>. Prüfen Sie, ob folgende Matrixprodukte definiert sind, und wenn ja, geben Sie die Größe der resultierenden Matrix an: <span class="math display">\[\begin{equation}
ABC, ABC^T, A^TCB^T, BAC.
\end{equation}\]</span></li>
<li>Es seien <span class="math display">\[\begin{equation}
A :=
\begin{pmatrix}
1 &amp; 2 &amp; 3 \\
4 &amp; 5 &amp; 6 \\
3 &amp; 2 &amp; 0
\end{pmatrix}
B :=
\begin{pmatrix}
1 &amp; 2 &amp; 2 \\
1 &amp; 3 &amp; 1 \\
2 &amp; 0 &amp; 0
\end{pmatrix}
\mbox{ und }
C :=
\begin{pmatrix}
1 \\ 3 \\ 2
\end{pmatrix}.
\end{equation}\]</span> Berechnen Sie die Matrixprodukte <span class="math display">\[\begin{equation}
AB,
B^TA^T,
\left(B^TA^T\right)^T,
AC.
\end{equation}\]</span></li>
<li>Definieren Sie die Begriff der inversen Matrix und der Invertierbarkeit einer Matrix.</li>
<li>Geben Sie die Formel für die Determinante von <span class="math inline">\(A := (A_{ij})_{1 \le i,j \le 2} \in \mathbb{R}^2\)</span> wieder.</li>
<li>Geben Sie die Formel für die Determinante von <span class="math inline">\(A := (A_{ij})_{1 \le i,j \le 3} \in \mathbb{R}^3\)</span> wieder.</li>
<li>Berechnen Sie die Determinanten von <span class="math display">\[\begin{equation}
A := \begin{pmatrix} 2 &amp; 1 \\ 1 &amp; 2 \end{pmatrix}
B := \begin{pmatrix} 3 &amp; 2 &amp; 1 \\ 2 &amp; 3 &amp; 2 \\ 1 &amp; 2 &amp; 3 \end{pmatrix} \mbox{ und }
C := \mbox{diag}(1,2,3).
\end{equation}\]</span></li>
<li>Geben Sie die Definitionen von Einheitsmatrix und Einheitsvektoren wieder.</li>
<li>Geben Sie die Definitionen von Nullmatrizen und Einsmatrizen wieder.</li>
<li>Geben Sie die Definition einer symmetrischen Matrix wieder.</li>
<li>Geben Sie die Definition einer Diagonalmatrix wieder.</li>
<li>Geben Sie die Definition einer positiv-definiten Matrix wieder.</li>
</ol>
</section>
<section id="sec-eigenanalyse" class="level2" data-number="9.9">
<h2 data-number="9.9" class="anchored" data-anchor-id="sec-eigenanalyse"><span class="header-section-number">9.9</span> Eigenanalyse</h2>
<p>Mit der <em>Eigenanalyse einer quadratischen Matrix</em>, der <em>Orthonormalzerlegung einer symmetrischen Matrix</em> und der <em>Singulärwertzerlegung einer beliebigen Matrix</em> behandeln wir in diesem Abschnitt drei eng zusammenhängende Konzepte der Matrixtheorie, die in vielen Gebieten der datenanalytischen Anwendung zentrale Rollen spielen. Allerdings erschließt sich die Bedeutung dieser Konzepte dann vor allem im jeweiligen Anwendungskontext, so dass dieser Abschnitt notwendigerweise etwas abstrakt anmuten mag.</p>
</section>
<section id="eigenvektoren-und-eigenwerte" class="level2" data-number="9.10">
<h2 data-number="9.10" class="anchored" data-anchor-id="eigenvektoren-und-eigenwerte"><span class="header-section-number">9.10</span> Eigenvektoren und Eigenwerte</h2>
<p>Unter der <em>Eigenanalyse</em> einer quadratischen Matrix versteht man das bestimmen ihrer <em>Eigenvektoren</em> und <em>Eigenwerte</em>. Diese sind für eine quadratische Matrix wie folgt definiert.</p>
<div id="def-eigenvektor-und-eigenwert" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 9.16 (Eigenvektor und Eigenwert)</strong></span> <span class="math inline">\(A \in \mathbb{R}^{m \times m}\)</span> sei eine quadratische Matrix. Dann heißt jeder vom Nullvektor <span class="math inline">\(0_m\)</span> verschiedene Vektor <span class="math inline">\(v \in \mathbb{R}^m\)</span>, für den mit einem Skalar <span class="math inline">\(\lambda \in \mathbb{R}\)</span> gilt, dass <span class="math display">\[\begin{equation}
Av = \lambda v
\end{equation}\]</span> ist, ein <em>Eigenvektor von <span class="math inline">\(A\)</span></em> und <span class="math inline">\(\lambda\)</span> heißt dann ein <em>Eigenwert von <span class="math inline">\(A\)</span></em>.</p>
</div>
<p>Nach Definition hat also jeder Eigenvektor einen zugehörigen Eigenwert, allerdings können die Eigenwerte verschiedener Eigenvektoren durchaus identisch sein. Intuitiv bedeutet die Definition von Eigenvektor und Eigenwert, dass ein Eigenvektor einer Matrix durch Multiplikation mit eben dieser Matrix in seiner Länge, nicht aber in seiner Richtung, verändert wird. Der zugehörige Eigenwert des Eigenvektors entspricht dem Faktor der Längenänderung. Allerdings ist die Zuordnung von Eigenvektoren und Eigenwerten nicht eindeutig, wie folgendes Theorem zeigt.</p>
<div id="thm-multiplikativität-von-eigenvektoren" class="theorem">
<p><span class="theorem-title"><strong>Theorem 9.15 (Multiplikativität von Eigenvektoren)</strong></span> <span class="math inline">\(A \in \mathbb{R}^{m \times m}\)</span> sei eine quadratische Matrix. Wenn <span class="math inline">\(v \in \mathbb{R}^m\)</span> Eigenvektor von <span class="math inline">\(A\)</span> mit Eigenwert <span class="math inline">\(\lambda \in \mathbb{R}\)</span> ist, dann ist für <span class="math inline">\(c \in \mathbb{R}\)</span> auch <span class="math inline">\(cv \in \mathbb{R}^m\)</span> Eigenvektor von <span class="math inline">\(A\)</span> und zwar wiederum mit Eigenwert <span class="math inline">\(\lambda \in \mathbb{R}\)</span>.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Beweis</em>. </span>Es gilt <span class="math display">\[\begin{equation}
Av = \lambda v   \Leftrightarrow
cAv = c\lambda v \Leftrightarrow
A(cv) = \lambda(cv).
\end{equation}\]</span> Also ist <span class="math inline">\(cv\)</span> ein Eigenvektor von <span class="math inline">\(A\)</span> mit Eigenwert <span class="math inline">\(\lambda\)</span>.</p>
</div>
<p>Um nun die Uneindeutigkeit in der Definition des zu einem Eigenwert zugeordneten Eigenvektors aufzulösen, nutzen wir die Konvention, nur diejenigen Vektoren also Eigenvektoren zu einem Eigenwert <span class="math inline">\(\lambda\)</span> zu betrachten, die die Länge 1 haben, für die also gilt, dass <span class="math display">\[\begin{equation}
\Vert v \Vert = 1.
\end{equation}\]</span> Sollten wir also einen Eigenvektor <span class="math inline">\(v\)</span> zu einem Eigenwert <span class="math inline">\(\lambda\)</span> einer Matrix <span class="math inline">\(A\)</span> finden, der nicht von der Länge 1 ist, so können wir ihn immer mit <span class="math inline">\(\Vert v \Vert^{-1}\)</span> multiplizieren. Der resultierende Vektor <span class="math inline">\(v' = v/\Vert v \Vert\)</span> hat dann die Länge 1 und ist nach <a href="#thm-multiplikativität-von-eigenvektoren" class="quarto-xref">Theorem&nbsp;<span>9.15</span></a> ebenso ein Eigenvektor von <span class="math inline">\(A\)</span> zum Eigenwert <span class="math inline">\(\lambda\)</span>. Bevor wir uns der Bestimmung von Eigenwerten und Eigenvektoren widmen, wollen wir die Konzepte von Eigenwert und Eigenvektor für den Fall einer <span class="math inline">\(2 \times 2\)</span> Matrix an einem Beispiel veranschaulichen</p>
<section id="beispiel" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="beispiel">Beispiel</h3>
<p>Es sei <span class="math display">\[\begin{equation}
A :=
\begin{pmatrix}
2 &amp; 1 \\
1 &amp; 2
\end{pmatrix}
\end{equation}\]</span> Dann ist der Vektor der Länge 1 <span class="math display">\[\begin{equation}
v :=
\frac{1}{\sqrt{2}}
\begin{pmatrix} 1 \\ 1 \end{pmatrix}
\end{equation}\]</span> ein Eigenvektor von <span class="math inline">\(A\)</span> zum Eigenwert <span class="math inline">\(\lambda = 3\)</span>, da gilt, dass <span class="math display">\[\begin{align}
\begin{split}
Av
&amp; =
\begin{pmatrix}
2 &amp; 1 \\
1 &amp; 2
\end{pmatrix}
\left(
\frac{1}{\sqrt{2}}
\begin{pmatrix} 1 \\ 1 \end{pmatrix}
\right)
\\
&amp; =
\frac{1}{\sqrt{2}}
\begin{pmatrix}
2 &amp; 1 \\
1 &amp; 2
\end{pmatrix}
\begin{pmatrix} 1 \\ 1 \end{pmatrix}
\\
&amp; =
\frac{1}{\sqrt{2}}
\begin{pmatrix} 3 \\ 3 \end{pmatrix}
\\
&amp; =
\frac{1}{\sqrt{2}}
3
\begin{pmatrix} 1 \\ 1 \end{pmatrix}
\\
&amp; =
3
\left(
\frac{1}{\sqrt{2}}
\begin{pmatrix} 1 \\ 1 \end{pmatrix}
\right)
\\
&amp; =
\lambda v.
\end{split}
\end{align}\]</span> Inspektion von <a href="#fig-eigenvektor" class="quarto-xref">Abbildung&nbsp;<span>9.2</span></a> zeigt dementsprechend, dass für die hier definierte Matrix <span class="math inline">\(A\)</span> die Vektoren <span class="math inline">\(v\)</span> und <span class="math inline">\(Av\)</span> in die gleiche Richtung zeigen, dass aber <span class="math inline">\(Av\)</span> um den Faktor <span class="math inline">\(\lambda\)</span> länger ist als <span class="math inline">\(v\)</span>.</p>
<p>Der Vektor <span class="math display">\[\begin{equation}
w := \begin{pmatrix} 1 \\ 0 \end{pmatrix}
\end{equation}\]</span> dagegen hat zwar die Länge 1, ist aber im Gegensatz zu <span class="math inline">\(v\)</span> kein Eigenvektor von <span class="math inline">\(A\)</span>, da es im Falle von <span class="math display">\[\begin{equation}
Aw =
\begin{pmatrix}
2 &amp; 1 \\
1 &amp; 2
\end{pmatrix}
\begin{pmatrix} 1 \\ 0 \end{pmatrix}
=
\begin{pmatrix} 2 \\ 1 \end{pmatrix}
\end{equation}\]</span> keinen Skalar <span class="math inline">\(\lambda\)</span> geben kann, der mit Null, dem zweiten Eintrag von <span class="math inline">\(w\)</span>, multipliziert einen Wert ungleich Null ergeben kann. Inspektion von <a href="#fig-eigenvektor" class="quarto-xref">Abbildung&nbsp;<span>9.2</span></a> zeigt dementsprechend, dass der aus der Multiplikation von <span class="math inline">\(w\)</span> mit <span class="math inline">\(A\)</span> resultierende Vektor in eine andere Richtung zeigt als <span class="math inline">\(w\)</span>.</p>
<div id="fig-eigenvektor" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-eigenvektor-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./_figures/110-eigenvektor.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-eigenvektor-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Abbildung&nbsp;9.2: Eigenvektor einer <span class="math inline">\(2 \times 2\)</span> Matrix. Für die Matrix <span class="math display">\[\begin{equation}
\begin{pmatrix}
2 &amp; 1 \\
1 &amp; 2
\end{pmatrix}
\end{equation}\]</span> ist <span class="math inline">\(v\)</span> ein Eigenvektor, <span class="math inline">\(w\)</span> jedoch nicht
</figcaption>
</figure>
</div>
</section>
<section id="bestimmung-von-eigenwerten-und-eigenvektoren" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="bestimmung-von-eigenwerten-und-eigenvektoren">Bestimmung von Eigenwerten und Eigenvektoren</h3>
<p>Folgendes Theorem besagt, wie die Eigenwerte und Eigenvektoren einer quadratischen Matrix berechnet werden können.</p>
<div id="thm-bestimmung-von-eigenwerten-und-eigenvektoren" class="theorem">
<p><span class="theorem-title"><strong>Theorem 9.16 (Bestimmung von Eigenwerten und Eigenvektoren)</strong></span> <span class="math inline">\(A \in \mathbb{R}^{m \times m}\)</span> sei eine quadratische Matrix. Dann ergeben sich die Eigenwerte von <span class="math inline">\(A\)</span> als die Nullstellen des <span class="math display">\[\begin{equation}
\chi_A(\lambda) := |A - \lambda I_m|
\end{equation}\]</span> von <span class="math inline">\(A\)</span>. Weiterhin seien <span class="math inline">\(\lambda_i^*, i = 1,2,...\)</span> die auf diese Weise bestimmten Eigenwerte von <span class="math inline">\(A\)</span>. Die entsprechenden Eigenvektoren <span class="math inline">\(v_i, i = 1,2,...\)</span> von <span class="math inline">\(A\)</span> können dann durch Lösen der linearen Gleichungssysteme <span class="math display">\[\begin{equation}
(A - \lambda_i^* I_m)v_i = 0_m \mbox{ für } i = 1,2,...
\end{equation}\]</span> bestimmt werden.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Beweis</em>. </span>(1) Bestimmen von Eigenwerten</p>
<p>Wir halten zunächst fest, dass mit der Definition von Eigenvektoren und Eigenwerten gilt, dass <span class="math display">\[\begin{equation}
Av = \lambda v
\Leftrightarrow Av - \lambda v = 0_m
\Leftrightarrow (A - \lambda I_m)v = 0_m.
\end{equation}\]</span> Für den Eigenwert <span class="math inline">\(\lambda\)</span> wird der Eigenvektor <span class="math inline">\(v\)</span> also durch Multiplikation mit <span class="math inline">\((A - \lambda I_m)\)</span> auf den Nullvektor <span class="math inline">\(0_m\)</span> abgebildet. Weil aber per Definition <span class="math inline">\(v \neq 0_m\)</span> gilt, ist die Matrix <span class="math inline">\((A - \lambda I_m)\)</span> somit nicht invertierbar: sowohl der Nullvektor als auch <span class="math inline">\(v\)</span> werden durch <span class="math inline">\(A\)</span> auf <span class="math inline">\(0_m\)</span> abgebildet, die Abbildung <span class="math display">\[\begin{equation}
f : \mathbb{R}^m \to \mathbb{R}^m, x \mapsto (A - \lambda I_m)x
\end{equation}\]</span> ist also nicht bijektiv, und <span class="math inline">\((A - \lambda I_m)^{-1}\)</span> kann nicht existieren. Die Tatsache, dass <span class="math inline">\((A - \lambda I_m)\)</span> nicht invertierbar ist, ist aber äquivalent dazu, dass die Determinante von <span class="math inline">\((A -\lambda I_m)\)</span> gleich Null ist. Also ist <span class="math display">\[\begin{equation}
\chi_A(\lambda) = |A - \lambda I_m| = 0
\end{equation}\]</span> eine notwendige und hinreichende Bedingung dafür, dass <span class="math inline">\(\lambda\)</span> ein Eigenwert von <span class="math inline">\(A\)</span> ist.</p>
<p>(2) Bestimmen von Eigenvektoren</p>
<p>Es sei <span class="math inline">\(\lambda_i^*\)</span> ein Eigenwert von <span class="math inline">\(A\)</span>. Dann gilt mit den obigen Überlegungen, dass Auflösen von <span class="math display">\[\begin{equation}
(A - \lambda_i^* I_m)v_i^* = 0_m
\end{equation}\]</span> nach <span class="math inline">\(v_i^*\)</span> einen Eigenvektor zum Eigenwert <span class="math inline">\(\lambda^*\)</span> ergibt.</p>
</div>
<p>Allgemein müssen zur Bestimmung von Eigenwerten und Eigenvektoren also Polynomnullstellen bestimmt und lineare Gleichungssysteme gelöst werden. Dies kann für kleine Matrizen mit <span class="math inline">\(m \le 4\)</span> durchaus manuell geschehen. Die in der Anwendung auftretetenden Matrizen sind jedoch meist weitaus größer, so dass zur Eigenananalyse numerische Verfahren der Nullstellenbestimmung und des Lösens linearer Gleichungssysteme eingesetzt werden, die zum Beispiel in Funktionen wie <strong>R</strong>’s <code>eigen()</code>, <strong>SciPy’s</strong> <code>linalg.eig()</code> oder <strong>Julia</strong>’s <code>eigvals()</code> und <code>eigvecs()</code> genutzt werden. Für Details zu diesen Verfahren verweisen wir auf die weiterführende Literatur, zum Beispiel <span class="citation" data-cites="burden2016">Burden et al. (<a href="#ref-burden2016" role="doc-biblioref">2016</a>)</span> und <span class="citation" data-cites="richter2017">Richter &amp; Wick (<a href="#ref-richter2017" role="doc-biblioref">2017</a>)</span>. Wir wollen <a href="#thm-bestimmung-von-eigenwerten-und-eigenvektoren" class="quarto-xref">Theorem&nbsp;<span>9.16</span></a> hier lediglich anhand eines Beispiels illustrieren.</p>
</section>
<section id="beispiel-1" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="beispiel-1">Beispiel</h3>
<p>Dazu sei wiederum <span class="math display">\[\begin{equation}
A :=
\begin{pmatrix*}[r]
2 &amp; 1 \\
1 &amp; 2\end{pmatrix*}
\end{equation}\]</span> Wir wollen zunächst die Eigenwerte von <span class="math inline">\(A\)</span> berechnen. Nach <a href="#thm-bestimmung-von-eigenwerten-und-eigenvektoren" class="quarto-xref">Theorem&nbsp;<span>9.16</span></a> sind dies die Nullstellen des charakteristischen Polynoms von <span class="math inline">\(A\)</span>. Wir berechnen also zunächst das charakteristische Polynom von <span class="math inline">\(A\)</span> durch <span class="math display">\[\begin{equation}
\chi_A(\lambda)
=
\left\vert
\begin{pmatrix*}[r]
2 &amp; 1 \\
1 &amp; 2\end{pmatrix*}
-
\begin{pmatrix*}[r]
\lambda &amp; 0 \\
0       &amp; \lambda
\end{pmatrix*}
\right\vert
=
\left\vert
\begin{pmatrix*}[r]
2 - \lambda &amp; 1 \\
1 &amp; 2 - \lambda
\end{pmatrix*}
\right\vert
= (2 - \lambda)^2 - 1.
\end{equation}\]</span> Mithilfe der pq-Formel zur Lösung quadratischer Gleichungen findet man dann <span class="math display">\[\begin{equation}
(2 - \lambda^*_{1/2})^2 - 1 = 0 \Leftrightarrow \lambda_1^* = 3 \mbox{ oder } \lambda_2^* = 1.
\end{equation}\]</span> Die Eigenwerte von <span class="math inline">\(A\)</span> sind also <span class="math inline">\(\lambda_1 = 3\)</span> und <span class="math inline">\(\lambda_2 = 1\)</span>. Die zugehörigen Eigenvektoren ergeben sich dann für <span class="math inline">\(i = 1,2\)</span> durch Lösen des linearen Gleichungssystems <span class="math display">\[\begin{equation}
(A - \lambda_i I_2)v_i = 0_2.
\end{equation}\]</span> Speziell ergibt sich hier, dass für <span class="math inline">\(\lambda_1 = 3\)</span> aus <span class="math display">\[\begin{equation}
(A - 3I_2)v_1 = 0_2
\Leftrightarrow
\begin{pmatrix*}[r]
-1 &amp; 1 \\
1 &amp; -1
\end{pmatrix*}
\begin{pmatrix*}[r]
v_{1_1} \\
v_{1_2}
\end{pmatrix*}
=
\begin{pmatrix*}[r]
0 \\
0
\end{pmatrix*}
\end{equation}\]</span> folgt, dass <span class="math display">\[\begin{equation}
v_1 =
\frac{1}{\sqrt{2}}
\begin{pmatrix*}[r]
1 \\
1
\end{pmatrix*}
\end{equation}\]</span> ein Eigenvektor zum Eigenwert <span class="math inline">\(\lambda_1\)</span> ist und dass für <span class="math inline">\(\lambda_2 = 1\)</span> aus <span class="math display">\[\begin{equation}
(A - 1I_2)v_2 = 0_2
\Leftrightarrow
\begin{pmatrix*}[r]
1 &amp; 1 \\
1 &amp; 1
\end{pmatrix*}
\begin{pmatrix*}[r]
v_{2_1} \\
v_{2_2}
\end{pmatrix*}
=
\begin{pmatrix*}[r]
0 \\
0
\end{pmatrix*}
\end{equation}\]</span> folgt, dass <span class="math display">\[\begin{equation}
v_2 =
\frac{1}{\sqrt{2}}
\begin{pmatrix*}[r]
-1 \\
1
\end{pmatrix*}
\end{equation}\]</span> ein Eigenvektor zum Eigenwert <span class="math inline">\(\lambda_2 = 1\)</span> ist. Weiterhin gelten hier offenbar <span class="math display">\[\begin{equation}
v_1^Tv_2 = 0 \mbox{ und } \Vert v_1 \Vert = \Vert v_2 \Vert = 1.
\end{equation}\]</span></p>
<p>Folgender <strong>R</strong> Code demonstriert die Bestimmung der Eigenwerte und Eigenvektoren der hier betrachteten Matrix mithilfe der <code>eigen()</code> Funktion.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1"></a><span class="co"># Matrixdefinition</span></span>
<span id="cb37-2"><a href="#cb37-2"></a>A <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">1</span>,</span>
<span id="cb37-3"><a href="#cb37-3"></a>             <span class="dv">1</span>,<span class="dv">2</span>),</span>
<span id="cb37-4"><a href="#cb37-4"></a>           <span class="at">nrow  =</span> <span class="dv">2</span>,</span>
<span id="cb37-5"><a href="#cb37-5"></a>           <span class="at">byrow =</span> <span class="cn">TRUE</span>)</span>
<span id="cb37-6"><a href="#cb37-6"></a></span>
<span id="cb37-7"><a href="#cb37-7"></a><span class="co"># Eigenanalyse</span></span>
<span id="cb37-8"><a href="#cb37-8"></a><span class="fu">eigen</span>(A)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>eigen() decomposition
$values
[1] 3 1

$vectors
          [,1]       [,2]
[1,] 0.7071068 -0.7071068
[2,] 0.7071068  0.7071068</code></pre>
</div>
</div>
<p>Zum Abschluss dieses Abschnittes betrachten wir zwei technische Theoreme, die Aussagen zum Zusammenhang spezieller Matrixprodukte und ihrer Eigenwerte und Eigenvektoren machen. Wir benötigen dieses Theoreme im Kontext der Kanonischen Korrelationsanalyse (<span class="quarto-unresolved-ref">?sec-kanonische-korrelationsanalyse</span>).</p>
<div id="thm-eigenwerte-und-eigenvektoren-von-matrixprodukten" class="theorem">
<p><span class="theorem-title"><strong>Theorem 9.17 (Eigenwerte und Eigenvektoren von Matrixprodukten)</strong></span> Für <span class="math inline">\(A \in \mathbb{R}^{n \times m}\)</span> und <span class="math inline">\(B \in \mathbb{R}^{m \times n}\)</span> sind die Eigenwerte von <span class="math inline">\(AB \in \mathbb{R}^{n \times n}\)</span> und <span class="math inline">\(BA \in \mathbb{R}^{m \times m}\)</span> gleich. Weiterhin gilt, dass für einen Eigenvektor <span class="math inline">\(v\)</span> zu einem von Null verschiedenen Eigenwert <span class="math inline">\(\lambda\)</span> von <span class="math inline">\(AB\)</span> <span class="math inline">\(w := Bv\)</span> ein Eigenvektor von <span class="math inline">\(BA\)</span> zum Eigenwert <span class="math inline">\(\lambda\)</span> ist.</p>
</div>
<p>Für einen Beweis verweisen wir auf <span class="citation" data-cites="mardia1979">Mardia et al. (<a href="#ref-mardia1979" role="doc-biblioref">1979</a>)</span>, S. 468. Wir demonstrieren die Aussage dieses Theorems anhand untenstehenden <strong>R</strong> Codes.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1"></a>A   <span class="ot">=</span> <span class="fu">matrix</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>, <span class="at">nrow =</span> <span class="dv">2</span>,  <span class="at">byrow =</span> T)           <span class="co"># Matrix A \in \mathbb{R}^{2 x 3}</span></span>
<span id="cb39-2"><a href="#cb39-2"></a>B   <span class="ot">=</span> <span class="fu">matrix</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>, <span class="at">ncol =</span> <span class="dv">2</span>,  <span class="at">byrow =</span> T)           <span class="co"># Matrix B \in \mathbb{R}^{3 x 2}</span></span>
<span id="cb39-3"><a href="#cb39-3"></a>EAB <span class="ot">=</span> <span class="fu">eigen</span>(A <span class="sc">%*%</span> B)                              <span class="co"># Eigenanalyse von AB \in \mathbb{R}^{2 \times 2}</span></span>
<span id="cb39-4"><a href="#cb39-4"></a>EBA <span class="ot">=</span> <span class="fu">eigen</span>(B <span class="sc">%*%</span> A)                              <span class="co"># Eigenanalyse von BA \in \mathbb{R}^{3 \times 3}</span></span>
<span id="cb39-5"><a href="#cb39-5"></a>w   <span class="ot">=</span> B <span class="sc">%*%</span> EAB<span class="sc">$</span>vectors[,<span class="dv">1</span>]                       <span class="co"># Eigenvektor von BA</span></span>
<span id="cb39-6"><a href="#cb39-6"></a><span class="fu">cat</span>(<span class="st">"Eigenwerte von AB :"</span>  , EAB<span class="sc">$</span>values[<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>],</span>
<span id="cb39-7"><a href="#cb39-7"></a>    <span class="st">"</span><span class="sc">\n</span><span class="st">Eigenwerte von BA :"</span>, EBA<span class="sc">$</span>values[<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>],</span>
<span id="cb39-8"><a href="#cb39-8"></a>    <span class="st">"</span><span class="sc">\n</span><span class="st">BAw mit w = Bv    :"</span>, B <span class="sc">%*%</span> A <span class="sc">%*%</span> w,</span>
<span id="cb39-9"><a href="#cb39-9"></a>    <span class="st">"</span><span class="sc">\n</span><span class="st">lw mit w = Bv     :"</span>, EBA<span class="sc">$</span>values[<span class="dv">1</span>] <span class="sc">*</span> w)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Eigenwerte von AB : 85.57934 0.4206623 
Eigenwerte von BA : 85.57934 0.4206623 
BAw mit w = Bv    : -191.1333 -416.7586 -642.3839 
lw mit w = Bv     : -191.1333 -416.7586 -642.3839</code></pre>
</div>
</div>
<div id="thm-eigenwert-und-eigenvektor-eines-matrixvektorprodukts" class="theorem">
<p><span class="theorem-title"><strong>Theorem 9.18</strong></span> Für <span class="math inline">\(A \in \mathbb{R}^{n \times m}, B \in \mathbb{R}^{p \times n}, a \in \mathbb{R}^m\)</span> und <span class="math inline">\(b \in \mathbb{R}^p\)</span> gilt, dass der einzige von Null verschiedene Eigenwert von <span class="math inline">\(Aab^TB \in \mathbb{R}^{n \times n}\)</span> gleich <span class="math inline">\(b^T BAa\)</span> mit zugehörigem Eigenvektor <span class="math inline">\(Aa\)</span> ist.</p>
</div>
<p>Für einen Beweis verweisen wir auf <span class="citation" data-cites="mardia1979">Mardia et al. (<a href="#ref-mardia1979" role="doc-biblioref">1979</a>)</span>, S. 468. Wir demonstrieren die Aussage dieses Theorems anhand untenstehenden <strong>R</strong> Codes.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1"></a>A      <span class="ot">=</span> <span class="fu">matrix</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>, <span class="at">nrow =</span> <span class="dv">2</span>,  <span class="at">byrow =</span> T)     <span class="co"># Matrix A \in \mathbb{R}^{2 x 3}</span></span>
<span id="cb41-2"><a href="#cb41-2"></a>B      <span class="ot">=</span> <span class="fu">matrix</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">8</span>, <span class="at">ncol =</span> <span class="dv">2</span>,  <span class="at">byrow =</span> T)     <span class="co"># Matrix B \in \mathbb{R}^{4 x 2}</span></span>
<span id="cb41-3"><a href="#cb41-3"></a>a      <span class="ot">=</span> <span class="fu">matrix</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>, <span class="at">nrow =</span> <span class="dv">3</span>,  <span class="at">byrow =</span> T)     <span class="co"># Vektor a \in \mathbb{R}^{3 x 1}</span></span>
<span id="cb41-4"><a href="#cb41-4"></a>b      <span class="ot">=</span> <span class="fu">matrix</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>, <span class="at">nrow =</span> <span class="dv">4</span>,  <span class="at">byrow =</span> T)     <span class="co"># Vektor b \in \mathbb{R}^{4 x 1}</span></span>
<span id="cb41-5"><a href="#cb41-5"></a>EAabTB <span class="ot">=</span> <span class="fu">eigen</span>(A <span class="sc">%*%</span> a <span class="sc">%*%</span> <span class="fu">t</span>(b) <span class="sc">%*%</span> B)         <span class="co"># Eigenanalyse von Aab^TB \in \mathbb{R}^{4 x 4}</span></span>
<span id="cb41-6"><a href="#cb41-6"></a><span class="fu">cat</span>(<span class="st">"Eigenwerte von AabTB :"</span>, EAabTB<span class="sc">$</span>values,</span>
<span id="cb41-7"><a href="#cb41-7"></a>    <span class="st">"</span><span class="sc">\n</span><span class="st">bTBAa                :"</span>, <span class="fu">t</span>(b) <span class="sc">%*%</span> B <span class="sc">%*%</span> A <span class="sc">%*%</span> a,</span>
<span id="cb41-8"><a href="#cb41-8"></a>    <span class="st">"</span><span class="sc">\n</span><span class="st">Aa                   :"</span>, A <span class="sc">%*%</span> a,</span>
<span id="cb41-9"><a href="#cb41-9"></a>    <span class="st">"</span><span class="sc">\n</span><span class="st">(AabTB)Aa            :"</span>,(A <span class="sc">%*%</span> a <span class="sc">%*%</span> <span class="fu">t</span>(b) <span class="sc">%*%</span> B) <span class="sc">%*%</span> A <span class="sc">%*%</span> a,            <span class="co"># Mv</span></span>
<span id="cb41-10"><a href="#cb41-10"></a>    <span class="st">"</span><span class="sc">\n</span><span class="st">(bTBAa)Aa            :"</span>,<span class="fu">as.vector</span>((<span class="fu">t</span>(b) <span class="sc">%*%</span> B <span class="sc">%*%</span> A <span class="sc">%*%</span> a)) <span class="sc">*</span> (A <span class="sc">%*%</span> a)) <span class="co"># = \lambda v</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Eigenwerte von AabTB : 2620 0 
bTBAa                : 2620 
Aa                   : 14 32 
(AabTB)Aa            : 36680 83840 
(bTBAa)Aa            : 36680 83840</code></pre>
</div>
</div>
</section>
</section>
<section id="sec-orthonormalzerlegung" class="level2" data-number="9.11">
<h2 data-number="9.11" class="anchored" data-anchor-id="sec-orthonormalzerlegung"><span class="header-section-number">9.11</span> Orthonormalzerlegung</h2>
<p>Mit dem Begriff der <em>Zerlegung</em> einer Matrix wird das Aufspalten einer gegebenen Matrix in das Matrixprodukt mehrerer Matrizen bezeichnet. Verschiedenste Matrixzerlegungen spielen in vielen mathematischen Anwendungen eine wichtige Rolle, für einen Überblick siehe beispielsweise <span class="citation" data-cites="golub2013">Golub &amp; Van Loan (<a href="#ref-golub2013" role="doc-biblioref">2013</a>)</span>. In diesem Abschnitt führen wir mit der <em>Orthonormalzerlegung einer symmetrischen Matrix</em> eine spezielle Matrixzerlegung ein, die direkt auf der Eigenanalyse aufbaut. Wir halten zunächst folgendes grundlegendes Theorem zu den Eigenwerten und Eigenvektoren symmetrischer Matrizen fest.</p>
<div id="thm-eigenwerte-und-eigenvektoren-symmetrischer-matrizen" class="theorem">
<p><span class="theorem-title"><strong>Theorem 9.19 (Eigenwerte und Eigenvektoren symmetrischer Matrizen)</strong></span> &nbsp;</p>
<span class="math inline">\(S \in \mathbb{R}^{m \times m}\)</span> sei eine symmetrische Matrix. Dann gelten
</div>
<div class="proof">
<p><span class="proof-title"><em>Beweis</em>. </span>Wir setzen die Tatsache, dass eine symmetrische Matrix <span class="math inline">\(m\)</span> reelle Eigenwerte hat, als gegeben voraus und zeigen lediglich, dass die Eigenvektoren zu je zwei verschiedenen Eigenwerten einer symmetrischen Matrix orthogonal sind. Ohne Beschränkung der Allgemeinheit seien also <span class="math inline">\(\lambda_i, \lambda_j \in \mathbb{R}\)</span> mit <span class="math inline">\(1 \le i,j \le m\)</span> und <span class="math inline">\(\lambda_i \neq \lambda_j\)</span> zwei verschiedenen Eigenwerte von <span class="math inline">\(S\)</span> mit zugehörigen Eigenvektoren <span class="math inline">\(q_i\)</span> und <span class="math inline">\(q_j\)</span>, respektive. Dann ergibt sich wie unten gezeigt, dass <span class="math display">\[\begin{equation}
\lambda_i q_i^Tq_j = \lambda_j q_i^Tq_j.
\end{equation}\]</span> Mit <span class="math inline">\(q_i \neq 0_m, q_j \neq 0_m\)</span> und <span class="math inline">\(\lambda_i \neq \lambda_j\)</span> folgt damit <span class="math inline">\(q_i^Tq_j = 0\)</span>, weil weil es keine andere Zahl <span class="math inline">\(c\)</span> als die Null gibt, für die bei <span class="math inline">\(a,b\in \mathbb{R}\)</span> und <span class="math inline">\(a \neq b\)</span> gilt, dass <span class="math display">\[\begin{equation}
ac = bc.
\end{equation}\]</span> Um abschließend <span class="math display">\[\begin{equation}
\lambda_i q_i^Tq_j = \lambda_j q_i^Tq_j.
\end{equation}\]</span> zu zeigen, halten wir zunächst fest, dass <span class="math display">\[\begin{equation}
                 Sq_i       = \lambda_i q_i      
\Leftrightarrow (Sq_i)^T    = (\lambda_i q_i)^T  
\Leftrightarrow q_i^TS^T    = q_i^T \lambda_i^T  
\Leftrightarrow q_i^T S     = q_i^T \lambda_i   
\Leftrightarrow q_i^T Sq_j  = \lambda_i q_i^Tq_j
\end{equation}\]</span> und <span class="math display">\[\begin{equation}
                 Sq_j           = \lambda_j q_j      
\Leftrightarrow q_j^T S         = q_j^T \lambda_j   
\Leftrightarrow q_j^T Sq_i      = \lambda_j q_j^Tq_i
\Leftrightarrow (q_j^T S q_i)^T = (\lambda_j q_j^Tq_i)^T
\Leftrightarrow q_i^T S q_j     =  \lambda_j q_i^Tq_j
\end{equation}\]</span> gelten. Sowohl <span class="math inline">\(\lambda_i q_i^Tq_j\)</span> als auch <span class="math inline">\(\lambda_j q_i^Tq_j\)</span> sind also mit <span class="math inline">\(q_i^T Sq_j\)</span> und damit auch miteinander identisch.</p>
</div>
<p>Offenbar haben wir nur Aussage (2) von <a href="#thm-eigenwerte-und-eigenvektoren-symmetrischer-matrizen" class="quarto-xref">Theorem&nbsp;<span>9.19</span></a> bewiesen. Ein vollständiger Beweis des Theorems findet sich zum Beispiel bei <span class="citation" data-cites="strang2009">Strang (<a href="#ref-strang2009" role="doc-biblioref">2009</a>)</span>. Wir merken außerdem an, dass, weil wir nach Konvention Eigenvektoren der Länge 1 betrachten, die in <a href="#thm-eigenwerte-und-eigenvektoren-symmetrischer-matrizen" class="quarto-xref">Theorem&nbsp;<span>9.19</span></a> angesprochenen orthogonalen Eigenvektoren insbesondere auch orthonormal sind. Mithilfe von <a href="#thm-eigenwerte-und-eigenvektoren-symmetrischer-matrizen" class="quarto-xref">Theorem&nbsp;<span>9.19</span></a> können wir nun die Orthonormalzerlegung einer symmetrischen Matrix formulieren und ihre Existenz beweisen.</p>
<div id="thm-orthonormale-zerlegung-einer-symmetrischen-matrix" class="theorem">
<p><span class="theorem-title"><strong>Theorem 9.20 (Orthonormalzerlegung einer symmetrischen Matrix)</strong></span> <span class="math inline">\(S \in \mathbb{R}^{m \times m}\)</span> sei eine symmetrische Matrix mit <span class="math inline">\(m\)</span> verschiedenen Eigenwerten. Dann kannn <span class="math inline">\(S\)</span> geschrieben werden als <span class="math display">\[\begin{equation}
S = Q \Lambda Q^T,
\end{equation}\]</span> wobei <span class="math inline">\(Q \in \mathbb{R}^{m \times m}\)</span> eine orthogonale Matrix ist und <span class="math inline">\(\Lambda \in \mathbb{R}^{m\times m}\)</span> eine Diagonalmatrix ist.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Beweis</em>. </span>Es seien <span class="math inline">\(\lambda_1 &gt; \lambda_2 &gt; ... &gt; \lambda_m\)</span> die der Größe nach geordneten Eigenwerte von <span class="math inline">\(S\)</span> und <span class="math inline">\(q_1,...,q_m\)</span> die zugehörigen orthonormalen Eigenvektoren. Mit <span class="math display">\[\begin{equation}
Q :=
\begin{pmatrix*}[r]
q_1 &amp; q_2 &amp; \cdots &amp; q_m
\end{pmatrix*}
\in \mathbb{R}^{m \times m}
\mbox{ und }
\Lambda :=
\mbox{diag}\begin{pmatrix*}[r]
\lambda_1,\lambda_2,...,\lambda_m
\end{pmatrix*}
\in \mathbb{R}^{m \times m},
\end{equation}\]</span> folgt dann mit den Definitionen von Eigenwerten und Eigenvektoren zunächst, dass <span class="math display">\[\begin{equation}
Sq_i = \lambda_i q_i \mbox{ für } i = 1,...,m
\Leftrightarrow
SQ = Q\Lambda.
\end{equation}\]</span> Rechtseitige Multiplikation mit <span class="math inline">\(Q^T\)</span> ergibt dann mit <span class="math inline">\(QQ^T = I_m\)</span>, dass <span class="math display">\[\begin{equation}
SQQ^T = Q \Lambda Q^T
\Leftrightarrow SI_m = Q \Lambda Q^T
\Leftrightarrow S    = Q \Lambda Q^T.
\end{equation}\]</span></p>
</div>
<p>Man nennt das Aufspalten von <span class="math inline">\(S\)</span> in das Matrixprodukt <span class="math inline">\(Q\Lambda Q^T\)</span> aufgrund der Diagonalität von <span class="math inline">\(\Lambda\)</span> auch eine <em>Diagonalisierung von <span class="math inline">\(S\)</span></em>. Wie im Beweis gezeigt, wählt man zur Darstellung von <span class="math inline">\(S\)</span> in Diagonaldarstellung für die Diagonalelemente von <span class="math inline">\(\Lambda\)</span> die der Größe nach geordneten Eigenwerte von <span class="math inline">\(S\)</span> und für die Spalten von <span class="math inline">\(Q\)</span> die jeweils zugehörigen Eigenvektoren von <span class="math inline">\(S\)</span>. Wir verdeutlichen dies an einem Beispiel.</p>
<p><strong>Beispiel</strong></p>
<p>Für die symmetrische Matrix <span class="math display">\[\begin{equation}
A = \begin{pmatrix} 2 &amp; 1 \\ 1 &amp; 2 \end{pmatrix}
\end{equation}\]</span> mit den oben bestimmten Eigenwerten <span class="math inline">\(\lambda_1 = 3\)</span> und <span class="math inline">\(\lambda_2 = 1\)</span> sowie den zugehörigen orthonormalen Eigenvektoren <span class="math display">\[\begin{equation}
v_1 = \frac{1}{\sqrt{2}}
\begin{pmatrix*}[r]
1 \\
1
\end{pmatrix*},
v_2 = \frac{1}{\sqrt{2}}
\begin{pmatrix*}[r]
-1 \\
1
\end{pmatrix*}
\end{equation}\]</span> seien <span class="math display">\[\begin{equation}
Q := \begin{pmatrix*}[r]
v_1 &amp; v_2
\end{pmatrix*}
\mbox{ und }
\Lambda = \mbox{diag}(\lambda_1,\lambda_2).
\end{equation}\]</span> Dann ergibt sich offenbar <span class="math display">\[\begin{align*}
Q\Lambda Q^T
&amp; =
\begin{pmatrix*}[r]
v_1 &amp; v_2
\end{pmatrix*}
\mbox{diag}(\lambda_1,\lambda_2)
\begin{pmatrix*}[r]
v_1 &amp; v_2
\end{pmatrix*}^T \\
&amp; =
\left(
\frac{1}{\sqrt{2}}
\begin{pmatrix*}[r]
1 &amp; -1\\
1 &amp;  1
\end{pmatrix*}
\begin{pmatrix*}[r]
3 &amp; 0 \\
0 &amp; 1
\end{pmatrix*}
\right)
\left(
\frac{1}{\sqrt{2}}
\begin{pmatrix*}[r]
1 &amp;  1 \\
-1 &amp;  1
\end{pmatrix*}
\right)
\\
&amp; =
\left(
\frac{1}{\sqrt{2}}
\begin{pmatrix*}[r]
3 &amp; -1 \\
3 &amp;  1
\end{pmatrix*}
\right)
\left(
\frac{1}{\sqrt{2}}
\begin{pmatrix*}[r]
1 &amp;  1 \\
-1 &amp;  1
\end{pmatrix*}
\right)
\\
&amp; =
\frac{1}{2}
\begin{pmatrix*}[r]
4 &amp; 2 \\
2 &amp; 4
\end{pmatrix*} \\
&amp; =
\begin{pmatrix*}[r]
2 &amp; 1 \\
1 &amp; 2
\end{pmatrix*} \\
&amp; = A
\end{align*}\]</span> und wir haben <a href="#thm-orthonormale-zerlegung-einer-symmetrischen-matrix" class="quarto-xref">Theorem&nbsp;<span>9.20</span></a> für dieses Beispiel verifiziert.</p>
<section id="symmetrische-quadratwurzel-einer-matrix" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="symmetrische-quadratwurzel-einer-matrix">Symmetrische Quadratwurzel einer Matrix</h3>
<p>Die Definition der Orthonormalzerlegung einer symmetrischen Matrix erlaubt es, den Begriff der <em>symmetrischen Quadratwurzel einer Matrix</em> einzuführen.</p>
<div id="def-symmetrische-quadratwurzel-einer-matrix" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 9.17 (Symmetrische Quadratwurzel einer Matrix)</strong></span> <span class="math inline">\(S \in \mathbb{R}^{m \times m}\)</span> sei eine invertierbare symmetrische Matrix mit positiven Eigenwerten. Dann sind für <span class="math inline">\(r \in \mathbb{N}^0\)</span> und <span class="math inline">\(s \in \mathbb{N}\)</span> die rationalen Potenzen von <span class="math inline">\(S\)</span> mit der orthonormalen Matrix <span class="math inline">\(Q \in \mathbb{R}^{m \times m}\)</span> der Eigenvektoren von <span class="math inline">\(S\)</span> und der Diagonalmatrix <span class="math inline">\(\Lambda = \mbox{diag}(\lambda_i) \in \mathbb{R}^{m \times m}\)</span> der zugehörigen Eigenwerte <span class="math inline">\(\lambda_1,...,\lambda_m\)</span> von <span class="math inline">\(S\)</span> definiert als <span class="math display">\[\begin{equation}
S^{r/s} = Q \Lambda^{r/s} Q^T \mbox{ mit } \Lambda^{r/s} = \mbox{diag}\left(\lambda_i^{r/s}\right).
\end{equation}\]</span> Der Spezialfall <span class="math inline">\(r:= 1, s := 2\)</span> wird als <em>symmetrische Quadratwurzel von <span class="math inline">\(S\)</span></em> bezeichnet und hat die Form <span class="math display">\[\begin{equation}
S^{1/2} = Q\Lambda^{1/2}Q^T \mbox{ mit } \Lambda^{1/2} = \mbox{diag}\left(\lambda_i^{1/2}\right).
\end{equation}\]</span></p>
</div>
<p>Wir halten fest, dass mit <a href="#def-symmetrische-quadratwurzel-einer-matrix" class="quarto-xref">Definition&nbsp;<span>9.17</span></a> offenbar gilt, dass <span class="math display">\[\begin{equation}
\left(S^{1/2} \right)^2
= Q\Lambda^{1/2}Q^TQ\Lambda^{1/2}Q^T
= Q\Lambda^{1/2}\Lambda^{1/2}Q^T
= Q\Lambda Q^T
= S.
\end{equation}\]</span> Weiterhin gilt, dass <span class="math display">\[\begin{equation}
\left(S^{-1/2} \right)^2
= Q\Lambda^{-1/2}Q^TQ\Lambda^{-1/2}Q^T
= Q\Lambda^{-1/2}\Lambda^{-1/2}Q^T
= Q\Lambda^{-1}Q^T
= S^{-1}.
\end{equation}\]</span> Schließlich gilt, dass <span class="math display">\[\begin{align}
\begin{split}
S^{-1/2}SS^{-1/2}
&amp; =  Q\Lambda^{-1/2}Q^T Q\Lambda Q^T Q\Lambda^{-1/2}Q^T   \\
&amp; =  Q\Lambda^{-1/2}\Lambda \Lambda^{-1/2}Q^T             \\
&amp; =  Q\Lambda \Lambda^{-1}Q^T                             \\
&amp; =  I_m                                          
\end{split}
\end{align}\]</span></p>
</section>
</section>
<section id="sec-singulärwertzerlegung" class="level2" data-number="9.12">
<h2 data-number="9.12" class="anchored" data-anchor-id="sec-singulärwertzerlegung"><span class="header-section-number">9.12</span> Singulärwertzerlegung</h2>
<p>Eine vielseitig einsetzbare Matrixzerlegung einer beliebigen Matrix ist die <em>Singulärwertzerlegung</em>. Wir sind an dieser Stelle lediglich an dem Zusammenhang von Singulärwertzerlegung und Eigenanalyse interessiert und verweisen für eine ausführliche Diskussion der Singulärwertzerlegung auf die weiterführende Literatur, beispielsweise <span class="citation" data-cites="strang2009">Strang (<a href="#ref-strang2009" role="doc-biblioref">2009</a>)</span>. Der Begriff der Singulärwertzerlegung ist wie folgt definiert.</p>
<div id="def-singulärwertzerlegung" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 9.18 (Singulärwertzerlegung)</strong></span> <span class="math inline">\(Y \in \mathbb{R}^{m \times n}\)</span> sei eine Matrix. Dann heißt die Zerlegung <span class="math display">\[\begin{equation}
Y = USV^T,
\end{equation}\]</span> wobei <span class="math inline">\(U \in \mathbb{R}^{m \times m}\)</span> eine orthogonale Matrix ist, <span class="math inline">\(S \in \mathbb{R}^{m \times n}\)</span> eine Diagonalmatrix ist und <span class="math inline">\(V \in \mathbb{R}^{n \times n}\)</span> eine orthogonale Matrix ist, <em>Singulärwertzerlegung</em> von <span class="math inline">\(Y\)</span>. Die Diagonalelemente von <span class="math inline">\(S\)</span> heißen die <em>Singulärwerte</em> von <span class="math inline">\(Y\)</span>.</p>
</div>
<p>Singulärwertzerlegungen werden auf Englisch <em>singular value decompositions</em> genannt und entsprechend mit <em>SVD</em> abgekürzt. Wir verzichten auf eine Diskussion der Berechnung einer Singulärwertzerlegung und weisen lediglich daraufhin, dass Singulärwertzerlegungen zum Beispiel in <strong>R</strong> mit der Funktion <code>svd()</code>, in <strong>SciyPy</strong> mit <code>scipy.linalg.svd()</code> und in <strong>Julia</strong> mit <code>svd()</code> berechnet werden können. Folgendes Theorem beschreibt den Zusammenhang zwischen Singulärwertzerlegung und Eigenanalyse und wird an vielen Stellen eingesetzt.</p>
<div id="thm-singulärwertzerlegung-und-eigenanalyse" class="theorem">
<p><span class="theorem-title"><strong>Theorem 9.21 (Singulärwertzerlegung und Eigenanalyse)</strong></span> &nbsp;</p>
<span class="math inline">\(Y \in \mathbb{R}^{m \times n}\)</span> sei eine Matrix und <span class="math display">\[\begin{equation}
Y = USV^T
\end{equation}\]</span> sei ihre Singulärwertzerlegung. Dann gilt:
</div>
<div class="proof">
<p><span class="proof-title"><em>Beweis</em>. </span>Wir halten zunächst fest, dass mit <span class="math display">\[\begin{equation}
\left(YY^T\right)^T = YY^T \mbox{ und } \left(Y^TY\right)^T = Y^TY,
\end{equation}\]</span> <span class="math inline">\(YY^T\)</span> und <span class="math inline">\(Y^TY\)</span> symmetrische Matrizen sind und somit Orthornomalzerlegungen haben. Wir halten weiterhin fest, dass mit <span class="math inline">\(V^TV = I_n\)</span>, <span class="math inline">\(U^TU = I_m\)</span> und <span class="math inline">\(S^T = S\)</span> gilt, dass <span class="math display">\[\begin{equation}
YY^T
= USV^T \left(USV^T\right)^T
= USV^TVS^TU^T
= USSU^T
=: U\Lambda U^T
\end{equation}\]</span> und <span class="math display">\[\begin{equation}
Y^TY
= \left(USV^T\right)^T USV^T
= VS^TU^T US^T V^T
=: V\Lambda V^T
\end{equation}\]</span> ist, wobei wir <span class="math inline">\(\Lambda := SS\)</span> definiert haben. Weil das Produkt von Diagonalmatrizen wieder eine Diagonalmatrix ist, ist <span class="math inline">\(\Lambda\)</span> eine Diagonalmatrix und per Definition sind <span class="math inline">\(U\)</span> und <span class="math inline">\(V\)</span> orthogonale Matrizen. Wir haben also <span class="math inline">\(YY^T\)</span> und <span class="math inline">\(Y^TY\)</span> in Form der Orthonormalzerlegungen <span class="math display">\[\begin{equation}
YY^T = U \Lambda U^T  \mbox{ und } Y^TY = V \Lambda V^T
\end{equation}\]</span> geschrieben, wobei für die Diagonalelemente von <span class="math inline">\(\Lambda\)</span> gilt, dass sie die quadrierten Werte der Diagonalemente von <span class="math inline">\(S\)</span> sind.</p>
</div>
</section>
<section id="literaturhinweise-1" class="level2" data-number="9.13">
<h2 data-number="9.13" class="anchored" data-anchor-id="literaturhinweise-1"><span class="header-section-number">9.13</span> Literaturhinweise</h2>
<p>Die in diesem Kapitel behandelten Konzepte werden ausführlich zum Beispiel in <span class="citation" data-cites="searle1982">Searle (<a href="#ref-searle1982" role="doc-biblioref">1982</a>)</span> und <span class="citation" data-cites="strang2009">Strang (<a href="#ref-strang2009" role="doc-biblioref">2009</a>)</span> behandelt. Die Verwendung des Präfix <em>Eigen-</em> für die beschriebenen Vektoren und Skalare in bezug zu einer Matrix beginnt offenbar <span class="citation" data-cites="hilbert1904">Hilbert (<a href="#ref-hilbert1904" role="doc-biblioref">1904</a>)</span> im Kontext der Analyse von Integralgleichungen und hat sich auch im Englischen durchgesetzt.</p>
</section>
<section id="selbstkontrollfragen-1" class="level2" data-number="9.14">
<h2 data-number="9.14" class="anchored" data-anchor-id="selbstkontrollfragen-1"><span class="header-section-number">9.14</span> Selbstkontrollfragen</h2>
<ol type="1">
<li>Geben Sie die Definition eines Eigenvektors einer quadratischen Matrix wieder.</li>
<li>Geben Sie die Definition eines Eigenwerts einer quadratischen Matrix wieder.</li>
<li>Geben Sie das Theorem zur Bestimmung von Eigenwerten und Eigenvektoren wieder.</li>
<li>Geben Sie das Theorem zu den Eigenwerten und Eigenvektoren symmetrischer Matrizen wieder.</li>
<li>Geben Sie das Theorem zur Orthonormalzerlegung einer symmetrischen Matrix wieder.</li>
<li>Geben Sie die Definition der symmetrischen Quadratwurzel einer Matrix wieder.</li>
<li>Geben Sie die Definition einer Singulärwertzerlegung wieder.</li>
<li>Geben Sie das Theorem zum Zusammenhang von Singulärwertzerlegung und Eigenanalyse wieder.</li>
</ol>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list">
<div id="ref-burden2016" class="csl-entry" role="listitem">
Burden, R. L., Faires, J. D., &amp; Burden, A. M. (2016). <em>Numerical Analysis</em> (Tenth edition). Cengage Learning.
</div>
<div id="ref-caley1858" class="csl-entry" role="listitem">
Caley, A. (1858). A Memoir on the Theory of Matrices. <em>Philosophical Transactions of the Royal Society of London</em>, <em>148</em>, 17–37. <a href="https://doi.org/10.1098/rstl.1858.0002">https://doi.org/10.1098/rstl.1858.0002</a>
</div>
<div id="ref-golub2013" class="csl-entry" role="listitem">
Golub, G. H., &amp; Van Loan, C. F. (2013). <em>Matrix Computations</em> (Fourth edition). The Johns Hopkins University Press.
</div>
<div id="ref-hilbert1904" class="csl-entry" role="listitem">
Hilbert, D. (1904). Grundz<span>ü</span>ge Einer Allgemeinen <span>Theorie</span> Der Linearen <span>Integralgleichungen</span>. <em>Nachrichten von der Gesellschaft der Wissenschaften zu G<span>ö</span>ttingen, Mathematisch-Physikalische Klasse</em>. <a href="https://doi.org/10.1007/978-3-322-84410-1_1">https://doi.org/10.1007/978-3-322-84410-1_1</a>
</div>
<div id="ref-mardia1979" class="csl-entry" role="listitem">
Mardia, K. V., Kent, J. T., &amp; Bibby, J. M. (1979). <em>Multivariate Analysis</em>. Academic Press.
</div>
<div id="ref-richter2017" class="csl-entry" role="listitem">
Richter, T., &amp; Wick, T. (2017). <em><span>Einf<span>ü</span>hrung in die Numerische Mathematik: Begriffe, Konzepte und zahlreiche Anwendungsbeispiele</span></em>. Springer Berlin Heidelberg. <a href="https://doi.org/10.1007/978-3-662-54178-4">https://doi.org/10.1007/978-3-662-54178-4</a>
</div>
<div id="ref-searle1982" class="csl-entry" role="listitem">
Searle, S. (1982). <em>Matrix <span>Algebra Useful</span> for <span>Statistics</span></em>. Wiley-Interscience.
</div>
<div id="ref-strang2009" class="csl-entry" role="listitem">
Strang, G. (2009). <em>Introduction to <span>Linear Algebra</span></em>. Cambridge University Press.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Kopiert");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Kopiert");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./108-Vektoren.html" class="pagination-link" aria-label="Vektoren">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Vektoren</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./110-Deskriptivstatistiken.html" class="pagination-link" aria-label="Deskriptivstatistiken">
        <span class="nav-page-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Deskriptivstatistiken</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/dirk-ostwald/dirk-ostwald.github.io/tree/gh-pages/edit/main/109-Matrizen.qmd" class="toc-action"><i class="bi bi-github"></i>Seite editieren</a></li></ul></div></div></div></footer></body></html>