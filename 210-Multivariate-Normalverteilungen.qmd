# Multivariate Normalverteilungen {#sec-multivariate-normalverteilungen}
\normalsize

Die multivariate Normalverteilung ist die multivariate Generalisierung der 
univariaten Normalverteilung. Die Motivation für die verbreiteten 
Normalverteilungsannahmen in der probabilistischen Modellierung liegt bekanntermaßen
im Zentralen Grenzwertsatz: In probabilistischen Modellen repräsentieren probabilistische 
Terme die Summation sehr vieler Zufallsvorgänge, die durch die deterministischen Bestandteile 
des jeweiligen Modells, also eine formalisierte wissenschaftliche Theorie, nicht 
erklärt werden. Nach dem Zentralen Grenzwertsatz ist die Summe dieser nicht erklärten
Zufallsvorgänge dann aber gerade normalverteilt. 

Über diesen grundlegenden Aspekt hinaus hat die Normalverteilung viele günstige 
mathematische Eigenschaften, die ihren Einsatz in vielen Bereichen der probabilistischen 
Modellierung ermöglichen. Anwendungen multivariater Normalverteilungen finden 
sich damit im Kontext des Allgemeinen Linearen Modells, den Generalisierungen 
des Allgemeinen Modells zu Hierarchischen Linearen Modellen oder Multivariaten 
Allgemeinen Linearen Modellen, der Bayesianischen Inferenz bei Normalverteilungsannahmen
und nicht zuletzt der Theorie probabilistischer Filter, wie zum Beispiel 
dem Kalman-Bucy Filter. 

## Konstruktion

In diesem Abschnitt wollen wir zeigen, wie ein bivariat normalverteilter Zufallsvektor 
durch Transformation und Konkatenation zweier univariat normalverteilter 
Zufallsvariablen konstruiert werden kann. Dazu erinnern wir zunächst an den 
Begriff der normalverteilten Zufallsvariable

:::{#def-normalverteilte-zufallsvariable}
## Normalverteilte Zufallsvariable
$\xi$ sei eine Zufallsvariable mit Ergebnisraum $\mathbb{R}$ und WDF
\begin{equation}
p : \mathbb{R} \to \mathbb{R}_{>0}, x\mapsto p(x)
:= \frac{1}{\sqrt{2\pi \sigma^2}}\exp\left(-\frac{1}{2\sigma^2}(x - \mu)^2\right).
\end{equation}
Dann sagen wir, dass $\xi$ einer *Normalverteilung (oder  Gauß-Verteilung)* mit 
*Erwartungswertparameter $\mu \in \mathbb{R}$* und *Varianzparameter $\sigma^2 > 0$* 
unterliegt und nennen $\xi$ eine *normalverteilte Zufallsvariable*. Wir kürzen dies 
mit $\xi \sim N(\mu,\sigma^2)$ ab. Die WDF einer normalverteilten Zufallsvariable 
bezeichnen wir mit
\begin{equation}
N\left(x;\mu,\sigma^2\right) := \frac{1}{\sqrt{2\pi \sigma^2}}\exp\left(-\frac{1}{2\sigma^2}(x - \mu)^2\right).
\end{equation}
:::

```{r, echo = F, eval = F}
library(latex2exp)
pdf(
file        = file.path("./_figures/210-univariate-normal-wdf.pdf"),
width       = 9,
height      = 3)
par(                                                                    
mfcol      = c(1,3),                                           
family     = "sans",                                                   
pty        = "s",                                                       
bty        = "l",                                                       
lwd        = 1,                                                         
las        = 1,                                                         
mgp        = c(2,1,0),                                                  
font.main  = 1,                                                         
cex.main   = 1.4)                                                        
 
# model formulation
x_min   = -10                                                                    # minimum x-value
x_max   = 10                                                                     # maximum x-value
x_res   = 1e3                                                                    # x space resolution
x       = seq(x_min,x_max,len = x_res)                                           # x space
mu      = c(0,-2.5,3)                                                            # expectation parameters
sigsqr  = c(1,10,0.5)                                                            # variance parameters

# parameter iterations
for (i in 1:length(mu)){

  # Gaussian PDFs
  plot(
       x,                                                                        # x values
       dnorm(x,mu[i],sqrt(sigsqr[i])),                                           # y values
       type         = "l",                                                       # line style
       lwd          =  1.5,                                                      # line width
       col          = "Black",                                                   # line color
       ylab         = " ",                                                       # no y-axis label
       xlab         = "x",                                                       # x-axis label
       ylim         = c(0,0.6))                                                  # y-axis limits
  title(sprintf("N(x; %g,%g)", mu[i], sigsqr[i]))                                # plot title, print formatted data to string
}
dev.off()
```

![Wahrscheinlichkeitsdichtefunktionen univariater Normalverteilungen.](./_figures/210-univariate-normal-wdf){#fig-univariate-normal-wdf fig-align="center" width=100%} 

Visuell entspricht der Parameter $\mu$ einer normalverteilten Zufallsvariable 
dem Wert höchster Wahrscheinlichkeitsdichte und der Parameter $\sigma^2$ spezifiziert 
die Breite der WDF (@fig-univariate-normal-wdf). Weiterhin gelten für den 
Erwartungswert und die Varianz einer normalverteilten Zufallsvariable bekanntlich
\begin{equation}
\mathbb{E}(\xi) = \mu \mbox{ und } \mathbb{V}(\xi) = \sigma^2.
\end{equation}
Eine normalverteilte Zufallsvariable der Form $\xi \sim N(0,1)$ schließlich 
heißt auch *standardnormalverteilt*.

Folgendes Theorem zeigt, wie zwei unabhängige, univariat standardnormalverteilte Zufallsvariablen
kombiniert werden können, um einen bivariat verteilten Zufallsvektor zu konstruieren.
Die Verteilung eines ebensolchen Zufallsvektors wird dann als *bivariate Normalverteilung*
bezeichnet. 
    
:::{#thm-konstruktion-bivariater-normalverteilungen}
## Konstruktion bivariater Normalverteilungen
$\zeta_1 \sim N(0,1)$ und $\zeta_2 \sim N(0,1)$ seien zwei unabhängige
standardnormalverteilte  Zufallsvariablen. Weiterhin seien $\mu_1,\mu_2\in \mathbb{R}$,
$\sigma_1,\sigma_2>0$ und $\rho \in ]-1,1[$. Schließlich seien
\begin{align}
\begin{split}
\xi_1 & := \sigma_1\zeta_1 + \mu_1                                            \\
\xi_2 & := \sigma_2\left(\rho\zeta_1 + (1 -\rho^2)^{1/2}\zeta_2\right) + \mu_2.
\end{split}
\end{align}
Dann hat die WDF des Zufallsvektors $\xi := (\xi_1,\xi_2)^T$, also der gemeinsamen
Verteilung von $\xi_1$ und $\xi_2$, die Form
\begin{equation}
p : \mathbb{R}^2 \to \mathbb{R}_{>0},\, x \mapsto p(x) := (2\pi)^{-\frac{n}{2}}|\Sigma|^{-\frac{1}{2}}\exp\left(-\frac{1}{2}(x-\mu)^T \Sigma^{-1} (x-\mu)\right),
\end{equation}
wobei $n:=2$ und $\mu \in \mathbb{R}^{2}$ und  $\Sigma \in \mathbb{R}^{2\times 2}$ durch
\begin{equation}
\mu = 
\begin{pmatrix}
\mu_1 \\
\mu_2
\end{pmatrix}
\mbox{ und }
\Sigma =
\begin{pmatrix}
\sigma_1^2           & \rho\sigma_1\sigma_2 \\
\rho\sigma_2\sigma_1 & \sigma_2^2           \\
\end{pmatrix}
\end{equation}
gegeben sind.
:::
Für einen Beweis des Theorems verweisen wir auf @degroot2012.

**Beispiel**

Folgender **R** Code zeichnet das obige Theorem anhand konkreter Beispielwerte
für $\mu_1,\mu_2,\sigma_1,\sigma_2$ und $\rho$ nach und gibt die Parameter
$\mu$ und $\Sigma$ der resultierenden bivariaten WDF aus.

\tiny
```{r}
# Parameterdefinitionen
mu_1   = 5.0                                              # \mu_1
mu_2   = 4.0                                              # \mu_2
sig_1  = 1.5                                              # \sigma_1
sig_2  = 1.0                                              # \sigma_2
rho    = 0.9                                              # \rho

# Realisierungen der standardnormalverteilten ZVen
n      = 100                                              # Anzahl Realisierungen
zeta_1 = rnorm(n)                                         # \zeta_1 \sim N(0,1)
zeta_2 = rnorm(n)                                         # \zeta_1 \sim N(0,1)

# Evaluation von Realisierungen von \xi_1 und \xi_2
xi_1   = sig_1*zeta_1 + mu_1                              # Realsierungen von zeta_1
xi_2   = sig_2*(rho*zeta_1 + sqrt(1-rho^2)*zeta_2) + mu_2 # Realsierungen von zeta_2

# Parameter der gemeinsamen Verteilung von \xi_1 und \xi_2
mu     = matrix(c(mu_1,                                   # \mu \in \mathbb{R}^2
                  mu_2),
                 nrow = 2, byrow = TRUE)
Sigma  = matrix(c(sig_1^2        , rho*sig_1*sig_2,       # \Sigma \in \mathbb{R}^{2 x 2}
                 rho*sig_1*sig_2, sig_2^2),
                 nrow = 2, byrow = TRUE)
print(mu)
print(Sigma)
```
\normalsize

Die durch obigen **R** Code generierten Realisierungen von $\xi = (\xi_1,\xi_2)^T$,
sowie die Isokonturen der durch @thm-konstruktion-bivariater-normalverteilungen
postulierten WDF sind in @fig-konstruktion dargestellt.

```{r echo = F, eval = F}
library(latex2exp)
library(mvtnorm)
pdf(
file        = file.path("./_figures/210-konstruktion.pdf"),
width       = 3.5,
height      = 3.5)
par(
family      = "sans",
mfcol       = c(1,1),
pty         = "s",
bty         = "l",
lwd         = 1,
las         = 1,
mgp         = c(2,1,0),
xaxs        = "i",
yaxs        = "i",
font.main   = 1,
cex         = .8,
cex.main    = 1)

# Visualisierung
x_min       = 0
x_max       = 10
x_res       = 1e3
x_1         = seq(x_min, x_max, length.out = x_res)
x_2         = seq(x_min, x_max, length.out = x_res)
X           = expand.grid(x_1,x_2)
p           = matrix(dmvnorm(as.matrix(X), mu, Sigma), nrow = x_res)
contour(
x_1,
x_2,
p,
xlim        = c(x_min,x_max),
ylim        = c(x_min,x_max),
xlab        = TeX("$x_1$"),
ylab        = TeX("$x_2$"),
nlevels     = 5)
points(
xi_1,
xi_2,
pch         = 21,
col         = "white",
bg          = "gray60",
cex         = .9)
dev.off()
```
![Konstruktion bivariater Normalverteilungen.](./_figures/210-konstruktion){#fig-konstruktion fig-align="center" width=50%}


```{r echo = F, eval = F}
library(latex2exp)
library(mvtnorm)
pdf(
file        = file.path("./_figures/210-bivariate-normal-wdf.pdf"),
width       = 9,
height      = 3)
par(
family      = "sans",
mfcol       = c(1,3),
pty         = "s",
bty         = "l",
lwd         = 1,
las         = 1,
mgp         = c(2,1,0),
xaxs        = "i",
yaxs        = "i",
font.main   = 1)

# Ergebnisraumdefintion
x_min  = 0                                           # x_i Minimum
x_max  = 2                                           # x_i Maxim
x_res  = 1e3                                         # x_i Auflösung
x_1    = seq(x_min, x_max, length.out = x_res)       # x_1 Raum
x_2    = seq(x_min, x_max, length.out = x_res)       # x_2 Raum
X      = expand.grid(x_1,x_2)                        # X = (x_1,x_2)^T Raum

# Parameterdefinition
mu     = c(1,1)                                      # \mu \in \mathbb{R}^2
S      = list(matrix(c(0.2,  0.15,  0.15, 0.2), 2),  # \Sigma in \mathbb{R}^{2 \times 2}
              matrix(c(0.2,  0.00,  0.00, 0.2), 2),  # \Sigma in \mathbb{R}^{2 \times 2}
              matrix(c(0.2, -0.15, -0.15, 0.2), 2))  # \Sigma in \mathbb{R}^{2 \times 2}

# Kovarianzparametervariantenschleife
i = 1
for (Sigma in S){

  # Wahrscheinlichkeitsdichtefunktionauswertung
  p      = matrix(                                   # Matrixkonversion des von
                  dmvnorm(as.matrix(X), mu, Sigma),  # dmvnorm() ausgegebenen Vektors
                  nrow = x_res)

  # Visualisierung
  contour(
  x_1,
  x_2,
  p,
  xlim  = c(x_min,x_max),
  ylim  = c(x_min,x_max),
  xlab  = TeX("$x_1$"),
  ylab  = TeX("$x_2$"),
  nlevels   = 5)
  mtext(LETTERS[i], adj=1, line=1, cex = 1.2, at = -.5)
  i = i + 1
}
dev.off()
```
![Wahrscheinlichkeitsdichtefunktionen bivariater Normalverteilungen.](./_figures/210-bivariate-normal-wdf){#fig-bivariate-normal-wdf fig-align="center" width=100%}


```{r, eval = F, echo = F}
library(mvtnorm)
library(latex2exp)
pdf(
file        = file.path("./_figures/210-gemeinsame-normalverteilungen.pdf"),
width       = 9,
height      = 4.5)
par(
family      = "sans",
mfcol       = c(1,3),
pty         = "s",
bty         = "l",
lwd         = 1,
las         = 1,
mgp         = c(2,1,0),
xaxs        = "i",
yaxs        = "i",
font.main   = 1,
cex         = .9,
cex.main    = 1)

# Ergebnisraumdefintion
x_min  = -1                                          # x_i Minimum
x_max  = 4                                           # x_i Maxim
x_res  = 1e3                                         # x_i Auflösung
x      = seq(x_min, x_max, length.out = x_res)       # x_1 Raum
y      = seq(x_min, x_max, length.out = x_res)       # x_2 Raum
xy     = expand.grid(x,y)                        # X = (x_1,x_2)^T Raum

# Parameterdefinition
mu_x      = 1                                        # \mu \in \mathbb{R}
Sigma_xx  = 0.2                                      # \Sigma_xx in \mathbb{R}
A         = 1                                        # A
b         = 1                                        # b
Sigma_yy  = 0.1                                      # \Sigma_yy

mu_xy     = c(mu_x, A*mu_x + b)
Sigma_xy  = matrix(c(Sigma_xx  , Sigma_xx*t(A),
                     A*Sigma_xx, Sigma_yy + A*Sigma_xx*t(A)),
                   nrow = 2,
                   byrow = TRUE)


# Visualisierung marginale Verteilung
plot(
x,
dnorm(x, mu_x, sqrt(Sigma_xx)),
type = "l",
xlab = TeX("$x$"),
ylim = c(0,2),
ylab = "",
main = TeX("$p(x) = N(x;\\mu_\\xi,\\Sigma_{\\xi\\xi})$"))
mtext(LETTERS[1], adj=1, line=2, cex = 1.5, at = -1.5)

# Visualisierung bedingte Verteilung
plot(
y,
dnorm(y, A*1 + b, sqrt(Sigma_yy)),
type = "l",
xlab = TeX("$y$"),
ylim = c(0,2),
ylab = "",
main = TeX("$p(y|x) = N(y; Ax + b, \\Sigma_{\\upsilon\\upsilon})$"))
text(0,1.75, TeX("$x = 1$"), cex = 1.2)
mtext(LETTERS[2], adj=1, line=2, cex = 1.5, at = -1.5)


# Visualisierung gemeinsame Verteilung
p_xy    = matrix(                                           # Matrixkonversion des von
                dmvnorm(as.matrix(xy), mu_xy, Sigma_xy),    # dmvnorm() ausgegebenen Vektors
                nrow = x_res)
contour(
x,
y,
p_xy,
xlim      = c(x_min,x_max),
ylim      = c(x_min,x_max),
xlab      = TeX("$x$"),
ylab      = TeX("$y$"),
main      = TeX("$p((x,y)^T) = N((x,y)^T; \\mu_{\\xi,\\upsilon},\\Sigma_{\\xi,\\upsilon})$"),
nlevels   = 5)
mtext(LETTERS[3], adj=1, line=2, cex = 1.5, at = -1.5)
dev.off()
```

```{r, eval = F, echo = F}
library(mvtnorm)
library(latex2exp())
pdf(
file        = file.path("./_figures/210-bedingte-normalverteilungen.pdf"),
width       = 10,
height      = 3.33)
par(
family      = "sans",
mfcol       = c(1,3),
pty         = "s",
bty         = "l",
lwd         = 1,
las         = 1,
mgp         = c(2,1,0),
xaxs        = "i",
yaxs        = "i",
font.main   = 1,
cex         = .8,
cex.main    = 1)

# Ergebnisraumdefintion
x_min  = 0                                           # x_i Minimum
x_max  = 4                                           # x_i Maxim
x_res  = 1e3                                         # x_i Auflösung
x      = seq(x_min, x_max, length.out = x_res)       # x Raum
y      = seq(x_min, x_max, length.out = x_res)        # y Raum
X      = expand.grid(x,y)                            # (x,y)^T Raum

# Parameterdefinition
mu     = c(1,2)                                      # \mu \in \mathbb{R}^2
Sigma  = matrix(c(0.12, 0.09,
                  0.09, 0.12),
                nrow = 2,
                byrow = TRUE)                        # \Sigma in \mathbb{R}^{2 \times 2}

# Visualisierung gemeinsame Verteilung
p      = matrix(                                     # Matrixkonversion des von
                dmvnorm(as.matrix(X), mu, Sigma),    # dmvnorm() ausgegebenen Vektors
                nrow = x_res)
contour(
x,
y,
p,
xlim      = c(x_min,x_max),
ylim      = c(x_min,x_max),
xlab      = TeX("$x$"),
ylab      = TeX("$y$"),
main      = TeX("$p(x,y) = N((x,y)^T; \\mu_{\\xi,\\upsilon},\\Sigma_{\\xi,\\upsilon})$"),
nlevels   = 8)
abline(1.5,0)
abline(2.5,0)
text(3.5,1, TeX("$y = 1.5$"))
text(3.5,3, TeX("$y = 2.8$"))
mtext(LETTERS[1], adj=1, line=2, cex = 1.5, at = -.8)

# Visualsierung bedingter Verteilung
plot(
x,
dnorm(x, mu_x + Sigma[1,2]*(1/Sigma[2,2])*(1.5 - mu[2]),sqrt(Sigma[1,1] - Sigma[1,2]*(1/Sigma[2,2]*Sigma[2,1]))),
type = "l",
xlim = c(x_min,x_max),
ylim = c(0,2),
xlab = TeX("$x$"),
ylab = "",
main = TeX("$p(x|y) = N(x; \\mu_{\\xi|\\upsilon},\\Sigma_{\\xi|\\upsilon})$"))
text(3.5,1.8, TeX("$y = 1.5$"))
mtext(LETTERS[2], adj=1, line=2, cex = 1.5, at = -.8)

# Visualsierung bedingter Verteilung
plot(
x,
dnorm(x, mu_x + Sigma[1,2]*(1/Sigma[2,2])*(2.8 - mu[2]),sqrt(Sigma[1,1] - Sigma[1,2]*(1/Sigma[2,2]*Sigma[2,1]))),
type = "l",
xlim = c(x_min,x_max),
ylim = c(0,2),
xlab = TeX("$x$"),
ylab = "",
main = TeX("$p(x|y) = N(x; \\mu_{\\xi|\\upsilon},\\Sigma_{\\xi|\\upsilon})$"))
text(3.5,1.8, TeX("$y = 2.8$"))
mtext(LETTERS[3], adj=1, line=2, cex = 1.5, at = -.8)
dev.off()
```

## Definition 

Wir wollen die multivariate Normalverteilung nun formal einführen und erste 
Eigenschaften angeben. Wir nutzen dazu folgende Definition.

:::{#def-multivariate-normalverteilung}
$\xi$ sei ein $n$-dimensionaler Zufallsvektor mit Ergebnisraum $\mathbb{R}^n$ und WDF
\begin{equation}
p : \mathbb{R}^n \to \mathbb{R}_{>0},\, x \mapsto p(x) := (2\pi)^{-\frac{n}{2}}|\Sigma|^{-\frac{1}{2}}\exp\left(-\frac{1}{2}(x-\mu)^T \Sigma^{-1} (x-\mu)\right).
\end{equation}
Dann sagen wird, dass $\xi$ einer *multivariaten (oder $n$-dimensionalen)
Normalverteilung* mit *Erwartungswertparameter* $\mu \in \mathbb{R}^n$ und
positiv-definitem *Kovarianzmatrixparameter* $\Sigma \in \mathbb{R}^{n \times n}$
unterliegt und nennen $\xi$ einen *(multivariat) normalverteilten Zufallsvektor*.
Wir kürzen dies mit $\xi \sim N(\mu,\Sigma)$ ab. Die WDF eines multivariat
normalverteilten Zufallsvektors bezeichnen wir mit
\begin{equation}
N(x;\mu,\Sigma):= (2\pi)^{-\frac{n}{2}}|\Sigma|^{-\frac{1}{2}}\exp\left(-\frac{1}{2}(x-\mu)^T \Sigma^{-1} (x-\mu)\right).
\end{equation}
:::

@fig-bivariate-normal-wdf A,B,C zeigen die Isokonturen der WDFen bivariat normlaverteilter
Zufallsvektoren für $\mu = (1,1)^T$ und
\begin{equation}
\Sigma_A := \begin{pmatrix} 0.20 &  0.15  \\   0.15 & 0.20 \end{pmatrix}, \quad
\Sigma_B := \begin{pmatrix} 0.20 &  0.00  \\   0.00 & 0.20 \end{pmatrix}, \quad
\Sigma_C := \begin{pmatrix} 0.20 &  -0.15 \\  -0.15 & 0.20 \end{pmatrix}
\end{equation}
respektive. @fig-bivariate-normal-realisierungen A-C zeigen jeweils 200 Realisierungen
der entsprechenden Zufallsvektoren.

```{r echo = F, eval = F}
library(latex2exp)
library(mvtnorm)

# Modellformulierung
mu     = c(1,1)                                # \mu \in \mathbb{R}^2
Sigma  = matrix(c(0.2,  0.15,  0.15, 0.2), 2)  # \Sigma in \mathbb{R}^{2 \times 2}

# Abbildungsparameter
pdf(
file        = file.path("./_figures/210-bivariate-normal-realisierungen.pdf"),
width       = 9,
height      = 3)
par(
family      = "sans",
mfcol       = c(1,3),
pty         = "s",
bty         = "l",
lwd         = 1,
las         = 1,
mgp         = c(2,1,0),
xaxs        = "i",
yaxs        = "i",
font.main   = 1,
cex         = .7,
cex.main    = 1.2)

# Parameterdefinition
mu     = c(1,1)                                      # \mu \in \mathbb{R}^2
S      = list(matrix(c(0.2,  0.15,  0.15, 0.2), 2),  # \Sigma in \mathbb{R}^{2 \times 2}
              matrix(c(0.2,  0.00,  0.00, 0.2), 2),  # \Sigma in \mathbb{R}^{2 \times 2}
              matrix(c(0.2, -0.15, -0.15, 0.2), 2))  # \Sigma in \mathbb{R}^{2 \times 2}

# Kovarianzparametervariantenschleife
i = 1
for (Sigma in S){

  # Zufallsvektorrealisierungen
  samples = rmvnorm(n = 200, mu, Sigma)

  # Visualisierung
  plot(
  samples,
  xlim  = c(0,2),
  ylim  = c(0,2),
  xlab  = TeX("$x_1$"),
  ylab  = TeX("$x_2$"),
  pch   = 21,
  col   = "white",
  bg    = "gray60")
  mtext(LETTERS[i], adj=1, line=1, cex = 1.2, at = -.5)
  i = i + 1
}
dev.off()
```

![Realisierungen bivariat normalverteilter Zufallsvektoren.](./_figures/210-bivariate-normal-realisierungen){#fig-bivariate-normal-realisierungen fig-align="center" width=100%}

Ohne Beweis halten wir fest, dass wie im Fall einer univariat normalverteilten
Zufallsvariable, der Erwartungswert und die Kovarianzmatrix eines normalverteilten
Zufallsvektors durch die entsprechenden Parameter gegeben sind.

:::{#thm-erwartungswert-und-kovarianzmatrix-normalverteilter-zufallsvektoren}
## Erwartungswert und Kovarianzmatrix normalverteilter Zufallsvektoren
$\xi \sim N(\mu,\Sigma)$ sei ein multivariat normalverteilter Zufallsvektor mit
Erwartungswertparameter $\mu \in \mathbb{R}^n$ und Kovarianzmatrixparameter 
$\Sigma \in \mathbb{R}^{n \times n} \mbox{ pd}$.
Dann gelten
\begin{equation}
\mathbb{E}(\xi) = \mu \mbox{ und } \mathbb{C}(\xi) = \Sigma.
\end{equation}
:::

Wie im Falle der univariat normalverteilten Zufallsvariable entspricht der 
Parameter $\mu \in \mathbb{R}^n$  dem Wert höchster Wahrscheinlichkeitsdichte
der multivariaten Normalverteilung. Analog zum Varianzparameter der univariat 
normalverteilten Zufallsvariable spezifizieren die  Diagonalelemente von 
$\Sigma \in \mathbb{R}^{n \times n} \mbox{ pd}$ die Breite der WDF bezüglich der
Zufallsvektorkomponenten $\xi_1,...,\xi_n$. Allgemein spezifiziert im Falle des 
multivariat normalverteilten Zufallsvektors das $i,j$te Element von 
$\Sigma \in \mathbb{R}^{n \times n} \mbox{ pd}$ hier nun die Kovarianz der 
Zufallsvektorkomponenten $\xi_i$ und $\xi_j$.

## Transformationen

In diesem Abschnitt stellen wir einige Resultate zu den Verteilungen
transformierter normalverteilter Zufallsvektoren zusammen. Wir verzichten
dabei auf Beweise.
    
:::{#thm-invertierbare-lineare-transformation}
## Invertierbare lineare Transformation eines normalverteilten Zufallsvektors
$\xi \sim N(\mu_\xi,\Sigma_\xi)$ sei ein normalverteilter $n$-dimensionaler Zufallsvektor
und es sei $\zeta := A\xi$ mit einer invertierbaren Matrix $A \in \mathbb{R}^{n \times n}$.
Dann gilt
\begin{equation}
\zeta \sim N\left(\mu_\zeta, \Sigma_\zeta\right) 
\mbox{ mit } 
\mu_\zeta = A\mu_\xi \mbox{ und } 
\Sigma_\zeta = A\Sigma_\xi A^T.
\end{equation}
:::

Nach @thm-invertierbare-lineare-transformation ergibt die invertierbare lineare 
Transformation eines multivariat normalverteilten Zuallsvektors also wiederum einen
multivariat normalverteilten Zufallsvektor und die Parameter der Verteilung
dieses normalverteilten Zufallsvektors ergeben sich aus den Parametern der Verteilung
des ursprünglichen Zufallsvektors und der Transformationsmatrix.

\newpage
**Beispiel**

Als Beispiel betrachten wir die invertierbare lineare Transformation eines
bivariaten normalverteilten Zufallsvektors $\xi$. Es seien 
\begin{equation}
\mu_\xi := \begin{pmatrix} 1 \\ 1 \end{pmatrix}
\mbox{ und }
\Sigma_\xi := \begin{pmatrix} 0.20 & 0.15 \\ 0.15 & 0.20 \end{pmatrix}
\end{equation}
der Erwartungswert- und Kovarianzmatrixparameter von $\xi$, respektive, und es sei
\begin{equation}
A := \begin{pmatrix} -2 & 1 \\ - 1 & 2 \end{pmatrix}
\end{equation}
die Transformationsmatrix. Da $|A| = -3 \neq 0$ ist $A$ invertierbar und es 
gilt nach @thm-invertierbare-lineare-transformation, dass
\begin{equation}
\zeta \sim N(\mu_\zeta,\Sigma_\zeta) \mbox{ mit }
\mu_\zeta = A\mu_\xi = \begin{pmatrix} -1 \\ 1 \end{pmatrix}
\mbox{ und }
A\Sigma_\xi A^T = \begin{pmatrix} 0.40 & 0.05 \\ 0.05 & 0.40 \end{pmatrix}.
\end{equation}
@fig-lineare-transformation A zeigt Isokonturen der WDF von $\xi$ und Realisierungen 
$x^{(i)} \in \mathbb{R}^2$ von $\xi$ für $i = 1,...,50$. @fig-lineare-transformation B
zeigt die transfomierten Realisierungen $z^{(i)} = Ax^{(i)} \in \mathbb{R}^{2}$
von $\zeta$ sowie die Isokonturen der WDF von $\zeta$ nach @thm-invertierbare-lineare-transformation.

```{r, eval = F, echo = F}
library(latex2exp)
library(mvtnorm)
pdf(
file        = file.path("./_figures/210-lineare-transformation.pdf"),
width       = 8,
height      = 4)
par(
family      = "sans",
mfcol       = c(1,2),
pty         = "s",
bty         = "l",
lwd         = 1,
las         = 1,
mgp         = c(2,1,0),
xaxs        = "i",
yaxs        = "i",
font.main   = 1,
cex         = 1,
cex.main    = 1)

# x-Modell
z_nin  = -3                                                                     # x_i Minimum
z_nax  = 3                                                                      # x_i Maximum
x_res  = 1e3                                                                    # x_i Auflösung
x_1    = seq(z_nin, z_nax, length.out = x_res)                                  # x_1 Raum
x_2    = seq(z_nin, z_nax, length.out = x_res)                                  # x_2 Raum
x      = expand.grid(x_1,x_2)                                                   # x = (x_1,x_2)^T Raum
mu     = c(1,1)                                                                 # \mu \in \mathbb{R}^2
Sigma  = matrix(c(0.2,  0.15,  0.15, 0.2), 2)                                   # \Sigma in \mathbb{R}^{2 \times 2}
px     = matrix(dmvnorm(as.matrix(x), mu, Sigma), nrow = x_res)                 # x \sim N(\mu,\Sigma)
xi     = rmvnorm(n = 50, mu, Sigma)                                             # Realisierungen
contour(
x_1,
x_2,
px,
xlim      = c(z_nin,z_nax),
ylim      = c(z_nin,z_nax),
xlab      = TeX("$x_1$"),
ylab      = TeX("$x_2$"),
levels    = c(0.9,0.7,0.5,0.3,0.1),
main      = TeX("$\\xi \\sim N(\\mu_\\xi,\\Sigma_\\xi)$"))
points(
xi,
pch   = 21,
col   = "white",
bg    = "gray60",
cex   = 1)
mtext(LETTERS[1], adj=1, line=2, cex = 1.5, at = -4)

# y-Modell
A      = matrix(c(-2,1,-1,2), nrow = 2, byrow = TRUE)                           # Transformationsmatrix
z_nin  = -3                                                                     # z_i Minimum
z_nax  =  3                                                                     # z_i Maximum
z_res  = 1e3                                                                    # z_i Auflösung
z_1    = seq(z_nin, z_nax, length.out = z_res)                                  # z_1 Raum
z_2    = seq(z_nin, z_nax, length.out = z_res)                                  # z_2 Raum
z      = expand.grid(z_1,z_2)                                                   # z = (z_1,z_2)^T Raum
pz     = matrix(dmvnorm(as.matrix(z), A%*%mu, A%*%Sigma%*%t(A)), nrow = z_res)  # \zeta \sim N(A\mu,A\SigmaA^T)
ups    = t(A %*% t(xi))                                                         # Realisierungen
contour(
z_1,
z_2,
pz,
xlim      = c(z_nin,z_nax),
ylim      = c(z_nin,z_nax),
xlab      = TeX("$z_1$"),
ylab      = TeX("$z_2$"),
levels    = c(0.9,0.7,0.5,0.3,0.1),
main      = TeX("$\\zeta \\sim N(A\\mu_\\xi,A\\Sigma_\\xi A^T)$"))
points(
ups,
pch   = 21,
col   = "white",
bg    = "gray60",
cex   = 1)
mtext(LETTERS[2], adj=1, line=2, cex = 1.5, at = -4)
dev.off()
print(A)
print(A%*%mu)
print(A%*%Sigma%*%t(A))
```

![Invertierbare lineare Transformation eines normalverteilten Zufallsvektors](./_figures/210-lineare-transformation){#fig-lineare-transformation fig-align="center" width=100%}

Die Tatsache, dass ein linear transfomierter normalverteilter Zufallsvektor wiederum
normalverteilt ist und dass sich die Parameter der Verteilung des transformierten Zufallsvektors
aus den Parametern der Verteilung des ursprünglichen Zufallsvektors sowie den Transformationsparametern
bestimmen lassen, bleibt auch im Falle einer nicht notwendigerweise invertierbaren
linearen Transformation und auch im Falle einer nicht notwendigerweise invertierbaren
linear-affinen Transformation wahr. Dies ist die Aussage folgenden zentralen Theorems.
Für einen Beweis verweisen wir auf @anderson2003. 

:::{#thm-linear-affine-transformation}
## Linear-affine Transformation eines normalverteilten Zufallsvektors
$\xi \sim N(\mu_\xi,\Sigma_\xi)$ sei ein normalverteilter $n$-dimensionaler Zufallsvektor
und es sei 
\begin{equation}
\zeta := Ax + b \mbox{ mit } A \in \mathbb{R}^{m \times n} \mbox{ und } b \in \mathbb{R}^m.
\end{equation}
Dann gilt
\begin{equation}
\zeta \sim N(\mu_\zeta, \Sigma_\zeta) 
\mbox{ mit } 
\mu_\zeta    = A\mu + b \in \mathbb{R}^m \mbox{ und } 
\Sigma_\zeta = A\Sigma A^T \in \mathbb{R}^{m \times m}.
\end{equation}
:::

## Sphärizität

Folgendes Theorem ist für die grundlegende Theorie des Allgemeinen Linearen Modells zentral.

:::{#thm-sphärizität}
## Sphärische multivariate Normalverteilung
Für $i = 1,...,n$ seien $N(x_i; \mu_i,\sigma^2)$ die WDFen von $n$ unabhängigen
univariaten normalverteilten Zufallsvariablen $\xi_1,...,\xi_n$ mit $\mu_1,...,\mu_n \in \mathbb{R}$
und $\sigma^2 > 0$. Weiterhin sei $N(x;\mu,\sigma^2I_n)$ die WDF eines $n$-variaten
normalverteilten Zufallsvektors $\xi$ mit Erwartungswertparameter $\mu := (\mu_1,...,\mu_n)^T \in \mathbb{R}^n$.
Dann gilt 
\begin{equation}
p_\xi(x) = p_{\xi_1,...,\xi_n}(x_1,...,x_n) = \prod_{i=1}^n p_{\xi_i}(x_i)
\end{equation}
und insbesondere
\begin{equation}
N\left(x;\mu,\sigma^2I_n\right) = \prod_{i=1}^n N\left(x_i;\mu_i,\sigma^2\right) 
\end{equation}
für alle $x = (x_1,...,x_n)^T \in \mathbb{R}^n$.
:::

:::{.proof}
Wir zeigen die Identität der multivariaten WDF $N(x;\mu,\sigma^2 I_n)$ mit dem
Produkt von $n$ univariaten WDFen $N(x_i;\mu_i,\sigma^2 I_n)$, wobei $\mu_i$
der $i$te Eintrag von $\mu \in \mathbb{R}^n$ ist. Es ergibt sich
\begin{align}
\begin{split}
N\left(x;\mu,\sigma^{2}I_{n} \right)
& = \left(2\pi \right)^{-\frac{n}{2}}
	\left|\sigma^2 I_n \right|^{-\frac{1}{2}}
	\exp\left(-\frac{1}{2}(x-\mu)^{T}(\sigma^2 I_n)^{-1}(x-\mu)\right)\\
& = \left(\prod_{i=1}^n 2\pi ^{-\frac{1}{2}} \right)
	\left(\sigma^2\right)^{-\frac{n}{2}}
	\exp\left(-\frac{1}{2\sigma^2}(x-\mu)^{T}(x-\mu)\right) \\
& = \left(\prod_{i=1}^n \left(2\pi\sigma^2 \right) ^{-\frac{1}{2}} \right)
	\exp\left(-\frac{1}{2\sigma^2} \sum_{i=1}^n (x_i - \mu_i)^2\right) \\
& = \prod_{i=1}^n \frac{1}{\sqrt{2\pi\sigma^2}}
	\prod_{i=1}^n \exp\left(-\frac{1}{2\sigma^2} (x_i - \mu_i)^2\right) \\
& = \prod_{i=1}^n \frac{1}{\sqrt{2\pi\sigma^2}}
	 				\exp\left(-\frac{1}{2\sigma^2} (x_i - \mu_i)^2\right) \\
& = \prod_{i=1}^n N\left(x_i; \mu_i,\sigma^2\right).
\end{split}
\end{align}
:::

Einen Kovarianzmatrixparameter der Form $\Sigma = \sigma^2 I_n$ nennt man auch *sphärisch*,
da die Isokonturen der WDF eines normalverteilten Zufallsvektors mit einem solchen
Kovarianzmatrixparameter *Sphären* bilden (zum Beispiel Kreise bei $n = 2$ und
Kugeln bei $n = 3$). Eine multivariate Normalverteilung mit sphärische Kovarianzmatrixparameter
nennt man entsprechend eine *sphärische Normalverteilung*. @thm-sphärizität besagt,
dass die WDF eines $n$-dimensionalen normalverteilten Zufallskvektors mit 
sphärischem Kovarianzparameter der gemeinsamen WDF von $n$ unabhängigen 
univariat normalverteilten Zufallsvariablen entspricht und umgekehrt. Eine 
Realisierung eines $n$-dimensionalen normalverteilten Zufallsvektors entspricht 
also den Realisierungen von $n$ unabhängigen univariat normalverteilten Zufallsvariablen 
und umgekehrt. Man beachte, dass die Identität der Verteilungen der $\xi_i, i = 1,...,n$ hier 
nicht voraussgesetzt ist, insbesondere können sich ihre Erwartungswertparameter 
$\mu_i, i = 1,...,n$ explizit unterscheiden. 


## Marginale und bedingte Verteilungen 

Multivariate Normalverteilungen haben die Eigenschaft, dass auch alle anderen
assoziierten Verteilungen Normalverteilungen sind und deren Erwartungswert- und
Kovarianzmatrixparameter aus den Parametern der jeweils komplementären Verteilung
errechnet werden können. Insbesondere gilt zum einen, dass die uni- und multivariaten 
Marginalverteilungen multivariater Normalverteilungen wiederum Normalverteilungen sind.
Zum anderen lassen sich wie alle multivariaten Verteilungen multivariate Normalverteilungen 
multiplikativ in eine marginale und eine bedingte Verteilung zerlegen. Insbesondere sind 
nun aber bei multivariaten Normalverteilungen diese Verteilungen wiederum (multivariate) 
Normalverteilungen, deren Parameter aus den Parametern der gemeinsame Verteilung errechnet 
werden können und umgekehrt. Wir fassen obige Erkenntnisse formal in den 
folgenden drei Theoremen zusammen.

:::{#thm-marginale-normalverteilungen}
## Marginale Normalverteilungen
Es sei $n := k + l$ und $\xi = (\xi_1,...,\xi_n)^T$ sei ein $n$-dimensionaler
normalverteilter Zufallsvektor mit Erwartungswertparameter
\begin{equation}
\mu =
\left(\begin{matrix}
\mu_\upsilon \\
\mu_\zeta
\end{matrix}\right) \in \mathbb{R}^n,
\end{equation}
mit $\mu_\upsilon \in \mathbb{R}^k$ and $\mu_\zeta \in \mathbb{R}^l$ und Kovarianzmatrixparameter
\begin{equation}
\Sigma =
\left(\begin{matrix}
\Sigma_{\upsilon\upsilon} 	& \Sigma_{\upsilon\zeta} \\
\Sigma_{\zeta\upsilon} 	& \Sigma_{\zeta\zeta}
\end{matrix}\right) \in \mathbb{R}^{n \times n},
\end{equation}
mit $\Sigma_{\upsilon\upsilon}  \in \mathbb{R}^{k \times k}$,
    $\Sigma_{\upsilon\zeta}     \in \mathbb{R}^{k \times l}$,
    $\Sigma_{\zeta\upsilon}     \in \mathbb{R}^{l \times k}$,
und $\Sigma_{\zeta\zeta}        \in \mathbb{R}^{l \times l}$.
Dann sind $\upsilon := (\xi_1,...,\xi_k)^T$ und $\zeta := (\xi_{k+1}, ...,\xi_n)^T$
$k$- und $l$-dimensionale normalverteilte Zufallsvektoren, respektive, und es gilt
\begin{equation}
\upsilon \sim N(\mu_\upsilon,\Sigma_{\upsilon\upsilon}) \mbox{ und } \zeta \sim N(\mu_\zeta,\Sigma_{\zeta\zeta}).
\end{equation}
:::

Die Marginalverteilungen einer multivariaten Normalverteilung sind also auch Normalverteilungen
und die Parameter der Marginalverteilungen ergeben sich aus den Parametern der gemeinsamen Verteilung.
Für Beweise dieses Theorems verweisen wir auf @mardia1979 und @anderson2003.
@fig-marginale-normalverteilungen visualisiert @thm-marginale-normalverteilungen für den
Fall $n := 2, k := 1, l := 1$,
\begin{equation}
\mu := \begin{pmatrix} 1 \\ 2 \end{pmatrix} \in \mathbb{R}^2 
\mbox{ und } 
\Sigma := \begin{pmatrix} 0.10 & 0.08 \\ 0.08 & 0.15 \end{pmatrix}  \in \mathbb{R}^{2 \times 2}.
\end{equation}
@fig-marginale-normalverteilungen A zeigt dabei die WDF des bivariaten Zufallsvektors
$\xi$ und @fig-marginale-normalverteilungen B und C die WDFen der entsprechenden
marginalen Zufallsvariablen $\upsilon$ und $\zeta$.

```{r, eval = F, echo = F}
library(mvtnorm)
library(latex2exp())
pdf(
file        = file.path("./_figures/210-marginale-normalverteilungen.pdf"),
width       = 9,
height      = 4.5)
par(
family      = "sans",
mfcol       = c(1,3),
pty         = "s",
bty         = "l",
lwd         = 1,
las         = 1,
mgp         = c(2,1,0),
xaxs        = "i",
yaxs        = "i",
font.main   = 1,
cex         = 1,
cex.main    = 1.2)

# Ergebnisraumdefintion
x_min  = 0                                           # x_i Minimum
x_max  = 3                                           # x_i Maxim
x_res  = 1e3                                         # x_i Auflösung
x_1    = seq(x_min, x_max, length.out = x_res)       # x_1 Raum
x_2    = seq(x_min, x_max, length.out = x_res)       # x_2 Raum
X      = expand.grid(x_1,x_2)                        # X = (x_1,x_2)^T Raum

# Parameterdefinition
mu     = c(1,2)                                      # \mu \in \mathbb{R}^2
Sigma  = matrix(c(0.10, 0.08,
                  0.08, 0.15),
                nrow = 2,
                byrow = TRUE)                        # \Sigma in \mathbb{R}^{2 \times 2}


# Visualisierung gemeinsame Verteilung
p      = matrix(                                     # Matrixkonversion des von
                dmvnorm(as.matrix(X), mu, Sigma),    # dmvnorm() ausgegebenen Vektors
                nrow = x_res)
contour(
x_1,
x_2,
p,
xlim      =  c(x_min,x_max),
ylim      =  c(x_min,x_max),
xlab      = TeX("$y$"),
ylab      = TeX("$z$"),
main      = TeX("$N(x;\\mu,\\Sigma)$"),
nlevels   = 10)
mtext(LETTERS[1], adj=1, line=2, cex = 1.5, at = -.3)

# Visualisierung Marginalverteilungen
p_marg   = list(dnorm(x_1, mu[1],Sigma[1,1]), dnorm(x_1, mu[2],Sigma[2,2]))
l_marg   = c(TeX("$y$"), TeX("$z$"))
L_marg   = c(TeX("$N(y;\\mu_\\upsilon,\\Sigma_{\\upsilon\\upsilon})$"), TeX("$N(z; \\mu_\\zeta,\\Sigma_{\\zeta\\zeta})$"))
i        = 1
for(i in 1:length(p_marg)){
  plot(x_1,
      p_marg[[i]],
      type = "l",
      xlab = l_marg[[i]],
      ylim = c(0,5),
      ylab = "",
      main = L_marg[[i]])
  mtext(LETTERS[i+1], adj=1, line=2, cex = 1.5, at = -.3)
}
dev.off()
```

![Marginale Verteilungen eines bivariaten normalverteilten Zufallsvektor.](./_figures/210-marginale-normalverteilungen){#fig-marginale-normalverteilungen fig-align="center" width=100%}

Mithilfe einer marginalen und einer bedingten multivariaten Normalverteilung
lässt sich eine gemeinsame multivariate Normalverteilung konstruieren, deren
Parameter sich aus den Parametern der marginalen und bedingten Verteilung 
ergeben. Dies ist die zentrale Aussage folgenden Theorems.

:::{#thm-gemeinsame-normalverteilungen}
## Gemeinsame Normalverteilungen
$\xi$ sei ein $m$-dimensionaler normalverteilter Zufallsvektor mit WDF
\begin{equation}
p_\xi : \mathbb{R}^m \to \mathbb{R}_{>0},\,x\mapsto
p_\xi(x) := N(x;\mu_\xi,\Sigma_{\xi\xi}) \mbox{ mit }
\mu_\xi \in \mathbb{R}^m,
\Sigma_{\xi\xi} \in \mathbb{R}^{m\times m},
\end{equation}
$A\in\mathbb{R}^{n\times m}$ sei eine Matrix, $b\in\mathbb{R}^n$ sei ein Vektor
und $\upsilon$ sei ein $n$-dimensionaler bedingt normalverteilter Zufallsvektor mit
bedingter WDF
\begin{equation}
p_{\upsilon|\xi}(\cdot|x) : \mathbb{R}^n \to \mathbb{R}_{>0},\, y\mapsto
p_{\upsilon|\xi}(y|x) := N(y;A\xi+b,\Sigma_{\upsilon\upsilon}) \mbox{ mit }
\Sigma_{\upsilon\upsilon} \in \mathbb{R}^{n\times n}.
\end{equation}
Dann ist der $m+n$-dimensionale Zufallsvektor $(\xi,\upsilon)^T$ normalverteilt mit (gemeinsamer) WDF
\begin{equation}\label{eq:gauss_joint}
p_{\xi,\upsilon} : \mathbb{R}^{m+n} \to \mathbb{R}_{>0},\, \begin{pmatrix} x \\ y \end{pmatrix} \mapsto
p_{\xi,\upsilon}\left(\begin{pmatrix} x \\ y \end{pmatrix}\right) = N\left(\begin{pmatrix} x \\ y \end{pmatrix};
\mu_{\xi,\upsilon}, \Sigma_{\xi,\upsilon} \right),
\end{equation}
mit $\mu_{\xi,\upsilon} \in \mathbb{R}^{m+n}$ und $\Sigma_{\xi,\upsilon} \in \mathbb{R}^{m+n \times m+n}$ und insbesondere
\begin{equation}
\mu_{\xi,\upsilon} = \left( \begin{matrix} \mu_\xi \\ A\mu_\xi + b \end{matrix} \right)
\mbox{ und }
\Sigma_{\xi,\upsilon} = \left(\begin{matrix} \Sigma_{\xi\xi} & \Sigma_{\xi\xi}A^T \\ A\Sigma_{\xi\xi} & \Sigma_{\upsilon\upsilon} + A\Sigma_{\xi\xi}A^T \end{matrix} \right).
\end{equation}
:::

Insbesondere ergeben sich die Parameter der gemeinsamen Verteilung also als
linear-affine Transformation der Parameter der induzierenden Verteilungen.
@fig-gemeinsame-normalverteilungen visualisiert @thm-gemeinsame-normalverteilungen für den
Fall $m := 1, n := 1, \mu_\xi := 1, \Sigma_{\xi\xi} := 0.2, A := 1, b := 1$ und 
$\Sigma_{\upsilon\upsilon} := 0.1$. @fig-gemeinsame-normalverteilungen A zeigt dabei 
die WDF der Zufallsvariable $\xi$,  @fig-gemeinsame-normalverteilungen B zeigt die
WDF der bedingten Verteilung der Zufallsvariable  $\upsilon$ gegeben $\xi$ und 
@fig-marginale-normalverteilungen C schließlich zeigt die WDFen des induzierten bivariaten
Zufallsvektors $(\xi,\upsilon)$.

![Gemeinsame Verteilungen einer marginalen und einer auf dieser bedingten normalverteilten Zufallsvariable.](./_figures/210-gemeinsame-normalverteilungen){#fig-gemeinsame-normalverteilungen fig-align="center" width=100%}

Die Definition einer multivariaten Normalverteilung erlaubt es weiterhin, die
bedingten Verteilungen aller Komponenten des entsprechenden Zufallsvektors direkt
mithilfe der Parameter der multivariaten Normalverteilung zu bestimmen. Dies
ist die zentrale Aussage folgenden Theorems.

:::{#thm-bedingte-normalverteilungen}
## Bedingte Normalverteilungen
$(\xi,\upsilon)$ sei ein $m+n$-dimensionaler normalverteilter Zufallsvektor mit WDF
\begin{equation}
p_{\xi,\upsilon} : \mathbb{R}^{m + n} \to \mathbb{R}_{>0}, \begin{pmatrix} x \\ y \end{pmatrix}
\mapsto p_{\xi,\upsilon}\left(\begin{pmatrix} x \\ y \end{pmatrix} \right)
:= N\left(\begin{pmatrix} x \\ y \end{pmatrix}; \mu_{\xi,\upsilon}, \Sigma_{\xi,\upsilon}\right),
\end{equation}
mit
\begin{equation}
\mu_{\xi,\upsilon} 
= \left(\begin{matrix} \mu_\xi \\ \mu_\upsilon \end{matrix} \right), 
\Sigma_{\xi,\upsilon} = \left(\begin{matrix} \Sigma_{\xi\xi} & \Sigma_{\xi\upsilon} \\ \Sigma_{\upsilon\xi} & \Sigma_{\upsilon\upsilon} \end{matrix} \right),
\end{equation}
mit $x,\mu_\xi \in \mathbb{R}^m, y,\mu_\upsilon\in\mathbb{R}^n$ und $\Sigma_{\xi\xi} \in \mathbb{R}^{m\times m}, \Sigma_{\xi\upsilon} \in \mathbb{R}^{m\times n}, \Sigma_{\upsilon\upsilon} \in \mathbb{R}^{n \times n}$. Dann ist die
bedingte Verteilung von $\xi$ gegeben $\upsilon$ eine $m$-dimensionale Normalverteilung
mit bedingter WDF
\begin{equation}
p_{\xi|\upsilon}(\cdot|y) : \mathbb{R}^m \to \mathbb{R}_{>0}, x \mapsto p_{\xi|\upsilon}(x|y) :=
N(x;\mu_{\xi|\upsilon},\Sigma_{\xi|\upsilon})
\end{equation}
mit
\begin{equation}\label{eq:gauss_cond_exp}
\mu_{\xi|\upsilon} = \mu_\xi  + \Sigma_{\xi\upsilon}\Sigma_{\upsilon\upsilon}^{-1}(y-\mu_\upsilon) \in \mathbb{R}^m
\end{equation}
und
\begin{equation}\label{eq:gauss_cond_var}
\Sigma_{\xi|\upsilon} = \Sigma_{\xi\xi}  - \Sigma_{\xi\upsilon}\Sigma_{\upsilon\upsilon}^{-1}\Sigma_{\upsilon\xi} \in \mathbb{R}^{m\times m}.
\end{equation}
:::

Im Zusammenspiel mit @thm-gemeinsame-normalverteilungen und @thm-marginale-normalverteilungen 
können die Parameter bedingter und marginaler Normalverteilungen also aus den 
Parametern der komplementären bedingten und marginalen Normalverteilungen bestimmt werden.
@fig-bedingte-normalverteilungen visualisiert @thm-bedingte-normalverteilungen für den Fall
$m := 2, n := 1$, 
\begin{equation}
\mu := \begin{pmatrix} 1 \\ 2 \end{pmatrix} 
\mbox{ und } 
\Sigma := \begin{pmatrix} 0.12 & 0.09 \\ 0.09 & 0.12 \end{pmatrix}
\end{equation}
Dabei zeigt @fig-bedingte-normalverteilungen A die WDF des bivariaten Zufallsvektors $(\xi,\upsilon)^T$
und @fig-bedingte-normalverteilungen B und C zeigen die WDF der bedingten Verteilung
der Zufallsvariable $\xi$ gegeben $\upsilon = 1.5$ und $\upsilon = 2.8$, respektive.

![Bedingte Normalverteilungen](./_figures/210-bedingte-normalverteilungen){#fig-bedingte-normalverteilungen fig-align="center" width=110%}

## Literaturhinweise

Die Entwicklung der bivariaten Normalverteilung hat ihre Ursprünge in der statistischen
Literatur zur Mitte des 19. Jahrhunderts, insbesondere in den Arbeiten von 
Francis Galton (1822-1911). Die mathematische Formalisierung der bivariaten Normalverteilung 
geht dabei wohl insbesondere auf @pearson1896 zurück (@seal1967). Die
ursprüngliche Formulierung der multivariaten Normalverteilung wird bei @edgeworth1892
verortet. @tong1990 gibt eine umfassenden Überblick zur Theorie und Anwendung
der multivariaten Normalverteilung.

## Selbstkontrollfragen
\footnotesize
1. Geben Sie Definition eines Zufallsvektors wieder.
1. Geben Sie Definition der multivariaten Verteilung eines Zufallsvektors wieder.
1. Geben Sie Definition einer multivariaten WMF wieder.
1. Geben Sie Definition einer multivariaten WDF wieder.
1. Geben Sie die Definition des Erwartungswerts eines Zufallsvektors wieder.
1. Geben Sie die Definition der Kovarianzmatrix eines Zufallsvektors wieder.
1. Was repräsentieren die Diagonalelemente der Kovarianzmatrix eines Zufallsvektors?
1. Was repräsentieren die Nichtdiagonalelemente der Kovarianzmatrix eines Zufallsvektors?
1. Geben Sie die Definition der Korrelationsmatrix eines Zufallsvektors wieder.
1. Geben Sie die Definition der univariaten Marginalverteilung eines Zufallsvektors wieder.
1. Wie berechnet man die WMF der $i$ten Komponente eines diskreten Zufallsvektors?
1. Wie berechnet man die WDF der $i$ten Komponente eines kontinuierlichen Zufallsvektors?
1. Geben Sie Definition der bedingten WMF und der diskreten bedingten Verteilung wieder.
1. Geben Sie Definition der bedingten WDF und der kontinuierlichen bedingten Verteilung wieder.
1. Geben Sie die Definition der WDF eines multivariaten normalverteilten Zufallsvektors wieder.
1. Erläutern Sie die Komponenten der WDF eines multivariaten normalverteilten Zufallsvektors.
1. Geben Sie den Erwartungswert und die Kovarianzmatrix eines normalverteilten Zufallsvektors an.
1. Geben Sie das Theorem zu marginalen Normalverteilungen wieder.
1. Geben Sie das Theorem zu gemeinsamen Normalverteilungen wieder.
1. Geben Sie das Theorem zu bedingten Normalverteilungen wieder.
\normalsize