# Grundbegriffe {#sec-grundbegriffe-frequentistischer-inferenz}
\normalsize

## Frequentistische Inferenzmodelle {#sec-frequentistische-inferenzmodelle}

Mit folgender Definition wollen wir zunächst einige grundlegende Begrifflichkeiten
bei der Betrachtung Frequentistischer Inferenzmodelle einführen.

:::{#def-frequentistisches-inferenzmodell}
## Frequentistische Inferenzmodelle
Ein *Frequentistisches Inferenzmodell* ist ein Tupel
\begin{equation}
\mathcal{M} := (\mathcal{Y}, \mathcal{A}, \{\mathbb{P}_\theta |\theta \in \Theta\})
\end{equation}
bestehend  aus einem *Datenraum* $\mathcal{Y}$, einer $\sigma$-Algebra
$\mathcal{A}$ auf $\mathcal{Y}$ und einer mindestens zweielementigen Menge
$\{\mathbb{P}_\theta |\theta \in \Theta\}$ von Wahrscheinlichkeitsmaßen auf
$(\mathcal{Y}, \mathcal{A})$, die durch $\theta \in \Theta$ indiziert sind. 
Wenn $\Theta \subset \mathbb{R}^k$ ist, heißt ein Frequentistisches Inferenzmodell 
auch *parametrisches Frequentistisches Inferenzmodell* und $\Theta$ heißt 
*Parameterraum* des Frequentistischen Inferenzmodells. Ein Frequentistisches 
Inferenzmodell $\mathcal{M}$ heißt ein *diskretes Modell*, wenn $\mathcal{Y}$ 
endlich oder abzählbar ist und jedes $\mathbb{P}_\theta$ eine WMF $p_\theta$ besitzt.
Ein Frequentistisches Inferenzmodell $\mathcal{M}$ heißt ein *stetiges Modell*, 
wenn $\mathcal{Y} \subset \mathbb{R}^n$ ist und jedes $\mathbb{P}_\theta$ eine 
WDF $p_\theta$ besitzt. Wenn der Datenraum $\mathcal{Y}$ eines Frequentistischen 
Inferenzmodells $\mathcal{M}$ eindimensional ist, also zum Beispiel 
$\mathcal{Y} := \mathbb{R}$, spricht man von einem *univariaten Frequentistischen 
Inferenzmodell*. Wenn der Datenraum  $\mathcal{Y}$ eines Frequentistischen 
Inferenzmodells $\mathcal{M}$ mehrdimensional ist, also zum Beispiel 
$\mathcal{Y} := \mathbb{R}^m$ für $m > 1$, spricht man von  einem 
*multivariaten Frequentistischen Inferenzmodell*. Für ein Frequentistisches 
Inferenzmodell $\mathcal{M}_0 := (\mathcal{Y}_0, \mathcal{A}_0, \{\mathbb{P}_\theta^0 |\theta \in \Theta\})$ 
wrid das Frequentistische Inferenzmodell $\mathcal{M} := (\mathcal{Y}, \mathcal{A}, \{\mathbb{P}_\theta |\theta \in \Theta\})$, 
für das $\mathcal{Y}$ das $n$-fache kartesische Produkt von $\mathcal{Y}_0$ mit 
sich selbst, $\mathcal{A}$ die entsprechende Produkt-$\sigma$-Algebra 
und $\{\mathbb{P}_\theta |\theta \in \Theta\}$ die entsprechende Menge an 
Produktmaßen ist, ein (zu $\mathcal{M}_0$ gehöriges) *Frequentistisches Produktmodell* 
genannt.
:::

Vor dem Hintergrund eines Frequentistischen Inferenzmodells wird der Vorgang
der Datenbeobachtung wird durch einen Zufallsvektor $\upsilon$, der Werte 
in $\mathcal{Y}$ annimmt und dessen Verteilung einer der prinzipiell möglichen
Verteilungen $\mathbb{P}_\theta$ entspricht, beschrieben. Man nennt diesen 
Zufallsvektor *Daten*, *Beobachtung*, *Messung* oder *Stichprobe*. Im Gegensatz 
zum Wahrscheinlichkeitsraummodell betrachtet man bei Frequentistische 
Inferenzmodellen also explizit zwei oder mehr Wahrscheinlichkeitsmaße, die die 
Verteilung von $\upsilon$ mutmaßlich bestimmen. Eine Realisierung von $\upsilon$, also 
konkret vorliegende Datenwerte $y \in \mathcal{Y}$, nennt man *Datensatz*, 
*Beobachtungswert*, *Messwert* oder *Stichprobenwert*. Erwartungswerte und 
(Ko)Varianzen von $\upsilon$ bezüglich $\mathbb{P}_\theta$ schreibt man meist als 
$\mathbb{E}_\theta(\upsilon)$, $\mathbb{V}_\theta(\upsilon)$ und $\mathbb{C}_\theta(\upsilon)$.
Frequentistische Produktmodelle modellieren die $n$-fache unabhängige 
Wiederholung eines Zufallsvorgangs. Die entsprechende Menge von Zufallsvektoren 
$\upsilon_1,....,\upsilon_n$ entspricht dann einer Menge von $n$ unabhängigen 
Zufallsvektoren.

In einem konkreten Datenanalyseproblem auf Grundlage eines parameterischen 
Frequentistischen Produktmodells nimmt man an, dass die beobachteten Werte 
$y_1,...,y_n$ von $\upsilon_1,...,\upsilon_n$  durch genau ein Wahrscheinlichkeitsmaß 
$\mathbb{P}_{\theta}$ mit Parameter $\theta \in \Theta$ generiert wurde. In der 
Anwendung wird dieses $\theta \in \Theta$ dann als  *wahrer, aber unbekannter, 
Parameterwert* bezeichnet. Der wahre, aber unbekannten, Parameterwert $\theta$ 
bleibt dabei auch nach jeglicher Form von Inferenz unbekannt. Allgemeines Ziel 
von parameterischen Inferenzverfahren ist es damit, basierend auf einem vorliegenden 
Datensatz eine möglichst valide Aussage hinsichtlich des wahren, aber unbekannten 
Parameters $\theta$ zu treffen. In diesem Sinne ist der wahre, aber unbekannte 
Parameterwert, nur indirekt beobachtbar. Dies wird manchmal auch durch die Sprechweisen 
ausgedrückt, dass der wahre, aber unbekannte Parameterwert *unbeobachtbar* oder
*latent*, d.h. nicht unmittelbar sichtbar oder zu erfassen, ist. In der mathematischen 
Analyse von Inferenzverfahren betrachtet man alle möglichen wahren, aber unbekannten, 
Parameterwerte, verzichtet deshalb also meist auf eine explizite notationelle 
Auszeichung des in einem Anwendungskontext unterstellten wahren, aber unbekannten,
Parameterwerts.

### Beispiele {-}

Mit dem univariten Normalverteilungsmodell und dem Bernoullimodell wollen wir
zwei erste Beispiel für Frequentistische Inferenzmodelle geben.

:::{#def-normalverteilungsmodell}
## Normalverteilungsmodell
Das univariate parametrische Produktmodell
\begin{equation}
\mathcal{M} := \left(\mathcal{Y}, \mathcal{A}, \{\mathbb{P}_\theta|\theta \in \Theta\}\right)
\end{equation}
mit
\begin{equation}
\mathcal{Y} := \mathbb{R}^n, \mathcal{A} := \mathcal{B}(\mathbb{R}^n), \mathbb{P}_\theta := N(\mu,\sigma^2), \theta := (\mu, \sigma^2), \Theta := \mathbb{R} \times \mathbb{R}_{>0},
\end{equation}
also
\begin{equation}
\{\mathbb{P}_\theta|\theta \in \Theta\}
:= \left\lbrace \prod_{i=1}^n N(\mu,\sigma^2)|(\mu,\sigma^2)\in \mathbb{R} \times \mathbb{R}_{>0} \right\rbrace,
\end{equation}
und damit
\begin{equation}
\upsilon_1,...,\upsilon_n \sim N(\mu,\sigma^2) \mbox{ mit } (\mu,\sigma^2)\in \mathbb{R} \times \mathbb{R}_{>0}
\end{equation}
heißt \textit{Normalverteilungsmodell}.
:::

Das Normalverteilungsmodell ist Grundlage vieler populärer statistischen 
Verfahren die im Rahmen des Allgemeinen Linearen Modells integrativ betrachtet 
werden. Man beachte, dass die Annahme normalverteilter Daten dabei durch additive
normalverteilte Fehlerterme motiviert ist, wie wir in @sec-grenzwerte schon kurz
angerissen haben und an späterer Stelle vertiefen werden.

:::{#def-bernoullimodell}
## Bernoullimodell
Das univariate parametrische Produktmodell
\begin{equation}
\mathcal{M} := \left(\mathcal{Y}, \mathcal{A}, \{\mathbb{P}_\theta|\theta \in \Theta\}\right)
\end{equation}
mit
\begin{equation}
\mathcal{Y} := \{0,1\}^n, \mathcal{A} := \mathcal{P}\left(\{0,1\}^n\right), \mathbb{P}_\theta := \mbox{Bern}(\mu), \theta:= \mu, \Theta := ]0,1[,
\end{equation}
also
\begin{equation}
\{\mathbb{P}_\theta|\theta \in \Theta\} := \left\lbrace \prod_{i=1}^n \mbox{Bern}(\mu)|\mu \in ]0,1[ \right\rbrace,
\end{equation}
und damit
\begin{equation}
\upsilon_1,...,\upsilon_n \sim \mbox{Bern}(\mu) \mbox{ mit } \mu \in ]0,1[,
\end{equation}
heißt \textit{Bernoullimodell}.
:::

## Statistiken und Schätzer {#sec-statistiken-und-schätzer}

Vor dem Hintergrund Frequentistischer Inferenzmodelle wollen wir nun formalisieren,
was unter den Begriffen einer *Statistik* und eines *Schätzers* zu verstehen ist.

:::{#def-statistik}
## Statistik
$\mathcal{M}$ sei ein Frequentistisches Inferenzmodell und $(\Sigma,\mathcal{S})$ 
sei ein Messraum. Dann ist eine *Statistik* ein Zufallsvektor der Form
\begin{equation}
S : \mathcal{Y} \to \Sigma.
\end{equation}
:::

Sowohl Daten als auch Statistiken werden in der Frequentistischen Inferenz also 
durch Zufallsvektoren (im univariaten Fall entsprechend durch Zufallsvariablen) 
modelliert. Allerdings unterscheiden sich diese Zufallvektoren hinsichtlich 
ihrer intuitiven  Bedeutung fundamental: Daten repräsentieren den Ausgang von 
Messvorgängen unter Unsicherheit, Statistiken dagegen modellieren von 
Datenwissenschaftler:innen konstruierte Funktionen von Daten. Diese liefern 
im besten Fall datenbasierte Informationen, aus denen sich Schlüsse über die 
latenten datengenerierenden Zufallsvorgänge ziehen lassen. Die Tatsache, dass 
Statistiken zufällig sind ergibt sich dabei daraus, dass sie als Funktionen 
auf zufällige Daten angewendet werden. (vgl. etwa @thm-arithmetik-reeller-zufallsvariablen).

**Beispiele**

$\mathcal{M}$ sei das Normalverteilungsmodell. Dann sind zum Beispiel folgende
Zufallsvariablen Statistiken:

* Das *Stichprobenmittel*
\begin{equation}
\bar{y} : \mathbb{R}^n \to \mathbb{R},
y \mapsto \bar{y}(y) := \frac{1}{n}\sum_{i=1}^n y_i,
\end{equation}
* Die *Stichprobenvarianz*
\begin{equation}
s^2  : \mathbb{R}^n \to \mathbb{R}_{\ge 0},
y \mapsto s^2(y) := \frac{1}{n-1}\sum_{i=1}^n (y_i - \bar{y}(y))^2,
\end{equation}
* Die *Stichprobenstandardabweichung*
\begin{equation}
s  : \mathbb{R}^n \to \mathbb{R}_{\ge 0},
y \mapsto s(y) := \sqrt{s^2(y)},
\end{equation}

Oft bleibt wie hier das Wesen von Statistiken als Zufallsvariablen oder
Zufallsvektoren notationell eher implizit. Dies ändert allerdings nichts an 
der fundamental zu beachtetenden Tatsache, dass Statistiken als Funktionen von 
vom Zufall abhängigen Werten selbst wiederrum Zufallsvariablen oder Zufallsvektoren sind. 

:::{#def-schätzer}
## Schätzer
$\mathcal{M}$ sei ein Frequentistisches Inferenzmodell, $(\Sigma, \mathcal{S})$ 
sei ein Messraum und $\tau : \Theta \to \Sigma$ sei eine Abbildung, die jedem 
$\theta \in \Theta$ eine Kenngröße $\tau(\theta) \in \Sigma$ zuordnet. Dann heißt 
eine Statistik 
\begin{equation}
\hat{\tau} : \mathcal{Y} \to \Sigma
\end{equation}
ein \textit{Schätzer} für $\tau$.
:::

*Schätzer* schätzen also Funktionen der Parameter eines parametrischen 
Frequentistischen Inferenzmodells. Typische Beispiele für solche Funktionen sind 

* $\tau(\theta) := \theta$ für die Schätzung des Parameters $\theta$,
* $\tau(\theta) := \theta_i$ mit $\theta \in \mathbb{R}^d, d > 1$ für die Schätzung einer Komponente des Parameters $\theta$,
* $\tau(\theta) := \mathbb{E}_\theta(y_1)$ für die Schätzung des Erwartungswerts,
* $\tau(\theta) := \mathbb{V}_\theta(y_1)$ für die Schätzung der Varianz.

Im Falle $\tau(\theta) := \theta$, also der Schätzung von Parametern, schreibt man
üblicherweise $\hat{\theta}$. Man beachte, dass Schätzer Zahlwerte 
in $\Sigma$ annehmen, bei der Schätzung von Parametern etwa in $\Theta$. Sie heißen 
deshalb auch *Punktschätzer*. Dies ist ein Charaketeristikum Frequentistischer 
Inferenzverfahren.  Im Rahmen der Bayesianischen Inferenz können Schätzer auch
generalisierte Formen annehmen, zum Beispiel werden dort auch Wahrscheinlichkeitsverteilungen
als Schätzer betrachtet. Schließlich ist festzuhalten, dass die Definition 
eines Schätzers keinerlei Aussage über die Validität von Schätzern macht. Nicht 
jeder Schätzer ist damit *perse* ein guter Schätzer. In der Frequentistischen 
Inferenz definiert man deshalb zusätzlich *Schätzgütekriterien*, wie in 
@sec-punktschaetzung ausführlich dargestellt.


### Beispiel {-}

$\mathcal{M}$ sei das Normalverteilungsmodell. Dann ist zum Beispiel das 
Stichprobenmittel  $\bar{y} : \mathbb{R}^n \to \mathbb{R}$ ein Schätzer für
\begin{equation}
\tau : \mathbb{R} \times \mathbb{R}_{>0} \to \mathbb{R},
(\mu, \sigma^2) \mapsto \tau(\mu,\sigma^2) := \mu.
\end{equation}
Ebenso ist $\bar{y}$ ein Schätzer für
\begin{equation}
\tau: \mathbb{R} \times \mathbb{R}_{>0} \to \mathbb{R},
(\mu, \sigma_2) \mapsto \tau(\mu,\sigma^2) := \mathbb{E}_{\mu,\sigma^2}(y_1).
\end{equation}
Weiterhin ist die konstante Funktion
\begin{equation}
\hat{\tau} : \mathbb{R}^n \to \mathbb{R}, y \mapsto \hat{\tau}(y) := 42
\end{equation}
ein Schätzer für
\begin{equation}
\tau : \mathbb{R} \times \mathbb{R}_{>0} \to \mathbb{R}_{>0},
(\mu, \sigma_2) \mapsto \tau(\mu,\sigma^2) := \sigma^2.
\end{equation}
Dass eine Funktion $\hat{\tau} : \mathcal{Y} \to \Sigma$ ein Schätzer ist impliziert
also keinesfalls, dass sie ein guter Schätzer ist.


## Standardannahmen und Standardproblemstellungen 

Wir wollen die in diesem Kapitel bisher betrachteten Konzepte zunächst noch
einmal unter dem Begriff der *datenanalytischen Standardannahmen der 
Frequentistischen Inferenz* zusammenfassen (vgl. auch @fig-frequentistische-inferenz).
Dazu sei $\mathcal{M}$ ein univariates parametrisches Frequentistisches Produktmodell 
und es seien $\upsilon_1,...,\upsilon_n \sim p_\theta$ die Zufallsvariablen der Stichprobe,
die wir etwa in einem Zufallvektor $\upsilon := (\upsilon_1,...,\upsilon_n)$ zusammenfassen können. 
Von einem konkret vorliegenden Datensatz  $y_1,...,y_n$ mit $y_i \in \mathbb{R}$,
$i = 1,...,n$, den wir etwa in einem $n$-dimensionalen Vektor $y := (y_1,...,y_n)^T \in \mathbb{R}^n$ 
zusammenfassen können, *wird dann angenommen, dass er eine der möglichen Realisierungen von $\upsilon$ 
auf Grundlage einer Verteilung $\mathbb{P}_\theta$ mit wahrem, aber unbekannten, Parameter $\theta$ 
ist*. Aus Frequentistischer Sicht kann man dabei die Beobachtung eines Datensatzes unendlich 
oft wiederholen und zu jeder Datenrealisierung Schätzer oder Statistiken auswerten, so 
zum Beispiel das Stichprobenmittel:

\begin{enumerate}
\item[] Datenrealisierung $y^{(1)} := \left(y_1^{(1)},...,y_n^{(1)}\right)$ mit $\bar{y}^{(1)} = \frac{1}{n}\sum_{i=1}^n y_i^{(1)}$
\item[] Datenrealisierung $y^{(2)} := \left(y_1^{(2)},...,y_n^{(2)}\right)$ mit $\bar{y}^{(2)} = \frac{1}{n}\sum_{i=1}^n y_i^{(2)}$
\item[] Datenrealisierung $y^{(3)} := \left(y_1^{(3)},...,y_n^{(3)}\right)$ mit $\bar{y}^{(3)} = \frac{1}{n}\sum_{i=1}^n y_i^{(3)}$
\item[] Datenrealisierung $y^{(4)} := \left(y_1^{(4)},...,y_n^{(4)}\right)$ mit $\bar{y}^{(4)} = \frac{1}{n}\sum_{i=1}^n y_i^{(4)}$ 
\item[] Datenrealisierung $y^{(5)} := \left(y_1^{(5)},...,y_n^{(4)}\right)$ mit $\bar{y}^{(5)} = \frac{1}{n}\sum_{i=1}^n y_i^{(5)}$ 
\item[] ...
\end{enumerate}

Vor diesem Hintegrund behandelt die behandelt die Frequentistische Inferenz dann
üblicheweise folgende Standardproblemstellungen:

(1) *Punktschätzung*. Ziel der Punktschätzung ist es, auf Grundlage beobachteter 
Daten einen präzisen und im Frequentistischen Sinn möglichst guten Tipp für den 
wahren, aber unbekannten, Parameterwert abzugeben.

(2) *Konfidenzintervallbestimmung*. Ziel der Konfidenzintervallbestimmung 
ist es, basierend auf der angenommenen Datenverteilung und den beobachteten Daten 
durch eine Intervallschätzung einen möglichst sicheren, wenn auch oft unpräzisen, 
Tipp für den wahren, aber unbekannten, Parameterwert abzugeben.

(3) *Hypothesentests*. Ziel des Frequentistischen Hypothesentestens ist es, 
basierend auf der angenommenen Verteilung der Daten in einer möglichst 
zuverlässigen Form zu entscheiden, ob ein wahrer, aber unbekannter Parameterwert 
in einer von zwei sich gegenseitig ausschließenden Untermengen des Parameterraumes

![Standardannahmen und Standardproblemstellungen Frequentistischer Inferenz. Die 
Frequentistische Inferenz unterstellt, dass es in der Wirklichkeit einen wahren,
aber unbekannten, Parameterwert des Wahrscheinlichkeitsmaßes $\mathbb{P}_\theta$
gibt, dass als Modell für die Erhebung eines Datensatzes dient. Ein konkret 
vorliegender Datenzsatz $y = (y_1,...,y_n)$ ist dann eine (und insbesondere *nur* eine) 
der möglichen Realisierungen des anhand $\mathbb{P}_\theta$ verteilten 
Zufallsvektors $\upsilon := (\upsilon_1,...,\upsilon_n)$. Auf Grundage dieser Realisierung
beabsichtigen die Verfahren zur Behandlung der Frequentistischen
Standardproblemstellungen von Punktschätzung, Konfidenzintervallbestimmung und
Hypothesentestauswertung möglichst valide Aussagen hinsichtlich des wahren, aber
unbekannten Parameterwertes zu machen, in den Kapiteln @sec-punktschaetzung,
@sec-konfidenzintervalle und @sec-hypothesentests diskutiert werden soll. 
Der tatsächliche wahre, aber unbekannte, Parameterwert aber bleibt auch nach 
Abschluss eines Inferenzverfahrens immer unbekannt.](./_figures/301-frequentistische-inferenz){#fig-frequentistische-inferenz fig-align="center"}

Verfahren zur Lösung dieser Problemstellungen bezeichnen wir als 
*Frequentistische Inferenzverfahren*. Um die *Qualität* von Frequentistischen 
Inferenzverfahren zu beurteilen,  betrachtet man in der Frequentistischen Inferenz 
üblicherweise die Verteilungen von Schätzern und Statistiken unter der Annahme von 
$\upsilon = (\upsilon_1,...,\upsilon_n) \sim p_\theta$. Man fragt zum Beispiel nach der 
Verteilung der oben skizzierten $\bar{y}^{(1)}$, $\bar{y}^{(2)}$, $\bar{y}^{(3)}$, 
$\bar{y}^{(4)}$, ... also der Verteilung der Zufallsvariable $\bar{\upsilon}_n$. 
Wenn ein Inferenzverfahren auf Grundlage dieser Annahmen für "gut" befunden wir,
so heißt das also insbesondere nur, dass das Verfahren bei häufiger Anwendung 
"im Mittel gut" ist. Im Einzelfall, also im Normalfall nur eines vorliegenden 
Datensatzes, kann sie auch "schlecht" sein. Wir werden diese Denkweise insbesondere
im Kontext der Punktschätzung (@sec-punktschaetzung) vertiefen. Ebenso 
beurteilt die Frequentistische Inferenz die *Stärke empirischer Evidenz* vor dem Hintegrund 
der angenommenen Verteilung von Schätzern und Statistiken in Szenarien, in denen angenommen wird,
das interessierende Effekt *nicht* existieren (sogenannte "Nullhypothesen"). Diese 
Denkweise verdeutlichen wir insbesondere im Rahmen der Betrachtung von 
Konfidenzintervallen (@sec-konfidenzintervalle) und Hypothesentests 
(@sec-hypothesentests). 

### Anwendungsbeispiel {#sec-anwendungsbeispiel-frequentistische-inferenz}

Für ein erstes Anwendungsbeispiel Frequentistischer Inferenzverfahren
betrachten wir die evidenzbasierte Evaluation einer Psychotherapie bei Depression.
Dazu sei der in @tbl-bdi dargestellte Datensatz von an $n = 12$ Patient:innen
Differenzen von Prä- und Post-Therapie erhobenen BDI-II Scores gegeben (`dBDI`; @beck1961, @beck2009). 
Die `dBDI` Werte sollen dabei die Reduktion des BDI-II Scores der Patient:innen über 
den Zeitraum der Therapie wiederspiegeln. Hohe positive Werte von `dBDI` entsprechen 
also einer starken Abnahme der durch den BDI-II Score quantifizierten 
Depressionssymptomatik, Werte um Null entsprechen keiner wesentlichen Änderung
und negative Werte entsprechen einer Zunahme der durch den BDI-II Score quantifizierten Depressionssymptomatik.     

```{r echo = F}
# Datensimulation 
set.seed(1)
n           = 12                                                                # Anzahl Proband:innnen 
mu          = 2                                                                 # Prä-Post BDI-II Score Reduktion
sigsqr      = 20                                                                # Fehlervarianzparameter  
D           = data.frame(dBDI = round(rnorm(n, mu, sqrt(sigsqr))))              # Dataframe
fname       = "./_data/301-Grundbegriffe-Frequentistischer-Inferenz.csv"        # Dateinanme
write.csv(D, file = fname,row.names = FALSE)                                    # Datenspeicherung            
```

```{r echo = F, warning = F}
#| label: tbl-bdi
#| tbl-cap : "Prä-Post-Therapie BDI-II Reduktionsscores von n = 12 Patient:innen"
library(knitr)                                                                  # knitr für Tabellen
fname       = "./_data/301-Grundbegriffe-Frequentistischer-Inferenz.csv"        # Dateinanme
D           = read.table(fname, header = TRUE)                                  # Dateneinlesen des Datensatzes
kable(D, digits = 2, align = "c")                                               # Markdowntabellenoutput für head(D)
``` 


Für jeden der $n := 12$ `dBDI` Werte legen wir nun das Modell
$$
\upsilon_{i} := \mu + \varepsilon_{i} \mbox{ mit } \varepsilon_{i} \sim N(0,\sigma^2) \mbox{ u.i.v. für } i = 1,...,n
$$ {#eq-normalverteilungsmodell}
zugrunde. Damit wird der `dBDI` der $i$ten Patient:in also mithilfe einer über 
die Gruppe von Patient:innen identischen BDI-II Score Reduktion $\mu \in \mathbb{R}$
und einer Patient:innen-spezifischen normalverteilten BDI-II Score Reduktionsabweichung 
$\varepsilon_{i}$ erklärt und es wird angenommen, dass sich diese Reduktionsabweichungen 
zwischen Patient:innen nicht gegenseitig beeinflussen. Intuitiv wird also davon
ausgegangen, dass die Therapie einen Effekt hat, der bei allen Patient:innen zur
gleichen BDI-II Score Reduktion $\mu$ führt und sich die Unterschiede in den
beobachteten `dBDI` Werten durch eine Vielzahl weiterer Zufallvorgänge, die in 
der Summe normalverteilt und zentriert sind erklären lässt. Alternativ mag man
diese Abweichungen als Realisierungen der Unsicherheit verstehen mit der das
Modell in @eq-normalverteilungsmodell behaftet ist.  

Aus @eq-normalverteilungsmodell folgt dann direkt
\begin{equation}
\upsilon_1,...,\upsilon_n \sim N(\mu,\sigma^2),
\end{equation}
denn für $i = 1,...,n$ und mit 
\begin{equation}
\upsilon_i = f(\varepsilon_i)
\mbox{ mit }
f : \mathbb{R} \to \mathbb{R}, e_i \mapsto f(e_i) := e_i + \mu.
\end{equation}
gilt für die WDFen der $\upsilon_i$, dass
\begin{align}
\begin{split}
p_{\upsilon_i}(y_i)
& = \frac{1}{|1|} p_{\varepsilon_i}\left(\frac{y_i - \mu}{1} \right)                        \\
& = N\left(y_i - \mu; 0, \sigma^2\right)                                                    \\
& = \frac{1}{\sqrt{2\pi\sigma^2}}\exp\left(-\frac{1}{2\sigma^2}(y_i - \mu - 0)^2 \right)    \\
& = \frac{1}{\sqrt{2\pi\sigma^2}}\exp\left(-\frac{1}{2\sigma^2}(y_i - \mu)^2 \right)        \\
& = N(y_i; \mu,\sigma^2) 
\end{split}
\end{align}

Die Standardproblemstellungen der Frequentistischen Inferenz führen in diesem 
Anwendungsszenario dann auf folgende Fragen, die wir jeweils in den Kapiteln
zur Punktschätzung, Konfidenzintervallbestimmung, und Hypothesentestevaluation
wieder aufgreifen wollen:

(1) Was sind sinnvolle Tipps für die wahren, aber unbekannten, Parameterwerte 
$\mu$ und $\sigma^2$, also den wahren, aber unbekannten, Erwartungswert der 
BDI-II Score Reduktion und ihre wahre, aber unbekannte, Varianz? Wie gut ist 
die Therapie also in diesem quantitativen Sinn, wenn wir versuchen, die 
Patient:innen-abhängigen Abweichungen zu berücksichtigen und wie groß ist die 
in der Datengeneration inhärente Unsicherheit?

(2) Wie kann im Sinne einer Intervallschätzung eine möglichst sichere Schätzung 
des wahren, aber unbekannten, Erwartungswert der BDI-II Score Reduktion gelingen?
Wie unpräzise muss eine solche Schätzung sein, um möglichst verlässlich zu sein? 

(3) Entscheiden wir uns sinnvollerweise für eine der Hypothesen, dass die Therapie
nicht wirksam ist ($\mu = 0$) oder dass sie etwa im positiven ($\mu > 0$) oder 
auch im negativen Sinne wirksam ist ($\mu < 0$)? Und wenn wir uns für eine dieser
Hypothesen entscheiden sollten, mit welcher Fehlerwahrscheinlichkeit täten wir dies?
Wie hoch ist also die einer solchen Entscheidung innewohnende Unsicherheit?

## Selbstkontrollfragen

\footnotesize

1. Geben Sie die Definition des Begriffs des parametrischen Frequentistischen Inferenzmodells wieder.
1. Erläutern Sie den Begriff des parametrischen Frequentistischen Inferenzmodells.
1. Geben Sie die Definition des Begriffs des parametrischen Frequentistischen Produktmodells wieder.
1. Erläutern Sie den Begriff des parametrischen Frequentistischen Produktmodells.
1. Was ist der Unterschied zwischen univariaten und multivariaten Frequentistischen Inferenzmodellen?
1. Geben Sie die Definition des Begriffs des Normalverteilungsmodells wieder.
1. Geben Sie die Definition des Begriffs des Bernoullimodells wieder.
1. Geben Sie die Definition des Begriffs der Statistik wieder.
1. Erläutern Sie den Begriff der Statistik.
1. Geben Sie die Definition des Begriffs des Schätzers wieder.
1. Erläutern Sie den Begriff des Schätzers.
1. Erläutern Sie die datenanalytischen Standardannahmen der Frequentistischen Inferenz.

\normalsize

