# Klassische Testtheorie

 <!-- Psychometrische Verfahren


Definition eines **Psychologischen Tests** nach @krauth1995

"Ein *psychologischer Test* besteht aus eine Menge von Reizen mit den zugehörigen
zugelassenen Reaktionen, d.h. aus einer Menge von manifesten Variablen, und einer
Vorschrift (Skala), die den Reaktionsmustern der manifesten Variablen Ausprägungen
einer oder mehrerer latenter Variable zuordnet. Anders ausgedrückt ist ein Test
ein Messinstrument zur Messung von nicht direkt beobachtbaren (latenten) Variablen,
deren Existenz man bei Personen (gelegentlich auch bei Tieren) postuliert."

Beispiel PHQ-9 


Der **PHQ-9 (Patient Health Questionnaire-9)** ist ein Fragebogen zur Erfassung von Depressionssymptomen. Die Fragen lauten:

**"Wie oft haben Sie sich in den letzten zwei Wochen durch folgende Beschwerden beeinträchtigt gefühlt?"**  

1. Wenig Interesse oder Freude an Ihren Tätigkeiten?  
2. Sich niedergeschlagen, deprimiert oder hoffnungslos gefühlt?  
3. Schwierigkeiten beim Ein- oder Durchschlafen oder vermehrter Schlaf?  
4. Sich müde oder wenig energiegeladen gefühlt?  
5. Weniger Appetit oder übermäßiges Essen?  
6. Sich schlecht über sich selbst gefühlt – oder dass Sie ein Versager sind oder sich selbst oder Ihre Familie enttäuscht haben?  
7. Schwierigkeiten, sich auf etwas zu konzentrieren, z. B. beim Lesen der Zeitung oder beim Fernsehen?  
8. Sind Sie in einer Weise langsam gewesen, dass es anderen aufgefallen ist, oder waren Sie übermäßig unruhig oder zappelig?  
9. Gedanken, dass Sie lieber tot wären oder sich Leid zufügen möchten?  

Die Antwortmöglichkeiten sind:  
- 0 = Überhaupt nicht  
- 1 = An einzelnen Tagen  
- 2 = An mehr als der Hälfte der Tage  
- 3 = Beinahe jeden Tag  

Die Summe der Punkte gibt Hinweise auf das Ausmaß einer depressiven Symptomatik.


# Tests
\textcolor{darkblue}{Klassifikation}

\small
Leistungstests
\vspace{-2mm}

* Entwicklungstests
* Intelligenztests
* Allgemeine Leistungstests
* Schultests
* Spezielle Funktionsprüfungs- und Eignungstests

Psychometrische Persönlichkeitstests
\vspace{-2mm}

* Klinische Tests
* Persönlichkeitsstrukturtests
* Einstellungstests
* Interessentests

Persönlichkeitsentfaltungs-Verfahren
\vspace{-2mm}

* Formdeuteverfahren
* Verbal-thematische Verfahren
* Zeichnerische- und Gestaltungsverfahren


# Tests
\textcolor{darkblue}{Items}
\setstretch{2}

* Grundbausteine eines psychologischen Tests
* Reize, auf die man eine Reaktion erwartet und zu registrierende Reaktionen
* Standardbeispiel: Frage und Antwortmöglichkeiten
* Oft besteht ein Test aus mehreren Untertests, die aus mehreren Items bestehen
* Prinzipiell können Untertests und Tests aus nur einem Item bestehen
* Jedes Item kann also auch als ein Test angesehen werden 

# Tests
\textcolor{darkblue}{Beck-Depressionsinventar (BDI-II)} 
\small
\vspace{-1mm}

\setstretch{2}

* Selbst­beurteilungsinstrument zur Erfassung der Schwere einer depressiver Symptomatik  
* Entwicklung von @beck1996 
* Nachfolger des Beck Depressionsinventar @beck1961 
* Deutschsprachige Version nach @hautzinger2006
* Sprachliche Überarbeitung und Anpassung an aktuelle Diagnosemanuale  
* 21 Items zur Erfassung des Schweregrads von 0 bis 3 und summative Gesamtauswertung
* Grenzwerte der [\textcolor{darkblue}{Nationalen Versorgungsleitlinie Unipolare Depression}](https://www.leitlinien.de/themen/depression)    

\center
\begin{tabular}{ll}
 0–13     & keine Depression bzw. klinisch unauffällig oder remittiert  \\
 14–19    & leichtes depressives Syndrom                                \\       
 20–28    & mittelgradiges depressives Syndrom                          \\
 $\ge$ 29 & schweres depressives Syndrom
\end{tabular}


# Tests
\setstretch{2}
\textcolor{darkblue}{Beck-Depressionsinventar (BDI-II)} 

Beispielitem Traurigkeit

(0) Ich bin nicht traurig
(1) Ich bin oft traurig
(2) Ich bin ständig traurig
(3) Ich bin so traurig oder unglücklich, dass ich es nicht aushalte


# Tests
\textcolor{darkblue}{Beck-Depressionsinventar (BDI-II)} 

Items
\footnotesize
\vspace{-1mm}

\setstretch{1.2}
1.	Traurigkeit
2.	Pessimismus
3.	Versagensgefühle
4.	Verlust an Freude
5.	Schuldgefühle
6.	Bestrafungsgefühle
7.	Selbstablehnung
8.	Selbstkritik
9.	Suizidgedanken
10.	Weinen
11.	Unruhe
12.	Interessensverlust
13.	Entschlussunfähigkeit
14.	Wertlosigkeit
15.	Energieverlust
16.	Veränderungen der Schlafgewohnheiten
17.	Reizbarkeit
18.	Appetitveränderung
19.	Konzentrations­schwierigkeiten
20.	Müdigkeit
21.	Verlust an sexuellem Interesse

# 
\vfill
\setstretch{3}
\large
Tests

**Testgütekriterien**

Testmodelle

Selbstkontrollfragen
\vfill

# Testgütekriterien
\setstretch{1.6}

\textcolor{darkblue}{Hauptgütekriterien}

1. Objektivität
1. Reliabilität
1. Validität

\textcolor{darkblue}{Nebengütekriterien}

1. Skalierung
1. Normierung (Eichung)
1. Testökonomie
1. Nützlichkeit
1. Zumutbarkeit
1. Unverfälschbarkeit
1. Fairness

\flushright @moosbrugger2012

# Testgütekriterien

\noindent (1) Objektivität

\small
Ein Test ist dann *objektiv*, wenn er dasjenige Merkmal, das er misst, unabhängig
von Testleitenden und Testauswertenden misst. Außerdem müssen klare und 
anwenderunabhängige Regeln für die Ergebnisinterpretation vorliegen.

\normalsize
\noindent (2) Reliabilität

\small
Ein Test ist dann *reliabel*, wenn er das Merkmal, das er misst, exakt, d.h.
ohne Messfehler misst. Vor dem Hintegrund der Klassischen Testtheorie unterscheidet
man die *Retest-Reliabilität*, die *Paralleltest-Reliabilität*, die 
*Testhalbierungs-Reliabilität (Split-Half-Reliabilität)* und die *Innere Konsistenz*
eines Tests.

\normalsize
\noindent (3) Validität

\small
Ein Test gilt dann als valide, wenn er das Merkmal, das er messen soll, auch wirklich
misst und nicht irgendein anderes. Man unterscheidet die *Inhaltsvalidität* auf
Grundlage logischer und fachlicher Überlegungen, die *Augenscheinvalidität* aufgrund
der Intuition, die *Kriteriumsvalidität* durch Vergleich mit externen Kriterien
und die *Konstruktvalidität*, meist aufgrund testtheoretischer Annahmen
und Modelle wie zum Beispiel Faktorenanalysen.

\footnotesize
\flushright @moosbrugger2012

# Testgütekriterien
\textcolor{darkblue}{Beck-Depressionsinventar (BDI-II)} 

Durchführungsobjektivität

\small
Schriftliche Instruktion des BDI-II Manuals

\footnotesize
"Dieser Fragebogen enthält 21 Gruppen von Aus­sagen. Bitte lesen Sie jede dieser Gruppen von Aussagen 
sorgfältig durch und suchen Sie sich dann in jeder Gruppe eine Aussage heraus, die am besten beschreibt, 
wie Sie sich in den letzten zwei Wochen, einschließlich heute, gefühlt haben. Kreuzen Sie die Zahl 
neben der Aussage an, die Sie sich herausgesucht haben (0, 1, 2 oder 3). Falls in einer Gruppe mehrere 
Aussagen gleicher­maBen auf Sie zutreffen, kreuzen Sie die Aussage mit der höheren Zahl an. Achten Sie bitte 
darauf, dass Sie in jeder Gruppe nicht mehr als eine Aussage ankreuzen, das gilt auch für Gruppe 16 
(Veränderungen der Schlafgewohnheiten) oder Gruppe 18 (Veränderungen des Appetits)." 

\normalsize
Auswertungsobjektivität

\footnotesize
"Der Fragebogen wird durch die einfache Addition der angekreuzten Aussagen ausgewertet. Jedes Item wird auf einer 
4-Punkt-Skala bewertet, die von O bis 3 reicht. Kreuzt ein Proband bei einem Item meh­rere Aussagen an, so geht nur die 
Aussage mit der höchsten Ziffer in den Summenwert ein. Der Ge­samtwert des BDI-II kann Werte zwischen O und 63 Punkten 
annehmen."

\small
Ergebnisinterpretation
\footnotesize

* Alle Selbstbeurteilun­gen weisen eine Tendenz zur Ergebnisverzerrung auf.
* Klinisch relevant ist es, auf spezifische Iteminhalte (Suizidalität) zu achten. 

\flushright
\footnotesize
@hautzinger2006

# Testgütekriterien
\textcolor{darkblue}{Nebengütekriterien}

\small
\noindent (4) Skalierung

\footnotesize
Ein Test erfüllt das Gütekriterium der Skalierung, wenn die laut Verrechnungsregel
resultierenden Testwerte die qualitativen Merkmalsrelationen adäquat abbilden. Formale
Skalierungseigenschaften werden meist (nur) im Rahmen der Item-Response-Theorie
überprüft.
\vspace{2mm}

\small
\noindent (5) Normierung (Eichung)

\footnotesize
Unter der Normierung (Eichung) eines Tests versteht man das Erstellen eines
Bezugssystems, mit dessen Hilfe die Ergebnisse einer Testperson im Vergleich
zu den Merkmalsausprägungen anderer Personen eindeutig eingeordnet und interpretiert
werden können. Meist nutzt man für die Bestimmung von Normwerten eine sogenannte
Eichstichprobe.
\vspace{1mm}

\small
\noindent (6) Testökonomie 

\footnotesize
Ein Test erfüllt das Gütekriterium der Ökonomie, wenn er, gemessen am 
diagnostischen Erkenntnisgewinn, relativ wenig finanzielle und zeitliche 
Ressource beansprucht.

\flushright @moosbrugger2012

# Testgütekriterien

\textcolor{darkblue}{Nebengütekriterien}
\small

\noindent (7) Nützlichkeit

\footnotesize
Ein Test ist dann nützlich, wenn für das von ihm gemessene Merkmal praktische
Relevanz besteht und die auf seiner Grundlage getroffenen Entscheidungen (Maßnahmen)
mehr Nutzen als Schaden erwarten lassen.

\small
\noindent  (8) Zumutbarkeit

\footnotesize
Ein Test erfüllt das Kriterium der Zumutbarkeit, wenn er absolut und relativ zu dem
aus seiner Anwendung resultierenden Nutzen die zu testende Person in zeitlicher,
psychischer sowie physischer Hinsicht nicht über Gebühr belastet.

\small
\noindent  (9) Unverfälschbarkeit

\footnotesize
Ein Testverfahren erfüllt das Gütekriterium der Unverfälschbarkeit, wenn das Verfahren
derart konstruiert ist, dass die zu testende Person durch gezieltes Testverhalten
die konkreten Ausprägungen ihrer Testwerte nicht steuern bzw. verzerren kann.

\small
\noindent  (10) Fairness

\footnotesize
Ein Test erfüllt das Gütekriterium der Fairness, wenn die resultierenden Testwerte
zu keiner systematischen Benachteiligung bestimmter Personen aufgrund ihrer Zugehörigkeit
zu ethnischen, soziokulturellen oder geschlechtspezifischen Gruppen führen.

\flushright @moosbrugger2012

# 
\vfill
\setstretch{3}
\large
Tests

Testgütekriterien

**Testmodelle**

Selbstkontrollfragen
\vfill




# Testmodelle
\textcolor{darkblue}{Faktorenanalyse}
\setstretch{1.8}

* Probabilistisches Modell der Kovarianzeigenschaften von Items eines Tests
* Zentrale Beiträge von  @spearman1904, @hotelling1933, @lawley1940
* Latentes Variablenmodell der Form
\begin{align}
\begin{split}
\mbox{Latent Variable}   & = \mbox{Zero} + \mbox{Latent Error}                                  \\
\mbox{Observed Variable} & = \mbox{Loadings} \cdot \mbox{Latent Variable} + \mbox{Observation Error}   \\
\end{split}
\end{align}
* Erklärung von Antwortmustern durch wenige nicht-direkt observierbare Faktoren
* Exploratorische und konfirmatorische Varianten

\flushright
$\Rightarrow$ Bestimmung der faktoriellen Validität 

# Testmodelle
\textcolor{darkblue}{Item-Response-Theorie}
\setstretch{1.8}

* Probabilistisches Modell von Itemantworten als Funktion von Fähigkeiten/Zustand
* Zentrale Beiträge von @rasch1960, @novick1966, @lord1980 
* Verschiedene mathematische Formen der Logistischen Regression
* Einsatz und Entwicklung insbesondere bei Fähigkeitstests 
* Bezüge zur Messtheorie nach Stevens und zum Rasch-Modell
* Zur Bedeutung im Klinischen Kontext, siehe @reise2009

\flushright
$\Rightarrow$ Kein Thema des Seminars im SoSe 2024 und im BDI-II Manual

# 
\vfill
\setstretch{3}
\large
Tests

Testgütekriterien

Testmodelle

**Selbstkontrollfragen**
\vfill

# Selbstkontrollfragen
\footnotesize
\setstretch{3}

1. Erläutern Sie den Begriff des psychologischen Tests.
1. Nennen und erläutern Sie die Hauptklassen psychologischer Tests.
1. Erläutern Sie den Begriff des Items.
1. Skizzieren Sie die Modelle der Klassischen Testheorie, der Faktoranalyse und der Item-Response-Theorie.
1. Nennen und erläutern Sie die drei Hauptgütekriterien psychologischer Tests.
1. Nennen und erläutern Sie sieben Nebengütekriterien psychologischer Tests.

# Referenzen {.allowframebreaks}
\footnotesize --> -->



<!-- Probabilistisches Modell von Item- und Summenwerten eines Tests

Zentrale Beiträge von @gulliksen1950 und @lord1968

Messfehlermodell der Form 
\begin{equation}
\mbox{Observed Score} = \mbox{True Score} + \mbox{Error Score}
\end{equation}

Modellierung von intra- und interindividueller Variabilität

Grundlage für die quantitative Reliabiliätsbeurteilung 

$\Rightarrow$ Paralleltestreliabiliät, Spearman-Brown-Formel, Cronbach's $\alpha$

Die Klassische Testtheorie ist zunächst einmal eine Reliabilitätstheorie

Wir sprechen von *Tests* meinen in der klinischen Anwendung aber vor allem Fragebögen

Paralleltestverfahren

Retestverfawhren

Interne Konsistenz


Wir gehen davon aus, dass Begrifflichkeiten wie *Paralleltestreliabilität, 
Retestreliabilität, Cronbach's $\alpha$, Spearman-Brown-Formel*  aus dem 
Bachelor schon bekannt, aber nicht wirklich formal verstanden sind.

Insbesondere wollen wir im Seminar folgende Partikularitäten der Klassischen Testheorie erläutern:

Warum kann die Reliabilität eines Tests einerseits über die Korrelation von 
True-Scores und Observed Scores definiert sein, gleichzeitig aber allein über die 
Korrelation der Observed Scores mehrerer Tests bestimmt werden?

Woher kommt die Formel für Cronbach's $\alpha$ und wann und warum gilt sie?

Woher kommt die Spearman-Brown Formel und wann und warum gilt sie?

Zur Beantwortung dieser Fragen müssen wir einiges an Vorarbeit leisten

(1) Wiederholung allgemeiner Grundlagen zu Erwartungswerten, Varianzen, Kovarianzen, Korrelation
(2) Explizite Formulierung des Modells der Klassischen Testtheorie
(3) Definition von Paralleltests
(4) Definition der Reliabilität

Basierend auf diesen Vorarbeiten sind dann Antworten auf obige Fragen möglich. -->


<!-- # Testmodelle
\textcolor{darkblue}{Klassische Testtheorie}
\setstretch{1.8}

* Probabilistisches Modell von Item- und Summenwerten eines Tests
* Zentrale Beiträge von @gulliksen1950 und @lord1968
* Messfehlermodell der Form 
\begin{equation}
\mbox{Observed Score} = \mbox{True Score} + \mbox{Error Score}
\end{equation}
* Modellierung von intra- und interindividueller Variabilität
* Grundlage für die quantitative Reliabiliätsbeurteilung 

\flushright
$\Rightarrow$ Paralleltestreliabiliät, Spearman-Brown-Formel, Cronbach's $\alpha$

#  
\textcolor{darkblue}{Beispielaussagen zur Reliabilität des BDI-II}

\footnotesize

*Retest-Reliabilität* 

In der Studie von Beck et al. (1996) resultierte bei 26 Patienten, die im Abstand 
von einer Woche un­tersucht wurden, ein Retestkoeffizient von $\mbox{r}_{\mbox{tt}} = .93$. 
Aus Studentenstichproben werden für ein- bis zwei­wöchige Zeiträume Koeffizienten 
von  $\mbox{r}_{\mbox{tt}} = .74-.96$ berichtet (Leigh &Antony-Tolbert, 2001; Al-Musa­wi, 
2001; Sprinkle, Lurie, Insko et al., 2002; Ghas­semzadeh, Mojtabai, Karamghadiri & Ebrahimkha­ni, 2005). 

*Interne Konsistenz* 

In Tabelle 2 sind bisherige Ergebnisse zur internen Konsistenz (Cronbach's $\alpha$) 
des BDI II aufgelistet. In psychiatrischen Stichproben lag die interne Kon­sistenz 
im Bereich von $.89 \le \alpha \le .94$, in nichtklini­schen Stichproben im Bereich 
von  $.84 \le \alpha \le .91$.

\flushright
\footnotesize
@hautzinger2006 -->


### Notation {-}

Zufallsvariablen $y, \tau, \eps$ mit Werten $\ups, t, e$ in $Y, T, E$

## Das Modell multipler Testmessungen {#sec-grundlagen}

Die Klassische Testtheorie in der Formalisierung nach @novick1966 und @lord1968
nimmt ihren Ausgang von der Definition des *True-Scores* einer Testmessung einer
Person, die die Definitionen des *Observed-Scores* und des *Error-Scores* impliziert.
Sie hat folgende Form.

:::{#def-true-score-observed-score-und-error-score} 
## True-Score, Observed-Score und Error-Score 
Für $i = 1,...,n$ und $j = 1,...,m$ ist der *True-Score* $t_{ij}$ 
einer Person $i$ für eine Testmessung $j$ definiert als der bedingte 
Erwartungswert des *Observed Scores* der Person für diese Testmessung
\begin{equation}
t_{ij} := \mathbb{E}(y_{ij}|\tau_{ij} = t_{ij}).
\end{equation}
Der *Error-Score* einer Person ist definiert als die Zufallsvariable
\begin{equation}
\eps_{ij} := y_{ij} - t_{ij}.
\end{equation}
:::

True-, Observed- und Error-Score werden im Deutschen natürlich auch *wahrer Wert*, 
*beobachteter Wert* und *Messfehler* genannt. Mit dem Begriff einer *Testmessung* 
ist hier etwas unspezifisch und je nach Anwendung entweder eine Messung mithilfe 
eines einzelnen Items oder mithilfe der Summe mehrer Items gemeint. An späterer 
Stelle werden wir die Unterscheidung von Itemscores und Testsummenscores explizit
machen, welche im Rahmen der Klassischen Testtheorie den Begriff der 
$m$-Komponententestmodelle (vgl. @sec-interne-konsistenz) induziert. Man beachte, dass 
der Definition bedingter Erwartungswerte gemäß $\tau_{ij}, y_{ij}$ und 
$\eps_{ij}$ hier Zufallsvariablen sind und $t_{ij} \in \mathbb{R}$ eine Konstante ist.

Die Definition des True-Scores $t_{ij}$ in @def-true-score-observed-score-und-error-score
ist etwas speziell, um nicht zu sagen zirkulär bis tautologisch, da $t_{ij}$ mithilfe 
von $t_{ij}$ definiert wird. Die zentrale Motivation von @novick1966 und @lord1968
den True-Scores $t_{ij}$ als bedingten Erwartungswert, anstelle von zum Beispiel
einfach einer Realisierung der Zufallvariable $tau_{ij}$ zu definieren, war es,
sich einer Diskussion zur metaphysischen Bedeutung eines True-Scores zu entziehen.
Hätten @novick1966 und @lord1968 beispielsweise den True-Score als Realisierung
einer latenten Variable definiert, die einer Person für eine bestimmte Testmessung
eigen sein soll, so hätte dies in der zeitgenössischen Diskussion eindeutig den 
Charakter einer angreifbaren metaphysischen Aussage. Stattdessen versuchen 
@novick1966 und @lord1968 in ihrer Definition möglichst operationalistisch vorzugehen
und den True Score einer Person für eine Testmessung als "Durchschnitt der Observed
Scores" einer Person über "wiederholte Testmessungen unter identischen Bedingungen"
darzustellen. Zur Bedeutung des True-Scores zitieren @lord1968, S.29 - 30 \hl{Lazarsfeld, 1959}

"Angenommen, wir fragen eine Person, Herrn Brown, wiederholt, ob er die Vereinten Nationen
befürwortet; nehmen wir weiter an, dass wir ihm nach jeder Frage „das Gehirn waschen“ 
und ihm dann dieselbe Frage erneut stellen. Da Herr Brown unsicher ist, wie er zu den 
Vereinten Nationen steht, wird er manchmal eine befürwortende und manchmal eine ablehnende 
Antwort geben. Nachdem wir dieses Verfahren viele Male durchgeführt haben, berechnen 
wir anschließend den Anteil der Male, in denen Herr Brown die Vereinten Nationen befürwortet hat."

Diese Proportion wollen @novick1966 und @lord1968 dann als True-Score verstehen 
(vgl. auch @borsboom2004). Natürlich ist dieser Versuch einer anti-metaphysischen
Grundhaltung nicht durchhaltbar: zum einen handelt es sich bei der "wiederholten
Testmessung unter identischen Bedingugen" um ein idealisiertes, in der Realität
nicht durchführbares Gedankenexperiment. Zum anderen definiern @novick1966 und @lord1968
den True-Score auch gerade nicht als (endlichen) Mittelwert einer Messreihe, sondern
als idealisierten Erwartungswert einer Zufallsvariable. Als wirklich operationalistische,
Metaphysik-freie Definition überzeugt @def-true-score-observed-score-und-error-score
also nicht, verkompliziert die Entwicklung einer Standardmessfehlertheorie, wie
sie beispielsweise dies klassische Formalisierung des ALMs darstellt, für die
Analyse von Tests und Fragebögen aber beträchtlich. Dies mag einer der Gründe sein,
warum die Klassische Testtheorie bis heute lediglich in der Psychologie und wenig
darüberhinaus von Bedeutung ist.

Ähnlich gelagert ist die Bezeichnung der bedingten Verteilung des Observed-Scores 
$\mathbb{P}(y_{ij}|\tau_{ij} = t_{ij})$ als *Propensitätsverteilung* durch
@lord1968, welche die intraindividuelle Observed-Score Variabilität bei festem 
True-Score modelliert. Dabei klingt an, dass @lord1968 eine Propensitätsinterpretation
von Wahrscheinlichkeiten als kausal bedingte "Verwicklungstendenzen", die, im 
Gegensatz zur Frequentistischen Interpretation auch im Einzelfall Sinn ergibt.
Allerdings unterstellen Propensitätsverteilungen kausale Prozesse, die in der
Regel nicht spezifiziert und damit auch nicht beobachtbar sind, und führen damit
letztlich auch wieder auf metaphysische Aussagen (vgl. auch @borsboom2004 und @borsboom2009).

In unserer Darstellung wollen wir dem zeitgemäßen modell-basiert-realistischem
Ansatz folgen und wählen mit @def-modell-multipler-testmessungen deshalb eine 
Formulierung des Modells multipler Testmessungen der Klassischen Testtheorie, die mit 
@def-true-score-observed-score-und-error-score und damit natürlich auch 
den theoretischen Ergebnissen der Klassischen Testtheorie kongruent ist, aber nicht versucht,
ihren Modellcharakter zu verschleiern und dabei insbesondere auch das Gesamtziel der
Modellierung einer Menge von $m$ Testmessungen von $n$ Personen, als eines Datensatzes
von $nm$ Datenpunkten in den Vordergrund stellt. Wir definieren das *Modell multipler
Testmessungen* daher wie folgt.  


:::{#def-modell-multipler-testmessungen}
## Modell multipler Testmessungen
Für $i = 1,...,n$ und $j = 1,...,m$ seien $\tau_{ij}$ eine Zufallsvariable, 
die den *True-Score* der $i$ten Person in der $j$ten Testmessung modelliere und
$y_{ij}$ eine Zufallsvariable, die den *Observed-Score* der $i$ten Person in 
der $j$ten Testmessung modelliere. Dann nennen wir die gemeinsame Verteilung der 
$\tau_{ij}$ und $y_{ij}$ mit der Faktorisierungseigenschaft
\begin{equation}
\mathbb{P}\left(\tau_{11},y_{11},...,\tau_{nm},y_{nm}\right)  
:= \prod_{i=1}^n \mathbb{P}(\tau_{i1},...,\tau_{im})\prod_{j=1}^m \mathbb{P}(y_{ij}|\tau_{ij})
\end{equation}
das *Modell multipler Testmessungen*, wenn gilt, dass
\begin{equation}
\mathbb{P}(\tau_{11},...,\tau_{1m})\prod_{j=1}^m \mathbb{P}(y_{1j}|\tau_{1j}) = \cdots =
\mathbb{P}(\tau_{n1},...,\tau_{nm})\prod_{j=1}^m \mathbb{P}(y_{nj}|\tau_{nj}).
\end{equation}     
:::

Die Definition des Modells multipler Testmessungen bildet einige grundlegende
Annahmen zur Unabhängigkeit und Identität von Verteilungen in der Klassischen
Testtheorie ab. Zunächst einmal wird angenommen, dass die gemeinsame Verteilung 
der $\tau_{ij}, y_{ij}$ über $i = 1,...,n$ faktorisiert, dass  die Verteilungen der 
True-Scores und Observed-Scores also über Personen unabhängig sind. Wissen um 
True- oder Observed-Scores einer Person ändert die angenommenen Verteilungen 
der True- oder Observed-Scores anderer Personen also nicht. Dagegen faktorisiert
für jedes $i = 1,...,n$ die gemeinsame Verteilung der $\tau_{i1},...,\tau_{im}$ 
über Testmessungen $j = 1,...,m$ nicht notwendigerweise. Die True-Scores einer 
Person können also abhängig sein und damit Wissen um die Ausprägung einer Testmessung
bei einer Person die Verteilung des True-Scores  anderen Testmessung derselben Person 
informieren. In der Klassischen Testtheorie werden verschiedene Arten dieser Form 
von Abhängigkeiten unterschieden und wie wir später sehen werden beispielsweise 
als *Parallelität*, *$\tau$-Äquivalenz* und *essentielle $\tau$-Äquivalenz* bezeichnet.
Weiterhin wird für jede Person $i = 1,...,n$ angenommen, dass die Observed-Scores 
$y_{ij}$ für $j = 1,...,m$ gegeben $\tau_{ij}$ bedingt unabhängig sind. Dies impliziert
einerseits, dass für eine Person der True-Score in Testmessung $k \neq j$ den 
Observed-Score in Testmessung $j$ nicht beinflusst und ebenso, dass der Observed-Score 
in Testmessung $k \neq j$ den Observed-Score in Testmessung $j$ nicht beeinflusst.


Schließlich wird angenommen, dass die Marginalverteilungen 
\begin{equation}
\mathbb{P}(\tau_{i1},y_{i1},...,\tau_{im},y_{im}) = \mathbb{P}(\tau_{i1},...,\tau_{im})\prod_{j=1}^m \mathbb{P}(y_{ij}|\tau_{ij})
\end{equation}
über Personen $i = 1,...,n$ identisch sind. Man mag sich die Realisierung der
True-Scores und Observed-Scores einer Person also als unabhängige und identische
Realisierungen aus einer "Populationsverteilung"
\begin{equation}
\mathbb{P}(\tau_{\bullet 1},y_{\bullet 1},...,\tau_{\bullet m},y_{\bullet m}) = \mathbb{P}(\tau_{\bullet 1},...,\tau_{\bullet m})\prod_{j=1}^m \mathbb{P}(y_{\bullet j}|\tau_{\bullet j})
\end{equation}
vorstellen, wobei das Subskript $\bullet$ die Unspezifität dieser Verteilung
bezüglich einer Person symbolisieren soll.

Betrachtet man den Spezialfall einer einzelnen Testmessung bei $n$ Personen,
so ergibt sich eine vereinfachte Form von @def-modell-multipler-testmessungen,
auf die man häufig in der psychologischen Einführungsliteratur trifft.  Nach
@def-modell-multipler-testmessungen gilt für $m = 1$ 
\begin{equation}
\mathbb{P}\left(\tau_{11},y_{11},...,\tau_{n1},y_{n1}\right)  
:= \prod_{i=1}^n \mathbb{P}(\tau_{i1})\mathbb{P}(y_{i1}|\tau_{i1})
\end{equation}
wobei nach Annahme von @def-modell-multipler-testmessungen die gemeinsamen Marginalverteilungen
$\mathbb{P}(\tau_{i1}, y_{i1})$ über Personden $i = 1,...,n$ identisch sind. Wie oben
kann man sich die observierten True- und Observed-Scores für eine Testmessung 
also als unabhängige Realisierungen der "Populationsverteilung"
\begin{equation}
\mathbb{P}(\tau_{\bullet 1})\mathbb{P}(y_{\bullet 1}|\tau_{\bullet 1})
\end{equation}
vorstellen. Verzichtet man nun noch auf die Subskripte $\bullet 1$, gelangt man
zu folgender vereinfachter Definition.

:::{#def-vereinfachtes-modell-der-klassischen-testtheorie}
## Vereinfachtes Modell der klassischen Testtheorie
$\tau$ sei eine Zufallsvariable, die die Verteilung der *True-Scores* 
zu einer Testmessung in einer Population beschreibe und $y$ sei eine 
Zufallsvariable, die die Verteilung der *Observed-Scores* einer Testmessung 
beschreibe. Dann heißt die gemeinsame Verteilung von $\tau$ und $y$, 
\begin{equation}
\mathbb{P}\left(\tau,y\right)  
= \mathbb{P}(\tau)\mathbb{P}(y|\tau) 
\end{equation}
das *Vereinfachte Modell der Klassischen Testtheorie* für eine Testmessung.
:::

@def-vereinfachtes-modell-der-klassischen-testtheorie hat gegenüber @def-modell-multipler-testmessungen
den Vorteil, dass weniger Zufallsvariablen und Indizes auftreten und auf die 
Redundanz der unterschiedlichen Bezeichnung vieler gleicher Verteilungen verzichtet 
werden kann. Im Sinne Frequentistischer Produktmodelle mag man bezüglich der Daten
von $n$ Personen hier auch 
\begin{equation}
(\tau_1,y_1), ...,(\tau_n,y_n) \sim \mathbb{P}(\tau,y) 
\end{equation}
schreiben, wobei nur die $y_1,...,y_n$ beobachtete, die $\tau_1,...,\tau_n$ dagegen
natürlich latente Zufallsvariablen sind. Weiterhin gilt, dass man viele wichtige
Eigenschaften des Modells der Klassischen Testtheorie schon basierend auf den 
Eigenschaften von $\mathbb{P}\left(\tau,y \right)$ begründen kann, wie wir unten sehen werden.
Generell ist das vereinfachte Modell der Klassischen Testtheorie einfacher zu handhaben
als das Modell multipler Testmessungen. Problematisch wird es allerdings insbesondere, 
sobald mehrere Testmessungen (z.B. bei Abhängigkeitsbetrachtungen zwischen zwei Tests 
oder zwei Items eines Tests) ins Spiel kommen, wie es bei den interessanteren 
Aussagen der Klassischen Testtheorie grundsätzlich der Fall ist. Außerdem gilt 
natürlich auch, dass Schätzer der Modellparameter einerseits immer auf allen Observed-Score 
Zufallsvariablen $y_{1j}, ...y_{nj}$ beruhen und andererseits diese in 
@def-vereinfachtes-modell-der-klassischen-testtheorie überhaupt nicht auftreten. 
In anderen Worten ist @def-vereinfachtes-modell-der-klassischen-testtheorie für 
theoretische Betrachtungen oft einfacher zu behandeln als @def-modell-multipler-testmessungen,
der Anwendung der Klassischen Testtheorie in der Fragebogendatenanalyse liegt in 
der Regel aber @def-modell-multipler-testmessungen zugrunde. Wir werden in der
Folge je nach Bedarf zwischen beiden Modellformulierungen hin und her wechseln, halten
aber fest, dass die Modellformulierung in Sinne von @def-modell-multipler-testmessungen
unser Standardfall ist.


### Eigenschaften des Modells multipler Testmessungen {-}

Das Modell multipler Testmessungen nach @def-modell-multipler-testmessungen hat 
zunächst eine Reihe von Eigenschaften bezüglich einer (und damit jeder) 
Testmessung, die für die Anwendung der Klassischen Testtheorie grundlegend sind. 

#### Eigenschaften bezüglich einer Testmessungen

Wir fassen fünf dieser Eigenschaften bezüglich einer einzelnen Testmessung 
in folgendem Theorem zusammen.

:::{#thm-eigenschaften-bezüglich-einer-testmessung}
## Eigenschaften bezüglich einer Testmessung
Gegeben sei das Modell multipler Testmessungen. Dann gelten für alle $i = 1,...,n$ und alle $j = 1,...,m$

(1) $\mathbb{E}(\eps_{ij}|\tau_{ij} = t_{ij}) = 0$ 
(2) $\mathbb{E}(\eps_{ij}) = 0$ 
(3) $\mathbb{C}(\tau_{ij}, \eps_{ij}) = 0$ 
(4) $\mathbb{V}(y_{ij}) = \mathbb{V}(\tau_{ij}) + \mathbb{V}(\eps_{ij})$ 
(5) $\mathbb{C}(y_{ij},\tau_{ij}) = \mathbb{V}(\tau_{ij})$ 

:::

:::{.proof}

Zur Vereinfachung der Notation im Sinne des einfachen Modells der klassischen 
Testtheorie nach @def-vereinfachtes-modell-der-klassischen-testtheorie setzen wir
zunächst für alle $i = 1,...,n$ und $j = 1,...n$
\begin{equation}
y := y_{ij} \mbox{ und } \tau := \tau_{ij} 
\mbox{ mit Ergebnisräumen } Y := Y_{ij} \mbox{ und } T := T_{ij}.
\end{equation}
Weiterhin bezeichnen wir Werte von $y$ mit $\ups$ und Werte von $\tau$ mit $t$.
Schließlich betrachten wir nur den diskreten Fall, setzen also die Existenz 
einer Wahrscheinlichkeitsmassefunktion  $p : Y \times T \to [0,1]$ der Form
\begin{equation}
p(t,\ups) = p(\ups|t)p(t)
\end{equation} 
voraus. Der kontinuierliche Fall oder gemischte Fall folgt dann jeweils analog.

\noindent (1) Es gilt
\begin{align}
\begin{split}
\mathbb{E}(\eps|\tau = t) 
& := \mathbb{E}(y - \tau|\tau = t) \\
&  = \sum_{\ups \in Y} \left(\ups - t\right)p(\ups|t) \\
&  = \sum_{\ups \in Y} \ups p(\ups|t) - \sum_{\ups \in Y} t p(\ups|t) \\
&  = \mathbb{E}(y|\tau = t) - t  \sum_{\ups \in Y} p(\ups|t)\\
&  = t - t\cdot 1  \\
&  = 0.
\end{split}
\end{align}
\noindent (2) Es gilt  
\begin{align}
\begin{split}
\mathbb{E}(\eps) 
& := \mathbb{E}(y - \tau) \\
& = \sum_{t \in T}\sum_{\ups \in Y} \left(\ups - t\right)p(t,\ups) \\
& = \sum_{t \in T}\sum_{\ups \in Y} \left(\ups - t\right)p(\ups|t)p(t) \\
& = \sum_{t \in T}\sum_{\ups \in Y} \ups p(\ups|t)p(t) - t p(\ups|t)p(t) \\
& = \sum_{t \in T}\sum_{\ups \in Y} p(t)\left(\ups p(\ups|t)  - t p(\ups|t)\right)\\
& = \sum_{t \in T} p(t)\left(\sum_{\ups \in Y} \ups p(\ups|t) - t \sum_{\ups \in Y}p(\ups|t)\right)\\
& = \sum_{t \in T} p(t) \left(t - t \cdot 1\right)\\
& = \sum_{t \in T} p(t) \cdot 0\\
& = 0.
\end{split}
\end{align}
\noindent (3) Es gilt 
\begin{align}
\begin{split}
\mathbb{C}(\tau, \eps)  
& = \mathbb{E}\left((\tau -\mathbb{E}(\tau))(\eps - \mathbb{E}(\eps))\right) \\
& = \mathbb{E}\left((\tau -\mathbb{E}(\tau))\eps \right) \\
& = \sum_{t \in T}\sum_{\ups \in Y} \left((t-\mathbb{E}(\tau))(\ups-t)\right)p(t,\ups) \\
& = \sum_{t \in T}\sum_{\ups \in Y} (t-\mathbb{E}(\tau))(\ups - t)p(\ups|t)p(t) \\
& = \sum_{t \in T}p(t)(t-\mathbb{E}(\tau))\sum_{\ups \in Y} \left(\ups - t\right)p(\ups|t) \\
& = \sum_{t \in T}p(t)(t-\mathbb{E}(\tau))\sum_{\ups \in Y} \left(\ups p(\ups|t) - t p(\ups|t) \right) \\
& = \sum_{t \in T}p(t)(t-\mathbb{E}(\tau)) \left(\sum_{\ups \in Y}\ups p(\ups|t) - t \sum_{\ups \in Y} p(\ups|t) \right) \\
& = \sum_{t \in T}p(t)(t-\mathbb{E}(\tau)) \left(t - t \cdot 1 \right) \\
& = \sum_{t \in T}p(t)(t-\mathbb{E}(\tau))  \cdot 0 \\
& = 0. \\
\end{split}
\end{align}
\noindent (4) Mit dem Theorem zu Varianzen von Summen und Differenzen von \hl{LINK} 
Zufallsvariablen sowie Aussage (3) des Theorems gilt
\begin{align}
\begin{split}
\mathbb{V}(y) 
= \mathbb{V}(\tau + \eps)  
= \mathbb{V}(\tau) + \mathbb{V}(\eps) + 2\mathbb{C}(\tau,\eps)
= \mathbb{V}(\tau) + \mathbb{V}(\eps) + 2\cdot 0 
= \mathbb{V}(\tau) + \mathbb{V}(\eps) 
\end{split}
\end{align}
\noindent (5) Mit dem Kovarianzverschiebungssatz  \hl{LINK} , der Linearkombinationseigenschaft
des Erwartungswerts  \hl{LINK} , Aussage (2) des Theorems und der Tatsache, dass mit Aussage (4) 
des Theorems außerdem folgt, dass
\begin{equation}
\mathbb{E}(\eps\tau)
= \mathbb{E}(\tau\eps)
= \mathbb{C}(\tau,\eps) + \mathbb{E}(\tau)\mathbb{E}(\eps)
= 0 + \mathbb{E}(\tau)\cdot 0
= 0
\end{equation}
gilt
\begin{align}
\begin{split}
\mathbb{C}(y, \tau) 
& = \mathbb{E}(y\tau) - \mathbb{E}(y)\mathbb{E}(\tau) \\ 
& = \mathbb{E}((\tau + \eps)\tau) - \mathbb{E}(\tau + \eps)\mathbb{E}(\tau) \\ 
& = \mathbb{E}(\tau^2 + \eps\tau) - \left(\mathbb{E}(\tau) + \mathbb{E}(\eps)\right)\mathbb{E}(\tau) \\
& = \mathbb{E}(\tau^2) + \mathbb{E}(\eps\tau) - \mathbb{E}(\tau)^2 - \mathbb{E}(\eps)\mathbb{E}(\tau) \\ 
& = \mathbb{E}(\tau^2) + \mathbb{E}(\eps\tau) - \mathbb{E}(\tau)^2 - 0\cdot \mathbb{E}(\tau) \\ 
& = \mathbb{E}(\tau^2) + 0 - \mathbb{E}(\tau)^2 - 0\cdot \mathbb{E}(\tau) \\
& = \mathbb{E}(\tau^2) - \mathbb{E}(\tau)^2 \\
& = \mathbb{V}(\tau).
\end{split}
\end{align}
:::

Wie die Subskripte in @thm-eigenschaften-bezüglich-einer-testmessung verdeutlichen,
beziehen sich die Aussagen von @thm-eigenschaften-bezüglich-einer-testmessung
auf die Zufallsvariablen zur Modellierung der Daten einer Person $i$ und einer 
Testmessung $j$ und gelten gleichermaßen für alle $i = 1,...,n$ und $j = 1,...,m$.
Aussage (1) von @thm-eigenschaften-bezüglich-einer-testmessung betrifft
den Erwartungswert des Error-Scores bedingt auf einem festen Wert des True-Scores,
in diesem Fall ist der True-Score also keine Zufallsvariable und die Verteilung
von Interesse $\mathbb{P}(\eps_{ij}|\tau_{ij} = t_{ij})$. Aussagen (2) - (5) 
beziehen sich auf Eigenschaften der (gemeinsamen) Marginalverteilungen von $y_{ij}$,
$\tau_{ij}$ und $\eps_{ij}$. Im Sinne des einfachen Modells der Klassischen 
Testtheorie werden obige Eigenschaften oft auch als

(1) $\mathbb{E}(\eps|\tau = t) = 0$
(2) $\mathbb{E}(\eps) = 0$ 
(3) $\mathbb{C}(\tau, \eps) = 0$ 
(4) $\mathbb{V}(y) = \mathbb{V}(\tau) +\mathbb{V}(\eps)$ 
(5) $\mathbb{C}(y,\tau) = \mathbb{V}(\tau)$ 

geschrieben. Wir wollen diese Eigenschaften nun noch kurz kommentieren. 

Spezieller Weise *folgt* für das Modell multipler Messungen, dass der bedingte Erwartungswert
des Error-Scores $\mathbb{E}(\eps|\tau = t)$ gleich Null ist aus der Definition des 
True-Scores. Dies steht im direkten Gegenentwurf zu typischen Annahmen über Messfehler,  
die üblicherweiseeinen Messfehler mit einem (bedingten) Erwartungswert von Null *definieren*,
da sie von Null verschiedene Beiträge zu einem Datenpunkt als Teil der durch sie 
repräsentierten Theorie konzeptualisieren (vgl. @sec-grenzwerte). Weil
im Modell multipler Testmessungen bedingte Error-Score Erwartungswert für jeden 
True-Score $t$ gleich Null, folgt dann, dass auch der marginale Erwarungswert 
des Errorscores $\mathbb{E}(\eps)$ gleich Null ist.

Die Tatsache, dass im Modell multipler Testmessungen gilt, dass die Kovarianz
der True- und Error-Scores gleich Null ist besagt bekanntlich, dass hohe oder 
niedrige True-Scores nicht systematisch mit hohen oder niedrigen Error-Scores 
assoziiert. Die daraus folgende Tatsachen, dass die Observed-Score Varianz additiv
in Beiträge der True-Score und der Error-Score Varianz zerlegt werden kann 
und dass die Kovarianz von Observed-Score und True-Score einer Testmessung
der Varianz der True Scores enstpricht werden an späterer Stelle essentiell für 
Eigenschaften der Reliabilität von Testmessungen sein.

Im Folgenden wollen wir @thm-eigenschaften-bezüglich-einer-testmessung noch an 
einem konkreten ersten Beispiel nach @lord1968, Exercise 2.17 für ein Modell 
multipler Testmessungen veranschaulichen, wobei wir hierbei natürlich auf eine 
einzige Testmessung fokussieren.


:::{#thm-normalverteilungsbeispiel}
## Normalverteilungsbeispiel
Es sei $i = 1,...,n$, $m := 1$ mit 
\begin{equation}
\mathbb{P}(\tau_{i1}) :=  N(\mu,1) \mbox{ und } \mathbb{P}(y_{i1}|\tau_{i1}) := N(\tau_{i1},1)
\end{equation}
Dann gelten

(1) $\mathbb{P}(y_{i1}) = N(\mu,2)$ 
(2) $\mathbb{P}(\eps_{i1}|\tau_{i1}) = N(0,1)$ 
(3) $\mathbb{P}(\eps_{i1}) = N(0,1)$
(4) $\mathbb{C}(\tau_{i1},\eps_{i1}) = 0$
::: 

:::{.proof}
Zur Vereinfachung der Notation setzen wir $\tau := \tau_{i1}, y := y_{i1}, 
\varepsilon := \eps_{i1}$.

\noindent (1) Wir betrachten die durch  
\begin{equation}
\mathbb{P}(\tau) = N(\mu,1) \mbox{ und }
\mathbb{P}(y|\tau) = N(\tau,1)
\end{equation}
induzierte gemeinsame Verteilung von $\tau$ und $y$, wobei offenbar
\begin{equation}
\mathbb{P}(y|\tau) = N(a\cdot \mu + b,1) \mbox{ mit } a:= 1 \mbox{ und } b := 0
\end{equation}
gilt. Aus dem Theorem zu gemeinsamen Normalverteilungen (\hl{LINK}) ergibt sich dann zunächst,
dass
\begin{equation}
\begin{pmatrix}
\tau \\ y
\end{pmatrix}
\sim
N\left(
\begin{pmatrix}
\mu \\ 1 \cdot \mu + 0
\end{pmatrix},
\begin{pmatrix}
1          & 1 \cdot 1 \\
1 \cdot 1  & 1 + 1 \cdot 1 \cdot 1
\end{pmatrix}
\right)
=
N\left(
\begin{pmatrix}
\mu \\ \mu
\end{pmatrix},
\begin{pmatrix}
1 & 1 \\
1 & 2 
\end{pmatrix}
\right)
\end{equation}
Aus dem Theorem zu marginalen Normalverteilungen (\hl{LINK}) ergibt sich dann 
durch Ablesen $y \sim N(\mu,2)$. 

\noindent (2) Wir betrachten $\mathbb{P}(\eps|\tau = t)$ 
für einen beliebigen Wert $t \in \mathbb{R}$. Dann gilt 
\begin{equation}
\eps := y - t \mbox{ mit } y \sim N(t,1)
\end{equation}
Mit dem Theorem zu linear-affinen Transformation einer normalverteilten 
Zufallsvariable (\hl{LINK}) gilt dann
\begin{equation}
\eps \sim N\left(t - t, 1^2 \cdot 1\right) = N(0,1)
\end{equation}
Die Tatsache, dass dies für alle möglichen Werte von $\tau$ gilt, ist gerade Aussage (2).

\noindent (3) und (4) Wir betrachten die durch  
\begin{equation}
\mathbb{P}(\tau) = N(\mu,1) \mbox{ und }
\mathbb{P}(\eps|\tau) = N(0,1)
\end{equation}
induzierte gemeinsame Verteilung von $\tau$ und $\eps$, wobei offenbar
\begin{equation}
\mathbb{P}(\eps|\tau) = N(a\cdot \mu + b,1) \mbox{ mit } a:= 0 \mbox{ und } b := 0
\end{equation}
gilt. Aus dem Theorem zu gemeinsamen Normalverteilungen ((\hl{LINK})) ergibt 
sich dann zunächst, dass
\begin{equation}
\begin{pmatrix}
\tau \\ \eps
\end{pmatrix}
\sim
N\left(
\begin{pmatrix}
\mu \\ 0 \cdot \mu + 0
\end{pmatrix},
\begin{pmatrix}
1         & 1 \cdot 0 \\
0\cdot 1  & 1 + 0 \cdot 1 \cdot 0
\end{pmatrix}
\right)
=
N\left(
\begin{pmatrix}
\mu \\ 0
\end{pmatrix},
\begin{pmatrix}
1 & 0 \\
0 & 1 
\end{pmatrix}
\right)
\end{equation}
Aus dem Theorem zu marginalen Normalverteilungen ((\hl{LINK})) ergeben sich dann 
durch Ablesen
\begin{equation}
\eps \sim N(0,1)
\mbox{ und }
\mathbb{C}(\tau,\eps) = 0.
\end{equation}
:::

Das Beispiel zeigt insbesondere, wie die Spezifika des Modells multipler Testmessungen
der Klassischen Testtheorie äquivalent durch Definition eines üblichen probabilistischen
Modells erzeugt werden können. Hier induzieren die Definition der marginalen Verteilung
der latenten True-Score Variable und die Definition der bedingten Verteilung der
observierten Observed-Score Variable zunächst eine eine gemeinsame Normalverteilung
von $\tau_{i1}$ und $y_{i1}$. Die Definition der Error-Score Variable als Differenz
zwischen Observed-Score und bedingtem True-Score Erwartungswert ergibt dann die
bedingte Error-Score Verteilung. Diese und die Definitionen des Beispiels 
induzieren dann eine gemeinsame Normalverteilung von $\tau_{i1}$ und $\eps_{i1}$. 
Die weiteren Eigenschaften im Sinne von @thm-eigenschaften-bezüglich-einer-testmessung
ergeben sich im Beispiel dann mit den Eigenschaften gemeinsamer Normalverteilungen.

\hl{SIMULATION UND VISUALISIERUNG}

Simulation mit $\mu := 1, n := 10^4$

\tiny
```{r, echo = T}
n           = 1e4                                           # Personenanzahl
m           = 1                                             # Testmessungsanzahl
mu          = 1                                             # True-Score Erwartungswertparameter   
T           = matrix(rep(NaN, n*m), nrow = n)               # True-Score Array
Y           = matrix(rep(NaN, n*m), nrow = n)               # Observed-Score Array 
E           = matrix(rep(NaN, n*m), nrow = n)               # Error-Score Array
for(i in 1:n){                                              # Iteration über Personen 
  for(j in 1:m){                                            # Iteration über Testmessungen 
    T[i,j]  = rnorm(1,mu,1)                                 # True-Score Realisierung
    Y[i,j]  = rnorm(1,T[i,j],1)                             # Observed-Score Realisierung
    E[i,j]  = Y[i,j] - T[i,j]}}                             # Error-Score Realisierung
e_hat_es    = mean(E[,1])                                   # Erwartungswertschätzung Error-Score 
c_hat_ts_es = cov(T[,1],E[,1])                              # Kovarianzschätzung True Score, Error-Score 
v_hat_os    = var(Y[,1])                                    # Varianzschätzung Observed-Score
v_hat_ts    = var(T[,1])                                    # Varianzschätzung True-Score 
v_hat_es    = var(E[,1])                                    # Varianzschätzung Error-Score  
c_hat_os_ts = cov(Y[,1],E[,1])                              # Kovarianzschätzung Observed-Score, True-Score
```
\normalsize

```{r, echo = F, eval = F}
library(latex2exp)
library(mvtnorm)
pdf(
file        =  "./_figures/901-normalverteilungsbeispiel-1.pdf",
width       = 12,
height      = 5)                                                                     
par(                                                                   
family     = "sans",                                                 
mfcol      = c(1,3),                                                  
pty        = "s",                                                      
bty        = "l",                                                     
lwd        = 1,                                                       
las        = 1,                                                      
mgp        = c(2,1,0),                                                
xaxs       = "i",                                                    
yaxs       = "i",                                                     
cex        = 1.1,                                                     
font.main  = 1,                                                       
cex.main   = 1.2)

# outcome space of interest
y_min       = -4                                                                 
y_max       = 6                                                                   
y_res       = 1e3                                                                 
y           = seq(y_min, y_max, len = y_res)                                     

# Marginalverteilung von y_{i1} 
p_ups   = dnorm(y, mu, sqrt(2))                                     
hist(
Y[,1],                                                                         
breaks  = 50,                                                                
col     = "gray90",                                                           
prob    = TRUE,                                                               
xlim    = c(y_min,y_max),                                                           
ylim    = c(0,.6),                                                             
xlab    = TeX("$y_{i1}$"),                                                                
ylab    = "",                                                                 
main    = TeX("$y_{i1} \\sim N(\\mu,2)$"))                                      
lines(
y,                                                                          
p_ups,                                                                      
lwd     = 2,                                                                  
col     = "darkorange")                                                       

# Marginalverteilung von \eps_{i1} 
p_eps   = dnorm(y, 0, 1)                                     
hist(
E[,1],                                                                         
breaks  = 50,                                                                
col     = "gray90",                                                           
prob    = TRUE,                                                               
xlim    = c(y_min,y_max),                                                           
ylim    = c(0,.6),                                                             
xlab    = TeX("$e_{i1}$"),                                                                
ylab    = "",                                                                 
main    = TeX("$\\epsilon_{i1} \\sim N(0,1)$"))                                      
lines(
y,                                                                          
p_eps,                                                                      
lwd   = 2,                                                                  
col   = "darkorange")  

# Gemeinsame Verteilung von \tau_{i1} und \eps_{i1}
mu          = c(mu,0)
Sigma       = matrix(c(1,0,0,1), nrow = 2) 
nsamp       = 200
y_1         = seq(y_min, y_max, length.out = y_res)
y_2         = seq(y_min, y_max, length.out = y_res)
X           = expand.grid(y_1,y_2)
p           = matrix(dmvnorm(as.matrix(X), mu, Sigma), nrow = y_res)
contour(
y_1,
y_2,
p,
xlim        = c(-2,4),
ylim        = c(-3,3),
xlab        = TeX("$t_{i1}$"),
ylab        = TeX("$e_{i1}$"),
nlevels     = 8,
main        = TeX("$P(\\tau_{i1},\\epsilon_{i1})$"))
points(
T[1:nsamp,1],
E[1:nsamp,1],
pch         = 21,
col         = "white",
bg          = "gray60",
cex         = .9)
dev.off()
```

<!-- ![Normalverteilungsbeispiel-1](./_figures/901-normalverteilungsbeispiel-1){#fig-normalverteilungsbeispiel-1 fig-align="center" width=100%} -->

Simulation mit $\mu := 1, n := 10^4$

```{r, eval = F, echo = F}
library(latex2exp)
pdf(file =  "./_figures/901-normalverteilungsbeispiel-2.pdf", width = 6, height = 6)                                                                      
par(                                                                   
family    = "sans",                                                  
mfcol     = c(1,1),                                                    
pty       = "m",                                                     
bty       = "l",                                                     
lwd       = 1,                                                        
las       = 1,                                                       
mgp       = c(2,1,0),                                                
xaxs      = "i",                                                     
yaxs      = "i",                                                     
cex       = 1.2,                                                     
font.main = 1,                                                      
cex.main  = 1.1)                                                        
labs      = c(TeX("$\\hat{E}(\\epsilon)$"), 
              TeX("$\\hat{C}(\\tau, \\epsilon)$"),
              TeX("$\\hat{V}(y)$"),
              TeX("$\\hat{V}(\\tau)$"),
              TeX("$\\hat{V}(\\epsilon)$"),
              TeX("$\\hat{C}(y, \\tau)$"))

plot(
1:6,
c(e_hat_es, c_hat_ts_es, v_hat_os, v_hat_ts, v_hat_es, c_hat_os_ts),
type     = "p",
ylim     = c(-1,3),
xlim     = c(0.5,6.5),
xaxt     = "n",
xlab     = "",
ylab     = "",
pch      =  19,
cex      =  1.4)
axis(1, at = 1:6, labels = labs)
grid()
dev.off()
```

<!-- ![Normalverteilungsbeispiel-2](./_figures/901-normalverteilungsbeispiel-2){#fig-normalverteilungsbeispiel-2 fig-align="center" width=60%} -->

\newpage
#### Eigenschaften bezüglich zweier Testmessungen {-}

Bisher haben wir fünf Eigenschaften des Modells multipler Testmessungen kennengelernt,
die für die True-, Observed-, und Error-Scores $\tau,y$ und $\eps$ einer (und damit jeder) 
Person $i$ und einer Testmessung $j$ gelten.  Im Folgenden beschäftigen wir uns 
mit Eigenschaften des Modells multipler Testmessungen, die für die True-, Observed-, 
und Error-Scores $\tau_j,y_j, \eps_j$ und $\tau_k,y_k, \eps_k$ einer (und damit jeder) Person 
$i$ hinsichtlich zweier Testmessungen  $j$ und $k$ gelten. Wir fassen diese Eigenschaften,
die manchmal als *lokale Unkorreliertheit* des Modells multipler Testmessungen 
bezeichnet werden, in folgende Theorem zusammen. 

:::{#thm-eigenschaften-bezüglich-zweier-testmessungen}
## Eigenschaften bezüglich zweier Testmessungen

Gegeben sei das Modell multipler Testmessungen. Dann gelten für alle Personen $i = 1,...,n$
und alle Testmessungen $j$ und $k$ mit $1 \le j,k \le m$ und $j \neq k$, dass

(1) $\mathbb{C}(y_{ij},y_{ik}|\tau_{ij} = t_{ij},\tau_{ik} = t_{ik}) = 0$,
(2) $\mathbb{C}(\eps_{ij},\eps_{ik}|\tau_{ij} = t_{ij},\tau_{ik} = t_{ik}) = 0$,
(3) $\mathbb{C}(\eps_{ij},\eps_{ik}) = 0$,
(4) $\mathbb{C}(\tau_{ij},\eps_{ik}) = 0$,
(5) $\mathbb{C}(y_{ij},y_{ik}) = \mathbb{C}(\tau_{ij},\tau_{ik})$.
::: 

:::{.proof}
Zur Vereinfachung der Notation verzichten wir in den Beweisen auf das $i$ Subskript.
Wir betrachten weiterhin nur den diskreten Fall und setzen die Existenz der marginalen
Wahrscheinlichkeitsmassefunktion
\begin{equation}
p(t_j,\ups_j,t_k,y_k) = p(t_j,t_k)p(\ups_j|t_j)p(\ups_k|t_k) 
\end{equation}
und folglich auch der bedingten Wahrscheinlichkeitsmassefunktion 
\begin{equation}
p(\ups_j, y_k|t_j,t_k) = \frac{p(t_j,\ups_j,t_k,y_k)}{p(t_j,t_k)} = \frac{p(t_j,t_k)p(\ups_j|t_j)p(\ups_k|t_k)}{p(t_j,t_k)} = p(\ups_j|t_j)p(\ups_k|t_k)
\end{equation}
voraus. Der kontinuierliche Fall folgt dann wieder analog.

\noindent (1) Es gilt
\begin{align}
\begin{split}
\mathbb{C}(y_{j},y_{k}|\tau_{j} = t_{j},\tau_{k} = t_{k})
& = 
\sum_{\ups_j \in Y_j}
\sum_{\ups_k \in Y_k}
(\ups_j - \mathbb{E}(y_j|\tau_j = t_j)) 
(\ups_k - \mathbb{E}(y_k|\tau_k = t_k))
p(\ups_j|t_j)p(\ups_k|t_k) \\
& = 
\sum_{\ups_j \in Y_j}
(\ups_j - t_j)
p(\ups_j|t_j)
\sum_{\ups_k \in Y_k}
(\ups_k - t_k)
p(\ups_k|t_k) \\
& = 
\sum_{\ups_j \in Y_j}
(\ups_j - t_j)
p(\ups_j|t_j)
\left(
\sum_{\ups_k \in Y_k}
\ups_k p(\ups_k|t_k) -
t_k \sum_{\ups_k \in Y_k}p(\ups_k|t_k) 
\right)
\\
& = 
\sum_{\ups_j \in Y_j}
(\ups_j - t_j)
p(\ups_j|t_j)
\left(
t_k -
t_k \cdot 1
\right)
\\
& = 
\sum_{\ups_j \in Y_j}
(\ups_j - t_j)
p(\ups_j|t_j)
\cdot 0
\\
& = 0.
\end{split}
\end{align}
\noindent (2) Wir bestimmen zunächst $\mathbb{E}(\eps_j\eps_k|\tau_j = t_j, \tau_k = t_k)$. Es gilt
\begin{align}
\begin{split}
\mathbb{E}(\eps_j\eps_k|\tau_j = t_j, \tau_k = t_k)
& = \mathbb{E}((y_j - \tau_j)(y_k - \tau_k)|\tau_j = t_j, \tau_k = t_k)
\\
& = 
\sum_{\ups_j \in Y_j}
\sum_{\ups_k \in Y_k}
(\ups_j - t_j)(\ups_k - t_k)
p(\ups_j|t_j)p(\ups_k|t_k)
\\
& = 
\sum_{\ups_j \in Y_j}
(\ups_j - t_j)
p(\ups_j|t_j)
\sum_{\ups_k \in Y_k}
(\ups_k - t_k)
p(\ups_k|t_k)
\\
& = 
\sum_{\ups_j \in Y_j}
(\ups_j - t_j)
p(\ups_j|t_j)
\left(
\sum_{\ups_k \in Y_k}
\ups_k
p(\ups_k|t_k) -
t_k
\sum_{\ups_k \in Y_k}
p(\ups_k|t_k)
\right)
\\
& = 
\sum_{\ups_j \in Y_j}
(\ups_j - t_j)
p(\ups_j|t_j)
\left(
t_k -
t_k \cdot 1
\right)
\\
& = 
\sum_{\ups_j \in Y_j}
(\ups_j - t_j)
p(\ups_j|t_j)
\cdot 0
\\
& = 0
\end{split}
\end{align}
Mit dem Verschiebungssatz der bedingten Kovarianz \hl{LINK} und Aussage (1) des Theorems zu den
Ersten Eigenschaften des Modells multipler Messungen \hl{LINK} folgt dann
\begin{equation}
\mathbb{C}(\eps_j,\eps_k|\tau_j = t_j, \tau_k = t_k)
= \mathbb{E}(\eps_j\eps_k|\tau_j = t_j, \tau_k = t_k) - \mathbb{E}(\eps_j|\tau_j = t_j)\mathbb{E}(\eps_k|\tau_k = t_k)
= 0 - 0 \cdot 0
= 0.
\end{equation}
\noindent (3) Wir bestimmen zunächst $\mathbb{E}(\eps_j\eps_k)$. Mit
dem Beweis von Aussage (2) ergibt sich
\begin{align}
\begin{split}
\mathbb{E}(\eps_{j}\eps_{k})
& = \mathbb{E}((y_j - \tau_j)(y_k - \tau_k)) \\
& = 
\sum_{t_j \in T_j}
\sum_{t_k \in T_k}
\sum_{\ups_j \in Y_j}
\sum_{\ups_k \in Y_k}
(\ups_j - t_j)(\ups_k - t_k)
p(\ups_j|t_j)p(\ups_k|t_k)
p(t_j,t_k)
\\
& = 
\sum_{t_j \in T_j}
\sum_{t_k \in T_k}
\sum_{\ups_j \in Y_j}
\sum_{\ups_k \in Y_k}
(\ups_j - \mathbb{E}(y_j |\tau_j = t_j))(\ups_k - \mathbb{E}(y_k |\tau_k = t_k))
p(\ups_j|t_j)p(\ups_k|t_k)
p(t_j,t_k)
\\
& = 
\sum_{t_j \in T_j}
\sum_{t_k \in T_k}
\mathbb{E}\left((y_j - \tau_j) (y_k - \tau_k)| \tau_j = t_j, \tau_j = t_j\right)
p(t_j,t_k)
\\
& = 
\sum_{t_j \in T_j}
\sum_{t_k \in T_k}
\mathbb{E}\left(\eps_j\eps_k | \tau_j = t_j, \tau_j = t_j\right)
p(t_j,t_k)
\\
& = 
\sum_{t_j \in T_j}
\sum_{t_k \in T_k}
0 \cdot
p(t_j,t_k)
\\
& = 
0.
\end{split}
\end{align}
Mit dem Kovarianzverschiebungssatz \hl{LINK} und Aussage (2) des Theorems zu den
Ersten Eigenschaften des Modells multipler Testmessungen  \hl{LINK} ergibt sich dann
\begin{equation}
\mathbb{C}(\eps_j,\eps_k)
= \mathbb{E}(\eps_j\eps_k) - \mathbb{E}(\eps_j)\mathbb{E}(\eps_k)
= 0 - 0 \cdot 0
= 0.
\end{equation}
\noindent (4) Mit dem Kovarianzverschiebungssatz \hl{LINK} und Aussage (2) des Theorems
zu den Ersten Eigenschaften des Modells multipler Testmessungen \hl{LINK} gilt
\begin{align}
\begin{split}
\mathbb{C}(\tau_j,\eps_k)
& = \mathbb{E}(\tau_j\eps_k)  - \mathbb{E}(\tau_j)\mathbb{E}(\eps_k) \\
& = \mathbb{E}(\tau_j\eps_k)  - \mathbb{E}(\tau_j)\cdot 0 \\
& = \mathbb{E}(\tau_j(y_k - \tau_k)) \\
& = \sum_{t_j \in T_j}
    \sum_{t_k \in T_k} 
    \sum_{\ups_k \in Y_k}
    t_j(y_k - t_k)
    p(\ups_k|t_k)
    p(t_j,t_k) \\
& = \sum_{t_j \in T_j}
    t_j
    \sum_{t_k \in T_k} 
    p(t_j, t_k)
    \sum_{\ups_k \in Y_k}
    (y_k - t_k)
    p(\ups_k|t_k) 
\\
& = \sum_{t_j \in T_j}
    t_j
    \sum_{t_k \in T_k} 
    p(t_j,t_k)
    \left(
    \sum_{\ups_k \in Y_k}y_k p(\ups_k|t_k)
     -  
    t_k  \sum_{\ups_k \in Y_k}p(\ups_k|t_k)
    \right)\\
& = \sum_{t_j \in T_j}
    t_j
    \sum_{t_k \in T_k} 
     p(t_j, t_k)
    \left(t_k - t_k \cdot 1\right)\\
& = \sum_{t_j \in T_j}
    t_j
    \sum_{t_k \in T_k} 
     p(t_j, t_k)
    \cdot 0\\
& = 0. \\
\end{split}
\end{align}
\noindent (5) Wir halten zunächst fest, dass mit Aussage (4) durch Vertauschen 
der Indizes und der Symmetrie der Kovarianz auch
\begin{equation}
\mathbb{C}(\tau_k,\eps_j) = \mathbb{C}(\eps_j, \tau_k) = 0
\end{equation}
gilt. Mit dem Theorem zu den Eigenschaften der Kovarianz aus Einheit (2) Theoretische 
Grundlagen und Aussage (3) gilt dann
\begin{align}
\begin{split}
\mathbb{C}(y_j,y_k)
& = \mathbb{C}(\tau_j + \eps_j,\tau_k + \eps_k) \\
& = \mathbb{C}(\tau_j ,\tau_k)         + 
    \mathbb{C}(\tau_j ,\eps_k)  +  
    \mathbb{C}(\eps_j,\tau_k)   +
    \mathbb{C}(\eps_j,\eps_k) \\
& = \mathbb{C}(\tau_j,\tau_k) + 0 + 0 + 0 \\
& = \mathbb{C}(\tau_j,\tau_k). 
\end{split} 
\end{align}
:::

Im Sinne des vereinfachten Modells der Klassischen Testtheorie nach 
@def-vereinfachtes-modell-der-klassischen-testtheorie werden die Aussagen
von @thm-eigenschaften-bezüglich-zweier-testmessungen oft auch als

(1) $\mathbb{C}(y_{j},y_{k}|\tau_{j} = t_{j},\tau_{k} = t_{k}) = 0$ 
(2) $\mathbb{C}(\eps_{j},\eps_{k}|\tau_{j} = t_{j},\tau_{k} = t_{k}) = 0$
(3) $\mathbb{C}(\eps_{j},\eps_{k}) = 0$
(4) $\mathbb{C}(\tau_{j},\eps_{k}) = 0$
(5) $\mathbb{C}(y_{j},y_{k}) = \mathbb{C}(\tau_{j},\tau_{k})$

geschrieben. Die ersten beiden Aussagen von @thm-eigenschaften-bezüglich-zweier-testmessungen
besagen also, dass, bedingt auf den jeweiligen True Scores, die Kovarianzen 
von Observed-Scores sowie die Kovarianzen der Error-Scores einer Person zwischen 
zwei Testmessungen gleich Null sind. Für die Error-Scores gilt dies nach Aussage
(3) von @thm-eigenschaften-bezüglich-zweier-testmessungen auch im Sinne der 
unbedingten Marginalverteilung.Dies entspricht also der paarweisen Unabhängigkeit
von Error-Scores über Testmessungen im Modell multipler Testmessungen. Weiterhin 
ist nach Aussage (4) die Kovarianz der True-Score Variable  bei einer Testmessung mit 
der Error-Score Variable bei einer anderen Testmessung gleich Null. Schließlich 
gilt nach Aussage (5), dass die Kovarianz der observierbaren
Observed-Scores zwischen zwei Testmessungen gleich der Kovarianz der latenten
True-Scores ist.

#### Beispiel  {-}

Als erstes Beispiel für ein Modell multipler Testmessungen mit $m>1$ setzen
wir obiges Beispiel fort und betrachten den Fall zweier Testmessungen $j = 1,2$.
Für  $i = 1,...,n$ seien entsprechend
\begin{equation}
\mathbb{P}(\tau_{i1}, \tau_{i2}) 
= \mathbb{P}(\tau_{i2}|\tau_{i1})\mathbb{P}(\tau_{i1}) 
\end{equation}
mit
\begin{equation}
\mathbb{P}(\tau_{i1}) := N(1,1) \mbox{ und }
\mathbb{P}(\tau_{i2}|\tau_{i1}) := N(\tau_{i1} + 1,1)
\end{equation}
Die Verteilung des True-Score von Person $i$ in Testmessung $j = 2$ hängt in diesem
Beispiel also explizit von der Verteilung  des True-Scores von Person $i$ in 
Testmessung $j = 1$ ab. Weiterhin seien
\begin{equation}
\mathbb{P}(y_{i1}|\tau_{i1}) := N(\tau_{i1},1) \mbox{ und }
\mathbb{P}(y_{i2}|\tau_{i2}) := N(\tau_{i2},2)
\end{equation}
Die Propensitätsverteilungen von Person $i$ in Testmessung $j = 1$ unterscheide
sich also von der von Person $i$ in Testmessung $j = 2$.

\hl{SIMULATION UND VISUALISIERUNG}

\tiny
```{r, eval = F}
n           = 1e5                               # Personenanzahl
m           = 2                                 # Testmessungsanzahl
mu          = 1                                 # True-Score Erwartungswertparameter   
T           = matrix(rep(NaN, n*m), nrow = n)   # True-Score Array
Y           = matrix(rep(NaN, n*m), nrow = n)   # Observed-Score Array 
E           = matrix(rep(NaN, n*m), nrow = n)   # Error-Score Array
for(i in 1:n){                                  # Iteration über Personen 
    T[i,1]  = rnorm(1,1,1)                      # True-Score Realisierung     für j = 1
    Y[i,1]  = rnorm(1,T[i,1],1)                 # Observed-Score Realisierung für j = 1
    E[i,1]  = Y[i,1] - T[i,1]                   # Error-Score Realisierung    für j = 1
    T[i,2]  = rnorm(1,T[i,1] + 1,.5)            # True-Score Realisierung     für j = 2
    Y[i,2]  = rnorm(1,T[i,2],.5)                # Observed-Score Realisierung für j = 2
    E[i,2]  = Y[i,2] - T[i,2]}                  # Error-Score Realisierung    für j = 2
c_hat_e1_e2 = cov(E[,1],E[,2])                  # Kovarianzschätzung Error-Score 1, Error-Score 2
c_hat_t1_e2 = cov(T[,1],E[,2])                  # Kovarianzschätzung True-Score 1, Error-Score 2
c_hat_o1_o2 = cov(Y[,1],Y[,2])                  # Kovarianzschätzung Observed-Score 1, Observed-Score 2
c_hat_t1_t2 = cov(T[,1],T[,2])                  # Kovarianzschätzung True-Score 1, True-Score 2
```
\normalsize

$n = 500$ Realisierungen

```{r, echo = F, eval = F}
library(latex2exp)
library(mvtnorm)
pdf(file =  "./_figures/901-normalverteilungsbeispiel-3.pdf", width = 7, height = 7)
par(                                                                   
family     = "sans",                                                 
mfcol      = c(2,2),                                                  
pty        = "s",                                                      
bty        = "l",                                                     
lwd        = 1,                                                       
las        = 1,                                                      
mgp        = c(2,1,0),                                                
xaxs       = "i",                                                    
yaxs       = "i",                                                     
cex        = 1,                                                     
font.main  = 1,                                                       
cex.main   = 1)
nsamp = 500
plot(
T[1:nsamp,1],
T[1:nsamp,2],
pch         = 21,
col         = "white",
bg          = "gray60",
xlab        = TeX("$\\tau_{i1}$"),
ylab        = TeX("$\\tau_{i2}$"),
xlim        = c(-3,5),
ylim        = c(-3,5),
cex         = .9)
plot(
Y[1:nsamp,1],
Y[1:nsamp,2],
pch         = 21,
col         = "white",
bg          = "gray60",
xlab        = TeX("$y_{i1}$"),
ylab        = TeX("$y_{i2}$"),
xlim        = c(-3,5),
ylim        = c(-3,5),
cex         = .9)
plot(
E[1:nsamp,1],
E[1:nsamp,2],
pch         = 21,
col         = "white",
bg          = "gray60",
xlab        = TeX("$\\epsilon_{i1}$"),
ylab        = TeX("$\\epsilon_{i2}$"),
xlim        = c(-4,4),
ylim        = c(-4,4),
cex         = .9)
plot(
T[1:nsamp,1],
E[1:nsamp,2],
pch         = 21,
col         = "white",
bg          = "gray60",
xlab        = TeX("$\\tau_{i1}$"),
ylab        = TeX("$\\epsilon_{i2}$"),
xlim        = c(-4,4),
ylim        = c(-4,4),
cex         = .9)
dev.off()
```

<!-- ![Normalverteilungsbeispiel-3](./_figures/901-normalverteilungsbeispiel-3){#fig-normalverteilungsbeispiel-2 fig-align="center" width=60%}

$n = 10^4$ Realisierungen -->

```{r, echo = F, eval = F}
library(latex2exp)
pdf(file  =  "./_figures/901-normalverteilungsbeispiel-4.pdf", 
width     = 6, 
height    = 6)                                                                      
par(                                                                   
family    = "sans",                                                  
mfcol     = c(1,1),                                                    
pty       = "m",                                                     
bty       = "l",                                                     
lwd       = 1,                                                        
las       = 1,                                                       
mgp       = c(2,1,0),                                                
xaxs      = "i",                                                     
yaxs      = "i",                                                     
cex       = 1.2,                                                     
font.main = 1,                                                      
cex.main  = 1.1)                                                        
labs      = c(TeX("$\\hat{C}(\\epsilon_{i1}, \\epsilon_{i2})$"), 
              TeX("$\\hat{C}(\\tau_{i1}, \\epsilon_{i2})$"),
              TeX("$\\hat{C}(y_{i1}, y_{i2})$"),
              TeX("$\\hat{C}(\\tau_{i1}, \\tau_{i2})$"))
plot(
1:4,
c(c_hat_e1_e2,c_hat_t1_e2,c_hat_o1_o2,c_hat_t1_t2),
type     = "p",
ylim     = c(-1,2),
xlim     = c(0.5,4.5),
xaxt     = "n",
xlab     = "",
ylab     = "",
pch      =  19,
cex      =  1.4)
axis(1, at = 1:4, labels = labs)
grid()
dev.off()
```


<!-- ![Normalverteilungsbeispiel-4](./_figures/901-normalverteilungsbeispiel-4){#fig-normalverteilungsbeispiel-4 fig-align="center" width=60%}  -->


## Das Modell paralleler Testmessungen {#sec-parallelität}

Bisher haben wir im Modell der multiplen Testmessungen keine Aussage zu den
Verhältnissen der True-Scores über verschiedene Testmessungen hinweg gemacht. 
Wir haben einerseits angenommen, dass für die Marginalverteilung der Testmessungen
bei einer Person $i$ keine Unabhängigkeit gelten muss, dass also im Allgemeinen
gilt, dass für $i = 1,...,n$
\begin{equation}
\mathbb{P}(\tau_{i1},...,\tau_{im}) \neq \prod_{j=1}^m\mathbb{P}(\tau_{ij}).
\end{equation}
Andererseits haben wir die Form möglicher Abhängigkeiten zwischen den True-Scores
$\tau_{i1}, ..., \tau_{im}$ bislang nicht genauer spezifiziert. Die Klassische 
Testtheorie betrachtet in dieser Hinsicht einige Spezialfälle, die sich allgemein 
durch funktionale Abhängigkeiten zwischen $\tau_{i1}$ und 
$\tau_{i2},...,\tau_{im}$ der Form
\begin{equation}
\tau_{ij} = f(\tau_{i1})  \mbox{ für  } f : \mathbb{R} \to \mathbb{R} \mbox{ und } j = 2,...,m.
\end{equation}
ausdrücken lassen. Wir betrachten im Folgenden den Fall, dass $f := \mbox{id}_{\mathbb{R}}$, 
dass also insbesondere für Realisierungen $t_{ij}$ von $\tau_{ij}$ gilt, dass
\begin{equation}
t_{ij} = \mbox{id}_{\mathbb{R}}\left(t_{i1}\right) = t_{i1}   \mbox{ für  }  j = 2,...,m,
\end{equation}   
dass also die Werte der True-Scores einer Person über Testmessungen identisch sind. Die Klassische
Testtheorie bezeichnet solche Testmessungen als *parallele Testmessungen*. Eine weitere 
Form der funktionalen Abhängigkeit, die wir hier nicht weiter vertiefen wollen,
ist der Fall, dass es sich bei $f$ um eine linear-affine Funktion handelt, dass also
\begin{equation}
\tau_{ij} = f(\tau_{i1}) = a\tau_{i1} + b \mbox{ für  } a,b \in \mathbb{R} \mbox{ und } j = 2,...,m.
\end{equation}
Die Klassische Testtheorie bezeichnet solche Testmessungen als 
*wesentlich $\tau$-äquivalente Testmessungen*.

:::{#def-modell-paralleler-testmessungen}
## Modell paralleler Testmessungen
Für $i = 1,...,n$ und $j = 1,...,m$ seien $\tau_{i}$ eine Zufallsvariable, die 
den *True-Score* der $i$ten Person in jeder Testmessung $j = 1,...,m$ modelliere,
$y_{ij}$ eine Zufallsvariable, die den *Observed-Score* der $i$ten Person in der
$j$ten Testmessung modelliere und $\eps_{ij} := y_{ij} -\tau_{i}$ die Zufallsvariable, 
die den *Error-Score* der $i$ten Person in der $j$ten Testmessung modelliere.
Dann heißt die gemeinsame Verteilung der $\tau_{i}$ und $y_{ij}$ mit den 
Faktorisierungseigenschaften
\begin{equation}
\mathbb{P}\left(\tau_{1},y_{11},...y_{1m}, ...,\tau_{n},y_{n1},...,y_{nm}\right)  
:= \prod_{i=1}^n \mathbb{P}(\tau_{i}) \prod_{j=1}^m \mathbb{P}(y_{ij}|\tau_{i}) 
\end{equation}
das *Modell paralleler Testmessungen*, wenn gilt, dass

(1) $\mathbb{P}(\tau_{1}) = \cdots = \mathbb{P}(\tau_{n})$
(2) $\mathbb{P}(y_{1j}|\tau_{1}) = \cdots = \mathbb{P}(y_{nj}|\tau_{n})$ für alle  $1 \le j \le m$
(3) $\mathbb{E}(y_{ij}\vert \tau_i = t_i) = \mathbb{E}(y_{ik}\vert \tau_i = t_i) := t_i$  für alle  $1 \le i \le n, 1 \le j,k \le n$
(4) $\mathbb{V}(y_{ij}\vert \tau_i = t_i) = \mathbb{V}(y_{ik}\vert \tau_i = t_i)$  für alle  $1 \le i \le n, 1 \le j,k \le n$ 

:::

Insbesondere werden also im Modell paralleler Testmessungen die  Werte des True-Scores 
einer Person werden über Testmessungen hinweg als identisch angenommen. Damit 
geht dann die  Observed-Score Varianz einer Person zwischen zwei Testmessungen 
allein auf die Propensitätsverteilung zurück.  Aus generativer Sichtweise entstehen
Werte der Observed Scores also wie folgt: Zunächst wird für die $i$te Person $i$ 
und Testmessungen $j = 1,...,m$ ein True-Score $t_{i}$ von gemäß $\mathbb{P}(\tau_{i})$ realisiert.
Dann wird für die $i$te und die Testmessung $j = 1,...,m$ ein Observed-Score $y_{ij}$ 
anhand von $\mathbb{P}(y_{ij}|\tau_{i}=t_{i})$ realisiert. Betrachtet man nur 
eine einzige Testmessung, so hat das Modell paralleler Testmessungen natürlich 
die gleiche Form wie das Modell multipler Testmessungen. Damit gilt dann aber auch
@thm-eigenschaften-bezüglich-einer-testmessung analog für das Modell paralleler
Testmessungen. Betrachtet man allerdings mehr als eine Testmessung, so ergeben
sich für das Modell paralleler Testmessungen speziellere Eigenschaften, die 
wir in folgendem Theorem festhalten

### Eigenschaften des Modells paralleler Testmessungen

:::{#thm-eigenschaften-des-modells-paralleler-testmessungen}
## Eigenschaften des Modells paralleler Testmessungen
Gegeben sei das Modell paralleler Testmessungen. Dann gelten für alle $i = 1,...,n$ 
und alle $j,k$ mit $1 \le j,k \le m$ und $j \neq k$, dass

(1) $\mathbb{E}(y_{ij}) = \mathbb{E}(y_{ik})$
(2) $\mathbb{V}(y_{ij}) = \mathbb{V}(y_{ik})$
(3) $\mathbb{C}(\eps_{ij},\eps_{ik}) = 0$
(4) $\mathbb{C}(\tau_{i},\eps_{ik}) =  0$
(5) $\mathbb{C}(y_{ij},y_{ik}) = \mathbb{V}(\tau_{i})$
:::

:::{.proof}
Zum Beweis setzen zur Vereinfachung der Notation zunächst 
\begin{equation}
y_j     := y_{ij}, 
y_k     := y_{ik}, 
\tau    := \tau_{i},
\ups_j  := \ups_{ij},  
\ups_k  := \ups_{ik}, 
t       := t_{i} , 
Y_j     := Y_{ij}, 
Y_k     := Y_{ik} \mbox{ und }
T       := T_{i}
\end{equation}
für alle $i = 1,...,n$. Wir betrachten weiterhin nur den diskreten Fall, setzen 
also die Existenz einer Wahrscheinlichkeitsmassefunktion der Form
\begin{equation}
p(t,\ups_j,\ups_k) = p(\ups_j|t)p(\ups_k|t)p(t)
\end{equation} 
voraus. Der kontinuierliche Fall folgt dann analog.

\noindent(1) Mit der Gleichheit der bedingten Erwartungswerte im Falle paralleler Testmessungen gilt
\begin{equation}
\mathbb{E}(y_{j})
 = \sum_{t \in T}\sum_{\ups_j \in Y_j}\ups_j p(\ups_j|t)p(t) 
 = \sum_{t \in T}\mathbb{E}(y_{j}\vert \tau = t)p(t)                   
 = \sum_{t \in T}\sum_{\ups_k \in Y_k}\ups_k p(\ups_k|t)p(t) 
 = \mathbb{E}(y_{k}).                  
\end{equation}

\noindent (2) Mit der Darstellung der Varianz \hl{LINK} ergibt sich
\begin{equation}
\mathbb{V}(y_{j})
= \mathbb{V}\left(\mathbb{E}(y_j\vert \tau)\right) + \mathbb{E}\left(\mathbb{V}(y_j\vert \tau)\right) 
= \mathbb{V}\left(\mathbb{E}(y_k\vert \tau)\right) + \mathbb{E}\left(\mathbb{V}(y_k\vert \tau)\right) 
= \mathbb{V}(y_{k}).
\end{equation}

\noindent (3)  Wir bestimmen zunächst $\mathbb{E}(\eps_j\eps_k)$. Mit Aussage
(2) von @thm-eigenschaften-bezüglich-einer-testmessung gilt dann
\begin{align}
\begin{split}
\mathbb{E}(\eps_j\eps_k)
& := \mathbb{E}((y_j - \tau)(y_k - \tau)) \\
&  = \sum_{t \in T}
     \sum_{\ups_j \in Y_j}
     \sum_{\ups_k \in Y_k}(\ups_j - t)(\ups_k - t)  p(t) p(\ups_j|t)p(\ups_k|t)  \\
&  = \sum_{t \in T}
     p(t)
     \sum_{\ups_j \in Y_j}
     \sum_{\ups_k \in Y_k}(\ups_j - t)(\ups_k - t) p(\ups_j|t)p(\ups_k|t)  \\
&  = \sum_{t \in T}
     p(t)
     \sum_{\ups_j \in Y_j} (\ups_j - t) p(\ups_j|t)
     \sum_{\ups_k \in Y_k}(\ups_k - t) p(\ups_k|t)  \\
&  = \sum_{t \in T}
     p(t)
    \left(\sum_{\ups_j \in Y_j} \ups_j p(\ups_j|t) - t\sum_{\ups_j \in Y_j}p(\ups_j|t)\right)
    \left(\sum_{\ups_k \in Y_k}\ups_k p(\ups_k|t) - t\sum_{\ups_k \in Y_k}p(\ups_k|t)\right) \\
&  = \sum_{t \in T} p(t)\left(t-t\right)\left(t-t\right) \\
&  = \sum_{t \in T} p(t)\cdot 0 \cdot 0 \\
&  =  0.  \\
\end{split}
\end{align}
Mit dem Kovarianzverschiebungssatz \hl{LINK} und wiederrum mit Aussage (2)  von 
@thm-eigenschaften-bezüglich-einer-testmessung folgt dann
\begin{align}
\begin{split}
\mathbb{C}(\eps_j,\eps_k)
= \mathbb{E}(\eps_j\eps_k) - \mathbb{E}(\eps_j)\mathbb{E}(\eps_k) 
= 0 - 0\cdot 0
= 0
\end{split}
\end{align}
\noindent (4) Mit dem Kovarianzverschiebungssatz \hl{LINK} und Aussage (2) von 
@thm-eigenschaften-bezüglich-einer-testmessung
\begin{align}
\begin{split}
\mathbb{C}(\tau,\eps_k)
& = \mathbb{E}(\tau\eps_k)  - \mathbb{E}(\tau)\mathbb{E}(\eps_k) \\
& = \mathbb{E}(\tau\eps_k)  - \mathbb{E}(\tau)\cdot 0 \\
& = \mathbb{E}(\tau(y_k - \tau)) \\
& = \sum_{t \in T} 
    \sum_{\ups_k \in Y_k}
    t(\ups_k - t)
    p(t)p(\ups_k|t) \\
& = \sum_{t \in T} t p(t)
    \sum_{\ups_k \in Y_k}(\ups_k - t)
    p(\ups_k|t) \\
& = \sum_{t \in T} t  p(t)
    \left(\sum_{\ups_k \in Y_k}\ups_k p(\ups_k|t) - t \sum_{\ups_k \in Y_k}p(\ups_k|t)\right)\\
& = \sum_{t \in T} t  p(t) \left(t - t\right)\\
& = \sum_{t \in T} t  p(t) \cdot 0\\
& = 0. \\
\end{split}
\end{align}

\noindent (5) Wir halten zunächst fest, dass mit Aussage (2) des Theorems neben
 $\mathbb{C}(\tau,\eps_k)=0$ durch Austausch des Index und der Symmetrie der Kovarianz auch
\begin{equation}
\mathbb{C}(\tau,\eps_j) = \mathbb{C}(\eps_j, \tau) = 0
\end{equation}
gilt. Mit dem Theorem zu den Eigenschaften der Kovarianz \hl{LINK} Aussage (1) des Theorems gilt dann
\begin{align}
\begin{split}
\mathbb{C}(y_j,y_k)
& = \mathbb{C}(\tau + \eps_j,\tau + \eps_k) \\
& = \mathbb{C}(\tau ,\tau)         + 
    \mathbb{C}(\tau ,\eps_k)  +  
    \mathbb{C}(\eps_j,\tau)   +
    \mathbb{C}(\eps_j,\eps_k) \\
& = \mathbb{C}(\tau,\tau) + 0 + 0 + 0 \\
& = \mathbb{C}(\tau,\tau) \\
& = \mathbb{V}(\tau).
\end{split} 
\end{align}
:::

Aussage (1) des Theorems besagt, dass bei Paralleltestmessungen alle Erwartungswerte 
der Observed Scores identisch sind und Aussage (2) besagt, dass bei Paralleltestmessungen 
alle Varianzen der Observed Scores identisch sind. Die Aussagen (3) und (4) sind 
analog zu den lokalen Unkorreliertheitseigenschaften des Modells multipler Testmessungen.
Aussage (5)  besagt insbesondere, dass $\mathbb{C}(y_{ij},y_{ik})$ für beliebe $j$ 
und $k$ identisch zu $\mathbb{V}(\tau_{i})$ sind. Mit 2 sind im Modell paralleler Testmessungen also
alle paarweisen Korrelationen verschiedener Testmessungen identisch.

**Beispiel** 

Wir betrachten den Fall zweier Testmessungen $j = 1,2$ im Modell paralleler 
Testmessungen. Für  $i = 1,...,n$ seien 
\begin{equation}
\mathbb{P}(\tau_{i}) =  N(1,1) 
\mbox{ und } 
\mathbb{P}(y_{i1}|\tau_{i}) := \mathbb{P}(y_{i2}|\tau_{i}) :=  N(\tau_{i},1)
\end{equation}

Für Person $i$ gibt es also nur eine True-Score Zufallsvariable für alle Testmessungen 
und die Propensitätsverteilungen unterscheiden sich zwischen Testmessungen nicht.

\hl{SIMULATION UND VISUALISIERUNG}
\tiny

```{r, echo = TRUE}
n           = 1e5                               # Personenanzahl
m           = 2                                 # Testmessungsanzahl
T           = matrix(rep(NaN, n)  , nrow = n)   # True-Score Array
Y           = matrix(rep(NaN, n*m), nrow = n)   # Observed-Score Array 
E           = matrix(rep(NaN, n*m), nrow = n)   # Error-Score Array
for(i in 1:n){                                  # Personeniterationen
    T[i]  = rnorm(1,1,1)                        # True-Score Realisierung für j = 1,2
    for(j in 1:m){                              # Testmessungsiterationen 
        Y[i,j]  = rnorm(1,T[i],1)               # Observed-Score Realisierung f 
        E[i,j]  = Y[i,j] - T[i]}}               # Error-Score Realisierung     
e_hat_o1_o2 = apply(Y, 2, mean)                 # Erwartungswertschätzung Observed-Score 1, Observed-Score 2
v_hat_o1_o2 = apply(Y, 2, var)                  # Varianzzschätzung Observed-Score 1, Observed-Score 2
c_hat_e1_e2 = cov(E[,1],E[,2])                  # Kovarianzzschätzung Error-Score 1, Error-Score 2
c_hat_t_e2  = cov(T    ,E[,2])                  # Kovarianzzschätzung True-Score 1, Error-Score 2
c_hat_o1_o2 = cov(Y[,1],Y[,2])                  # Kovarianzzschätzung Observed-Score 1, Observed-Score 2
v_hat_t     = var(T)                            # Varianzschätzung True-Score  
``` 
\normalsize 

```{r, echo = F, eval = F}
library(latex2exp)
pdf(file  =  "./_figures/901-normalverteilungsbeispiel-5.pdf", 
width     = 10, 
height    = 6)                                                                      
par(                                                                   
family    = "sans",                                                  
mfcol     = c(1,1),                                                    
pty       = "m",                                                     
bty       = "l",                                                     
lwd       = 1,                                                        
las       = 1,                                                       
mgp       = c(2,1,0),                                                
xaxs      = "i",                                                     
yaxs      = "i",                                                     
cex       = 1.2,                                                     
font.main = 1,                                                      
cex.main  = 1.1)                                                        
labs      = c(TeX("$\\hat{E}(y_{i1})$"), 
              TeX("$\\hat{E}(y_{i2})$"), 
              TeX("$\\hat{V}(y_{i1})$"), 
              TeX("$\\hat{V}(y_{i2})$"),
              TeX("$\\hat{C}(\\epsilon_{i1},\\epsilon_{i2})$"),
              TeX("$\\hat{C}(\\tau_i,\\epsilon_{i2})$"),
              TeX("$\\hat{C}(y_{i1},y_{i2})$"),
              TeX("$\\hat{V}(\\tau)$")) 
plot(
1:8,
c(e_hat_o1_o2,v_hat_o1_o2,c_hat_e1_e2, c_hat_t_e2, c_hat_o1_o2,v_hat_t ),
type     = "p",
ylim     = c(-1,3),
xlim     = c(0.5,8.5),
xaxt     = "n",
xlab     = "",
ylab     = "",
pch      =  19,
cex      =  1.4)
axis(1, at = 1:8, labels = labs)
grid()
dev.off()
```

<!-- ![Normalverteilungsbeispiel-5](./_figures/901-normalverteilungsbeispiel-5){#fig-normalverteilungsbeispiel-5 fig-align="center" width=60%}  -->

## Reliabilität {#sec-reliabilität}

Die *Reliabilität* einesr Testmessung ist das zentrale Konzept der Klassischen Testtheorie.
Wir folgen hier dem Ansatz nach \hl{HISTORISCHE REFERENZ}, wonach die Reliabilität
einer Testmessung als quadrierte Korrelation von Observed- und True-Score definiert 
ist. Basierend auf den Eigenschaften des Modells multipler Testmessungen ergeben
sich dann verschiedene Möglichkeiten, diese Korrelation darzustellen und damit
verschiedene Möglichkeiten, die Reliabilität einer Testmessung zu interpretieren. 
Allerdings ergibt sich dabei keine Möglichkeit, die Reliabilität von Testmessungen 
empirisch zu messen. Zentral ist dann die Übertragung des Konzepts der Reliabilität 
in das Modell paralleler Testmessungen. Die so definierte *Paralleltestreliabilität*,
ist dann empirisch schätzbar. Wir beginnen zunächst mit der Definition der Reliabilität
einer Testmessung im Modell multipler Testmessungen.


:::{#def-reliabilität-einer-testmessung}
## Reliabilität einer Testmessung

Gegeben sei das Modell multipler Testmessungen für eine beliebige Testmessung $j$ mit $1 \le j \le m$,
\begin{equation}
\mathbb{P}(\tau_{1j},y_{1j} ..., \tau_{nj}, y_{nj}) 
:= \prod_{i=1}^n \mathbb{P}(\tau_{ij},y_{ij}) 
:= \prod_{i=1}^n \mathbb{P}(y_{ij}|\tau_{ij})\mathbb{P}(\tau_{ij}) 
\end{equation}
wobei nach Definition des Modells gilt, dass 
\begin{equation}
\mathbb{P}(\tau_{1j},y_{1j}) = \cdots = \mathbb{P}(\tau_{nj},y_{nj}).
\end{equation}
Die *Reliabilität der Testmessung $j$* ist dann definiert als
\begin{equation}
\mbox{R}_j := \rho(y_{ij},\tau_{ij})^2 \mbox{ für ein beliebiges } 1 \le i \le n.
\end{equation} 
::: 

Vor dem Hintergrund des vereinfachen Modells der Klassischen Testtheorie 
@def-vereinfachtes-modell-der-klassischen-testtheorie schreibt man auch 
\begin{equation}
\mbox{R} = \rho(y,\tau)^2
\end{equation}
Per Definition ist die Reliabilität eine Testmessung also die quadrierte Korrelation 
von Observed- und True-Score. Mit  
\begin{equation}
-1 \le \rho(y_{ij},\tau_{ij})\le 1
\end{equation}
folgt direkt, dass für die Reliailität einer Testmessung gilt, dass
\begin{equation}
0 \le \mbox{R}_j \le 1
\end{equation}
Die Aussage $\mbox{R}_j = 0$ impliziert dann $\rho(y_{ij},\tau_{ij}) = 0$, also 
die linear-affine Unabhängigkeit von Observed-Score und True-Score (vgl. \hl{LINK})
und damit den Umstand, dasss der Observed-Score hinsichtlich des True- Scores 
nicht aussagekräftig ist. $\mbox{R}_j= 1$ dagegen impliziert $\rho(y_{ij},\tau_{ij}) = \pm 1$, 
also die deterministische linear-affine Abhängigkeit von Observed-Score und True-Score
und damit, dass der Observed-Score hinsichtlich des True-Scores vollständig aussagekräftig ist.

Folgendes Theorem zeigt weitere Möglichkeiten auf, die Reliabilität einer Testmessung
äquivalent zu formulieren und damit zu interpretieren.

:::{#thm-eigenschaften-der-reliabilität-einer-testmessung}
## Eigenschaften der Reliabilität einer Testmessung

Gegeben sei das Modell multipler Testmessungen für eine beliebige Testmessung $j$ mit $1 \le j \le m$,
\begin{equation}
\mathbb{P}(\tau_{1j},y_{nj} ..., \tau_{nj}, y_{nj}) 
:= \prod_{i=1}^n \mathbb{P}(y_{ij}|\tau_{ij})\mathbb{P}(\tau_{ij}). 
\end{equation}
Dann gelten für die Reliabilät $\mbox{R}_j$ der Testmessung $j$, dass

(1) $\mbox{R}_j = \frac{\mathbb{V}(\tau_{ij})}{\mathbb{V}(y_{ij})}$
(2) $\mbox{R}_j = 1 - \frac{\mathbb{V}(\eps_{ij})}{\mathbb{V}(y_{ij})}$

:::

:::{.proof}

\noindent (1) Mit Aussage (5) von @thm-eigenschaften-bezüglich-einer-testmessung gilt   
\begin{equation}
\mbox{R}_j  
= \rho(y_{ij},\tau_{ij})^2 
= \left(\frac{\mathbb{C}(y_{ij},\tau_{ij})}{\mathbb{S}(y_{ij})\mathbb{S}(\tau_{ij})}\right)^2
= \frac{\mathbb{C}(y_{ij},\tau_{ij})^2}{\mathbb{V}(y_{ij})\mathbb{V}(\tau_{ij})}
= \frac{\mathbb{V}(\tau_{ij})^2}{\mathbb{V}(y_{ij})\mathbb{V}(\tau_{ij})}
= \frac{\mathbb{V}(\tau_{ij})}{\mathbb{V}(y_{ij})}.
\end{equation}

\noindent (2) Mit Aussage (4) von @thm-eigenschaften-bezüglich-einer-testmessung 
gilt dann weiter
\begin{equation}
\mbox{R}_j  
= \frac{\mathbb{V}(\tau_{ij})}{\mathbb{V}(y_{ij})}
= \frac{\mathbb{V}(y_{ij})-\mathbb{V}(\eps_{ij})}{\mathbb{V}(y_{ij})}
= \frac{\mathbb{V}(y_{ij})}{\mathbb{V}(y_{ij})} - \frac{\mathbb{V}(\eps_{ij})}{\mathbb{V}(y_{ij})}
= 1 - \frac{\mathbb{V}(\eps_{ij})}{\mathbb{V}(y_{ij})}.
\end{equation}
:::

Da $\tau_{ij}$ und $\eps_{ij}$ weiterhin latent und damit nur indirekt beobachtbar
sind, sind die Darstellungen nach @thm-eigenschaften-der-reliabilität-einer-testmessung 
nur von theoretischem Interesse. Die erste Aussage besagt dabei insbesondere, dass 
die Reliabilität einer Testmessung der Anteil der True-Score Varianz an der 
Observed-Score Varianz ist, 
\begin{equation}
\mbox{R}_j = \frac{\mathbb{V}(\tau_{ij})}{\mathbb{V}(y_{ij})} = \frac{\mathbb{V}(\tau_{ij})}{\mathbb{V}(\tau_{ij}) + \mathbb{V}(\eps_{ij})}.
\end{equation}
Gilt dabei, dass $\mathbb{V}(\tau_{ij}) = 0$, so ist auch $\mbox{R}_j = 0$, 
ist dagegen $\mathbb{V}(\eps_{ij}) = 0$ so ist $\mbox{R}_j = 1$. Eine Reliabilität
$\mbox{R}_j > 0$ impliziert also immer eine von Null verschiedene True-Score Varianz.

### Paralleltestreliabilität {-}

Um das Konzept der Reliabilität nun anhand empirischer Daten von Observed-Scores 
schätzbar zu machen, bedarf es seiner Übertragung in das Modell paralleler Testmessungen.
Wir definieren daher die Reliabilität einer Paralleltestmessung explizit wie folgt.

:::{#def-reliabilität-einer-paralleltestmessung}
## Reliabilität einer Paralleltestmessung

Gegeben sei das Modell paralleler Testmessungen für eine beliebige Testmessung $j$ mit $1 \le j \le m$,
\begin{equation}
\mathbb{P}(\tau_{1},y_{1j} ..., \tau_{n},y_{nj}) 
:= \prod_{i=1}^n \mathbb{P}(\tau_i, y_{ij}) 
= \prod_{i=1}^n \mathbb{P}(\tau_i)\mathbb{P}(y_{ij}|\tau_i)  
\end{equation}
wobei nach Definition des Modells gilt, dass
\begin{equation}
\mathbb{P}(\tau_{1},y_{1j}) = \cdots = \mathbb{P}(\tau_{n},y_{nj}).
\end{equation}
Die *Reliabilität der Paralleltestmessung $j$* ist dann definiert als
\begin{equation}
\mbox{R}_j := \rho(y_{ij},\tau_{i})^2 \mbox{ für ein beliebiges } 1 \le i \le n.
\end{equation} 
::: 

Vor dem Hintergrund des vereinfachten Modells der Klassischen Testtheorie nach
@def-vereinfachtes-modell-der-klassischen-testtheorie schreibt man auch hier 
\begin{equation}
\mbox{R}=\rho(y,\tau)^2.
\end{equation}


:::{#thm-paralleltestreliabilität}
## Paralleltestreliabilität

Gegeben sei das Modell der paralleler Testmessungen 
\begin{equation}
\mathbb{P}(\tau_{1},y_{1j} ..., \tau_{n},y_{nj}) 
:= \prod_{i=1}^n \mathbb{P}(\tau_i, y_{ij}) 
= \prod_{i=1}^n \mathbb{P}(\tau_i)\mathbb{P}(y_{ij}|\tau_i)  
\end{equation}
Dann gelten 

(1) $\mbox{R}_j = \frac{\mathbb{V}(\tau_{i})}{\mathbb{V}(y_{ij})}$ für alle $1 \le j \le m$.
(2) $\mbox{R}_j = 1 - \frac{\mathbb{V}(\eps_{ij})}{\mathbb{V}(y_{ij})}$ für alle $1 \le j \le m$.
(3) $\mbox{R}_j = \rho(y_{ij},y_{ik}) = \mbox{R}_k$ für alle $1 \le j,k \le m$.

:::


:::{.proof}

\noindent (1) Mit Aussage (5) von @thm-eigenschaften-bezüglich-einer-testmessung gilt   
\begin{equation}
\mbox{R}_j  
= \rho(y_{ij},\tau_{i})^2 
= \left(\frac{\mathbb{C}(y_{ij},\tau_{i})}{\mathbb{S}(y_{ij})\mathbb{S}(\tau_{i})}\right)^2
= \frac{\mathbb{C}(y_{ij},\tau_{i})^2}{\mathbb{V}(y_{ij})\mathbb{V}(\tau_{i})}
= \frac{\mathbb{V}(\tau_{i})^2}{\mathbb{V}(y_{ij})\mathbb{V}(\tau_{i})}
= \frac{\mathbb{V}(\tau_{i})}{\mathbb{V}(y_{ij})}.
\end{equation}
\noindent (2) Mit Aussage (4) von @thm-eigenschaften-bezüglich-einer-testmessung gilt dann weiter
\begin{equation}
\mbox{R}_j  
= \frac{\mathbb{V}(\tau_{i})}{\mathbb{V}(y_{ij})}
= \frac{\mathbb{V}(y_{ij})-\mathbb{V}(\eps_{ij})}{\mathbb{V}(y_{ij})}
= \frac{\mathbb{V}(y_{ij})}{\mathbb{V}(y_{ij})} - \frac{\mathbb{V}(\eps_{ij})}{\mathbb{V}(y_{ij})}
= 1 - \frac{\mathbb{V}(\eps_{ij})}{\mathbb{V}(y_{ij})}.
\end{equation}
\noindent (3) Mit Aussagen (2) und (5) von @thm-eigenschaften-bezüglich-zweier-testmessungen
gilt dann weiter 
\begin{equation}
\mbox{R}_j  
= \frac{\mathbb{V}(\tau_{i})}{\mathbb{V}(y_{ij})}  
= \frac{\mathbb{C}(y_{ij},y_{ik})}{\sqrt{\mathbb{V}(y_{ij})}\sqrt{\mathbb{V}(y_{ij})}} 
= \frac{\mathbb{C}(y_{ij},y_{ik})}{\sqrt{\mathbb{V}(y_{ij})}\sqrt{\mathbb{V}(y_{ik})}}   
= \rho(y_{ij},y_{ik})
\end{equation}
und dass ebenso
\begin{equation}
\mbox{R}_k  
= \frac{\mathbb{V}(\tau_{i})}{\mathbb{V}(y_{ik})}  
= \frac{\mathbb{C}(y_{ij},y_{ik})}{\sqrt{\mathbb{V}(y_{ik})}\sqrt{\mathbb{V}(y_{ik})}} 
= \frac{\mathbb{C}(y_{ij},y_{ik})}{\sqrt{\mathbb{V}(y_{ij})}\sqrt{\mathbb{V}(y_{ik})}}   
= \rho(y_{ij},y_{ik}).
\end{equation}
:::

Aussagen (1) und (2) sind von @thm-reliabilität-einer-paralleltestmessung analog zum Theorem der Reliabilität multipler Testmessungen. Aussage (3) des Theorems begründet das
empirische Vorgehen der Reliabilitätsschätzung mithilfe von \hl{Parallel- oder 
Retestverfahren}. Zur Bestimmung der Reliabilität eines Tests nutzt man entspreched 
eine Schätzung der Korrelation zweier paralleler Testmessungen, wobei die 
Klassische Testtheorie dieses Vorgehen vor der Annahme von von latenten True- und 
Error-Scores begründet. Vereinfacht wird Aussage (3) oft dadurch ausgedrückt, dass
man sagt, dass  "die Korrelation paralleler Testmessungen gleich ihrer Reliabilität" ist.

### Beispiel {-}

Wir betrachten den Fall zweier Testmessungen $j = 1,2$ im Modell paralleler Testmessungen. 
Für  alle $i = 1,...,n$  seien in WDF Form, wobei wir der notationellen Einfachheit 
halber auf das $i$ Subskript verzichten wollen,
\begin{equation}
p(t) =  N(t; 0,\sigma_\tau^2) 
\mbox{ und } 
p(\ups_1|t) :=  N(\ups_1; t,\sigma_{\eps}^2) \mbox{ und } p(\ups_2|t) :=  N(\ups_2; t,\sigma_{\eps}^2) 
\end{equation}
Für Person $i$ gibt es also nur eine True-Score Zufallsvariable für alle Testmessungen 
und die Propensitätsverteilungen unterscheiden sich zwischen Testmessungen nicht.

Dann gilt zunächst mit dem Theorem zu gemeinsamen Normalverteilungen mit $A := 1$ und $b := 0$
\begin{equation}
p(t)p(\ups_1|t) 
= p(t,\ups_1) 
= N\left(
\begin{pmatrix} t \\ \ups_1 \end{pmatrix};
\begin{pmatrix} \mu_{\tau} \\ \mu_\tau \end{pmatrix},
\begin{pmatrix} \sigma_{\tau}^2 & \sigma_{\tau}^2  \\  \sigma_{\tau}^2  & \sigma_{\tau}^2 + \sigma_{\eps}^2  \end{pmatrix} 
\right)
\end{equation}
und weiterhin mit $A := \begin{pmatrix} 1 & 0\end{pmatrix}$ und $b := 0$
\begin{equation}
p(t,\ups_1)p(\ups_2|t) 
= p(t,\ups_1,\ups_2) 
= N\left(
\begin{pmatrix} t  \\ \ups_1 \\ \ups_2 \end{pmatrix};
\begin{pmatrix} \mu_\tau \\ \mu_\tau \\ \mu_\tau \\ \end{pmatrix},
\begin{pmatrix} 
\sigma_{\tau}^2  & \sigma_{\tau}^2                              & \sigma_{\tau}^2            \\  
\sigma_{\tau}^2  & \sigma_{\tau}^2 + \sigma_{\eps}^2     & \sigma_{\tau}^2            \\
\sigma_{\tau}^2  & \sigma_{\tau}^2                              & \sigma_{\tau}^2 + \sigma_{\eps}^2  
\end{pmatrix} 
\right) 
\end{equation}
Damit gilt dann durch Ablesen am Kovarianzmatrixparameter von $p(t,\ups_1,\ups_2)$, dass
\begin{equation}
\rho(y_1, y_2)
= \frac{\mathbb{C}(y_1, y_2)}{\sqrt{\mathbb{V}(y_1)}\sqrt{\mathbb{V}(y_2)}}
= \frac{\sigma_{\tau}^2}{\sqrt{\sigma_{\tau}^2 + \sigma_{\eps}^2}\sqrt{\sigma_{\tau}^2 + \sigma_{\eps}^2}}
= \frac{\sigma_{\tau}^2}{\sigma_{\tau}^2 + \sigma_{\eps}^2}
\end{equation}
Insbesondere gilt also auch für $j = 1,2$
\begin{equation}
\mbox{R}_j
= \rho(y_j,\tau)^2 
= \left(\frac{\mathbb{C}(y_j,\tau)}{\mathbb{S}(y_j)\mathbb{S}(\tau)}\right)^2
= \frac{\mathbb{C}(y_j,\tau)^2}{\mathbb{V}(y_j)\mathbb{V}(\tau)}
= \frac{\left(\sigma_\tau^2\right)^2}{(\sigma_{\tau}^2 + \sigma_{\eps}^2)\sigma_\tau^2}
= \frac{\sigma_\tau^2}{\sigma_{\tau}^2 + \sigma_{\eps}^2}
= \rho(y_1, y_2).
\end{equation}
Gilt also beispielsweise $\sigma_{\tau}^2 := 1.0$ und  $\sigma_{\eps}^2 := 0.2$,
so ergibt sich für die Paralleltestreliabilität
\begin{equation}
\mbox{R}_j = \rho(y_j,\tau)^2 = \rho(y_1, y_2) = \frac{1.0}{1.0 + 0.2} \approx 0.83.
\end{equation}

#### Paralleltestreliabilitätsschätung {-}

Wie üblich wird die Korrelation zweier paralleler Testmessungen durch eine
Stichprobenkorrelation geschätzt. Wir formulieren dies für das aktuelle Szenario
in mithilfe folgender Definition.

:::{#def-paralleltestreliabilitätsschätzer}
## Paralleltestreliabilitätsschätzer

Gegeben sei das Modell paralleler Testmessungen für $n$ Personen und zwei Testmessungen $j = 1,2$,
\begin{equation}
\mathbb{P}(\tau_1,y_{11},y_{12},...,\tau_n,y_{n1},y_{n2}) = 
\prod_{i=1}^n\mathbb{P}(\tau_i)\mathbb{P}(y_{i1}|\tau_i)\mathbb{P}(y_{i2}|\tau_i)
\end{equation}
Dann wird der  mit den Stichprobenmitteln 
\begin{equation}
\bar{y}_1 := \frac{1}{n}\sum_{i=1}^n y_{i1}
\mbox{ und }
\bar{y}_2 := \frac{1}{n}\sum_{i=1}^n y_{i2}
\end{equation}
definierte Stichprobenkorrelationskoeffizient
\begin{equation}
r_{12}:= \frac{\frac{1}{n-1}\sum_{i=1}^n(y_{i1} - \bar{y}_1)(y_{i2} - \bar{y}_2)}{\sqrt{\frac{1}{n-1}\sum_{i=1}^n (y_{i1} - \bar{y}_1)^2}\sqrt{\frac{1}{n-1}\sum_{i=1}^n (y_{i2} - \bar{y}_2)^2}}
\end{equation}
*Paralleltestreliabilitätsschätzer* genannt. 
:::

Bekanntlich bietet **R**  mit der `cor()` Funktion eine Möglichkeit, 
Stichprobenkorrelationskoeffizienten zu berechnen. Wir demonstrieren dies an 
einem Simulationsbeispiel dazu seien
\begin{equation}
p(t_i) =  N(t_i; 0,\sigma_\tau^2) 
\mbox{ und }
p(y_{ij}|t_i) :=  N(y_{ij}; t_i,\sigma_{\eps}^2)
\end{equation}
für $j = 1,2$ mit $\sigma_\tau^2 := 1.0$ und $\sigma_{\eps}^2 := 0.2$  für $i = 1,...,30$.

\tiny
```{r, echo = TRUE}
n           = 30                                            # Personenanzahl
m           = 2                                             # Testmessungsanzahl
sigsqr_tau  = 1                                             # True-Score Varianz
sigsqr_eps  = .2                                            # Observed-Score-Varianz
R_12        = sigsqr_tau/(sigsqr_tau+sigsqr_eps)            # Paralletestreliabilität
T           = matrix(rep(NaN, n)  , nrow = n)               # True-Score Array
Y           = matrix(rep(NaN, n*m), nrow = n)               # Observed-Score Array 
E           = matrix(rep(NaN, n*m), nrow = n)               # Error-Score Array
for(i in 1:n){                                              # Personeniterationen
    T[i]  = rnorm(1,1,sqrt(sigsqr_tau))                     # True-Score Realisierung für j = 1,2
    for(j in 1:m){                                          # Testmessungsiterationen 
        Y[i,j]  = rnorm(1,T[i],sqrt(sigsqr_eps))            # Observed-Score Realisierung f 
        E[i,j]  = Y[i,j] - T[i]}}                           # Error-Score Realisierung     
r_12      = cor(Y[,1],Y[,2])                                # Paralleltestreliabilitätsschätzer
```

```{r}
cat("Paralleltestreliabilität R_12            : ", round(R_12,4),
    "\nParalleltestrelibabilitätsschätzer  r_12 : ",  round(r_12,4))
``` 
\normalsize

Um ein Konfidenzintervall für die Paralleltestreliabilät anzugeben, ist eine
Annahme zur empirischen Verteilung des Reliabilitätsschätzers erforderlich. Dazu
nutzt man üblicherweise folgende asymptotische Verteilungsaussage.

:::{#thm-fishertransformation-des-paralleltestreliabilitätsschätzers}

## Fishertransformation des Paralleltestreliabilitätsschätzers
Gegeben sei das Modell paralleler Testmessungen für $n$ Personen mit Paralleltestreliabilität
$\mbox{R}_j$. Für zwei Testmessungen $j = 1,2$ sei $r_{12}$ der Paralleltestreliabilitätsschätzer.
Dann gilt, dass 
\begin{equation}
\tilde{r}_{12} := \frac{1}{2} \ln \left(\frac{1 + r_{12}}{1 - r_{12}} \right)
\end{equation}
asymptotisch normalverteilt ist nach
\begin{equation}
\tilde{r}_{12}  \stackrel{a}{\sim}  N\left(\mbox{R}_j,  (n-3)^{-1} \right)
\end{equation}
:::

Wir verzichten auf einen Beweis und verweisen für eine ausführliche Darstellung
auf @johnson1994, Kapitel 32. Dabei wird die Transformation eines 
Stichprobenkorrelationskoeffizienten anhand von 
\begin{equation}
\tilde{r} := \frac{1}{2} \ln \left(\frac{1 + r}{1 - r} \right)
\end{equation}
wird nach @fisher1925 als *Fisher-Transformation* bezeichnet.

\hl{SIMULATION UND VISUALISIERUNG}


<!-- $p(t_i) =  N(t_i; 0,\sigma_\tau^2)$ und $p(y_{ij}|t_i) :=  N(y_{ij}; t_i,\sigma_{\eps}^2)$ für $j = 1,2$
mit $\sigma_\tau^2 := 1.0$ und $\sigma_{\eps}^2 := 0.2$   für   $i = 1,...,30$. -->

\tiny
```{r, echo = TRUE}
nsim                = 1e4                                   # Realisierungsanzahl
n                   = 30                                    # Personenanzahl
m                   = 2                                     # Testmessungsanzahl
sigsqr_tau          = 1                                     # True-Score Varianz
sigsqr_eps          = .2                                    # Observed-Score-Varianz
R_12                = sigsqr_tau/(sigsqr_tau+sigsqr_eps)    # Paralletestreliabilität
tilde_r_12          = rep(NaN, nsim)                        # Fisher Transformation von r_12 Array
for(s in 1:nsim){                                           # Simulationsiterationen
    T               = matrix(rep(NaN, n)  , nrow = n)       # True-Score Array
    Y               = matrix(rep(NaN, n*m), nrow = n)       # Observed-Score Array 
    E               = matrix(rep(NaN, n*m), nrow = n)       # Error-Score Array
    for(i in 1:n){                                          # Personeniterationen
        T[i]        = rnorm(1,1,sqrt(sigsqr_tau))           # True-Score Realisierung für j = 1,2
        for(j in 1:m){                                      # Testmessungsiterationen 
            Y[i,j]  = rnorm(1,T[i],sqrt(sigsqr_eps))        # Observed-Score Realisierung f 
            E[i,j]  = Y[i,j] - T[i]}}                       # Error-Score Realisierung     
    r_12            = cor(Y[,1],Y[,2])                      # Paralleltestreliabilitätsschätzer
    tilde_r_12[s]   = 1/2*log((1+r_12)/(1-r_12))            # Fisher Transformation von r_12
}
```
\normalsize

```{r, echo = F, eval = F}
pdf(file    = "./_figures/901-fisher-transformation-verteilung.pdf", 
width       = 10, 
height      = 5)                                                                                                                                 
library(latex2exp)
par(                                                                    
family     = "sans",                                                  
mfcol      = c(1,1),                                                 
pty        = "m",                                                     
bty        = "l",                                                     
lwd        = 1,                                                       
las        = 1,                                                      
mgp        = c(2,1,0),                                               
xaxs         = "i",                                                   
yaxs         = "i",                                                   
font.main  = 1,                                                       
cex        = 1.2,
cex.main   = 1.2)                                                      

# Histogramm und WDF
hist(
tilde_r_12,                                                                         
breaks  = 100,                                                                
col     = "gray90",                                                           
prob    = TRUE,                                                               
xlim    = c(0.5,2.0),                                                                                                               
xlab    = TeX("$\\tilde{r}_{12}$"),                                                                
ylab    = "",                                                                 
main    = "Approximation der Fishertransformationsverteilung")
r_min   = -4                                                                  
r_max   = 4                                                                  
r_res   = 1e3                                                                
r_space = seq(r_min, r_max, len = r_res)                                      
p_r     = dnorm(r_space, 1/2*log((1+R_12)/(1-R_12)),sqrt(1/(n-3)))                                                                                
lines(
r_space,                                                                         
p_r,                                                                        
lwd   = 2,                                                                  
col   = "darkorange")                                                       
dev.off()      
```


<!-- 
![Fishertransformationverteilung](./_figures/901-fisher-transformation-verteilung.pdf){#fig-fisher-transformation-verteilung fig-align="center" width=60%} -->

\hl{KONFIDENZINTERVALL FÜR RELIABILITÄTSSCHÄTZER.}

\newpage
## Interne Konsistenz {#sec-interne-konsistenz}
### $m$-Komponententestmodelle {-}

In den vorherigen Abschnitten bezeichnete $y_{ij}$ die Zufallsvariable zur 
Modellierung des Observed-Scores der $j$ten Testmessung der $i$ten Person, 
wobei wir $m$ Testmessungen $j = 1,...,m$ und $n$ Personen $i = 1,...,n$ angenommen haben.
Wir haben dabei aber zunächst offen gelassen, ob mit der *$j$ten Testmessung* das
summative Ergebnis eines *Tests* oder ein einzelnes *Item* eines Tests
gemeint ist um die Theorie für beide Anwendungsfälle zu entwickeln. Als Grundlage
der Bestimmung der inneren Konsistenz eines Tests identifizieren wir in diesem
Abschnitt nun die $j$te Testmessung nun mit dem $j$ten *Item eines Tests*.
$y_{ij}$ bezeichnet also im Folgenden die Zufallsvariable zur Modellierung des 
Observed-Scores des $j$ten Items der $i$ten Person in einem Test, wobei  wir 
weiterhin $m$ Items $j = 1,...,m$ und $n$ Personen $i = 1,...,n$ annehmen. 
Weiterhin  gehen wir in diesem Zusammenhang davon aus, dass für jede Person ein 
*Gesamt-Observed-Score* durch Summation über die Items eines Test gebildet wird. 
Die Zufallsvariable zur Modellierung dieses Gesamt-Observed-Scores bezeichnen 
wir entsprechend mit
\begin{equation}
y_i := \sum_{j=1}^m y_{ij}.
\end{equation}
Wir fassen diese Vorüberlegungen mit folgender Definition des *$m$-Komponententestmodells* zusammen.

:::{#def-m-komponententestmodell}
## $m$-Komponententestmodell

Gegeben sei das Modell multipler Testmessungen für $i = 1,...,n$ Personen und 
$j = 1,...,m$ Testmessungen. Für $i = 1,...,n$ seien

* $y_i      := \sum_{j=1}^m y_{ij}$ die *Observed-Score-Summe* und
* $\tau_i   := \sum_{j=1}^m \tau_{ij}$ die *True-Score-Summe*.

Dann heißt die gemeinsame Verteilung der $y_i$ und $\tau_i$ für $i = 1,...n$ 
mit der Faktorisierungseigenschaft
\begin{equation}
\mathbb{P}(\tau_1,...,\tau_n,y_1,...,y_n) 
:= \prod_{i=1}^n \mathbb{P}(\tau_i,y_i) 
= \prod_{i=1}^n \mathbb{P}(y_i|\tau_i)\mathbb{P}(\tau_i)
\end{equation}
*das $m$-Komponententestmodell*, wenn gilt dass
\begin{equation}
\mathbb{P}(\tau_1,y_1) = \cdots = \mathbb{P}(\tau_n,y_n). 
\end{equation}
:::

Zum Verständnis dazu, wie Cronbach's $\alpha$ die inneren Konsistenz eines Tests 
misst, bietet es sich zunächst an, für das $m$-Komponententestmodell die Reliabilität
im Sinne der Formulierung von Aussage (1) in @thm-eigenschaften-der-reliabilität-einer-testmessung
zu definieren. 

:::{#def-reliabilität-von-m-komponententestmodellen}
## Reliabilität von $m$-Komponententestmodellen

Gegeben sei ein $m$-Komponententestmodell mit Observed-Score-Summe $y_i$
und True-Score-Summe $\tau_i$ für $i = 1,...,n$ Personen oder ein $m$-Parallelkomponententestmodell
mit Observed-Score-Summe $y_i$ und True-Score $\tau_i$ für $i = 1,...,n$ . 
Dann ist die Reliabilität des Modells definiert als
\begin{equation}
\mbox{R} := \frac{\mathbb{V}(\tau_i)}{\mathbb{V}(y_i)} \mbox{ für ein beliebiges } 1 \le i \le n.
\end{equation}
:::

### Cronbach's $\alpha$ {-}

Vor dem Hintegrund des $m$-Komponentenmodells definieren wir *Cronbach's $\alpha$*
wie folgt.

:::{#def-cronbachs-alpha}
## Cronbach's $\alpha$

Gegeben sei ein $m$-Komponententestmodell. Dann heißt
\begin{equation}
\alpha := \frac{m}{m-1}\left(1 - \frac{\sum_{j=1}^m \mathbb{V}(y_{ij})}{\mathbb{V}(y_i)}\right)
\end{equation}
*Cronbach's $\alpha$* oder *Koeffizient $\alpha$*.
:::

Man beachte, dass in @def-cronbachs-alpha $\mathbb{V}(y_i)$ die Varianzen der 
Observed-Score-Summen für Personen $i = 1,...,n$  und $\mathbb{V}(y_{ij})$ 
die Varianzen des Observed-Scores für Personen $i = 1,...,n$ und Items $j = 1,...,m$
bezeichnen. 

\hl{INTUITIVE BEDEUTUNG DER FORMEL FÜR CRONBACHS ALPHA / GRENZ SZENARIEN BEZ. VIJ UND VI}

Seine zentrale Bedeutung in der Klassischen Testtheorie bekommt Cronbach's $\alpha$
durch seinen Zusammenhang mit der Reliabilität eines $m$-Komponententests, welchen
wir in unterem Theorem darstellen.

:::{#thm-cronbachs-alpha-und-reliabilität}
## Cronbach's $\alpha$ und Reliabilität

Gegeben sei ein $m$-Komponententestmodell mit Reliabilität $\mbox{R}$. Dann gilt
für Cronbach's $\alpha$, dass
\begin{equation}
\alpha \le  \mbox{R}
\end{equation}
und Gleichheit tritt insbesondere dann ein, wenn die Testmessungen des $m$-Komponententestmodell 
parallel sind.
:::

:::{.proof}
Zur Vereinfachung der Notation verzichten wir auf die explizite Auszeichung der 
Personen $i = 1,...,n$ und setzen  
\begin{equation} 
y_{j} := y_{ij},  
\tau_{j} := \tau_{ij}, 
y := \sum_{j=1}^m y_{j}
\mbox{ und }
\tau := \sum_{j=1}^m \tau_{j}, 
\end{equation}
sowie
\begin{equation}
\mbox{R} := \frac{\mathbb{V}(\tau)}{\mathbb{V}(y)} \mbox{ und } 
\alpha := \frac{m}{m-1}\left(1 - \frac{\sum_{j=1}^m \mathbb{V}(y_{j})}{\mathbb{V}(y)}\right).
\end{equation}
Wir gehen in vier Schritten vor.

\noindent (1) (*Summendarstellung*) Wir schreiben zunächst die Summe von $m$ Zahlen um. Speziell gilt für reelle Zahlen $x_1,...,x_m$, dass
\begin{equation}
\sum_{j=1}^m x_j = \frac{1}{m-1}\sum_{j=1}^{m-1}\sum_{k = j + 1}^m (x_j + x_k).
\end{equation}

Anstelle eines Beweises betrachten wir den Fall $m := 4$. Dann gilt
\begin{align}
\begin{split}
\frac{1}{3}\sum_{j=1}^{3}\sum_{k = j + 1}^4 (x_j + x_k)  
& = \frac{1}{3}\left(\sum_{k = 1 + 1}^4 (x_1 + x_k)  + \sum_{k = 2 + 1}^4 (x_2 + x_k) + \sum_{k = 3 + 1}^4 (x_3 + x_k)\right) \\
& = \frac{1}{3}\left(\sum_{k = 2}^4 (x_1 + x_k) + \sum_{k = 3}^4 (x_2 + x_k) +\sum_{k = 4}^4 (x_3 + x_k)\right) \\
& = \frac{1}{3}\left((x_1 + x_2) + (x_1 + x_3) + (x_1 + x_4) + (x_2 + x_3) + (x_2 + x_4) + (x_3 + x_4) \right) \\
& = \frac{1}{3}\left((x_1 + x_1 + x_1) + (x_2 + x_2 + x_2) + (x_3 + x_3 + x_3) + (x_4 + x_4 + x_4)  \right) \\
& = \frac{1}{3}\left(3x_1+ 3x_2+ 3x_3 + 3x_4 \right) \\
& = x_1 + x_2 + x_3 + x_4   \\
& = \sum_{j = 1}^4 x_j      \\
\end{split}
\end{align}

\noindent (2) (*True-Score-Kovarianzungleichung*) Wir leiten nun im Modell multipler 
Testmessungen eine Ungleichung her. Dazu betrachten wir im Modell multipler Testmessungen 
die Varianz der Differenz zweier True-Scores $\tau_j$ und $\tau_k$. Mit der Nicht-Negativität 
der Varianz und dem Theorem zur Varianz spezieller Linearkombinationen von Zufallsvariable 
\hl{LINK} ergibt sich  
\begin{align}
\begin{split}
\mathbb{V}(\tau_j - \tau_k)                                            \ge 0 
\Leftrightarrow 
\mathbb{V}(\tau_j) + \mathbb{V}(\tau_k) - 2\mathbb{C}(\tau_j,\tau_k)   \ge 0
\Leftrightarrow 
\mathbb{V}(\tau_j) + \mathbb{V}(\tau_k)                                \ge 2\mathbb{C}(\tau_j,\tau_k)    
\end{split}
\end{align}
Weiterhin ergibt sich für beliebige $1 \le j,k \le m$ parallele Testmessungen, dass
\begin{equation}
\mathbb{V}(\tau_j - \tau_k) = \mathbb{V}(f_j(\tau_1) - f_k(\tau_1)) =  \mathbb{V}(\tau_1 - \tau_1) = \mathbb{V}(0) = 0.
\end{equation}
In diesem Fall ergibt sich in obiger Ungleichung und ihrer Anwendung im Folgenden also Gleichheit.

\noindent(3) (*Summen-True-Score-Varianzungleichung*) Wir betrachten nun die 
Varianz der True-Score Summe im $m$-Komponententestmodell. Mit dem Theorem zur Varianz
einer Linearkombination von Zufallsvariablen \hl{LINK}, der Summendarstellung aus (1) 
und der True-Score-Kovarianzungleichung aus (2) ergibt sich zunächst
\begin{align}
\begin{split}
\mathbb{V}(\tau) 
& = \mathbb{V}\left(\sum_{j=1}^m \tau_j\right) \\
& = \sum_{j=1}^m \mathbb{V}(\tau_j) + 2\sum_{j=1}^{m-1}\sum_{k = j + 1 }^m \mathbb{C}(\tau_j, \tau_k) \\
& = \frac{1}{m-1}\sum_{j=1}^{m-1}\sum_{k = j + 1 }^m \left(\mathbb{V}(\tau_j) + \mathbb{V}(\tau_k)\right) + 2\sum_{j=1}^{m-1}\sum_{k = j + 1 }^m \mathbb{C}(\tau_j, \tau_k) \\
& \ge \frac{1}{m-1}\sum_{j=1}^{m-1}\sum_{k = j + 1 }^m 2 \mathbb{C}(\tau_j, \tau_k) + \sum_{j=1}^{m-1}\sum_{k = j + 1 }^m 2\mathbb{C}(\tau_j, \tau_k) \\
& = \left(\frac{1}{m-1} + 1 \right) \sum_{j=1}^{m-1}\sum_{k = j + 1 }^m \mathbb{C}(\tau_j, \tau_k) \\
& = \left(\frac{1}{m-1} + \frac{m-1}{m-1} \right) \sum_{j=1}^{m-1}\sum_{k = j + 1 }^m 2\mathbb{C}(\tau_j, \tau_k) \\
& = \frac{1 + m - 1}{m-1} \sum_{j=1}^{m-1}\sum_{k = j + 1 }^m 2\mathbb{C}(\tau_j, \tau_k) \\
& = \frac{m}{m-1} \sum_{j=1}^{m-1}\sum_{k = j + 1 }^m 2\mathbb{C}(\tau_j, \tau_k) \\
\end{split}
\end{align}
Mit Aussage (5) von @thm-eigenschaften-bezüglich-zweier-testmessungen  
und wiederum mit dem Theorem zur Varianz einer Linearkombination \hl{LINK}
gilt dann
\begin{align}
\begin{split}
\mathbb{V}(\tau)
& \ge \frac{m}{m-1} \sum_{j=1}^{m-1}\sum_{k = j + 1 }^m 2\mathbb{C}(\tau_j, \tau_k) \\
&  =  \frac{m}{m-1} \sum_{j=1}^{m-1}\sum_{k = j + 1 }^m 2\mathbb{C}(y_j, y_k) \\
& = \frac{m}{m-1} \left(\mathbb{V}\left(\sum_{j=1}^m y_j\right) - \sum_{j=1}^m \mathbb{V}\left(y_j\right) \right)\\
& = \frac{m}{m-1} \left(\mathbb{V}(y) - \sum_{j=1}^m \mathbb{V}\left(y_j\right) \right)\\
\end{split}
\end{align}
\noindent (4) (*Reliabilität*) Wir betrachten schließlich die Reliabilität im $m$-Komponententestmodell. Es ergibt sich
\begin{align}
\begin{split}
\mbox{R} 
& = \frac{\mathbb{V}(\tau)}{\mathbb{V}(y)} \\
& \ge \frac{\frac{m}{m-1} \left(\mathbb{V}(y) - \sum_{j=1}^m \mathbb{V}\left(y_j\right)\right)}{\mathbb{V}(y)} \\
& = \frac{m}{m-1} \left(\frac{\mathbb{V}(y)}{\mathbb{V}(y)} - \frac{\sum_{j=1}^m \mathbb{V}\left(y_j\right)}{\mathbb{V}(y)}\right) \\
& = \frac{m}{m-1} \left(1 - \frac{\sum_{j=1}^m \mathbb{V}\left(y_j\right)}{\mathbb{V}(y)}\right) \\
& =: \alpha.
\end{split}
\end{align}
:::

Cronbach's $\alpha$ ist also eine untere Grenze für die Reliabilität eines 
$m$-Komponententestmodells, die Relibabilität eines $m$-Komponententestmodells also 
ist mindestens so groß wie Cronbach's $\alpha$, kann aber größer sein. Für parallele 
Testmessungen (also parallele Items), ist die Reliabilität eines $m$-Komponententestmodells 
gleich $\alpha$.


Eine Schätzung von Cronbach's $\alpha$ greift dementsprechend auf die
Stichprobenvarianzen der Summenscores und die Stichprobenvarianzen der Itemscores
zurück. 

$\mathbb{V}(y_i)$ ist die Varianz der Observed-Score Summen für Personen $i = 1,...,n$. 

Es gilt $\mathbb{V}(y_1) = \cdots = \mathbb{V}(y_n)$.

Ein Schätzer für $\mathbb{V}(y_i)$ ist die Stichprobenvarianz der Observed-Score-Summe
\begin{equation}
S^2 := \frac{1}{n-1}\sum_{i=1}^n \left(y_i - \bar{y}\right)^2 \mbox{ mit } \bar{y} := \frac{1}{n}\sum_{i=1}^n y_i.
\end{equation}

$\mathbb{V}(y_{ij})$ ist die Varianz des Observed-Scores für Personen $i = 1,...,n$ und Items $j = 1,...,m$.

Es gilt $\mathbb{V}(y_{1j}) = \cdots = \mathbb{V}(y_{nj})$ für  $i = 1,...,n$.

Ein Schätzer für $\mathbb{V}(y_{ij})$ ist die Stichprobenvarianz des Observed-Scores von Item $j$
\begin{equation}
S^2_j := \frac{1}{n-1}\sum_{i=1}^n \left(y_{ij} - \bar{y}_j\right)^2 \mbox{ mit } \bar{y}_j := \frac{1}{n}\sum_{i=1}^n y_{ij}.
\end{equation}



\hl{THEOREM UNVERZERRTER CRONBACHS ALPHA SCHTZER}

Wir demonstrieren dies untenstehen anhand einer Simulation im Modell 
paralleler Testmessungen für $n := 30$ und $m := 21$  mit
\begin{equation}
\mathbb{P}(\tau_{i}) := N(1,1), \mathbb{P}(y_{ij}|\tau_{i}) := N(\tau_{i},4)
\mbox{ für } i = 1,...,n, j = 1,...,m.
\end{equation}

\tiny
```{r, echo = TRUE, warning = FALSE, message = FALSE}
library(psych)                                                  # R Paket zur Testanalyse 
set.seed(0)                                                     # Reproduzierbarkeit
n   = 30                                                        # Personenanzahl
m   = 21                                                        # Itemanzahl
mu  = 1                                                         # True-Score Erwartungswertparameter   
T   = matrix(rep(NaN, n)  , nrow = n)                           # True-Score Array
Y   = matrix(rep(NaN, n*m), nrow = n)                           # Observed-Score Array 
for(i in 1:n){                                                  # Iteration über Personen 
  T[i]  = rnorm(2,mu,sqrt(1))                                   # True-Score Realisierung
  for(j in 1:m){                                                # Iteration über Items
    Y[i,j]  = rnorm(1,T[i],sqrt(4))}}                           # Observed-Score Realisierung
vsi  = var(apply(Y,1,sum))                                      # Stichprobenvarianz der Observed-Score-Summem
siv  = sum(apply(Y,2,var))                                      # Summe der Item-Stichprobenvarianzen                
a    = (m/(m-1))*(1-(siv/vsi))                                  # direkte Berechnung von Cronbach's alphca
ap   = alpha(Y,warnings = F)                                    # Berechnung von Cronbach's alpha mit psych    
```

```{r, echo = FALSE}
cat("Cronbach's alpha (manuell) : ", round(a,3),
    "\nCronbach's alpha (psych)   : ", round(ap$total$raw_alpha,3))
```
\normalsize







