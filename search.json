[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Probabilistische Datenwissenschaft für die Psychologie",
    "section": "",
    "text": "Willkommen\nDieses Werk ist lizenziert unter einer Creative Commons Namensnennung 4.0 International Lizenz."
  },
  {
    "objectID": "101-Sprache-und-Logik.html#sec-mathematik-ist-eine-sprache",
    "href": "101-Sprache-und-Logik.html#sec-mathematik-ist-eine-sprache",
    "title": "1  Sprache und Logik",
    "section": "1.1 Mathematik ist eine Sprache",
    "text": "1.1 Mathematik ist eine Sprache\nMathematik ist die Sprache der naturwissenschaftlichen Modellbildung. So entspricht zum Beispiel der Ausdruck \\[\\begin{equation}\nF = ma\n\\end{equation}\\] im Sinne des zweiten Newtonschen Axioms einer Theorie zur Bewegung von Objekten unter der Einwirkung von Kräften (Newton (1687)). Gleichermaßen entspricht der Ausdruck \\[\\begin{equation}\n\\max_{q(z)} \\int q(z) \\ln \\left(\\frac{p(y,z)}{q(z)}\\right)\\,dz\n\\end{equation}\\] im Sinne der Variational Inference der zeitgenössischen Theorie zur Funktionsweise des Gehirns (Friston (2005), Friston et al. (2023), Ostwald et al. (2014), Blei et al. (2017)). Mathematische Symbolik dient dabei insbesondere der genauen Kommunikation wissenschaftlicher Erkenntnisse und zielt darauf ab, komplexe Sachverhalte exakt und effizient zu beschreiben. Wie beim reflektierten Umgang mit jeder Form von Sprache steht also die Frage “Was soll das heißen?” als Leitfrage im Umgang mit mathematischen Inhalten und Symbolismen immer im Vordergrund.\nAls Sprachgebäude weist die Mathematik einige Besonderheiten auf. Zum einen sind ihre Inhalte oft abstrakt. Dies rührt daher, dass sich die Mathematik um eine möglichst breite Allgemeinverständlichkeit und Anwendbarkeit bemüht. Mathematische Zugänge zu den Phänomenen der Welt sind dabei an einer möglichst einfache Transferierbarkeit von Erkenntnissen in andere Kontexte interessiert. Um dies zu ermöglichen, versucht die Mathematik möglichst genau und verständlich, also im Sinne präziser Begriffsbildungen zu arbeiten. Sie geht dabei insbesondere streng hierarchisch vor, so dass an späterer Stelle eingeführte Begrifflichkeiten oft ein gutes Verständnis der ihnen zugrundeliegenden und an früherer Stelle eingeführten Begrifflichkeiten voraussetzen.\nDie Genauigkeit der mathematischen Sprache impliziert dabei eine hohe Informationsdichte. Sie ist daher eher nüchtern und lässt überflüssiges weg, so dass in mathematischen Texten im besten Fall alles für die Kommunikation einer Idee relevant ist. Als Rezipient:in mathematischer Texte nimmt man die Informationsdichte mathematischer Texte anhand des hohen Verbrauchs an kognitiver Energie beim Lesen eines Textes wahr. Dieser hohe Energieverbrauch gebietet insbesondere Ruhe und Langsamkeit bei einem auf ein gutes Verständnis abzielenden Lesen. Als Leitsatz im Umgang mit mathematischen Texten mag dabei folgendes Zitat dienen: “Einen mathematischen Text kann man nicht lesen wie einen Roman, man muss ihn sich erarbeiten” (Unger (2000)). Nach dem Lesen eines kurzen mathematischen Textes sollte man sich immer kritisch fragen, ob man das Gelesene wirklich verstanden hat oder ob man zur Klärung des Sachverhaltes weitere Quellen heranziehen sollte. Auch ist es hilfreich, sich im Sinne des berühmten Zitats “What I cannot create, I do not understand” von Richard Feynman eigene Aufzeichnungen anzufertigen und mathematische Sprachgebäude selbst nachzubauen.\nMöchte man sich also die Welt der naturwissenschaftliche Modellbildung erschließen, so ist es hilfreich, beim Umgang mit ihrer mathematischen Ausdrucksweise und Symbolik die gleichen Strategien wie beim Erlernen einer Fremdsprache anzuwenden. Hierzu gehört neben dem Eintauchen in den entsprechenden Sprachraum, also der ständige Exposition mit mathematischen Ausdrucksweisen, sicherlich auch zunächst einmal das Auswendiglernen von Begriffen und das aktive Lesen und das Übersetzen von Texten in die Alltagssprache. Ein tiefes und sicheres Verständnis mathematischer Modellbildung ergibt sich dann insbesondere durch die Anwendung mathematischer Herangehensweisen in schriftlicher und mündlicher Form."
  },
  {
    "objectID": "101-Sprache-und-Logik.html#sec-grundbausteine-mathematischer-kommunikation",
    "href": "101-Sprache-und-Logik.html#sec-grundbausteine-mathematischer-kommunikation",
    "title": "1  Sprache und Logik",
    "section": "1.2 Grundbausteine mathematischer Kommunikation",
    "text": "1.2 Grundbausteine mathematischer Kommunikation\nIn diesem Abschnitt stellen wir mit den Begriffen der Definition, des Theorems und des Beweises drei Grundbausteine mathematischer Kommunikation vor, die uns durchgängig begleiten.\nDefinition\nEine Definition ist eine Grundannahme eines mathematischen Systems, die innerhalb dieses Systems weder begründet noch deduktiv abgeleitet wird. Definitionen können nur nach ihrer Nützlichkeit innerhalb eines mathematischen Systems bewertet werden. Eine Definition lernt man am besten erst einmal auswendig und hinterfragt sie erst dann, wenn man ihren Nutzen in der Anwendung verstanden hat oder von diesem nicht überzeugt ist. Etwas Entspannung und Ruhe beim Umgang mit auf den ersten Blick komplexen Definitionen ist generell hilfreich. Um zu kennzeichnen, dass wir ein Symbol als etwas definieren, nutzen wir die Schreibweise “\\(:=\\)”. Zum Beispiel definiert der Ausdruck “\\(a := 2\\)” das Symbol \\(a\\) als die Zahl Zwei. Definitionen enden in diesem Text immer mit dem Symbol \\(\\bullet\\).\nTheorem\nEin Theorem ist eine mathematische Aussage, die mittels eines Beweises als wahr (richtig) erkannt werden kann. Dass heißt, ein Theorem wird immer aus Definitionen und/oder anderen Theoremen hergeleitet. Theoreme sind in diesem Sinne die empirischen Ergebnisse der Mathematik. Im Deutschen werden Theoreme auch oft als Sätze bezeichnet. In der angewandten, datenanalytischen Mathematik sind Theoreme oft für Berechnungen hilfreich. Es lohnt sich also, sie auswendig zu lernen, da sie meist die Grundlage für Datenauswertung und Dateninterpretation bilden. Oft tauchen in Theoremen Gleichungen auf. Diese ergeben sich dabei aus den Voraussetzungen des Theorems. Um Gleichungen zu kennzeichnen nutzen wir das Gleichheitszeichen “\\(=\\)”. So besagt also zum Beispiel der Ausdruck “\\(a = 2\\)” in einem gegebenen Kontext, dass aufgrund bestimmter Voraussetzungen das Symbol oder die Variable \\(a\\) den Wert zwei hat. Theoreme enden in diesem Text immer mit dem Symbol \\(\\circ\\).\nBeweis\nEin Beweis ist eine logische Argumentationskette, die auf bekannte Definitionen und Theoreme zurückgreift, um die Wahrheit (Richtigkeit) eines Theorems zu belegen. Kurze Beweise tragen dabei oft zum Verständnis eines Theorems bei, lange Beweise eher nicht. Beweise sind also insbesondere die Antwort auf die Frage, warum eine mathematische Aussage gilt (“Warum ist das so?”). Beweise lernt man nicht auswendig. Wenn Beweise kurz sind, ist es sinnvoll, sie durchzuarbeiten, da sie meist als bekannt vorausgesetzte Inhalte wiederholen. Wenn sie lang sind, ist es sinnvoller sie zunächst zu übergehen, um sich nicht in Details zu verlieren und vom eigentlichen Weg durch das entsprechende mathematische Gebäude abzukommen. Beweise enden in diesem Text immer mit dem Symbol \\(\\Box\\).\nNeben den oben vorgestellten Begriffen gibt es mit Axiomen, Lemmata, Korollaren und Vermutungen noch weitere typische Grundbausteine mathematischer Texte. Wir werden diese Begriff nicht verwenden und geben deshalb für sie nur einen kurzen Überblick.\nAxiome sind unbeweisbare Theoreme, in dem Sinne, als dass sie als Grundannahmen zum Aufbau mathematischer Systeme dienen. Der Übergang zwischen Definitionen und Axiomen ist dabei oft fließend. Da wir mathematisch nicht besonders tief arbeiten, bevorzugen wir in den allermeisten Fällen den Begriff der Definition.\nEin Lemma ist ein “Hilfstheorem”, also eine mathematische Aussage, die zwar bewiesen wird, aber nicht so bedeutend ist wie ein Theorem. Da wir einerseits auf bedeutende Inhalte fokussieren und andererseits mathematische Aussagen nicht diskriminieren wollen, verzichten wir auf diesen Begriff und nutzen stattdessen den Begriff des Theorems.\nEin Korollar ist eine mathematische Aussage, die sich durch einen einfachen Beweis aus einem Theorem ergibt. Da die “Einfachheit” mathematischer Beweise eine relative Eigenschaft ist, verzichten wir auf diesen Begriff und nutzen stattdessen auch hier den Begriff des Theorems.\nVermutungen sind mathematische Aussagen von denen unbekannt ist, ob sie beweisbar oder widerlegbar sind. Da wir im Bereich der angewandten Mathematik arbeiten, treffen wir nicht auf Vermutungen."
  },
  {
    "objectID": "101-Sprache-und-Logik.html#sec-aussagenlogik",
    "href": "101-Sprache-und-Logik.html#sec-aussagenlogik",
    "title": "1  Sprache und Logik",
    "section": "1.3 Aussagenlogik",
    "text": "1.3 Aussagenlogik\nNachdem wir nun einige Grundbausteine mathematischer Modellbildung kennengelernt haben, wollen wir uns mit der Aussagenlogik einem einfachem System nähern, das es erlaubt, Beziehungen zwischen mathematischen Aussagen herzustellen und zu formalisieren. Im Folgenden spielt die Aussagenlogik zum Beispiel in der Definition von Mengenoperationen, bei Optimierungsbedingungen von Funktionen und in vielen Beweisen einen tragende Rolle. In der mathematischen Anwendung ist Aussagenlogik die Grundlage der Booleschen Logik der Programmierung. In der mathematischen Psychologie ist die Aussagenlogik zum Beispiel die Grundlage der Repräsentationstheorie des Messens.\nWir beginnen mit der Definition des Begriffs der mathematischen Aussage.\n\nDefinition 1.1 (Aussage) Eine ist ein Satz, dem eindeutig die Eigenschaft oder zugeordnet werden kann.\n\nDas Adjektiv wahr kann auch als richtig verstanden werden. Wir kürzen wahr mit “w” und falsch mit “f” ab. Im Körper der reellen Zahlen ist zum Beispiel die Aussage \\(1 + 1 = 2\\) wahr und die Aussage \\(1 + 1 = 3\\) falsch. Man beachte, dass die Binärität des Wahrheitsgehalts von Aussagen eine Grundannahme der Aussagenlogik und damit formal wissenschaftlich und nicht empirisch zu verstehen ist. Wahrheitsgehalte beziehen sich nicht auf Definitionen, Definitionen sind immer wahr. Eine erste Möglichkeit, mit Aussagen zu arbeiten, ist, sie zu negieren. Dies führt auf folgende Definition.\n\nDefinition 1.2 (Negation) \\(A\\) sei eine Aussage. Dann ist die die Aussage, die falsch ist, wenn \\(A\\) wahr ist und die wahr ist, wenn \\(A\\) falsch ist. Die Negation von \\(A\\) wird mit \\(\\neg A\\), gesprochen als “nicht \\(A\\)”, bezeichnet.\n\nBeispielsweise ist die Negation der Aussage “Die Sonne scheint” die Aussage “Die Sonne scheint nicht”. Die Negation der Aussage \\(1 + 1 = 2\\) ist die Aussage \\(1 + 1 \\neq 2\\) und die Negation der Aussage \\(x&gt;1\\) ist die Aussage \\(x \\le 1\\). Tabellarisch stellt man die Definition der Negation einer Aussage \\(A\\) wie folgt dar.\nTabellen dieser Form nennt man Wahrheitstafeln. Sie sind ein beliebtes Hilfsmittel in der Aussagenlogik. Möchte man zwei Aussagen logisch verbinden, so bieten sich zunächst die Begriffe der Konjunktion und Disjunktion an.\n\nDefinition 1.3 (Konjunktion) \\(A\\) und \\(B\\) seien Aussagen. Dann ist die die Aussage, die dann und nur dann wahr ist, wenn \\(A\\) und \\(B\\) beide wahr sind. Die Konjunktion von \\(A\\) und \\(B\\) wird mit \\(A \\land B\\), gesprochen als “\\(A\\) und \\(B\\)”, bezeichnet.\n\nDie Definition der Konjunktion impliziert folgende Wahrheitstafel.\nAls Beispiel sei \\(A\\) die Aussage \\(2\\ge1\\) und \\(B\\) die Aussage \\(2&gt;1\\). Da sowohl \\(A\\) und \\(B\\) wahr sind, ist auch die Aussage \\(2 \\ge 1 \\land 2 &gt; 1\\) wahr. Als weiteres Beispiel sei \\(A\\) die Aussage \\(1\\ge 1\\) und \\(B\\) die Aussage \\(1&gt;1\\). Hier ist nun \\(A\\) wahr und \\(B\\) falsch. Also ist die Aussage \\(1 \\ge 1 \\land 1 &gt; 1\\) falsch.\n\nDefinition 1.4 (Disjunktion) \\(A\\) und \\(B\\) seien Aussagen. Dann ist die die Aussage, die dann und nur dann wahr ist, wenn mindestens eine der beiden Aussagen \\(A\\) und \\(B\\) wahr ist. Die Disjunktion von \\(A\\) und \\(B\\) wird mit \\(A \\lor B\\), gesprochen als “\\(A\\) oder \\(B\\)”, bezeichnet.\n\nDie Definition der Disjunktion impliziert folgende Wahrheitstafel\n\\(A \\lor B\\) ist also insbesondere auch dann wahr, wenn \\(A\\) und \\(B\\) beide wahr sind. Damit ist das hier betrachtete “oder” genauer ein “und/oder”. Man nennt die Disjunktion daher auch ein “nicht-exklusives oder”. Als Beispiel sei \\(A\\) die Aussage \\(2\\ge1\\) und \\(B\\) die Aussage \\(2&gt;1\\). \\(A\\) ist wahr und \\(B\\) ist wahr. Also ist die Aussage \\(2 \\ge 1 \\lor 2 &gt; 1\\) wahr. Sei nun wiederrum \\(A\\) die Aussage \\(1\\ge 1\\) wahr und \\(B\\) die Aussage \\(1&gt;1\\). Dann ist \\(A\\) wahr und \\(B\\) falsch. Also ist die Aussage \\(1 \\ge 1 \\lor 1 &gt; 1\\) wahr.\nEine Möglichkeit, Aussagen in einen mechanischen logischen Zusammenhang zu stellen, ist die Implikation. Diese ist wie folgt definiert.\n\nDefinition 1.5 (Implikation) \\(A\\) und \\(B\\) seien Aussagen. Dann ist die , bezeichnet mit \\(A \\Rightarrow B\\), die Aussage, die dann und nur dann falsch ist, wenn \\(A\\) wahr und \\(B\\) falsch ist. \\(A\\) heißt dabei die und \\(B\\) der der Implikation. \\(A \\Rightarrow B\\) spricht man als “aus \\(A\\) folgt \\(B\\)”, “\\(A\\) impliziert \\(B\\)”, oder “wenn \\(A\\), dann \\(B\\)”.\n\nMan mag \\(\\Rightarrow\\) auch als “daraus folgt” lesen. Die Definition der Implikation impliziert folgende Wahrheitstafel.\nEin Verständnis der Definition der Implikation im Sinne obiger Wahrheitstafel ergibt sich am ehesten, indem man sie als Versuch liest, die intuitive Vorstellung einer Folgerung im Kontext der Aussagenlogik abzubilden und zu formalisieren. Betrachtet man obige Wahrheitstafel unter diesem Gesichtspunkt, so sieht man, dass wenn \\(A\\) wahr ist und \\(A \\Rightarrow B\\) wahr ist, \\(B\\) wahr ist. Konstruiert man basierend auf einer wahren Aussage also (zum Beispiel durch das Umformen von Gleichungen) eine wahre Implikation so folgt, dass auch \\(B\\) wahr ist. Ist dies nicht möglich (dass also gilt, wenn \\(A\\) wahr ist, dass \\(A \\Rightarrow B\\) immer falsch ist), dann ist auch \\(B\\) falsch. So mag man Aussagen widerlegen. Schließlich sieht man, dass wenn \\(A\\) falsch ist und \\(A \\Rightarrow B\\) wahr ist, \\(B\\) wahr oder falsch sein kann. Aus einer wahren Voraussetzung folgt also nur bei wahrer Implikation eine wahre Konklusion. Insbesondere genügt die Definition der Implikation damit der Forderung “Aus Falschem folgt beliebiges (ex falso sequitur quodlibet)”. Aus falschen Aussagen kann man also mithilfe der Implikation nichts richtiges folgern.\nIm Kontext der Implikation ergeben sich die Begriffe der hinreichenden und der notwendigen Aussagen (Bedingungen). Diese sind definiert wie folgt: wenn \\(A \\Rightarrow B\\) wahr ist, sagt man “\\(A\\) ist hinreichend für \\(B\\)” und “\\(B\\) ist notwendig für \\(A\\)”. Diese Sprachregelung erklärt sich folgendermaßen. Wenn \\(A \\Rightarrow B\\) wahr ist, gilt dass, wenn \\(A\\) wahr ist auch \\(B\\) wahr ist. Die Wahrheit von \\(A\\) reicht also für die Wahrheit von \\(B\\) aus. \\(A\\) ist also hinreichend (ausreichend) für \\(B\\). Weiterhin gilt, dass wenn \\(A \\Rightarrow B\\) wahr ist, dass wenn \\(B\\) falsch ist, dann auch \\(A\\) falsch ist. Die Wahrheit von \\(B\\) ist also für die Wahrheit von \\(A\\) notwendig.\nEine sehr häufig autretender Zusammenhang zwischen zwei Aussagen ist ihre Äquivalenz.\n\nDefinition 1.6 (Äquivalenz) \\(A\\) und \\(B\\) seien Aussagen. Die ist die Aussage, die dann und nur dann wahr ist,wenn \\(A\\) und \\(B\\) beide wahr sind oder wenn \\(A\\) und \\(B\\) beide falsch sind. Die Äquivalenz von \\(A\\) und \\(B\\) wird mit \\(A \\Leftrightarrow B\\) bezeichnet und gesprochen als “\\(A\\) genau dann wenn \\(B\\)” oder “\\(A\\) ist äquivalent zu \\(B\\)”.\n\nDie Definition der Äquivalenz impliziert folgende Wahrheitstafel\nDie Definition des Begriffes der logischen Äquivalenz erlaubt es unter anderem, die Äquivalenz zweier Aussagen mithilfe von Implikationen nachzuweisen.\n\nDefinition 1.7 (Logische Äquivalenz) Zwei Aussagen heißen , wenn ihre Wahrheitstafeln gleich sind.\n\nAls Beispiele für logische Äquivalenzen, die häufig in Beweisargumentationen genutzt werden, zeigen wir folgendes Theorem.\n\nTheorem 1.1 (Logische Äquivalenzen)  \n\\(A\\) und \\(B\\) seien zwei Aussagen. Dann sind folgende Aussagen logisch äquivalent\n\n\nBeweis. Nach Definition des Begriffs der logischen Äquivalenz müssen wir zeigen, dass die Wahrheitstafeln der betrachteten Aussagen gleich sind. Wir zeigen erst (1), dann (2).\n(1) Wir erinnern an die Wahrheitstafel von \\(A \\Leftrightarrow B\\):\nWir betrachten weiterhin die Wahrheitstafel von \\((A \\Rightarrow B) \\land (B \\Rightarrow A)\\):\nDer Vergleich der Wahrheitstafel von \\(A \\Leftrightarrow\\) mit den ersten beiden und der letzten Spalte der Wahrheitstafel von \\((A \\Rightarrow B) \\land (B \\Rightarrow A)\\) zeigt ihre Gleichheit.\n(2) Wir erinnern an die Wahrheitstafel von \\(A \\Rightarrow B\\):\nWir betrachten weiterhin die Wahrheitstafel von \\((\\neg B) \\Rightarrow (\\neg A)\\):\nDer Vergleich der Wahrheitstafel von \\(A \\Rightarrow B\\) mit den ersten beiden und der letzten Spalte der Wahrheitstafel von \\((\\neg B) \\Rightarrow (\\neg A)\\) zeigt ihre Gleichheit.\n\nDie erste Aussage von Theorem 1.1 besagt, dass die Aussage “\\(A\\) und”\\(B\\) sind äquivalent” logisch äquivalent zur Aussage “Aus \\(A\\) folgt \\(B\\)” und aus “\\(B\\) folgt \\(A\\)” ist. Dies ist die Grundlage für viele sogenannte direkte Beweise mithilfe von Äquivalenzumformungen. Die zweite Aussage von Theorem 1.1 besagt, dass die Aussage “Aus \\(A\\) folgt”\\(B\\)” logisch äquivalent zur Aussage “Aus nicht \\(B\\) folgt nicht \\(A\\)” ist. Dies ist die Grundlage für die Technik des indirekten Beweises."
  },
  {
    "objectID": "101-Sprache-und-Logik.html#sec-beweistechniken",
    "href": "101-Sprache-und-Logik.html#sec-beweistechniken",
    "title": "1  Sprache und Logik",
    "section": "1.4 Beweistechniken",
    "text": "1.4 Beweistechniken\nIm letzten Abschnitt wollen wir mit den Begriffen der direkten und indirekten Beweise sowie des Beweises durch Widerspruch kurz drei Beweistechniken skizzieren, von denen vor allem die erste in diesem Text immer wieder zur Begründung von Theoremen herangezogen wird. Dabei haben typische Theoreme die Form \\(A \\Rightarrow B\\) für Aussagen \\(A\\) und \\(B\\).\nEs gilt dabei\n\nDirekte Beweise nutzen Äquivalenzumformungen, um \\(A \\Rightarrow B\\) zu zeigen.\nIndirekte Beweise nutzen die logische Äquivalenz von \\(A \\Rightarrow B\\) und \\((\\neg B) \\Rightarrow (\\neg A)\\).\nBeweise durch Widerspruch zeigen, dass \\((\\neg B) \\land A\\) falsch ist.\n\nUm diese Techniken an einem Beispiel zu erläutern, erinnern wir kurz an folgende Äquivalenzumformungen von Gleichungen:\n\nAddition oder Subtraktion einer Zahl auf beiden Seiten der Gleichung, zum Beispiel \\[\\begin{equation}\n2x + 4 = 10 \\Leftrightarrow 2x = 6,\n\\end{equation}\\]\nMultiplikation mit einer oder Division durch eine von Null verschiedene Zahl auf beiden Seiten der Gleichung, zum Beispiel \\[\\begin{equation}\n2x = 6 \\Leftrightarrow x = 3,\n\\end{equation}\\]\nAnwendung einer injektiven Funktion auf beiden Seiten der Gleichung, zum Beispiel \\[\\begin{equation}\n\\exp(x) = 2 \\Leftrightarrow x = \\ln(2),\n\\end{equation}\\]\n\nsowie an folgende elementaren Äquivalenzumformungen von Ungleichungen:\n\nAddition oder Subtraktion einer Zahl auf beiden Seiten der Ungleichung, zum Beispiel \\[\\begin{equation}\n-2x + 4 \\ge 10 \\Leftrightarrow -2x \\ge 6,\n\\end{equation}\\]\nMultiplikation mit einer Zahl oder Division durch eine von Null verschiedene Zahl auf beiden Seiten der Ungleichung, wobei die Multiplikation oder Division mit einer negativen Zahl die Umkehrung der Ungleichung impliziert, zum Beispiel \\[\\begin{equation}\n-2x \\ge 6 \\Leftrightarrow x \\le -3,\n\\end{equation}\\]\nAnwendung monotoner Funktionen auf beiden Seiten der Ungleichung\n\\[\\begin{equation}\n\\exp(x) \\ge 2 \\Leftrightarrow x \\ge \\ln(2).\n\\end{equation}\\]\n\nDamit ausgestattet wollen wir nun folgendes Theorem mithilfe eines direkten Beweises, eines indirekten Beweises und eines Beweises durch Widerspruch beweisen (vgl. Arens et al. (2018)).\n\nTheorem 1.2 (Quadrate positiver Zahlen) Es seien \\(a\\) und \\(b\\) zwei positive Zahlen. Dann gilt \\(a^2 &lt; b^2 \\Rightarrow a &lt; b\\).\n\n\nBeweis. Wir geben zunächst einen direkten Beweis. Dazu sei \\(a^2 &lt; b^2\\) die Aussage \\(A\\) und \\(a &lt; b\\) die Aussage \\(B\\). Dann gilt \\[\\begin{equation}\na^2 &lt; b^2\n\\Leftrightarrow 0 &lt; b^2 - a^2\n\\Leftrightarrow 0 &lt; (b+a)(b-a)\n\\Leftrightarrow 0 &lt; (b-a)\n\\Leftrightarrow a &lt; b.\n\\end{equation}\\] Wir geben nun einen indirekten Beweis. Es sei \\(a^2 \\ge b^2\\) die Aussage \\(\\neg A\\). Weiterhin sei \\(a \\ge b\\) die Aussage \\(\\neg B\\). Dann gilt \\[\\begin{equation}\na \\ge b\n\\Leftrightarrow a^2 \\ge ab \\land ab \\ge b^2\n\\Leftrightarrow a^2 \\ge b^2.\n\\end{equation}\\] Schließlich geben wir einen Beweis durch Widerspruch. Wir zeigen, dazu, dass die Annahme \\((\\neg B) \\land A\\) auf eine falsche Aussage führt. Es gilt \\[\\begin{equation}\na \\ge b \\land a^2 &lt; b^2 \\Leftrightarrow  a^2  \\ge ab \\land a^2 &lt; b^2   \\Leftrightarrow ab \\le a^2 &lt; b^2.\n\\end{equation}\\] Weiterhin gilt \\[\\begin{equation}\na \\ge b \\land a^2 &lt; b^2 \\Leftrightarrow  ab  \\ge b^2 \\land a^2 &lt; b^2   \\Leftrightarrow a^2 &lt; b^2 \\le ab.\n\\end{equation}\\] Insgesamt gilt dann also die falsche Aussage \\[\\begin{equation}\nab \\le a^2 &lt; b^2 \\le ab \\Leftrightarrow ab &lt; ab.\n\\end{equation}\\]"
  },
  {
    "objectID": "101-Sprache-und-Logik.html#sec-selbstkontrollfragen-sprache-und-logik",
    "href": "101-Sprache-und-Logik.html#sec-selbstkontrollfragen-sprache-und-logik",
    "title": "1  Sprache und Logik",
    "section": "1.5 Selbstkontrollfragen",
    "text": "1.5 Selbstkontrollfragen\n\nErläutern Sie die Besonderheiten der mathematischen Sprache.\nWas sind wesentliche Tätigkeiten zum Erlernen einer Sprache?\nErläutern Sie den Begriff der Definition.\nErläutern Sie den Begriff des Theorems.\nErläutern Sie den Begriff des Beweises.\nGeben Sie die Definition einer mathematischen Aussage wieder.\nGeben Sie die Definition der Negation einer mathematischen Aussage wieder.\nGeben Sie die Definition der Konjunktion zweier mathematischer Aussagen wieder.\nGeben Sie die Definition der Disjunktion zweier mathematischer Aussagen wieder.\nGeben Sie die Definition der Implikation wieder.\nGeben Sie die Definition der Äquivalenz wieder.\nGeben Sie die Definition der logischen Äquivalenz wieder.\nErläutern Sie die Begriffe des direkten Beweises, des indirekten Beweises und des Beweises durch Widerspruch.\n\n\n\n\n\nArens, T., Hettlich, F., Karpfinger, C., Kockelkorn, U., Lichtenegger, K., & Stachel, H. (2018). Mathematik. Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-56741-8\n\n\nBlei, D. M., Kucukelbir, A., & McAuliffe, J. D. (2017). Variational Inference: A Review for Statisticians. Journal of the American Statistical Association, 112(518), 859–877. https://doi.org/10.1080/01621459.2017.1285773\n\n\nFriston, K. (2005). A Theory of Cortical Responses. Philosophical Transactions of the Royal Society B: Biological Sciences, 360(1456), 815–836. https://doi.org/10.1098/rstb.2005.1622\n\n\nFriston, K., Da Costa, L., Sakthivadivel, D. A. R., Heins, C., Pavliotis, G. A., Ramstead, M., & Parr, T. (2023). Path Integrals, Particular Kinds, and Strange Things. Physics of Life Reviews, 47, 35–62. https://doi.org/10.1016/j.plrev.2023.08.016\n\n\nNewton, I. (1687). Philosophiae Naturalis Principia Mathematica. Royal Society.\n\n\nOstwald, D., Kirilina, E., Starke, L., & Blankenburg, F. (2014). A Tutorial on Variational Bayes for Latent Linear Stochastic Time-Series Models. Journal of Mathematical Psychology, 60, 1–19. https://doi.org/10.1016/j.jmp.2014.04.003\n\n\nUnger, L. (2000). Grundkurs Mathematik."
  },
  {
    "objectID": "102-Mengen.html#grundlegende-definitionen",
    "href": "102-Mengen.html#grundlegende-definitionen",
    "title": "2  Mengen",
    "section": "2.1 Grundlegende Definitionen",
    "text": "2.1 Grundlegende Definitionen\nMengen fassen mathematische Objekte wie beispielsweise Zahlen zusammen und bilden die Grundlage der modernen Mathematik. Wir beginnen mit folgender Definition.\n\nDefinition 2.1 (Mengen) Nach Cantor (1895) ist eine Menge definiert als “eine Zusammenfassung \\(M\\) von bestimmten wohlunterschiedenen Objekten \\(m\\) unsere Anschauung oder unseres Denken (welche die Elemente der Menge genannt werden) zu einem Ganzen”. Wir schreiben \\[\\begin{equation}\nm \\in M \\mbox{ bzw. } m \\notin M\n\\end{equation}\\] um auszudrücken, dass \\(m\\) ein Element bzw. kein Element von \\(M\\) ist.\n\nZur Definition von Mengen gibt es mindestens folgende Möglichkeiten:\n\nAuflisten der Elemente in geschweiften Klammern, z.B. \\(M := \\{1,2,3\\}\\).\nAngabe der Eigenschaften der Elemente, z.B. \\(M := \\{x \\in \\mathbb{N}|x &lt; 4\\}\\).\nGleichsetzen mit einer anderen eindeutig definieren Menge, z.B. \\(M := \\mathbb{N}_3\\).\n\nDie Schreibweise \\(\\{x \\in \\mathbb{N}|x &lt; 4\\}\\) wird gelesen als “\\(x \\in \\mathbb{N}\\), für die gilt, dass \\(x &lt; 4\\) ist”, wobei die Bedeutung von \\(\\mathbb{N}\\) im Folgenden noch zu erläutern sein wird. Es ist wichtig zu erkennen, dass Mengen ungeordnete mathematische Objekte sind, dass heißt die Reihenfolge der Auflistung der Elemente einer Menge spielt keine Rolle. Zum Beispiel bezeichnen \\(\\{1,2,3\\}\\), \\(\\{1,3,2\\}\\) und \\(\\{2,3,1\\}\\) dieselbe Menge, nämlich die Menge der ersten drei natürlichen Zahlen.\nGrundlegende Beziehungen zwischen mehreren Mengen werden in der nächsten Definition festgelegt.\n\nDefinition 2.2 (Teilmengen und Mengengleichheit) \\(A\\) und \\(B\\) seien zwei Mengen.\n\nEine Menge \\(A\\) heißt Teilmenge einer Menge \\(B\\), wenn für jedes Element \\(a \\in A\\) gilt, dass auch \\(a\\in B\\). Ist \\(A\\) eine Teilmenge von \\(B\\), so schreibt man \\[\\begin{equation}\nA \\subseteq B\n\\end{equation}\\] und nennt \\(A\\) Untermenge von \\(B\\) und \\(B\\) Obermenge von \\(A\\).\nEine Menge \\(A\\) heißt echte Teilmenge einer Menge \\(B\\), wenn für jedes Element \\(a \\in A\\) gilt, dass auch \\(a\\in B\\), es aber zumindest ein Element \\(b \\in B\\) gibt, für das gilt \\(b \\notin A\\). Ist \\(A\\) eine echte Teilmenge von \\(B\\), so schreibt man \\[\\begin{equation}\nA \\subset B.\n\\end{equation}\\]\nZwei Mengen \\(A\\) und \\(B\\) heißen gleich, wenn für jedes Element \\(a \\in A\\) gilt, dass auch \\(a \\in B\\), und wenn für jedes Element \\(b \\in B\\) gilt, dass auch \\(b \\in A\\). Sind die Mengen \\(A\\) und \\(B\\) gleich, so schreibt man \\[\\begin{equation}\nA = B.\n\\end{equation}\\]\n\n\nBetrachten wir zum Beispiel die Mengen \\(A := \\{1\\}\\), \\(B := \\{1,2\\}\\), und \\(C := \\{1,2\\}\\). Dann gilt mit obigen Definitionen, dass \\(A \\subset B\\), weil \\(1 \\in A\\) und \\(1 \\in B\\), aber \\(2 \\in B\\) und \\(2 \\notin A\\). Weiterhin gilt, dass \\(B \\subseteq C\\), weil \\(1 \\in B\\) und \\(1 \\in C\\) sowie \\(2 \\in B\\) und \\(2 \\in C\\) und es kein Element von \\(C\\) gibt, welches nicht in \\(B\\) ist. Ebenso gilt \\(C \\subseteq B\\), weil \\(1 \\in C\\) und \\(1 \\in B\\) sowie \\(2 \\in C\\) und \\(2 \\in B\\) und es kein Element von \\(B\\) gibt, welches nicht in \\(C\\) ist. Schließlich gilt sogar \\(B = C\\), weil für jedes Element \\(b \\in B\\) gilt, dass auch \\(b \\in C\\), und gleichzeitig für jedes Element \\(c \\in C\\) gilt, dass auch \\(c\\in B\\).\nEine wichtige Eigenschaft einer Menge ist die Anzahl der in ihr enthaltenen Elemente. Diese wird als Kardinalität der Menge bezeichnet.\n\nDefinition 2.3 (Kardinalität) Die Anzahl der Elemente einer Menge \\(M\\) heißt Kardinalität und wird mit \\(|M|\\) bezeichnet.\n\nEine besondere Menge ist die Menge ohne Elemente.\n\nDefinition 2.4 Eine Menge mit Kardinalität Null heißt leere Menge und wird mit \\(\\emptyset\\) bezeichnet.\n\nAls Beispiele seien \\(A := \\{1,2,3\\}\\), \\(B = \\{a,b,c,d\\}\\) und \\(C := \\{\\,\\}\\). Dann gelten \\(|A| = 3\\), \\(B = 4\\) und \\(|C| = 0\\).\nZu jeder Menge kann man die Menge aller Teilmengen dieser Menge betrachten. Dies führt auf den wichtigen Begriff der Potenzmenge.\n\nDefinition 2.5 (Potenzmenge) Die Menge aller Teilmengen einer Menge \\(M\\) heißt Potenzmenge von \\(M\\) und wird mit \\(\\mathcal{P}(M)\\) bezeichnet.\n\nMan beachte, dass die leere Untermenge von \\(M\\) und \\(M\\) selbst auch immer Elemente von \\(\\mathcal{P}(M)\\) sind. Wir betrachten vier Beispiele zum Begriff der Potenzmenge.\n\n\\(M_0 := \\emptyset\\) sei die leere Menge. Dann gilt \\[\\begin{equation}\n\\mathcal{P}(M_0) = \\emptyset.\n\\end{equation}\\]\n\\(M_1\\) sei die einelementige Menge \\(M_1 := \\{a\\}\\). Dann gilt \\[\\begin{equation}\n\\mathcal{P}(M_1) = \\{\\emptyset,\\{a\\}\\}.\n\\end{equation}\\]\nEs sei \\(M_2 := \\{a,b\\}\\). Dann hat \\(M_2\\) sowohl ein- als auch zweielementige Teilmengen und es gilt \\[\\begin{equation}\n\\mathcal{P}(M_2) = \\{\\emptyset,\\{a\\}\\, \\{b\\}, \\{a,b\\}\\}.\n\\end{equation}\\]\nSchließlich sei \\(M_3 := \\{a,b,c\\}\\). Dann hat \\(M\\) ein-, zwei-, als auch dreielementige Teilmengen und es gilt \\[\\begin{equation}\n\\mathcal{P}(M_3) = \\{\\emptyset, \\{a\\},\\{b\\},\\{c\\},\\{a,b\\},\\{a,c\\},\\{b,c\\},\\{a,b,c\\}\\}.\n\\end{equation}\\]\n\nHinsichtlich der Kardinalitäten einer Menge und ihrer Potenzmenge kann man beweisen, dass aus \\(|M| = n\\) mit \\(n&gt;0\\) folgt, dass die Kardinalität der Potenzmenge \\(|\\mathcal{P}(M)| = 2^n\\) ist. In den obigen Beispielen haben wir die Fälle \\(|M_1| = 1\\) und somit \\(|\\mathcal{P}(M_1)| = 2^1 = 2\\), \\(|M_2| = 2\\) und somit \\(|\\mathcal{P}(M_3)| = 2^2 = 4\\) und schließlich \\(|M_3| = 3\\) und somit \\(|\\mathcal{P}(M_3)| = 2^3 = 8\\), wovon man sich durch Nachzählen schnell überzeugt."
  },
  {
    "objectID": "102-Mengen.html#sec-verknuepfung-von-mengen",
    "href": "102-Mengen.html#sec-verknuepfung-von-mengen",
    "title": "2  Mengen",
    "section": "2.2 Verknüpfungen von Mengen",
    "text": "2.2 Verknüpfungen von Mengen\nZwei Mengen können auf unterschiedliche Weise miteinander verknüpft werden. Das Ergebnis einer solchen Verknüpfung ist eine weitere Menge. Wir bezeichnen die Verknüpfung zweier Mengen als Mengenoperation und geben folgende Definitionen.\n\nDefinition 2.6 (Mengenoperationen) \\(M\\) und \\(N\\) seien zwei Mengen.\n\nDie Vereinigung von \\(M\\) und \\(N\\) ist definiert als die Menge \\[\\begin{equation}\nM \\cup N := \\{x | x \\in M \\lor x \\in N\\},\n\\end{equation}\\] wobei \\(\\lor\\) wie immer im inklusiven Sinne als und/oder zu verstehen ist.\nDer Durchschnitt von \\(M\\) und \\(N\\) ist definiert als die Menge \\[\\begin{equation}\nM \\cap N := \\{x | x \\in M \\land x \\in N\\}.\n\\end{equation}\\] Wenn für \\(M\\) und \\(N\\) gilt, dass \\(M \\cap N= \\emptyset\\), dann heißen \\(M\\) und \\(N\\) disjunkt.\nDie Differenz von \\(M\\) und \\(N\\) ist definiert als die Menge \\[\\begin{equation}\nM\\setminus N := \\{x | x \\in M \\land x \\notin N\\}.\n\\end{equation}\\] Die Differenz \\(M\\) und \\(N\\) heißt, insbesondere bei \\(M \\subseteq N\\), auch das Komplement von \\(N\\) bezüglich \\(M\\) und wird mit \\(N^c\\) bezeichnet.\nDie symmetrische Differenz von \\(M\\) und \\(N\\) ist definiert als die Menge \\[\\begin{equation}\nM \\Delta N := \\{x|(x \\in M \\lor x \\in N ) \\land x \\notin M \\cap N\\},\n\\end{equation}\\] Die symmetrische Differenz kann also als exklusives oder verstanden werden.\n\n\nAls Beispiel betrachten wir die Mengen \\(M := \\{1,2,3\\}\\)und \\(N := \\{2,3,4,5\\}\\). Dann gelten\n\n\\(M \\cup N = \\{1,2,3,4,5\\}\\), weil \\(1 \\in M\\), \\(2 \\in M\\), \\(3 \\in M\\), \\(4 \\in N\\) und \\(5 \\in N\\).\n\\(M \\cap N = \\{2,3\\}\\), weil nur für \\(2\\) und \\(3\\) gilt, dass \\(2\\in M, 3 \\in M\\) und auch \\(2\\in N, 3 \\in N\\). Für \\(1\\) gilt lediglich, dass \\(1 \\in M\\) und für \\(4\\) und \\(5\\) gelten lediglich, dass \\(4 \\in N\\) und \\(5 \\in N\\).\n\\(M \\setminus N = \\{1\\}\\), weil \\(1 \\in M\\), aber \\(1 \\notin N\\) und \\(2 \\in M\\), aber auch \\(2 \\in N\\).\n\\(N \\setminus M = \\{4,5\\}\\), weil \\(2 \\in N\\) und \\(3 \\in N\\), aber auch \\(2\\in M\\) und \\(3 \\in M\\). Dies zeigt insbesondere, dass die Differenz von \\(M\\) Und \\(N\\) nicht symmetrisch ist, also dass nicht zwangsläufig gilt, dass \\(M\\setminus N\\) gleich \\(N \\setminus M\\) ist.\n\\(M \\Delta N = \\{1,4,5\\}\\), weil \\(1 \\in M\\), aber \\(1 \\notin \\{2,3\\}\\), \\(2 \\in M\\), aber \\(2 \\in \\{2,3\\}\\), \\(3 \\in M\\), aber \\(3 \\in \\{2,3\\}\\), \\(4 \\in N\\), aber \\(4 \\notin \\{2,3\\}\\) und \\(5 \\in N\\), aber \\(5 \\notin \\{2,3\\}\\).\n\nSchließlich wollen wir noch den Begriff der Partition einer Menge einführen.\n\nDefinition 2.7 (Partition) \\(M\\) sei eine Menge und \\(P := \\{N_i\\}\\) sei eine Menge von Mengen \\(N_i\\) mit \\(i = 1,...,n\\), so dass gilt \\[\\begin{equation}\nM = \\cup_{i=1}^n N_i \\land N_i \\cap N_j = \\emptyset \\mbox{ für } i = 1,...,n, j = 1,...,n, i \\neq j.\n\\end{equation}\\] Dann heißt \\(P\\) eine .\n\nIntuitiv entspricht die Partition einer Menge also dem Aufteilen der Menge in disjunkte Teilmengen. Partitionen sind generell nicht eindeutig, d.h. es gibt meist verschiedene Möglichkeiten eine gegebene Menge zu partitionieren. Betrachten wir zum Beispiel die Menge \\(M := \\{1,2,3,4,5,6\\}\\). Dann sind \\(P_1 := \\{\\{1\\}, \\{2,3,4,5,6\\}\\}\\), \\(P_2 := \\{\\{1,2,3\\}, \\{4,5,6\\}\\}\\) und \\(P_3 := \\{\\{1,2\\},\\{3,4\\}, \\{5,6\\}\\}\\) drei mögliche Partitionen von \\(M\\)."
  },
  {
    "objectID": "102-Mengen.html#spezielle-mengen",
    "href": "102-Mengen.html#spezielle-mengen",
    "title": "2  Mengen",
    "section": "2.3 Spezielle Mengen",
    "text": "2.3 Spezielle Mengen\nIn der Naturwissenschaft versucht man, Phänomene der Welt mit Zahlen zu beschreiben. Je nach Phänomen bieten sich dazu diskrete oder kontinuierliche Zahlenmengen an. Die Mathematik stellt dazu unter anderem die in folgender Definition gegebenen Zahlenmengen bereit.\n\nDefinition 2.8 (Zahlenmengen) Es bezeichnen\n\n\\(\\mathbb{N}\\,\\,\\, := \\{1,2,3,...\\}\\) die natürlichen Zahlen,\n\\(\\mathbb{N}_n := \\{1,2,3,...,n\\}\\) die natürlichen Zahlen der Ordnung \\(n\\),\n\\(\\mathbb{N}^0 := \\mathbb{N} \\cup \\{0\\}\\) die natürlichen Zahlen und Null,\n\\(\\mathbb{Z}\\,\\,\\, := \\{...,-3,-2,-1,0,1,2,3...\\}\\) die ganzen Zahlen,\n\\(\\mathbb{Q}\\,\\,\\, := \\{\\frac{p}{q}|p,q \\in \\mathbb{Z}, q \\neq 0\\}\\) die rationalen Zahlen,\n\\(\\mathbb{R}\\,\\,\\,\\) die reellen Zahlen, und\n\\(\\mathbb{C}\\,\\,\\, := \\{a + ib|a,b\\in \\mathbb{R}, i := \\sqrt{-1} \\}\\) die komplexen Zahlen.\n\n\nDie natürlichen und ganzen Zahlen eignen sich insbesondere zum Quantifizieren diskreter Phänomene. Die rationalen und insbesondere die reellen Zahlen eignen sich zum Quantifizieren kontinuierlicher Phänomene. \\(\\mathbb{R}\\) umfasst dabei die rationalen Zahlen und die sogenannten irrationalen Zahlen \\(\\mathbb{R}\\setminus \\mathbb{Q}\\). Rationale Zahlen sind Zahlen, die sich, wie oben definiert, durch Brüche ganzer Zahlen ausdrücken lassen. Dies sind alle ganzen Zahlen sowie die negativen und positiven Dezimalzahlen wie z.B. \\(-\\frac{9}{10} = -0.9\\), \\(\\frac{1}{3} = 1.3\\bar{3}\\), und \\(\\frac{196}{100} = 1.96\\). Irrationale Zahlen sind Zahlen, die sich nicht als rationale Zahlen ausdrücken lassen. Beispiele für irrationale Zahlen sind die Eulersche Zahl \\(e \\approx 2.71\\), die Kreiszahl \\(\\pi \\approx 3.14\\) und die Quadratwurzel von \\(2\\), \\(\\sqrt{2} \\approx 1.41\\).\nDie reellen Zahlen enthalten als Teilmengen die natürlichen, ganzen, und die rationalen Zahlen. Es gibt also sehr viele reelle Zahlen. Tatsächlich kann man beweisen (Cantor (1892)), dass es mehr reelle Zahlen als natürliche Zahlen gibt, obwohl es sowohl unendlich viele reelle Zahlen als auch unendlich viele natürliche Zahlen gibt. Diese Eigenschaft der reellen Zahlen bezeichnet man als die Überabzählbarkeit der reellen Zahlen. Insbesondere gilt \\[\\begin{equation}\n\\mathbb{N} \\subset \\mathbb{Z} \\subset \\mathbb{Q} \\subset \\mathbb{R}.\n\\end{equation}\\] Zwischen zwei reellen Zahlen gibt es unendlich viele weitere reelle Zahlen. Positiv-Unendlich (\\(\\infty\\)) und Negativ-Unendlich (\\(-\\infty\\)) sind keine Zahlen, mit denen in der Standardmathematik gerechnet werden kann. Sie gehören auch nicht zu den in obiger Definition gegebenen Zahlenmengen, es gilt also sowohl \\(\\infty \\notin \\mathbb{R}\\) als auch \\(-\\infty \\notin \\mathbb{R}\\).\nKomplexe Zahlen eignen sich zur Beschreibung zweidimensionaler kontinuierlicher Phänomene. Dabei werden die Werte der ersten Dimension im reellen Teil \\(a\\) und die Werte der zweiten Dimension im komplexen Teil \\(b\\) einer komplexen Zahl repräsentiert. Komplexe Zahlen kommen insbesondere bei der Modellierung physikalischer Phänomene und im Bereich der Fourieranalyse zum Einsatz. Wir vertiefen die Theorie komplexer Zahlen an dieser Stelle nicht.\nWichtige Teilmengen der reellen Zahlen sind die sogenannten Intervalle. Wir geben folgende Definitionen.\n\nDefinition 2.9 Zusammenhängende Teilmengen der reellen Zahlen heißen Intervalle. Für \\(a,b\\in \\mathbb{R}\\) unterscheidet man\n\ndas abgeschlossene Intervall \\[\\begin{equation}\n[a,b] := \\{x \\in \\mathbb{R}|a \\le x \\le b\\},\n\\end{equation}\\]\ndas offene Interval \\[\\begin{equation}\n]a,b[ := \\{x \\in \\mathbb{R}|a &lt; x &lt; b\\},\n\\end{equation}\\]\nund die halboffenen Intervalle \\[\\begin{equation}\n]a,b] := \\{x \\in \\mathbb{R}| a &lt; x \\le b\\} \\mbox{ und }\n[a,b[ := \\{x \\in \\mathbb{R}| a \\le x &lt; b\\}.\n\\end{equation}\\]\n\n\nWie oben erwähnt sind Positiv-Unendlich (\\(\\infty\\)) und Negativ-Unendlich (\\(-\\infty\\)) keine Elemente von \\(\\mathbb{R}\\). Es gilt also immer \\(]-\\infty,b]\\) oder \\(]-\\infty,b[\\) bzw. \\(]a,\\infty[\\) oder \\([a,\\infty[\\), sowie \\(\\mathbb{R} = ]-\\infty, \\infty[\\).\nOft möchte man mehrere Eigenschaften eines Phänomens gleichzeitig quantitativ beschreiben. Zu diesem Zweck können die oben definierten eindimensionalen Zahlenmenge durch Bildung Kartesischer Produkte auf mehrdimensionale Zahlenmengen erweitert werden. Die Elemente Kartesischer Produkte nennt man geordnete Tupel oder auch Vektoren.\n\nDefinition 2.10 (Kartesische Produkte) \\(M\\) und \\(N\\) seien zwei Mengen. Dann ist das Kartesische Produkt der Mengen \\(M\\) und \\(N\\) die Menge aller geordneten Tupel \\((m,n)\\) mit \\(m \\in M\\) und \\(n \\in N\\), formal \\[\\begin{equation}\nM \\times N := \\{(m,n)|m\\in M, n \\in N \\}.\n\\end{equation}\\]\nDas Kartesische Produkt einer Menge \\(M\\) mit sich selbst wird bezeichnet mit \\[\\begin{equation}\nM^2 := M \\times M.\n\\end{equation}\\] Seien weiterhin \\(M_1, M_2, ..., M_n\\) Mengen. Dann ist das Kartesische Produkt der Mengen \\(M_1,...,M_n\\) die Menge aller geordneten \\(n\\)-Tupel \\((m_1,...,m_n)\\) mit \\(m_i \\in M_i\\) für \\(i = 1,...,n\\), formal \\[\\begin{equation}\n\\prod_{i=1}^n M_i := M_1 \\times \\cdots \\times M_n := \\{(m_1,...,m_n)\n                |m_i \\in M_i \\mbox{ für } i = 1,...,n\\}.\n\\end{equation}\\] Das \\(n\\)-fache Kartesische Produkt einer Menge \\(M\\) mit sich selbst wird bezeichnet mit \\[\\begin{equation}\nM^n := \\prod_{i=1}^n M := \\{(m_1,,...,m_n)|m_i \\in M\\}.\n\\end{equation}\\]\n\nIm Gegensatz zu Mengen sind die in Definition 2.10 eingeführten Tupel geordnet. Das heißt, für Mengen gilt zum Beispiel \\(\\{1,2\\} = \\{2,1\\}\\), aber für Tupel gilt \\((1,2) \\neq (2,1)\\).\nWie oben beschrieben eignen sich insbesondere die reellen Zahlen zur Beschreibung kontinuierlicher Phänomene. Zur simultanen Beschreibung mehrere Aspekte eines kontinuierlichen Phänomens bietet sich entsprechend die Menge der reellen Tupel \\(n\\)-ter Ordnung an.\n\nDefinition 2.11 (Menge der reellen Tupel \\(n\\)-ter Ordnung) Das \\(n\\)-fache Kartesische Produkt der reellen Zahlen mit sich selbst wird bezeichnet mit \\[\\begin{equation}\n\\mathbb{R}^n := \\prod_{i=1}^n \\mathbb{R} := \\{x := (x_1,,...,x_n)|x_i \\in \\mathbb{R}\\}\n\\end{equation}\\] und wird “\\(\\mathbb{R}\\) hoch \\(n\\)” gesprochen. Wir schreiben die Elemente von \\(\\mathbb{R}^n\\) als Spalten \\[\\begin{equation}\nx :=\n\\begin{pmatrix}\nx_1\n\\\\\n\\vdots\n\\\\\nx_n\n\\end{pmatrix}\n\\end{equation}\\] und nennen sie \\(n\\)-dimensionale Vektoren. Zu Abgrenzung nennen wir die Elemente von \\(\\mathbb{R}^1 = \\mathbb{R}\\) auch Skalare.\n\nEin Beispiel für \\(x \\in \\mathbb{R}^4\\) ist \\[\\begin{equation}\nx = \\begin{pmatrix} 0.16 \\\\ 1.76 \\\\ 0.23 \\\\ 7.11 \\end{pmatrix}.\n\\end{equation}\\]"
  },
  {
    "objectID": "102-Mengen.html#sec-selbstkontrollfragen-mengen",
    "href": "102-Mengen.html#sec-selbstkontrollfragen-mengen",
    "title": "2  Mengen",
    "section": "2.4 Selbstkontrollfragen",
    "text": "2.4 Selbstkontrollfragen\n\nGeben Sie die Definition einer Menge nach Cantor (1895) wieder.\nNennen Sie drei Möglichkeiten zur Definition einer Menge.\nErläutern Sie die Ausdrücke \\(m \\in M, m \\notin N, M \\subseteq N, M \\subset N\\) für zwei Mengen \\(M\\) und \\(N\\).\nGeben Sie die Definition der Kardinalität einer Menge wieder.\nGeben Sie die Definition der Potenzmenge einer Menge wieder.\nEs sei \\(M := \\{1,2\\}\\). Bestimmen Sie \\(\\mathcal{P}(M)\\).\nEs seien \\(M := \\{1,2\\}, N := \\{1,4,5\\}\\). Bestimmen Sie \\(M \\cup N, M \\cap N, M\\setminus N, M \\Delta N\\).\nErläutern Sie die Symbole \\(\\mathbb{N}\\), \\(\\mathbb{N}_n\\), und \\(\\mathbb{N}^0\\).\nErläutern Sie die Unterschiede zwischen \\(\\mathbb{N}\\) und \\(\\mathbb{Z}\\) und zwischen \\(\\mathbb{R}\\) und \\(\\mathbb{Q}\\).\nGeben Sie die Definition abgeschlossener, offener, und halboffener Intervalle wieder.\nEs seien \\(M\\) und \\(N\\) Mengen. Erläutern Sie die Notation \\(M \\times N\\).\nGeben Sie die Definition von \\(\\mathbb{R}^n\\) wieder.\n\n\n\n\n\nCantor, G. (1892). Über Eine Eigenschaft Des Inbegriffes Aller Reellen Algebraischen Zahlen. Jahresbericht der Deutschen Mathematiker-Vereinigung, 1.\n\n\nCantor, G. (1895). Beiträge Zur Begründung Der Transfiniten Mengenlehre. Mathematische Annalen, 46(4), 481–512. https://doi.org/10.1007/BF02124929"
  },
  {
    "objectID": "103-Summen-Produkte-Potenzen.html#sec-summen",
    "href": "103-Summen-Produkte-Potenzen.html#sec-summen",
    "title": "3  Summen, Produkte, Potenzen",
    "section": "3.1 Summen",
    "text": "3.1 Summen\nDiese Einheit führt einige Schreibweisen für die Grundrechenarten ein.\n\nDefinition 3.1 (Summenzeichen) Es bezeichnet \\[\\begin{equation}\n\\sum_{i=1}^{n} x_i = x_1 + x_{2} + \\cdots + x_{n}.\n\\end{equation}\\] Dabei stehen\n\n\\(\\Sigma\\) für das griechische Sigma, mnemonisch fürSumme,\ndas Subskript \\(i = 1\\) für den Laufindex und den Startindex,\ndas Superskript \\(n\\) für den Endindex und\n\\(x_1, x_2, ..., x_n\\) für die Summanden.\n\n\nFür die sinnvolle Benutzung des Summenzeichens ist es essentiell, dass mit mithilfe des Subskripts und des Superskripts Anfang und Ende der Summation festgelegt werden. Die genaue Bezeichnung des Laufindexes ist dagegen für den Wert der Summe irrelevant, es gilt \\[\\begin{equation}\n\\sum_{i=1}^n x_i = \\sum_{j=1}^n x_j.\n\\end{equation}\\] Manchmal wird der Laufindex auch als Element einer Indexmenge angegeben. Ist z.B. die Indexmenge \\(I := \\{1,5,7\\}\\) definiert, so ist \\[\\begin{equation}\n\\sum_{i \\in I}x_i := x_1 + x_5 + x_7.\n\\end{equation}\\] Im Folgenden wollen wir kurz einige Beispiele für die Benutzung des Summenzeichens betrachten.\n\nSummation vordefinierter Summanden. Es seien \\(x_1 := 2\\), \\(x_2 := 10\\), \\(x_3 := -4\\). Dann gilt \\[\\begin{equation}\n\\sum_{i=1}^3 x_i = x_1 + x_2 + x_3 = 2 + 10 - 4 = 8.\n\\end{equation}\\]\nSummation natürlicher Zahlen. Es gilt \\[\\begin{equation}\n\\sum_{i=1}^5 i = 1 + 2 + 3 + 4 + 5 = 15.  \n\\end{equation}\\]\nSummation gerader natürlicher Zahlen. Es gilt \\[\\begin{equation}\n\\sum_{i=1}^5 2i = 2\\cdot 1  + 2\\cdot 2 + 2\\cdot 3 + 2\\cdot 4 + 2\\cdot 5 = 2 + 4 + 6 + 8 + 10 = 30.\n\\end{equation}\\]\nSummation ungerader natürlicher Zahlen. Es gilt \\[\\begin{equation}\n\\sum_{i=1}^5 (2i - 1) = 2\\cdot 1 - 1  + 2\\cdot 2 - 1 + 2\\cdot 3 - 1 + 2\\cdot 4 - 1 + 2\\cdot 5 - 1 = 1 + 3 + 5 + 7 + 9 = 25.\n\\end{equation}\\]\n\nDer Umgang mit dem Summenzeichen wird oft durch die Anwendung folgender Rechenregeln vereinfacht.\n\nTheorem 3.1 (Rechenregeln für Summen)  \n\nSummen gleicher Summanden \\[\\begin{equation}\n\\sum_{i=1}^n x = nx\n\\end{equation}\\]\nAssoziativität bei Summen gleicher Länge \\[\\begin{equation}\n\\sum_{i=1}^n x_i + \\sum_{i=1}^n y_i = \\sum_{i=1}^n (x_i + y_i)\n\\end{equation}\\]\nDistributivität bei Multiplikation mit einer Konstante \\[\\begin{equation}\n\\sum_{i=1}^n ax_i = a\\sum_{i=1}^n x_i\n\\end{equation}\\]\nAufspalten von Summen mit \\(1 &lt; m &lt; n\\) \\[\\begin{equation}\n\\sum_{i = 1}^n x_i = \\sum_{i=1}^m x_i + \\sum_{i=m+1}^n x_i\n\\end{equation}\\]\nUmindizierung \\[\\begin{equation}\n\\sum_{i=0}^n x_i = \\sum_{j = m}^{n+m} x_{j - m}\n\\end{equation}\\]\n\n\n\nBeweis. Man überzeugt sich von diesen Rechenregeln durch Ausschreiben der Summen und Anwenden der Rechenregeln von Addition und Multiplikation. Wir zeigen hier exemplarisch die Assoziativität bei Summen gleicher Länge und die Distributivität bei Multiplikation mit einer Konstante. Hinsichtlich ersterer haben wir \\[\\begin{align}\n\\begin{split}\n\\sum_{i=1}^n x_i + \\sum_{i=1}^n y_i\n& = x_1 + x_2 + \\cdots + x_n +  y_1 + y_2 + \\cdots + y_n    \\\\\n& = x_1 + y_1 + x_2 + y_2 + \\cdots + x_n + y_n               \\\\\n& = \\sum_{i=1}^n (x_i + y_i).\n\\end{split}\n\\end{align}\\] Hinsichtlich letzterer gilt \\[\\begin{align}\n\\begin{split}\n\\sum_{i=1}^n ax_i\n& = ax_1 + ax_2 + \\cdots + ax_n                             \\\\\n& = a(x_1 + x_2 + \\cdots + x_n)                             \\\\\n& = a\\sum_{i=1}^n x_i.\n\\end{split}\n\\end{align}\\]\n\nAls Beispiel für die Anwendung einer Rechenregel betrachten wir die Auswertung eines Mittelwertes (manchmal auch Durchschnitt genannt). Dazu seien \\(x_1, x_2,...,x_n\\) reelle Zahlen. Der Mittelwert dieser Zahlen entspricht der Summe von \\(x_1, x_2,...,x_n\\) geteilt durch die Anzahl der Zahlen \\(n\\). Dabei ist es nach obiger Rechenregel (3) irrelevant, ob zunächst die Zahlen aufaddiert werden und dann die resultierende Summe durch \\(n\\) geteilt wird, oder die Zahlen jeweils einzeln durch \\(n\\) geteilt werden und die entsprechenden Ergebenisse dann aufaddiert werden. Genauer gilt durch Anwendung von Rechenregel (3) mit \\(a =1/n\\), dass \\[\\begin{equation}\n\\frac{1}{n}\\sum_{i=1}^n x_i = \\sum_{i=1}^n \\frac{x_i}{n}.\n\\end{equation}\\] So ist zum Beispiel der Mittelwert von \\(x_1 := 1, x_2 := 4, x_3 := 2\\) \\(x_4 := 1\\) gegeben durch \\[\\begin{equation}\n\\frac{1}{4}\\sum_{i=1}^4 x_i\n= \\frac{1}{4}(1 + 4 + 2 + 1)\n= \\frac{8}{4}\n= 2\n= \\frac{8}{4}\n= \\frac{1}{4} + \\frac{4}{4} + \\frac{2}{4} + \\frac{1}{4}\n= \\sum_{i=1}^4 \\frac{x_i}{4}.\n\\end{equation}\\]"
  },
  {
    "objectID": "103-Summen-Produkte-Potenzen.html#sec-produkte",
    "href": "103-Summen-Produkte-Potenzen.html#sec-produkte",
    "title": "3  Summen, Produkte, Potenzen",
    "section": "3.2 Produkte",
    "text": "3.2 Produkte\nEine analoge Schreibweise zum Summenzeichen bietet das Produktzeichen für Produkte.\n\nDefinition 3.2 (Produktzeichen) Es bezeichnet \\[\\begin{equation}\n\\prod_{i=1}^{n} x_i = x_1 \\cdot x_{2} \\cdot \\cdots \\cdot x_{n}.\n\\end{equation}\\] Dabei stehen\n\n\\(\\prod\\) für das griechische i, mnemonisch für Produkt,\ndas Subskript \\(i = 1\\) für den Laufindex und den Startindex,\ndas Superskript \\(n\\) für den Endindex,\n\\(x_1, x_2, ..., x_n\\) für die Produktterme\n\n\nAnalog zum Summenzeichen gilt, dass das Produktzeichen nur mit Subskript und Superskripten zu Lauf- und Endindex Sinn ergibt. Die genaue Bezeichnung des Laufindizes ist wiederum irrelevant, es gilt \\[\\begin{equation}\n\\prod_{i=1}^n x_i = \\prod_{j=1}^n x_j.\n\\end{equation}\\] Auch hier wird in seltenen Fällen der Laufindex als Element einer Indexmenge angegeben. Ist z.B. die Indexmenge \\(J := \\mathbb{N}_2^0\\) definiert, so ist \\[\\begin{equation}\n\\prod_{j \\in J}x_j := x_0 \\cdot x_1 \\cdot x_2.\n\\end{equation}\\]"
  },
  {
    "objectID": "103-Summen-Produkte-Potenzen.html#sec-potenzen",
    "href": "103-Summen-Produkte-Potenzen.html#sec-potenzen",
    "title": "3  Summen, Produkte, Potenzen",
    "section": "3.3 Potenzen",
    "text": "3.3 Potenzen\nProdukte von Zahlen mit sich selbst können mithilfe der Potenzschreibweise abgekürzt werden.\n\nDefinition 3.3 (Potenz) Für \\(a \\in \\mathbb{R}\\) und \\(n \\in \\mathbb{N}^0\\) ist die \\(n\\)-te Potenz von \\(a\\) definiert durch \\[\\begin{equation}\na^0 := 1 \\mbox{ und } a^{n+1} := a^n \\cdot a.\n\\end{equation}\\] Weiterhin ist für \\(a\\in \\mathbb{R} \\setminus 0\\) und \\(n \\in \\mathbb{N}^0\\) die negative \\(n\\)-te Potenz von \\(a\\) definiert durch \\[\\begin{equation}\na^{-n} := (a^n)^{-1} := \\frac{1}{a^n}.\n\\end{equation}\\] \\(a\\) wird dabei Basis und \\(n\\) wird Exponent genannt.\n\nDie Art der Definition von \\(a^{n+1}\\) mit Rückbezug auf die Potenz \\(a^n\\) in obiger Definition nennt man rekursiv. Die Definition \\(a^0 := 1\\) nennt man dabei den Rekursionsanfang; er macht die rekursive Definition von \\(a^{n+1}\\) erst möglich. Die Definition \\(a^{n+1} := a^n \\cdot a\\) nennt man auch Rekursionsschritt. Folgende Rechenregeln vereinfachen das Rechnen mit Potenzen.\n\nTheorem 3.2 (Rechenregeln für Potenzen) Für \\(a,b\\in \\mathbb{R}\\) und \\(n,m \\in \\mathbb{Z}\\) mit \\(a\\neq 0\\) bei negativen Exponenten gelten folgende Rechenregeln: \\[\\begin{align}\na^n a^m & = a^{n+m} \\\\\n(a^n)^m & = a^{nm}  \\\\\n(ab)^n  & = a^nb^n\n\\end{align}\\]\n\nWir verzichten auf einen Beweis. Beispielsweise gelten also \\[\\begin{equation}\n2^2 \\cdot 2^3 = (2\\cdot 2) \\cdot (2 \\cdot 2 \\cdot 2) = 2^5 = 2^{2 + 3},\n\\end{equation}\\] \\[\\begin{equation}\n(3^2)^3 = (3\\cdot 3)^3 = (3\\cdot 3)\\cdot(3\\cdot 3)\\cdot(3\\cdot 3)= 3^6 = 3^{2\\cdot3},\n\\end{equation}\\] und \\[\\begin{equation}\n(2 \\cdot 4)^2 = (2\\cdot 4)\\cdot (2 \\cdot 4) = (2 \\cdot 2)\\cdot(4\\cdot 4) = 2^2 \\cdot 4^2.\n\\end{equation}\\]\nIn enger Beziehung zur Potenz steht die Definition der \\(n\\)ten Wurzel:\n\nDefinition 3.4 (\\(n\\)-te Wurzel) Für \\(a \\in \\mathbb{R}\\) und \\(n \\in \\mathbb{N}\\) ist die \\(n\\)-te Wurzel von \\(a\\) definiert als die Zahl \\(r\\), so dass \\[\\begin{equation}\nr^n = a.\n\\end{equation}\\]\n\nBeim Rechnen mit Wurzeln ist die Potenzschreibweise von Wurzeln oft hilfreich, da sie die direkte Anwendung der Rechenregeln für Potenzen ermöglicht.\n\nTheorem 3.3 (Potenzschreibweise der \\(n\\)-ten Wurzel) Es sei \\(a \\in \\mathbb{R}\\), \\(n \\in \\mathbb{N}\\), und \\(r\\) die \\(n\\)-te Wurzel von \\(a\\). Dann gilt \\[\\begin{equation}\nr = a^{\\frac{1}{n}}\n\\end{equation}\\]\n\n\nBeweis. Es gilt \\[\\begin{equation}\n\\left(a^{\\frac{1}{n}}\\right)^n\n= a^{\\frac{1}{n}}\\cdot a^{\\frac{1}{n}}\\cdot \\cdots \\cdot a^{\\frac{1}{n}}\n= a^{\\sum_{i=1}^n \\frac{1}{n}}\n= a^1\n= a.\n\\end{equation}\\] Also gilt mit der Definition der \\(n\\)-ten Wurzel, dass \\(r = a^\\frac{1}{n}\\).\n\nDas Rechnen mit Quadratwurzeln wird durch die Potenzschreibweise \\(\\sqrt{x} = x^{\\frac{1}{2}}\\) sehr erleichtert. Zum Beispiel gilt \\[\\begin{equation}\n\\frac{2\\pi}{\\sqrt{2\\pi}}\n= \\frac{2\\pi}{(2\\pi)^{\\frac{1}{2}}}\n= (2\\pi)^{1} \\cdot (2\\pi)^{-\\frac{1}{2}}\n= (2\\pi)^{1-\\frac{1}{2}}\n= (2\\pi)^{\\frac{1}{2}}\n= \\sqrt{2\\pi}.\n\\end{equation}\\]"
  },
  {
    "objectID": "103-Summen-Produkte-Potenzen.html#sec-selbstkontrollfragen-summen-produkte-potenzen",
    "href": "103-Summen-Produkte-Potenzen.html#sec-selbstkontrollfragen-summen-produkte-potenzen",
    "title": "3  Summen, Produkte, Potenzen",
    "section": "3.4 Selbstkontrollfragen",
    "text": "3.4 Selbstkontrollfragen\n\nGeben Sie die Definition des Summenzeichens wieder.\nBerechnen Sie die Summen \\(\\sum_{i=1}^3 2\\), \\(\\sum_{i=1}^3 i^2\\), und \\(\\sum_{i=1}^3 \\frac{2}{3}i\\).\nSchreiben Sie die Summe \\(1 + 3 + 5 + 7 + 9 + 11\\) mithilfe des Summenzeichens.\nSchreiben Sie die Summe \\(0 + 2 + 4 + 6 + 8 + 10\\) mithilfe des Summenzeichens.\nGeben Sie die Definition des Produktzeichens wieder.\nGeben Sie die Definition der \\(n\\)-ten Potenz von \\(a \\in \\mathbb{R}\\) wieder.\nBerechnen Sie \\(2^2\\cdot 2^3\\) und \\(2^5\\) und geben Sie die zugehörige Potenzregel wieder.\nBerechnen Sie \\(6^2\\) und \\(2^2\\cdot 3^2\\) und geben Sie die zugehörige Potenzregel wieder.\nBegründen Sie, warum die \\(n\\)-te Wurzel von \\(a\\) als \\(a^{\\frac{1}{n}}\\) geschrieben werden kann.\nBerechnen Sie \\((\\sqrt{2})^{\\frac{2}{3}}, 9^{\\frac{1}{2}}\\), und \\(4^{-\\frac{1}{2}}\\)."
  },
  {
    "objectID": "104-Funktionen.html#definition-und-eigenschaften",
    "href": "104-Funktionen.html#definition-und-eigenschaften",
    "title": "4  Funktionen",
    "section": "4.1 Definition und Eigenschaften",
    "text": "4.1 Definition und Eigenschaften\n\nDefinition 4.1 (Funktion) Eine Funktion oder Abbildung \\(f\\) ist eine Zuordnungsvorschrift, die jedem Element einer Menge \\(D\\) genau ein Element einer Zielmenge \\(Z\\) zuordnet. \\(D\\) wird dabei Definitionsmenge von \\(f\\) und \\(Z\\) wird Zielmenge von \\(f\\) genannt. Wir schreiben \\[\\begin{equation}\nf : D \\to Z, x \\mapsto f(x),\n\\end{equation}\\] wobei \\(f : D \\to Z\\) gelesen wird als “die Funktion \\(f\\) bildet alle Elemente der Menge \\(D\\) eindeutig auf Elemente in \\(Z\\) ab” und \\(x \\mapsto f(x)\\) gelesen wird als “\\(x\\), welches ein Element von \\(D\\) ist, wird durch die Funktion \\(f\\) auf \\(f(x)\\) abgebildet, wobei \\(f(x)\\) ein Element von \\(Z\\) ist”. Der Pfeil \\(\\to\\) steht für die Abbildung zwischen den Mengen \\(D\\) und \\(Z\\), der Pfeil \\(\\mapsto\\) steht für die Abbildung zwischen einem Element von \\(D\\) und einem Element von \\(Z\\).\n\nEs ist zentral, zwischen der Funktion \\(f\\) als Zuordnungsvorschrift und einem Wert der Funktion \\(f(x)\\) als Element von \\(Z\\) zu unterscheiden. \\(x\\) ist das Argument der Funktion (der Input der Funktion), \\(f(x)\\) der Wert, den die Funktion \\(f\\) für das Argument \\(x\\) annimmt (der Output der Funktion). Üblicherweise folgt in der Definition einer Funktion \\(f(x)\\) die Definition der funktionalen Form von \\(f\\), also einer Regel, wie aus \\(x\\) der Wert \\(f(x)\\) zu bilden ist. Zum Beispiel wird in folgender Definition einer Funktion \\[\\begin{equation}\nf : \\mathbb{R} \\to \\mathbb{R}_{\\ge 0}, x \\mapsto f(x) := x^2\n\\end{equation}\\] die Definition der Potenz genutzt.\nFunktionen sind immer eindeutig, in dem Sinne dass sie jedem \\(x \\in D\\) bei jeder Anwendung der Funktion immer dasselbe \\(f(x) \\in Z\\) zuordnen. Funktionen setzen dabei Elemente von Mengen miteinander in Beziehung. Die Mengen dieser Elemente erhalten spezielle Bezeichnungen.\n\nDefinition 4.2 (Bildmenge und Urbildmenge) Es sei \\(f : D \\to Z, x \\mapsto f(x)\\) eine Funktion und es seien \\(D' \\subseteq D\\) und \\(Z' \\subseteq Z\\). Die Menge \\[\\begin{equation}\nf(D') := \\{z \\in Z| \\mbox{Es gibt ein } x \\in D' \\mbox{ mit } z = f(x)\\}\n\\end{equation}\\] heißt die Bildmenge von \\(D'\\)  und \\(f(D) \\subseteq Z\\) heißt der Wertebereich von \\(f\\). Weiterhin heißt die Menge \\[\\begin{equation}\nf^{-1}(Z') := \\{x \\in D | f(x) \\in Z'\\}\n\\end{equation}\\] die Urbildmenge von \\(Z'\\). \\(x \\in D\\) mit \\(z = f(x) \\in Z\\) heißt auch Urbild von \\(z\\).\n\nMan beachte, dass der Wertebereich \\(f(D)\\) von \\(f\\) und die Zielmenge \\(Z\\) von \\(f\\) sind nicht notwendigerweise identisch sein müssen. Grundlegende Eigenschaften von Funktionen werden in folgender Definition festgelegt.\n\nDefinition 4.3 (Injektivität, Surjektivität, Bijektivität) \\(f : D \\to Z, x \\mapsto f(x)\\) sei eine Funktion. \\(f\\) heißt injektiv, wenn es zu jedem Bild \\(z \\in f(D)\\) genau ein Urbild \\(x \\in D\\) gibt. Äquivalent gilt, dass \\(f\\) injektiv ist, wenn aus \\(x_1,x_2 \\in D\\) mit \\(x_1 \\neq x_2\\) folgt, dass \\(f(x_1) \\neq f(x_2)\\) ist. \\(f\\) heißt surjektiv, wenn \\(f(D) = Z\\) gilt, wenn also jedes Element der Zielmenge \\(Z\\) ein Urbild in der Definitionsmenge \\(D\\) hat. Schließlich heißt \\(f\\) bijektiv, wenn \\(f\\) injektiv und surjektiv ist. Bijektive Funktionen werden auch eineindeutige Funktionen (engl. one-to-one mappings) genannt.\n\nAbbildung 4.1 verdeutlicht diese Definitionen anhand dreier (Gegen)beispiele.\n\n\n\nAbbildung 4.1: Injektivität, Surjektivität, Bijektivität.\n\n\nAbbildung 4.1 A visualisiert die nicht-injektive Funktion \\[\\begin{equation}\nf : \\{1,2,3\\} \\to \\{A,B\\}, x \\mapsto f(x) := \\begin{cases} f(1) & := A \\\\ f(2) & := A \\\\ f(3) & := B \\end{cases}.\n\\end{equation}\\] Die Funktion ist nicht-injektiv, weil es zum Element \\(A\\) in der Bildmenge von \\(f\\) mehr als ein Urbild in der Definitionsmenge von \\(f\\) gibt, nämlich \\(1\\) und \\(2\\).\nAbbildung 4.1 B visualisiert die nicht-surjektive Funktion \\[\\begin{equation}\ng : \\{1,2,3\\} \\to \\{A,B,C,D\\}, x \\mapsto g(x) := \\begin{cases} g(1) & := A \\\\ g(2) & := B \\\\ g(3) & := D \\end{cases}.\n\\end{equation}\\] Die Funktion ist nicht surjektiv, weil das Element \\(D\\) in der Zielmenge von \\(f\\) kein Urbild in der Definitionsmenge von \\(f\\) hat. Abbildung 4.1 C schließlich visualisiert die bijektive Funktion \\[\\begin{equation}\nh : \\{1,2,3\\} \\to \\{A,B,C\\}, x \\mapsto g(x) := \\begin{cases} h(1) & := A \\\\ h(2) & := B \\\\ h(3) & := C \\end{cases}.\n\\end{equation}\\] Zu jedem Element in der Zielmenge von \\(h\\) gibt es genau ein Urbild, die Funktion ist also injektiv und surjektiv und damit bijektiv.\nAls weiteres Beispiel betrachten wir die Funktion \\[\\begin{equation}\nf : \\mathbb{R} \\to \\mathbb{R}, x \\mapsto f(x) := x^2\n\\end{equation}\\] Diese Funktion ist nicht injektiv, weil z.B. für \\(x_1 = 2 \\neq -2 = x_2\\) gilt, dass \\(f(x_1) = 2^2 = 4 = (-2)^2 = f(x_2)\\). Weiterhin ist \\(f\\) auch nicht surjektiv, weil z.B. \\(-1 \\in \\mathbb{R}\\) kein Urbild unter \\(f\\) hat. Schränkt man die Definitionsmenge von \\(f\\) allerdings auf die nicht-negativen reellen Zahlen ein, definiert man also die Funktion \\[\\begin{equation}\n\\tilde{f} : [0,\\infty[ \\to [0,\\infty[, x \\mapsto \\tilde{f}(x) := x^2,\n\\end{equation}\\] so ist \\(\\tilde{f}\\) im Gegensatz zu \\(f\\) injektiv und surjektiv, also bijektiv."
  },
  {
    "objectID": "104-Funktionen.html#funktionentypen",
    "href": "104-Funktionen.html#funktionentypen",
    "title": "4  Funktionen",
    "section": "4.2 Funktionentypen",
    "text": "4.2 Funktionentypen\nDurch Verkettung lassen sich aus Funktionen weitere Funktionen bilden.\n\nDefinition 4.4 (Verkettung von Funktionen) Es seien \\(f : D \\to Z\\) und \\(g : Z \\to S\\) zwei Funktionen, wobei die Wertemenge von \\(f\\) mit der Definitionsmenge von \\(g\\) übereinstimmen sollen. Dann ist durch \\[\\begin{equation}\ng \\circ f : D \\to S, x \\mapsto (g \\circ f)(x) := g(f(x))\n\\end{equation}\\] eine Funktion definiert, die die Verkettung von \\(f\\) und \\(g\\) genannt wird.\n\nDie Schreibweise für verkettete Funktionen ist etwas gewöhnungsbedürftig. Wichtig ist es zu erkennen, dass \\(g \\circ f\\) die verkette Funktion und \\((g \\circ f)(x)\\) ein Element in der Zielmenge der verketten Funktion bezeichnen. Intuitiv wird bei der Auswertung von \\((g \\circ f)(x)\\) zunächst die Funktion \\(f\\) auf \\(x\\) angewendet und dann die Funktion \\(g\\) das Element auf \\(f(x)\\) von \\(R\\) angewendet. Dies ist in der funktionalen Form \\(g(f(x))\\) festgehalten. Der Einfachheit halber benennt man die Verkettung zweier Funktionen auch oft mit einem einzelnen Buchstaben und schreibt beispielsweise, \\(h := g \\circ f\\) mit \\(h(x) = g(f(x))\\).\nLeicht zur Verwirrung kann es führen, wenn Elemente in der Zielmenge von \\(f\\) mit \\(y\\) bezeichnet werden, also die Schreibweise \\(y = f(x)\\) und \\(h(x) = g(y)\\) genutzt wird. Allerdings ist diese Schreibweise manchmal zur notationellen Vereinfachung nötig.\nAls Beispiel für die Verkettung zweier Funktionen betrachten wir \\[\\begin{equation}\nf : \\mathbb{R} \\to \\mathbb{R}, x \\mapsto f(x) := -x^2\n\\end{equation}\\] und \\[\\begin{equation}\ng : \\mathbb{R} \\to \\mathbb{R}, x \\mapsto g(x) := \\exp(x).\n\\end{equation}\\] Die Verkettung von \\(f\\) und \\(g\\) ergibt sich in diesem Fall zu \\[\\begin{equation}\ng \\circ f : \\mathbb{R} \\to \\mathbb{R}, x \\mapsto (g \\circ f)(x) := g(f(x)) = \\exp\\left(-x^2\\right).\n\\end{equation}\\]\nEine erste Anwendung der Verkettung von Funktionen findet sich in folgender Definition.\n\nDefinition 4.5 (Inverse Funktion) Es sei \\(f : D \\to Z, x \\mapsto f(x)\\) eine bijektive Funktion. Dann heißt die Funktion \\(f^{-1}\\) mit \\[\\begin{equation}\nf^{-1} \\circ f : D \\to D, x \\mapsto (f^{-1} \\circ f)(x) := f^{-1}(f(x)) = x\n\\end{equation}\\] inverse Funktion, Umkehrfunktion oder einfach Inverse von \\(f\\).\n\nInverse Funktionen sind immer bijektiv. Dies folgt, weil \\(f\\) bijektiv ist und damit jedem \\(x \\in D\\) genau ein \\(f(x) = z \\in Z\\) zugeordnet wird. Damit wird aber auch jedem \\(z \\in Z\\) genau ein \\(x \\in D\\), nämlich \\(f^{-1}(f(x)) = x\\) zugeordnet.\nIntuitiv macht die inverse Funktion von \\(f\\) den Effekt von \\(f\\) auf ein Element \\(x\\) rückgängig. Betrachtet man den Graphen einer Funktion in einem Kartesischen Koordinatensystem, so führt die Anwendung von einem Wert auf der \\(x\\)-Achse zu einem Wert auf der \\(y\\)-Achse. Die Anwendung der inversen Funktion führt dementsprechend von einem Wert auf der \\(y\\)-Achse zu einem Wert auf der \\(x\\)-Achse. Betrachten wir zum Beispiel die Funktion \\[\\begin{equation}\nf : \\mathbb{R} \\to \\mathbb{R}, x \\mapsto f(x) := 2x =:y.\n\\end{equation}\\] Dann ist die inverse Funktion von \\(f\\) gegeben durch \\[\\begin{equation}\nf^{-1} : \\mathbb{R} \\to \\mathbb{R}, y \\mapsto f^{-1}(y) := \\frac{1}{2}y,\n\\end{equation}\\] weil für jedes \\(x \\in \\mathbb{R}\\) gilt, dass \\[\\begin{equation}\n(f^{-1} \\circ f)(x) := f^{-1}(f(x)) = f^{-1}(2x) = \\frac{1}{2}\\cdot 2x = x.\n\\end{equation}\\]\nEine wichtige Klasse von Funktionen sind lineare Abbildungen.\n\nDefinition 4.6 (Lineare Abbildung) Eine Abbildung \\(f : D \\to Z, x \\mapsto f(x)\\) heißt lineare Abbildung, wenn für \\(x,y \\in D\\) und einen Skalar \\(c\\) gelten, dass \\[\\begin{equation}\nf(x + y) = f(x) + f(y)  f(cx) = cf(x) \\tag*{(Additivität)}\n\\end{equation}\\] und \\[\\begin{equation}\nf(cx) = cf(x) \\tag*{(Homogenität)}\n\\end{equation}\\] Eine Abbildung, für die obige Eigenschaften nicht gelten, heißt nicht-lineare Abbildung.\n\nLineare Abbildungen sind oft als “gerade Linien” bekannt. Die allgemeine Definition linearer Abbildungen ist mit dieser Intuition nicht komplett kongruent. Insbesondere sind lineare Abbildungen nur solche Funktionen, die den Nullpunkt auf den Nullpunkt abbilden. Wir zeigen dazu folgendes Theorem.\n\nTheorem 4.1 (Lineare Abbildung der Null) \\(f : D \\to Z\\) sei eine lineare Abbildung. Dann gilt \\[\\begin{equation}\nf(0) = 0.\n\\end{equation}\\]\n\n\nBeweis. Wir halten zunächst fest, dass mit der Additivität von \\(f\\) gilt, dass \\[\\begin{equation}\nf(0) = f(0 + 0) = f(0) + f(0).\n\\end{equation}\\] Addition von \\(-f(0)\\) auf beiden Seiten obiger Gleichung ergibt dann \\[\\begin{align}\n\\begin{split}\nf(0) - f(0) & = f(0) + f(0) - f(0) \\\\\n0           & = f(0) \\\\\n\\end{split}\n\\end{align}\\] und damit ist alles gezeigt.\n\nWir wollen den Begriff der linearen Abbildung noch an zwei Beispielen verdeutlichen.\n\nFür \\(a \\in \\mathbb{R}\\) ist die Abbildung \\[\\begin{equation}\nf : \\mathbb{R} \\to \\mathbb{R}, x \\mapsto f(x) := ax\n\\end{equation}\\] eine lineare Abbildung, weil gilt, dass \\[\\begin{equation}\nf(x + y) = a(x + y) = ax + ay = f(x) + f(y) \\mbox{ und } f(cx) = acx = cax = cf(x).\n\\end{equation}\\]\nFür \\(a,b \\in \\mathbb{R}\\) ist dagegen die Abbildung \\[\\begin{equation}\nf : \\mathbb{R} \\to \\mathbb{R}, x \\mapsto f(x) := ax + b\n\\end{equation}\\] nicht-linear, weil z.B. für \\(a := b := 1\\) gilt, dass \\[\\begin{equation}\nf(x+y) = 1(x+y)+1 = x + y + 1 \\neq x + 1 + y + 1 = f(x) + f(y).\n\\end{equation}\\]\n\nEine Abbildung der Form \\(f(x) := ax + b\\) heißt linear-affine Abbildung oder linear-affine Funktion. Etwas unsauber werden Funktionen der Form \\(f(x) := ax + b\\) auch manchmal als lineare Funktionen bezeichnet.\nNeben den bisher diskutierten Funktionentypen gibt es noch viele weitere Klassen von Funktionen. In folgender Definition klassifizieren wir Funktionen anhand der Dimensionalität ihrer Definitions- und Zielmengen. Diese Art der Funktionsklassifikation ist oft hilfreich, um sich einen ersten Überblick über ein mathematisches Modell zu verschaffen.\n\nDefinition 4.7 (Funktionenarten) Wir unterscheiden\n\nunivariate reellwertige Funktionen der Form \\[\\begin{equation}\nf : \\mathbb{R} \\to \\mathbb{R}, x \\mapsto f(x),\n\\end{equation}\\]\nmultivariate reellwertige Funktionen der Form \\[\\begin{equation}\nf : \\mathbb{R}^n \\to \\mathbb{R}, x \\mapsto f(x) = f(x_1,...,x_n),\n\\end{equation}\\]\nund multivariate vektorwertige Funktionen der Form \\[\\begin{equation}\nf : \\mathbb{R}^n \\to \\mathbb{R}^m, x \\mapsto\nf(x) =\n\\begin{pmatrix}\nf_1(x_1,...,x_n)    \\\\\n\\vdots              \\\\\nf_m(x_1,...,x_n)\n\\end{pmatrix},\n\\end{equation}\\] wobei \\(f_i, i = 1,...,m\\) die Komponenten(funktionen) von \\(f\\) genannt werden.\n\n\nIn der Physik werden multivariate reellwertige Funktionen Skalarfelder und multivariate vektorwertige Funktionen Vektorfelder genannt. In manchen Anwendungen treten zum Beispiel auch matrixvariate matrixwertige Funktionen auf."
  },
  {
    "objectID": "104-Funktionen.html#sec-elementare-funktionen",
    "href": "104-Funktionen.html#sec-elementare-funktionen",
    "title": "4  Funktionen",
    "section": "4.3 Elementare Funktionen",
    "text": "4.3 Elementare Funktionen\nAls elementare Funktionen bezeichnen wir eine kleine Schar von univariaten reellwertigen Funktionen, die häufig als Bausteine komplexerer Funktionen auftreten. Dies sind die Polynomfunktionen, die Exponentialfunktion, die Logarithmusfunktion und die Gammafunktion. Im Folgenden geben wir wesentliche Eigenschaften dieser Funktionen und ihre Graphen an. Für Beweise der Eigenschaften der hier vorgestellten F unktionen verweisen wir auf die weiterführende Literatur.\n\nDefinition 4.8 (Polynomfunktionen) Eine Funktion der Form \\[\\begin{equation}\nf : \\mathbb{R} \\to \\mathbb{R}, x \\mapsto f(x)\n:= \\sum_{i=0}^{k} a_i x^i = a_0 + a_1 x^1 + a_2 x^2 + \\cdots + a_k x^k\n\\end{equation}\\] heißt Polynomfunktion \\(k\\)-ten Grades mit Koeffizienten \\(a_0, a_1,...,a_k \\in \\mathbb{R}\\).\n\nEinige ausgewählte Polynomfunktionen sind in Tabelle aufgelistet, Abbildung 4.2 zeigt die enstprechende Graphen.\n\n\n\nAusgewählte Polynomfunktionen\n\n\n\n\n\n\n\nName\nFunktionale Form\nKoeffizienten\n\n\n\n\nKonstante Funktion\n\\(f(x) = a\\)\n\\(a_0 := a, a_i := 0, i &gt; 0\\)\n\n\nIdentitätsfunktion\n\\(f(x) = x\\)\n\\(a_0 := 0, a_1 := 1, a_i := 0, i &gt; 1\\)\n\n\nLinear-affine Funktion\n\\(f(x) = ax + b\\)\n\\(a_0 := b, a_1 := a, a_i := 0, i &gt; 1\\)\n\n\nQuadratfunktion\n\\(f(x) = x^2\\)\n\\(a_0 := 0, a_1 := 0, a_2 := 1, a_i := 0, i &gt; 2\\)\n\n\n\n\n\n\n\n\nAbbildung 4.2: Ausgewählte Polynomfunktionen\n\n\nEin wichtiges Funktionenpaar sind die Exponentialfunktion und die Logarithmusfunktion. Die Graphen der Exponential- und Logarithmusfunktion sind in Abbildung 4.3 abgebildet.\n\n\n\nAbbildung 4.3: Exponentialfunktion und Logarithmusfunktion\n\n\n\nDefinition 4.9 (Exponentialfunktion) Die Exponentialfunktion ist definiert als \\[\\begin{equation}\n\\exp : \\mathbb{R} \\to \\mathbb{R},\nx \\mapsto \\exp(x)\n:= e^x\n:= \\sum_{n=0}^\\infty \\frac{x^n}{n!}\n= 1 + x + \\frac{x^2}{2!} + \\frac{x^3}{3!} + \\frac{x^4}{4!} + \\cdots.\n\\end{equation}\\]\n\nDie Exponentialfunktion hat unter anderem folgende Eigenschaften.\nWertebereich der Exponentialfunktion\n\n\\(x \\in ]-\\infty,0[\\, \\Rightarrow \\exp(x) \\in ]0,1[\\)\n\\(x \\in ]0,\\infty[\\quad\\,\\, \\Rightarrow \\exp(x) \\in ]1,\\infty[\\)\n\nInsbesondere nimmt die Exponentialfunktion also nur positive Werte an.\nMonotonieeigenschaft der Exponentialfunktion\n\n\\(x &lt; y \\Rightarrow \\exp(x) &lt; \\exp(y)\\)\n\nSpezielle Werte der Exponentialfunktion\n\n\\(\\exp(0) = 1\\)\n\\(\\exp(1) = e \\approx 2.71\\)\n\nDie Logarithmusfunktion schneidet die \\(y\\)-Achse also bei 0. Die Zahl \\(e\\) heißt Eulersche Zahl.\nSummationseigenschaft und Subtraktionseigenschaft der Exponentialfunktion\n\n\\(\\exp(x + y) = \\exp(x)\\exp(y)\\)\n\\(\\exp(x - y) = \\frac{\\exp(x)}{\\exp(y)}\\)\n\nMit den speziellen Werten der Exponentialfunktion gilt dann insbesondere auch \\[\\begin{equation}\n\\exp(x)\\exp(-x) = \\exp(x - x) = \\exp(0) = 1.\n\\end{equation}\\]\n\nDefinition 4.10 (Logarithmusfunktion) Die Logarithmusfunktion ist definiert als inverse Funktion der Exponentialfunktion, \\[\\begin{equation}\n\\ln : ]0,\\infty[ \\to \\mathbb{R}, x \\mapsto \\ln(x)\n\\mbox{ mit } \\ln(\\exp(x)) = x \\mbox{ für alle } x \\in \\mathbb{R}.\n\\end{equation}\\]\n\nDie Logarithmusfunktion hat unter anderem folgende Eigenschaften.\nWertebereich der Logarithmusfunktion\n\n\\(x \\in \\, ]0,1[\\,\\,\\, \\Rightarrow \\ln(x) \\in\\,]-\\infty,0[\\)\n\\(x \\in \\, ]1,\\infty[ \\Rightarrow \\ln(x) \\in\\, ]0,\\infty[\\)\n\nDie Logarithmusfunktion nimmt also sowohl negative als auch positive Werte an.\nMonotonie der Logarithmusfunktion\n\n\\(x &lt; y \\Rightarrow \\ln(x) &lt; \\ln(y)\\)\n\nSpezielle Werte der Logarithmusfunktion\n\n\\(\\ln(1) = 0\\) und \\(\\ln(e) = 1\\).\n\nDie Logarithmusfunktion schneidet die \\(x\\)-Achse also bei 1.\nProdukteigenschaft, Potenzeigenschaft und Divisionseigenschaft der Logarithmusfunktion\n\n\\(\\ln(xy) = \\ln(x) + \\ln(y)\\)\n\\(\\ln(x^c) = c\\ln(x)\\)\n\\(\\ln\\left(\\frac{1}{x}\\right) = -\\ln(x)\\)\n\nLetztere Eigenschaft sind beim Rechnen Logarithmusfunktionen zentral. Man merkt sie sich intuitiv als “Die Logarithmusfunktion wandelt Produkte in Summen und Potenzen in Produkte um.”\nEin häufiger Begleiter in der Wahrscheinlichkeitstheorie ist die Gammafunktion. Ein Auschnitt des Graphen der Gammafunktion ist in Abbildung 4.4 dargestellt.\n\n\n\nAbbildung 4.4: Gammafunktion\n\n\n\nDefinition 4.11 (Gammafunktion) Die Gammafunktion ist definiert durch \\[\\begin{equation}\n\\Gamma : \\mathbb{R} \\to \\mathbb{R}, x \\mapsto\n\\Gamma(x) := \\int_0^\\infty \\xi^{x-1}\\exp(-\\xi)\\,d\\xi\n\\end{equation}\\]\n\nDie Gammafunktion hat folgende Eigenschaften:\nSpezielle Werte der Gammafunktion\n\n\\(\\Gamma(1) = 1\\)\n\\(\\Gamma\\left(\\frac{1}{2} \\right) = \\sqrt{\\pi}\\)\n\\(\\Gamma(n) = (n-1)!\\) für \\(n \\in \\mathbb{N}\\).\n\nRekursionseigenschaft der Gammafunktion\n\nFür \\(x&gt;0\\) gilt \\(\\Gamma(x+1) = x\\Gamma(x)\\)"
  },
  {
    "objectID": "104-Funktionen.html#sec-selbstkontrollfragen-funktionen",
    "href": "104-Funktionen.html#sec-selbstkontrollfragen-funktionen",
    "title": "4  Funktionen",
    "section": "4.4 Selbstkontrollfragen",
    "text": "4.4 Selbstkontrollfragen\n\nGeben Sie die Definition einer Funktion wieder.\nGeben Sie die Definition der Begriffe Bildmenge, Wertebereich, und Urbildmenge wieder.\nGeben Sie die Definitionen der Begriffe Surjektivität, Injektivität, und Bijektivität wieder.\nErläutern Sie, warum \\(f:\\mathbb{R} \\to \\mathbb{R}, x \\mapsto f(x) := x^2\\) weder injektiv noch surjektiv ist.\nErläutern Sie, warum \\(f: [0,\\infty[ \\to [0,\\infty[ , x \\mapsto f(x) := x^2\\) bijektiv ist.\nGeben Sie die Definition der Verkettung von Funktionen wieder.\nGeben Sie die Definition des Begriffs der inversen Funktion wieder.\nGeben Sie die inverse Funktion von \\(x^2\\) auf \\([0,\\infty[\\) an.\nGeben Sie die Definition des Begriffs der linearen Abbildung wieder.\nGeben Sie die Definitionen der Begriffe der univariat-reellwertigen, multivariat-reellwertigen und multivariat-vektorwertigen Funktion wieder.\nSkizzieren Sie die Identitätsfunktion und die konstante Funktion für \\(a := 1\\).\nSkizzieren Sie die linear-affine Funktion \\(f(x) = ax + b\\) für \\(a = 2\\) und \\(b = 3\\).\nSkizzieren Sie die Funktionen \\(f(x) := (x-1)^2\\) und \\(g(x) := (x + 3)^2\\).\nSkizzieren Sie die Exponential- und Logarithmusfunktionen.\nGeben Sie die Summations- und Subtraktionseigenschaften der Exponentialfunktion an.\nGeben Sie die Produkt-, Potenz- und Divisionseigenschaften der Logarithmusfunktion an."
  },
  {
    "objectID": "105-Differentialrechnung.html#sec-definitionen-rechenregeln",
    "href": "105-Differentialrechnung.html#sec-definitionen-rechenregeln",
    "title": "5  Differentialrechnung",
    "section": "5.1 Definitionen und Rechenregeln",
    "text": "5.1 Definitionen und Rechenregeln\nWir beginnen mit folgender Definition.\n\nDefinition 5.1 (Differenzierbarkeit und Ableitung) Es sei \\(I \\subseteq \\mathbb{R}\\) ein Intervall und \\[\\begin{equation}\nf : I \\to \\mathbb{R}, x \\mapsto f(x)\n\\end{equation}\\] eine univariate reellwertige Funktion. \\(f\\) heißt in \\(a \\in I\\) differenzierbar, wenn der Grenzwert \\[\\begin{equation}\nf'(a) := \\lim_{h\\to 0} \\frac{f(a+h)-f(a)}{h}\n\\end{equation}\\] existiert. \\(f'(a)\\) heißt dann die Ableitung von \\(f\\) an der Stelle \\(a\\). Ist \\(f\\) differenzierbar für alle \\(x \\in I\\), so heißt \\(f\\) differenzierbar und die Funktion \\[\\begin{equation}\nf' : I \\to \\mathbb{R}, x \\mapsto f'(x)\n\\end{equation}\\] heißt Ableitung von \\(f\\).\n\nFür \\(h&gt;0\\) heißt der Ausdruck \\[\\begin{equation}\n\\frac{f(a+h)-f(a)}{h}\n\\end{equation}\\] Newtonscher Differenzquotient. Der Newtonsche Differenzquotient misst die Änderung \\(f(a+h)-f(a)\\) von \\(f\\) pro Strecke \\(h\\) auf der \\(x\\)-Achse. Wenn also zum Beispiel \\(f(a)\\) und \\(f(a+h)\\) die Position eines Objektes zu einem Zeitpunkt \\(a\\) und zu einem späteren Zeitpunkt \\(a+h\\) repräsentieren, dann ist \\(f(a+h)-f(a)\\) die von diesem Objekt in der Zeit \\(h\\) zurückgelegte Strecke, also seine durchschnittliche Geschwindigkeit über den Zeitraum \\(h\\). Für \\(h\\to 0\\) misst der Newtonsche Differenzquotient die instantane Änderungsrate von \\(f\\) in \\(a\\), also im Beispiel die Geschwindigkeit des Objektes zu einem Zeitpunkt \\(a\\).\nAus mathematischer Sicht ist es wichtig, bei der Definition der Ableitung zwischen den Symbolen \\(f'(a)\\) und \\(f'\\) zu unterscheiden. Wie üblich bezeichnet \\(f'(a)\\) den Wert einer Funktion, also eine Zahl. \\(f'\\) dagegen bezeichnet eine Funktion, nämlich die Funktion, deren Werte als \\(f'(a)\\) für alle \\(a \\in \\mathbb{R}\\) bestimmt sind.\nEs existieren in der Literatur verschiedene, historisch gewachsene Notationen für Ableitungen, welche alle das identische Konzept der Ableitung repräsentieren.\n\nDefinition 5.2 (Notation für Ableitungen univariater reellwertiger Funktionen) Es sei \\(f\\) eine univariate reellwertige Funktion. Äquivalente Schreibweisen für die Ableitung von \\(f\\) und die Ableitung von \\(f\\) an einer Stelle \\(x\\) sind\n\ndie Lagrange-Notation \\(f'\\) und \\(f'(x)\\),\ndie Leibniz-Notation \\(\\frac{df}{dx}\\) und \\(\\frac{df(x)}{dx}\\),\ndie Newton-Notation \\(\\dot{f}\\) und \\(\\dot{f}(x)\\), sowie\ndie Euler-Notation \\(Df\\) und \\(Df(x)\\),\n\nrespektive\n\nWir werden im Folgenden für univariate reellwertige Funktionen vor allem die Lagrange-Notation \\(f'\\) und \\(f'(x)\\) als Bezeichner wählen. In Berechnungen nutzen wir auch eine adapatierte Form der Leibniz-Notation und verstehen dort die Schreibweise \\(\\frac{d}{dx}f(x)\\) als den Auftrag, die Ableitung von \\(f\\) zu berechnen. Die Newton-Notation wird vor allem eingesetzt, wenn das Funktionsargument die Zeit repräsentiert und dann üblicherweise mit \\(t\\) für “time” bezeichnet wird. \\(\\dot{f}(t)\\) bezeichnet dann die Änderungsrate von \\(f\\) zum Zeitpunkt \\(t\\). Die Euler-Notation ist vor allem im Kontext multivariater reell- oder vektorwertiger Funktionen nützlich.\nBasierend auf der Definition der Ableitung einer univariaten reellwertigen Funktionen lassen sich leicht weitere Ableitungen einer solchen Funktion definieren.\n\nDefinition 5.3 (Höhere Ableitungen) Es sei \\(f\\) eine univariate reellwertige Funktion und \\[\\begin{equation}\nf^{(1)} := f'\n\\end{equation}\\] sei die Ableitung von \\(f\\). Die \\(k\\)-te Ableitung von \\(f\\) ist rekursiv definiert durch \\[\\begin{equation}\nf^{(k)} := \\left(f^{(k-1)}\\right)' \\mbox{ für } k \\ge 0,\n\\end{equation}\\] unter der Annahme, dass \\(f^{(k-1)}\\) differenzierbar ist. Insbesondere ist die zweite Ableitung von \\(f\\) definiert durch die Ableitung von \\(f'\\), also \\[\\begin{equation}\nf'' := (f')'\n\\end{equation}\\]\n\nIn Analogie zu oben Gesagtem schreiben wir in Berechnungen auch \\(\\frac{d^2}{dx^2}f(x)\\) für den Auftrag, die zweite Ableitung einer Funktion \\(f\\) zu bestimmen. Die nullte Ableitung \\(f^{(0)}\\) von \\(f\\) ist \\(f\\) selbst. Der Tradition und Einfachheit halber schreibt man für \\(k &lt; 4\\) gemäß der Lagrange-Notation meist \\(f',f''\\) und \\(f'''\\) anstelle von \\(f^{(1)}, f^{(2)}\\) und \\(f^{(3)}\\).\nZum Bestimmen der Ableitung einer Funktion sind eine Reihe von Rechenregeln hilfreich, die es erlauben, die Ableitung einer Funktion aus den Ableitungen ihrer Unterfunktionen herzuleiten. Für Beweise der in folgendem Theorem eingeführten Rechenregeln verweisen wir auf die weiterführende Literatur\n\nTheorem 5.1 (Rechenregeln für Ableitungen) Für \\(i = 1,...,n\\) seien \\(g_i\\) reellwertige univariate differenzierbare Funktionen. Dann gelten folgende Rechenregeln:\n\nSummenregel \\[\\begin{equation}\n\\mbox{Für } f(x) := \\sum_{i=1}^n g_i(x) \\mbox{ gilt } f'(x) = \\sum_{i=1}^n g_i'(x).\n\\end{equation}\\]\nProduktregel \\[\\begin{equation}\n\\mbox{Für } f(x) := g_1(x)g_2(x) \\mbox{ gilt } f'(x) = g_1'(x)g_2(x) + g_1(x)g_2'(x).\n\\end{equation}\\]\nQuotientenregel \\[\\begin{equation}\n\\mbox{Für } f(x) := \\frac{g_1(x)}{g_2(x)} \\mbox{ gilt } f'(x) = \\frac{g_1'(x)g_2(x) - g_1(x)g_2'(x)}{g_2^2(x)}.\n\\end{equation}\\]\nKettenregel \\[\\begin{equation}\n\\mbox{Für } f(x) := g_1(g_2(x)) \\mbox{ gilt } f'(x) = g_1'(g_2(x))g'_2(x).\n\\end{equation}\\]\n\n\nErste Beispiele für die Anwendung obiger Rechenregeln lernen wir im Abschnitt Kapitel 5.2 kennen. Wir setzen eine Reihe von Ableitungen elementarer Funktionen als bekannt voraus, diese sind in Tabelle zusammengstellt. Für Beweise verweisen wir wiederum auf die weiterführende Literatur.\n\n\n\nAbleitungen elementarer Funktionen\n\n\n\n\n\n\n\nName\nDefinition\nAbleitung\n\n\n\n\nPolynomfunktion\n\\(f(x) := \\sum_{i=0}^n a_ix^i\\)\n\\(f'(x) = \\sum_{i=1}^n ia_ix^{i-1}\\)\n\n\nKonstante Funktion\n\\(f(x) := a\\)\n\\(f'(x) = 0\\)\n\n\nIdentitätsfunktion\n\\(f(x) := x\\)\n\\(f'(x) = 1\\)\n\n\nLinear-affine Funktion\n\\(f(x) := ax + b\\)\n\\(f'(x) = a\\)\n\n\nQuadratfunktion\n\\(f(x) := x^2\\)\n\\(f'(x) = 2x\\)\n\n\nExponentialfunktion\n\\(f(x) := \\exp(x)\\)\n\\(f'(x) = \\exp(x)\\)\n\n\nLogarithmusfunktion\n\\(f(x) := \\ln(x)\\)\n\\(f'(x) = \\frac{1}{x}\\)\n\n\n\n\n\nIn Abbildung 5.1 visualisieren wir die Identitätsfunktion, eine linearen Funktion und die Quadratfunktion zusammen mit ihrer jeweiligen Ableitung. In Abbildung Abbildung 5.2 visualisieren wir die Exponential- und Logarithmusfunktionen zusammen mit ihrer jeweiligen Ableitung.\n\n\n\nAbbildung 5.1: Ableitungen dreier elementarer Funktionen\n\n\n\n\n\nAbbildung 5.2: Ableitungen von Exponentialfunktion und Logarithmusfunktion"
  },
  {
    "objectID": "105-Differentialrechnung.html#sec-analytische-optimierung",
    "href": "105-Differentialrechnung.html#sec-analytische-optimierung",
    "title": "5  Differentialrechnung",
    "section": "5.2 Analytische Optimierung",
    "text": "5.2 Analytische Optimierung\nEine wichtige Anwendung der Differentialrechnung ist das Bestimmen von Extremstellen von Funktionen. Dabei geht es im Kern um die Frage, für welche Werte ihrer Definitionsmenge eine Funktion ein Maximum oder ein Minimum annimmt. Bei einfachen Funktionen ist dies analytisch möglich. Die generelle Vorgehensweise dabei ist oft auch unter dem Stichwort “Kurvendiskussion” bekannt. In der Anwendung ist ein analytisches Vorgehen zur Optimierung von Funktionen meist nicht möglich und es werden Computeralgorithmen zur Bestimmung von Extremstellen genutzt. Ein Verständnis dieser Algorithmen setzt allerdings ein Verständnis der Prinzipien der analytischen Optimierung voraus. In diesem Abschnitt geben wir eine Einführung in die analytische Optimierung von univariaten reellwertigen Funktionen. Wir gehen dabei eher informell vor. Einen formaleren Zugang geben wir an späterer Stelle im Kontext der nichtlinearen Optimierung. Wir beginnen damit, die Begriffe der erwähnten Maxima und Minima von univariaten reellwertigen Funktionen zu präzisieren.\n\nDefinition 5.4 (Extremstellen und Extremwerte) Es seien \\(U \\subseteq \\mathbb{R}\\) und \\(f : U \\to \\mathbb{R}\\) eine univariate reellwertige Funktion. \\(f\\) hat an der Stelle \\(x_0 \\in U\\)\n\nein lokales Minimum, wenn es ein Intervall \\(I := ]a,b[\\) gibt mit \\(x_0 \\in ]a,b[\\) und \\[\\begin{equation}\nf(x_0) \\le f(x) \\mbox{ für alle } x\\in I\\cap U,\n\\end{equation}\\]\nein globales Minimum, wenn gilt, dass \\[\\begin{equation}\nf(x_0) \\le f(x) \\mbox{ für alle } x\\in U,\n\\end{equation}\\]\nein lokales Maximum, wenn es ein Intervall \\(I := ]a,b[\\) gibt mit \\(x_0 \\in ]a,b[\\) und \\[\\begin{equation}\nf(x_0) \\ge f(x) \\mbox{ für alle }  x\\in I\\cap U,\n\\end{equation}\\]\nein lokales Maximum, wenn gilt, dass \\[\\begin{equation}\nf(x_0) \\ge f(x) \\mbox{ für alle } x\\in U.\n\\end{equation}\\]\n\nDer Wert \\(x_0 \\in U\\) der Definitionsmenge von \\(f\\) heißt entsprechend lokale oder globale Minimalstelle oder Maximalstelle, der Funktionswert \\(f(x_0) \\in \\mathbb{R}\\) heißt entsprechend lokales oder globales Minimum oder Maximum. Generell heißt der Wert \\(x_0 \\in U\\) Extremstelle und der Funktionswert \\(f(x_0) \\in \\mathbb{R}\\) Extremwert.\n\nExtremstellen von Funktionen werden häufig mit \\[\\begin{equation}\n\\underset{x \\in I \\cap U}{\\operatorname{argmin}} f(x) \\mbox{ oder }\n\\underset{x \\in I \\cap U}{\\operatorname{argmax}} f(x)\n\\end{equation}\\] bezeichnet und Extremwerte von Funktionen werden häufig mit \\[\\begin{equation}\n\\min_{x \\in I \\cap U} f(x) \\mbox{ oder }\n\\max_{x \\in I \\cap U} f(x)\n\\end{equation}\\] bezeichnet.\nDie analytische Optimierung von univariaten reellwertigen Funktionen basiert auf den sogenannten notwendigen und hinreichenden Bedingungen für Extrema. Erstere macht eine Aussage über das Verhalten der ersten Ableitung einer Funktion an einer Extremstelle, letztere macht eine Aussage über das Verhalten einer Funktion an einer Stelle, die bestimmten Forderungen an ihre erste und zweite Ableitung genügt.\n\nTheorem 5.2 (Notwendige Bedingung für Extrema) \\(f\\) sei eine univariate reellwertige Funktion. Dann gilt \\[\\begin{equation}\nx_0 \\mbox{ ist Extremstelle von } f \\Rightarrow f'(x_0) = 0.\n\\end{equation}\\]\n\nWenn \\(x_0\\) eine Extremstelle von \\(f\\) ist, dann ist also die erste Ableitung von \\(f\\) in \\(x_0\\) gleich null. Anstelle eines Beweises überlegen wir uns, dass zum Beispiel an eine lokaler Maximalstelle \\(x_0\\) von \\(f\\) gilt: links von \\(x_0\\) steigt \\(f\\) an, rechts von \\(x_0\\) fällt \\(f\\) ab. In \\(x_0\\) aber steigt \\(f\\) weder an, noch fällt \\(f\\) ab, es ist also nachvollziehbar, dass \\(f'(x_0) = 0\\) ist.\n\nTheorem 5.3 (Hinreichende Bedingungen für lokale Extrema) \\(f\\) sei eine zweimal differenzierbare univariate reellwertige Funktion.\n\nWenn für \\(x_0 \\in U \\subseteq \\mathbb{R}\\) \\[\\begin{equation}\nf'(x_0) = 0 \\mbox{ und } f''(x_0) &gt; 0\n\\end{equation}\\] gilt, dann hat \\(f\\) an der Stelle \\(x_0\\) ein Minimum.\nWenn für \\(x_0 \\in U \\subseteq \\mathbb{R}\\) \\[\\begin{equation}\nf'(x_0) = 0 \\mbox{ und } f''(x_0) &lt; 0\n\\end{equation}\\] gilt, dann hat \\(f\\) an der Stelle \\(x_0\\) ein Maximum.\n\n\nWir verzichten wiederum auf einen Beweis und verdeutlichen uns die Bedingung an dem in Abbildung 5.3 gezeigtem Beispiel. Hier ist offenbar \\(x_0 = 1\\) eine lokale Minimalstelle von \\(f(x) = (x-1)^2\\). Man erkennt: links von \\(x_0\\) fällt \\(f\\) ab, rechts von \\(x_0\\) steigt \\(f\\) an. In \\(x_0\\) steigt \\(f\\) weder an, noch fällt \\(f\\) ab, also ist \\(f'(x_0) = 0\\). Weiter gilt, dass links und rechts von \\(x_0\\) und in \\(x_0\\) die Änderung \\(f''\\) von \\(f'\\) positiv ist: links von \\(x_0\\) schwächt sich die Negativität von \\(f'\\) zu \\(0\\) ab und rechts von \\(x_0\\) verstärkt sich die Positivität von \\(f'\\).\n\n\n\nAbbildung 5.3: Analytische Optimierung von \\(f(x) := (x-1)^2\\)\n\n\nInsbesondere die hinreichende Bedingung für das Vorliegen von Extremstellen legt folgendes Standardverfahren zur Bestimmung von lokalen Extremstellen nahe.\n\nTheorem 5.4 (Standardverfahren der analytischen Optimierung) \\(f\\) sei eine univariate reellwertige Funktion. Lokale Extremstellen von \\(f\\) können mit folgendem Standardverfahren der analytischen Optimierung identifiziert werden:\n\nBerechnen der ersten und zweiten Ableitung von \\(f\\).\nBestimmen von Nullstellen \\(x^*\\) von \\(f'\\) durch Auflösen von \\(f'(x^*) = 0\\) nach \\(x^*\\). Die Nullstellen von \\(f'\\) sind dann Kandidaten für Extremstellen von \\(f\\).\nEvaluation von \\(f''(x^*)\\): Wenn \\(f''(x^*) &gt; 0\\) ist, dann ist \\(x^*\\) lokale Minimumstelle von \\(f\\); wenn \\(f''(x^*) &lt; 0\\) ist, dann ist \\(x^*\\) lokale Maximumstelle von \\(f\\); wenn \\(f''(x^*) = 0\\) ist, dann ist \\(x^*\\) keine Extremstelle von \\(f\\).\n\n\nAnstelle eines Beweises betrachten wir beispielhaft die Funktion \\[\\begin{equation}\nf : \\mathbb{R} \\to \\mathbb{R}, x \\mapsto f(x) := (x - 1)^2.\n\\end{equation}\\] aus Abbildung 5.3. Die erste Ableitung von \\(f\\) ergibt sich mit der Kettenregel zu \\[\\begin{equation}\nf'(x) = \\frac{d}{dx}\\left((x-1)^2 \\right) = 2(x-1)\\cdot \\frac{d}{dx}(x-1) = 2x - 2.\n\\end{equation}\\] Die zweite Ableitung von \\(f\\) ergibt sich zu \\[\\begin{equation}\nf''(x) = \\frac{d}{dx}f'(x) = \\frac{d}{dx}(2x - 2) = 2 &gt; 0 \\mbox{ für alle }\nx \\in \\mathbb{R}.\n\\end{equation}\\] Auflösen von \\(f'(x^*) = 0\\) nach \\(x^*\\) ergibt \\[\\begin{equation}\nf'(x^*) = 0\n\\Leftrightarrow\n2x^* - 2 = 0\n\\Leftrightarrow\n2x^* = 2\n\\Leftrightarrow\nx^* = 1.\n\\end{equation}\\] \\(x^* = 1\\) ist folglich eine Minimalstelle von \\(f\\) mit zugehörigen Minimalwert \\(f(1) = 0\\)."
  },
  {
    "objectID": "105-Differentialrechnung.html#sec-differentialrechnung-multivariater-reellwertiger-funktionen",
    "href": "105-Differentialrechnung.html#sec-differentialrechnung-multivariater-reellwertiger-funktionen",
    "title": "5  Differentialrechnung",
    "section": "5.3 Differentialrechnung multivariater reellwertiger Funktionen",
    "text": "5.3 Differentialrechnung multivariater reellwertiger Funktionen\nWir erinnern zunächst an den Begriff der multivariaten reellwertigen Funktion.\n\nDefinition 5.5 (Multivariate reellwertige Funktion) Eine Funktion der Form \\[\\begin{equation}\nf : \\mathbb{R}^n \\to \\mathbb{R}, x \\mapsto f(x) = f(x_1,...,x_n)\n\\end{equation}\\] heißt Funktion.\n\nDie Argumente multivariater reellwertiger Funktionen sind also reelle \\(n\\)-Tupel der Form \\(x := (x_1,...,x_n)\\) während ihre Funktionswerte reelle Zahlen sind. Ein Beispiel für eine multivariate reellwertige für \\(n:=2\\) ist \\[\\begin{equation}\nf : \\mathbb{R}^2 \\to \\mathbb{R}, x \\mapsto f(x) := x_1^2 + x_2^2\n\\end{equation}\\]\nWir visualisieren diese Funktion in Abbildung 5.4. Dabei zeigt die rechte Abbildung eine Darstellung mithilfe sogenannter Isokonturen, also Linien im Definitionsbereich der Funktion, für die die Funktion identische Werte annimmt. Die entsprechenden Werte sind für ausgewählte Isokonturen in der Abbildung vermerkt.\n\n\n\nAbbildung 5.4: Visualisierungen einer bivariaten Funktion.\n\n\nWir wollen nun beginnen, die Begriffe der Differenzierbarkeit und der Ableitung univariater reellwertiger Funktionen auf den Fall multivariater reellwertiger Funktion zu erweitern. Dazu führen wir zunächst die Begriffe der partiellen Differenzierbarkeit und der partiellen Ableitung ein.\n\nDefinition 5.6 (Partielle Differenzierbarkeit und partielle Ableitung) Es sei \\(D \\subseteq \\mathbb{R}^n\\) eine Menge und \\[\\begin{equation}\nf : D \\to \\mathbb{R}, x \\mapsto f(x)\n\\end{equation}\\] eine multivariate reellwertige Funktion. \\(f\\) heißt in \\(a \\in D\\) , wenn der Grenzwert \\[\\begin{equation}\n\\frac{\\partial}{\\partial x_i}f(x) := \\lim_{h\\to 0} \\frac{f(a + he_i)-f(a)}{h}\n\\end{equation}\\] existiert. \\(\\frac{\\partial}{\\partial x_i}f(a)\\) heißt dann die . Wenn \\(f\\) für alle \\(x \\in D\\), nach \\(x_i\\) partiell differenzierbar ist, dann heißt \\(f\\) und die Funktion \\[\\begin{equation}\n\\frac{\\partial}{\\partial x_i} f: D \\to \\mathbb{R}, x \\mapsto \\frac{\\partial}{\\partial x_i}f(x)\n\\end{equation}\\] heißt . \\(f\\) heißt , wenn \\(f\\) für alle \\(i = 1,...,n\\) in \\(x \\in D\\) nach \\(x_i\\) partiell differenzierbar ist, und \\(f\\) heißt partiell differenzierbar, wenn \\(f\\) für alle \\(i = 1,...,n\\) in allen \\(x \\in D\\) nach \\(x_i\\) partiell differenzierbar ist.\n\nIn Definition 5.6 bezeichnet \\(e_i \\in \\mathbb{R}^n\\) bezeichnet den \\(i\\)ten kanonischen Einheitsvektor, für den gilt, dass \\(e_{i_j} = 1\\) für \\(i=j\\) und \\(e_{i_j} = 0\\) für \\(i \\neq j\\) mit \\(j = 1,...,n\\) (vgl. Definition 8.14). In Analogie und Verallgemeinerung zum Newtonschen Differenzquotienten misst der hier auftretende Differenzquotient \\[\\begin{equation}\n\\frac{f(x + he_i)-f(x)}{h}\n\\end{equation}\\] die Änderung \\(f(x+he_i)-f(x)\\) von \\(f\\) pro Strecke \\(h\\) in Richtung \\(e_i\\). Für \\(h\\to 0\\) misst der Differenzquotient entsprechend die Änderungsrate von \\(f\\) in \\(x\\) in Richtung \\(e_i\\). Wie bei der Betrachtung von Ableitungen gilt, dass \\(\\frac{\\partial}{\\partial x_i}f(x)\\) eine Zahl, \\(\\frac{\\partial}{\\partial x_i}f\\) dagegen eine Funktion ist. Praktisch berechnet man \\(\\frac{\\partial}{\\partial x_i}f\\) als die (einfache) Ableitung \\[\\begin{equation}\n\\frac{d}{dx_i}\\tilde{f}_{x_1,...x_{i-1},x_{i+1}, ...,x_n}(x_i)\n\\end{equation}\\] der univariaten reellwertigen Funktion \\[\\begin{equation}\n\\tilde{f} : \\mathbb{R} \\to \\mathbb{R}, x_i \\mapsto \\tilde{f}_{x_1,...x_{i-1},x_{i+1}, ...,x_n}(x_i) := f(x_1,...,x_i, ...,x_n).\n\\end{equation}\\] Man betrachtet für die \\(i\\)te partielle Ableitung also alle \\(x_j\\) mit \\(j \\neq i\\) als Konstanten und ist auf das gewohnte Berechnen von Ableitungen von univariaten reellwertigen Funktionen geführt. Wir wollen das Vorgehen zum Berechnen von partiellen Ableitungen an einem ersten Beispiel verdeutlichen.\nBeispiel (1)\nWir betrachten die Funktion \\[\\begin{equation}\nf:\\mathbb{R}^2\\to \\mathbb{R}, x\\mapsto f(x):=x_1^2+x_2^2.\n\\end{equation}\\] Weil die Definitionsmenge dieser Funktion zweidimensional ist, kann man zwei partielle Ableitungen berechnen \\[\\begin{equation}\\label{eq:pdex_1}\n\\frac{\\partial }{\\partial x_1}f:\\mathbb{R}^2 \\to \\mathbb{R},\nx\\mapsto \\frac{\\partial}{\\partial x_{1}} f(x)\n\\mbox{ und }\n\\frac{\\partial}{\\partial x_2} f:\\mathbb{R}^2\\to \\mathbb{R},\nx\\mapsto \\frac{\\partial }{\\partial x_2}f(x).\n\\end{equation}\\] Um die erste dieser partiellen Ableitungen zu berechnen, betrachtet man die Funktion \\[\\begin{equation}\nf_{x_2}:\\mathbb{R} \\to \\mathbb{R}, x_1 \\mapsto f_{x_2}(x_1):=x_1^2+x_2^2,\n\\end{equation}\\] wobei \\(x_2\\) hier die Rolle einer Konstanten einnimmt. Um explizit zu machen, dass \\(x_2\\) kein Argument der Funktion ist, die Funktion aber weiterhin von \\(x_2\\) abhängt haben wir die Subskriptnotation \\(f_{x_2}(x_1)\\) verwendet. Um nun die partielle Ableitung zu berechnen, berechnen wir die (einfache) Ableitung von \\(f_{x_2}\\), \\[\\begin{equation}\nf_{x_2}'(x)=2x_{1}.\n\\end{equation}\\] Es ergibt sich also \\[\\begin{equation}\n\\frac{\\partial}{\\partial x_1}f:\\mathbb{R}^2\\to \\mathbb{R},\nx\\mapsto \\frac{\\partial}{\\partial x_1}f(x)\n=\\frac{\\partial}{\\partial x_1}(x_1^2+x_2^2)\n=f_{x_2}'(x)=2x_1.\n\\end{equation}\\] Analog gilt mit der entsprechenden Formulierung von \\(f_{x_1}\\), dass \\[\\begin{equation}\n\\frac{\\partial}{\\partial x_2}f:\\mathbb{R}^2\\to \\mathbb{R},\nx\\mapsto \\frac{\\partial}{\\partial x_2}f(x)\n=\\frac{\\partial}{\\partial x_2}(x_1^2+x_2^2)\n=f_{x_1}'(x)=2x_2.\n\\end{equation}\\]\nWie bei der Ableitung einer univariaten reellwertigen Funktion ist es auch für eine multivariate reellwertige Funktion möglich, rekursiv eine höhere Ableitung zu definieren.\n\nDefinition 5.7 (Zweite partielle Ableitungen) \\(f: \\mathbb{R}^n \\to \\mathbb{R}\\) sei eine multivariate reellwertige Funktion und \\(\\frac{\\partial}{\\partial x_i}f\\) sei die partielle Ableitung von \\(f\\) nach \\(x_i\\). Dann ist die zweite partielle Ableitung von \\(f\\) nach \\(x_i\\) und \\(x_j\\) definiert als \\[\\begin{equation}\n\\frac{\\partial^2}{\\partial x_j x_i} f(x)\n:= \\frac{\\partial}{\\partial x_j}\\left(\\frac{\\partial}{\\partial x_i}f\\right).\n\\end{equation}\\]\n\nMan beachte, dass es zu jeder partiellen Ableitung \\(\\frac{\\partial}{\\partial x_i}f\\) für \\(i = 1,...,n\\) insgesamt \\(n\\) zweite partiellen Ableitungen \\(\\frac{\\partial^2}{\\partial x_j\\partial x_i}f\\) für \\(j = 1,...,n\\) gibt. Die so resultierenden \\(n^2\\) zweiten partiellen Ableitungen sind jedoch nicht alle verschieden. Dies ist eine wesentliche Aussage des Satzes von Schwarz\n\nTheorem 5.5 (Satz von Schwarz) \\(f: \\mathbb{R}^n \\to \\mathbb{R}\\) sei eine partiell differenzierbare multivariate reellwertige Funktion. Dann gilt \\[\\begin{equation}\n  \\frac{\\partial^2}{\\partial x_j\\partial x_i}f(x)\n= \\frac{\\partial^2}{\\partial x_i\\partial x_j}f(x)\n    \\mbox{ für alle }  1 \\le i,j \\le n.\n\\end{equation}\\]\n\nFür einen Beweis verweisen wir auf die weiterführende Literatur. Der Satz von Schwarz besagt insbesondere also auch, dass bei Bildung der zweiten partiellen Ableitungen die Reihenfolge des partiellen Ableitens irrelevant ist. Das Theorem erleichtert auf diese Weise die Berechnung von zweiten partiellen Ableitungen und hilft zudem, analytische Fehler bei der Berechnung zweiter partieller Ableitungen aufzudecken. Wir verdeutlichen dies in Fortführung obigen Beispiels.\nBeispiel (1)\nWir wollen die partiellen Ableitungen zweiter Ordnung der Funktion \\[\\begin{equation}\nf:\\mathbb{R}^{2}\\to \\mathbb{R}, x\\mapsto f(x):=x_1^2+x_2^2.\n\\end{equation}\\] berechnen. Mit den Ergebnissen für die partiellen Ableitungen erster Ordnung dieser Funktion ergibt sich \\[\\begin{align}\n\\begin{split}\n\\frac{\\partial^2}{\\partial x_1 x_1} f(x)\n& = \\frac{\\partial}{\\partial x_1}\\left(\\frac{\\partial}{\\partial x_1} f(x)\\right)\n  = \\frac{\\partial}{\\partial x_1}(2x_1)\n  = 2\n\\\\\n\\frac{\\partial^2}{\\partial x_1 x_2} f(x)\n& = \\frac{\\partial}{\\partial x_1}\\left(\\frac{\\partial}{\\partial x_2} f(x)\\right)\n  = \\frac{\\partial}{\\partial x_1}(2x_2)\n  = 0\n\\\\\n\\frac{\\partial^2}{\\partial x_2 x_1} f(x)\n& = \\frac{\\partial}{\\partial x_2}\\left(\\frac{\\partial}{\\partial x_1} f(x)\\right)\n  = \\frac{\\partial}{\\partial x_2}(2x_1)\n  = 0\n  \\\\\n\\frac{\\partial^2}{\\partial x_2 x_2} f(x)\n& = \\frac{\\partial}{\\partial x_2}\\left(\\frac{\\partial}{\\partial x_2} f(x)\\right)\n  = \\frac{\\partial}{\\partial x_2}(2x_2)\n  = 2\n\\end{split}\n\\end{align}\\] Offenbar gilt \\[\\begin{equation}\n\\frac{\\partial^2}{\\partial x_1 x_2} f(x) = \\frac{\\partial^2}{\\partial x_2 x_1} f(x).\n\\end{equation}\\]\nBeispiel (2)\nAls weiteres Beispiel wollen wird die partiellen Ableitungen erster und zweiter Ordnung der Funktion \\[\\begin{equation}\nf:\\mathbb{R}^{3}\\to \\mathbb{R}, x\\mapsto f(x):=x_1^2+x_1x_2+x_2\\sqrt{x_3}.\n\\end{equation}\\] berechnen. Mit den Rechenregeln für Ableitungen ergibt sich für die partiellen Ableitungen erster Ordnung \\[\\begin{align}\n\\begin{split}\n& \\frac{\\partial}{\\partial x_1}f(x)\n= \\frac{\\partial}{\\partial x_1}\\left(x_1^2+x_1x_2+x_2\\sqrt{x_3} \\right) = 2x_1+x_2,                   \\\\\n& \\frac{\\partial}{\\partial x_2}f(x)\n= \\frac{\\partial}{\\partial x_2}\\left(x_1^2+x_1x_2+x_2\\sqrt{x_3} \\right) = x_1+\\sqrt{x_3},             \\\\\n& \\frac{\\partial}{\\partial x_3}f(x)\n= \\frac{\\partial}{\\partial x_3}\\left(x_1^2+x_1x_2+x_2\\sqrt{x_3} \\right) = \\frac{x_{2}}{2\\sqrt{x_3}}.\n\\end{split}\n\\end{align}\\] Für die zweiten partiellen Ableitungen hinsichtlich \\(x_1\\) ergibt sich \\[\\begin{align}\n\\begin{split}\n    \\frac{\\partial^2}{\\partial x_1 \\partial x_1}f(x)\n& = \\frac{\\partial}{\\partial x_1} \\left(\\frac{\\partial}{\\partial x_1} f(x) \\right)\n  = \\frac{\\partial}{\\partial x_1}\\left(2x_1+x_2\\right) = 2, \\\\\n    \\frac{\\partial^2}{\\partial x_2\\partial x_1}f(x)\n& = \\frac{\\partial}{\\partial x_2} \\left(\\frac{\\partial}{\\partial x_1} f(x) \\right)\n  = \\frac{\\partial}{\\partial x_2}\\left(2x_1+x_2 \\right) = 1, \\\\\n    \\frac{\\partial^2}{\\partial x_3\\partial x_1} f(x)\n& = \\frac{\\partial}{\\partial x_3}\\left(\\frac{\\partial}{\\partial x_{1}} f(x) \\right)\n  = \\frac{\\partial}{\\partial x_3}\\left(2x_1+x_2\\right)=0.\n\\end{split}\n\\end{align}\\] Für die zweiten partiellen Ableitungen hinsichtlich \\(x_2\\) ergibt sich \\[\\begin{align}\n\\begin{split}\n    \\frac{\\partial^2}{\\partial x_1\\partial x_2}f(x)\n& = \\frac{\\partial}{\\partial x_1}\\left(\\frac{\\partial}{\\partial x_2}f(x) \\right)\n  = \\frac{\\partial}{\\partial x_{1}}\\left(x_1+ \\sqrt{x_3} \\right) = 1, \\\\\n    \\frac{\\partial^2}{\\partial x_2 \\partial x_2}f(x)\n& = \\frac{\\partial}{\\partial x_2}\\left(\\frac{\\partial}{\\partial x_2}f(x) \\right)\n  = \\frac{\\partial}{\\partial x_2}\\left(x_1 + \\sqrt{x_3} \\right) = 0, \\\\\n    \\frac{\\partial^2}{\\partial x_3\\partial x_2}f(x)\n& = \\frac{\\partial}{\\partial x_3}\\left(\\frac{\\partial}{\\partial x_2}f(x) \\right)\n  = \\frac{\\partial}{\\partial x_3}\\left(x_1+\\sqrt{x_3} \\right) =\\frac{1}{2\\sqrt{x_3}}.\n\\end{split}\n\\end{align}\\] Beispiel (2) Für die zweiten partiellen Ableitungen hinsichtlich \\(x_3\\) ergibt sich \\[\\begin{align}\n\\begin{split}\n    \\frac{\\partial^{2}}{\\partial x_1\\partial x_3}f(x)\n& = \\frac{\\partial}{\\partial x_1}\\left(\\frac{\\partial}{\\partial x_3} f(x) \\right)\n  = \\frac{\\partial}{\\partial x_1}\\left(\\frac{x_2}{2}\\sqrt{x_3}\\right) = 0, \\\\\n    \\frac{\\partial^2}{\\partial x_2\\partial x_3}f(x)\n& = \\frac{\\partial}{\\partial x_2}\\left(\\frac{\\partial}{\\partial x_3}f(x) \\right)\n  = \\frac{\\partial}{\\partial x_2}\\left(\\frac{x_2}{2 \\sqrt{x_3}} \\right)\n  = \\frac{1}{2\\sqrt{x_3}}, \\\\\n    \\frac{\\partial^2}{\\partial x_3 \\partial x_3}f(x)\n& = \\frac{\\partial}{\\partial x_3}\\left(\\frac{\\partial}{\\partial x_3}f(x) \\right)\n  = \\frac{\\partial}{\\partial x_3}\\left(x_2\\frac{1}{2}x_3^{-\\frac{1}{2}}\\right)\n  = -\\frac{1}{4}x_2x_3^{-\\frac{3}{2}}.\n\\end{split}\n\\end{align}\\] Weiterhin erkennt man, dass die Reihenfolge der partiellen Ableitungen irrelevant ist, denn es gilt \\[\\begin{align}\n\\begin{split}\n& \\frac{\\partial^{2}}{\\partial x_{1}\\partial x_{2}}f(x)\n= \\frac{\\partial^{2}}{\\partial x_{2}\\partial x_{1}}f(x) = 1, \\\\\n& \\frac{\\partial^{2}}{\\partial x_{1}\\partial x_{3}}f(x)\n= \\frac{\\partial^{2}}{\\partial x_{3}\\partial x_{1}}f(x) = 0, \\\\\n& \\frac{\\partial^{2}}{\\partial x_{2}\\partial x_{3}}f(x)\n= \\frac{\\partial^{2}}{\\partial x_{3}\\partial x_{2}}f(x) = \\frac{1}{2\\sqrt{x_3}}.\n\\end{split}\n\\end{align}\\]\nWie oben gesehen gibt es für eine multivariate reellwertige Funktion \\(f:\\mathbb{R}^n \\to \\mathbb{R}\\) insgesamt \\(n\\) erste partielle Ableitungen und \\(n^2\\) zweite partielle Ableitungen. Diese werden im Gradienten und der Hesse-Matrix einer multivariaten reellwertigen Funktion zusammengefasst.\n\nDefinition 5.8 (Gradient) \\(f : \\mathbb{R}^n \\to \\mathbb{R}\\) sei eine multivariate reellwertige Funktion. Dann ist der \\(\\nabla f(x)\\) von \\(f\\) an der Stelle \\(x \\in \\mathbb{R}^n\\) definiert als \\[\\begin{equation}\n\\nabla f(x) :=\n\\begin{pmatrix}\n\\frac{\\partial}{\\partial x_1} f(x)  \\\\\n\\frac{\\partial}{\\partial x_2} f(x)  \\\\\n\\vdots                                            \\\\\n\\frac{\\partial}{\\partial x_n} f(x)  \\\\\n\\end{pmatrix} \\in \\mathbb{R}^n.\n\\end{equation}\\]\n\nMan beachte, dass Gradienten multivariate vektorwertige Funktionen der \\[\\begin{equation}\n\\nabla f: \\mathbb{R}^n \\to \\mathbb{R}^n, x \\mapsto \\nabla f(x)\n\\end{equation}\\] sind. Für \\(n = 1\\) gilt \\(\\nabla f(x) = f'(x)\\). Eine wichtige Eigenschaften des Gradienten ist, dass \\(-\\nabla f(x)\\) die Richtung des steilsten Abstiegs von \\(f\\) in \\(\\mathbb{R}^n\\) anzeigt. Diese Einsicht ist aber nicht trivial und soll an späterer Stelle vertieft werden. Als Beispiele betrachten wir die Gradienten der oben analysierten Funktionen\nBeispiel (1)\nFür die in Beispiel (1) betrachtete Funktion \\(f: \\mathbb{R}^2 \\to \\mathbb{R}\\) gilt \\[\\begin{equation}\n\\nabla f(x) :=\n\\begin{pmatrix}\n\\frac{\\partial}{\\partial x_1} f(x)  \\\\\n\\frac{\\partial}{\\partial x_2} f(x)  \\\\\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n2x_1                    \\\\\n2x_2\n\\end{pmatrix}\n\\in \\mathbb{R}^2.\n\\end{equation}\\]\nIn Abbildung 5.5 visualisieren wir ausgewählte Werte dieses Gradienten für\n\n\n\nAbbildung 5.5: Exemplarische Gradientenwerte der bivariaten Funktion \\(f(x) = x_1^2 + x_2^2\\).\n\n\nBeispiel (2)\nFür die in Beispiel (2) betrachtete Funktion \\(f: \\mathbb{R}^3 \\to \\mathbb{R}\\) gilt \\[\\begin{equation}\n\\nabla f(x) :=\n\\begin{pmatrix}\n\\frac{\\partial}{\\partial x_1} f(x)  \\\\\n\\frac{\\partial}{\\partial x_2} f(x)  \\\\\n\\frac{\\partial}{\\partial x_3} f(x)  \\\\\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n2x_1+x_2                    \\\\\nx_1+\\sqrt{x_3}              \\\\\n\\frac{x_{2}}{2\\sqrt{x_3}}   \\\\\n\\end{pmatrix}\n\\in \\mathbb{R}^3.\n\\end{equation}\\]\nSchließlich widmen wir uns der Zusammenfassung der zweiten partiellen Ableitungen einer multivariaten reellwertigen Funktion in der Hesse-Matrix.\n\nDefinition 5.9 (Hesse-Matrix) \\(f : \\mathbb{R}^n \\to \\mathbb{R}\\) sei ein multivariate reellwertige Funktion. Dann ist die \\(\\nabla^2 f(x)\\) von \\(f\\) an der Stelle \\(x \\in \\mathbb{R}^n\\) definiert als \\[\\begin{equation}\n\\nabla^2 f(x) :=\n\\begin{pmatrix}\n    \\frac{\\partial^2}{\\partial x_1 x_1} f(x)\n&   \\frac{\\partial^2}{\\partial x_1 x_2} f(x)\n&   \\cdots\n&   \\frac{\\partial^2}{\\partial x_1 x_n} f(x)  \\\\\n    \\frac{\\partial^2}{\\partial x_2 x_1} f(x)\n&   \\frac{\\partial^2}{\\partial x_2 x_2} f(x)\n&   \\cdots\n&   \\frac{\\partial^2}{\\partial x_2 x_n} f(x)  \\\\\n    \\vdots\n&   \\vdots\n&   \\ddots\n&   \\vdots                                      \\\\\n    \\frac{\\partial^2}{\\partial x_n x_1} f(x)\n&   \\frac{\\partial^2}{\\partial x_n x_2} f(x)\n&   \\cdots\n&   \\frac{\\partial^2}{\\partial x_n x_n} f(x)  \\\\\n\\end{pmatrix} \\in \\mathbb{R}^{n \\times n}.\n\\end{equation}\\]\n\nMan beachte, dass Hesse-Matrizen multivariate matrixwertige Abbildungen der Form \\[\\begin{equation}\n\\nabla^2 f: \\mathbb{R}^n \\to \\mathbb{R}^{n\\times n}, x \\mapsto \\nabla^2 f(x)\n\\end{equation}\\] sind. Für \\(n = 1\\) gilt \\(\\nabla^2 f(x) = f''(x)\\). Weiterhin folgt aus \\[\\begin{equation}\n\\frac{\\partial^2}{\\partial x_i\\partial x_j}f(x) = \\frac{\\partial^2}{\\partial x_j\\partial x_i}f(x) \\mbox{ für } 1 \\le i,j\\le n\n\\end{equation}\\] dass die Hesse-Matrix symmetrisch ist, dass also \\[\\begin{equation}\n\\left(\\nabla^2f(x)\\right)^T = \\nabla^2f(x)\n\\end{equation}\\] gilt.\nBeispiel (1)\nFür die in Beispiel (1) betrachtete Funktion \\(f: \\mathbb{R}^2 \\to \\mathbb{R}\\) gilt \\[\\begin{equation}\n\\nabla^2 f(x)\n:=\n\\begin{pmatrix}\n\\frac{\\partial^2}{\\partial x_1x_1} f(x) & \\frac{\\partial^2}{\\partial x_1x_2}    f(x) \\\\\n\\frac{\\partial^2}{\\partial x_2x_1} f(x) & \\frac{\\partial^2}{\\partial x_2x_2}    f(x) \\\\\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n2 & 0   \\\\\n0 & 2   \\\\\n\\end{pmatrix}\n\\in \\mathbb{R}^{2 \\times 2}\n\\end{equation}\\] Die Hesse-Matrix dieser Funktion ist also eine konstante Funktion, die nicht von \\(x\\) abhängt.\nBeispiel (2)\nFür die in Beispiel (2) betrachtete Funktion \\(f: \\mathbb{R}^3 \\to \\mathbb{R}\\) gilt\n\\[\\begin{equation}\n\\nabla^2 f(x)\n:=\n\\begin{pmatrix}\n  \\frac{\\partial^2}{\\partial x_1x_1}  f(x)\n& \\frac{\\partial^2}{\\partial x_1x_2}    f(x)\n& \\frac{\\partial^2}{\\partial x_1x_3}    f(x)\n\\\\\n  \\frac{\\partial^2}{\\partial x_2x_1}  f(x)\n& \\frac{\\partial^2}{\\partial x_2x_2}    f(x)\n& \\frac{\\partial^2}{\\partial x_2x_3}    f(x)\n\\\\\n  \\frac{\\partial^2}{\\partial x_3x_1}  f(x)\n& \\frac{\\partial^2}{\\partial x_3x_2}    f(x)\n& \\frac{\\partial^2}{\\partial x_3x_3}    f(x)\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n  2\n& 1\n& 0\n\\\\\n  1\n& 0\n& \\frac{1}{2\\sqrt{3}}\n\\\\\n  0\n& \\frac{1}{2\\sqrt{3}}\n& -\\frac{1}{4}x_2x_3^{-3/2}\n\\end{pmatrix}.\n\\end{equation}\\] Im Gegensatz zu Beispiel (1) ist die Hesse-Matrix der hier betrachteten Funktion keine konstante Funktion und ihr Wert hängt vom Wert des Funktionsarguments \\(x \\in \\mathbb{R}^3\\) ab."
  },
  {
    "objectID": "105-Differentialrechnung.html#sec-selbskontrollfragen-differentialrechnung",
    "href": "105-Differentialrechnung.html#sec-selbskontrollfragen-differentialrechnung",
    "title": "5  Differentialrechnung",
    "section": "5.4 Selbstkontrollfragen",
    "text": "5.4 Selbstkontrollfragen\n\nGeben Sie die Definition des Begriffs der Ableitung \\(f'(a)\\) einer Funktion \\(f\\) an einer Stelle \\(a\\) wieder.\nGeben Sie die Definition des Begriffs der Ableitung \\(f'\\) einer Funktion \\(f\\).\nErläutern Sie die Symbole \\(f'(x), \\dot{f}(x)\\), \\(\\frac{df(x)}{dx}\\), und \\(\\frac{d}{dx}f(x)\\).\nGeben Sie die Definition des Begriffs der zweiten Ableitung \\(f''\\) einer Funktion \\(f\\) wieder.\nGeben Sie die Summenregel für Ableitungen wieder.\nGeben Sie die Produktregel für Ableitungen wieder.\nGeben Sie die Quotientenregel für Ableitungen wieder.\nGeben Sie die Kettenregel für Ableitungen wieder.\nBestimmen Sie die erste Ableitung der Funktion \\(f(x) := 3x^2 + \\exp\\left(-x^2\\right) - x \\ln(x)\\).\nBestimmen Sie die erste Ableitung der Funktion \\(f(x) :=\\frac{1}{2}\\sum_{i=1}^n (x_i - \\mu)^2\\) für \\(\\mu \\in \\mathbb{R}\\).\nGeben Sie die Definition der Begriffe des globalen und lokalen Maximums/Minimums einer univariaten reellwertigen Funktion wieder.\nGeben Sie die notwendige Bedingung für ein Extremum einer Funktion wieder.\nGeben Sie die hinreichende Bedingung für ein lokales Extremum einer Funktion wieder.\nGeben Sie das Standardverfahren der analytischen Optimierung wieder.\nBestimmen Sie einen Extremwert von \\(f(x) := \\exp\\left(-\\frac{1}{2}(x - \\mu)^2\\right)\\) für \\(\\mu \\in \\mathbb{R}\\).\nBerechnen Sie die partiellen Ableitungen der Funktion \\[\nf : \\mathbb{R}^2 \\to \\mathbb{R}, x \\mapsto f(x) := \\exp\\left(-\\frac{1}{2}\\left(x_1^2 + x_2^2\\right)\\right).\n\\tag{5.1}\\]\nBerechnen Sie die zweiten partiellen Ableitungen obiger Funktion \\(f\\).\nGeben Sie den Satz von Schwarz wieder.\nGeben Sie die Definition des Gradienten einer multivariaten reellwertigen Funktion wieder.\nGeben Sie den Gradienten der Funktion in Gleichung 5.1 an und werten Sie ihn in \\(x = (1,2)^T\\) aus.\nGeben Sie die Definition der Hesse-Matrix einer multivariaten reellwertigen Funktion wieder.\nGeben Sie die Hesse-Matrix der Funktion in Gleichung 5.1 an und werten Sie sie in \\(x = (1,2)^T\\) aus."
  },
  {
    "objectID": "106-Folgen-Grenzwerte-Stetigkeit.html#sec-folgen",
    "href": "106-Folgen-Grenzwerte-Stetigkeit.html#sec-folgen",
    "title": "6  Folgen, Grenzwerte, Stetigkeit",
    "section": "6.1 Folgen",
    "text": "6.1 Folgen\nWir beginnen mit der Definition des Begriffs der reellen Folge.\n\nDefinition 6.1 (Reelle Folge) Eine ist eine Funktion der Form \\[\\begin{equation}\nf : \\mathbb{N} \\to \\mathbb{R}, n \\mapsto f(n)\n\\end{equation}\\] Die Funktionswerte \\(f(n)\\) einer reellen Folge werden üblicherweise mit \\(x_n\\) bezeichnet und genannt. Übliche Schreibweisen für Folgen sind \\[\\begin{equation}\n(x_1,x_2,...)\n\\mbox{ oder }\n(x_n)_{n=1}^\\infty\n\\mbox{ oder }\n(x_n)_{n\\in \\mathbb{N}}\n\\mbox{ oder }\n(x_n).\n\\end{equation}\\]\n\nMan beachte, dass weil es unendlich viele natürliche Zahlen gibt, eine reelle Folge immer unendlich viele Folgenglieder hat. Dies sollte man sich insbesondere bei der Schreibweise \\((x_1,x_2,...)\\) bewusst machen. Wir wollen zwei Standardbeispiele für reelle Folgen betrachten.\nBeispiele für reelle Folgen\n\nReelle Folgen der Form \\[\\begin{equation}\nf : \\mathbb{N} \\to \\mathbb{R}, n \\mapsto f(n) := \\left(\\frac{1}{n}\\right)^{\\frac{p}{q}} \\mbox{ mit } p,q\\in \\mathbb{N}\n\\end{equation}\\] nennen wir harmonische Folgen. Für \\(p := q := 1\\) hat eine harmonische Folge die Folgengliederform \\[\\begin{equation}\n\\left(\\frac{1}{1}, \\frac{1}{2}, \\frac{1}{3}, ...\\right).\n\\end{equation}\\]\nReelle Folgen der Form \\[\\begin{equation}\nf : \\mathbb{N} \\to \\mathbb{R}, n \\mapsto f(n) := q^n \\mbox{ mit } q \\in ]-1,1[\n\\end{equation}\\] werden geometrische Folgen genannt. Für \\(q := \\frac{1}{2}\\) hat eine geometrische Folge die Folgengliederform \\[\\begin{align}\n\\begin{split}\n\\left(\\left(\\frac{1}{2}\\right)^1,\\left(\\frac{1}{2}\\right)^2,\\left(\\frac{1}{2}\\right)^3, ...\\right)    \n& = \\left(\\left(\\frac{1}{2}\\right)^1,\\left(\\frac{1}{2}\\right)^2,\\left(\\frac{1}{2}\\right)^3, ...\\right)\\\\\n& = \\left(\\frac{1^1}{2^1},\\frac{1^2}{2^2},\\frac{1^3}{2^3} ...\\right)                                  \\\\\n& = \\left(\\frac{1}{2},\\frac{1}{4},\\frac{1}{8} ...\\right)\n\\end{split}\n\\end{align}\\]\n\nNeben den reellen Folgen, die Folgen reeller Zahlen sind, kann man auch Folgen anderer mathematischer Objekte betrachten. Eine wichtige Folgenart sind die Funktionenfolgen.\n\nDefinition 6.2 (Funktionenfolge) Es sei \\(\\phi\\) eine Menge univariater reellwertiger Funktionen mit Definitionsmenge \\(D \\subseteq \\mathbb{R}\\). Dann ist eine Funktionenfolge eine Funktion der Form \\[\\begin{equation}\nF: \\mathbb{N} \\to \\phi, n \\mapsto F(n).\n\\end{equation}\\] Die Funktionswerte \\(F(n)\\) einer Funktionenfolgen werden üblicherweise mit \\(f_n\\) bezeichnet und genannt. Übliche Schreibweisen für Funktionenfolgen sind \\[\\begin{equation}\n(f_1,f_2,...)\n\\mbox{ oder }\n(f_n)_{n=1}^\\infty\n\\mbox{ oder }\n(f_n)_{n\\in \\mathbb{N}}\n\\mbox{ oder }\n(f_n).\n\\end{equation}\\]\n\nDie Definition einer Funktionenfolge ist offenbar analog zur Definition einer reellen Folge. Der Unterschied zwischen einer reellen Folge und einer Funktionenfolge ist, dass die Folgenglieder einer reellen Folge reelle Zahlen, die Folgenglieder einer Funktionenfolgen dagegen univariate reellwertige Funktionen sind. Auch hier wollen wir zwei Standardbeispiel diskutieren.\nBeispiele für Funktionenfolgen\n\nWir betrachten die Menge \\(\\phi\\) der univariaten reellwertigen Funktionen der Form \\[\\begin{equation}\n\\phi := \\{f_n|f_n : [0,1] \\to \\mathbb{R}, x \\mapsto f_n(x) := x^n \\mbox{ für } n \\in \\mathbb{N}\\}\n\\end{equation}\\] Dann definiert \\[\\begin{equation}\nF : \\mathbb{N} \\to \\phi, n\\mapsto F(n)\n\\end{equation}\\] eine Funktionenfolge. Für die Funktionswerte der Folgenglieder von \\(F\\) gilt \\[\\begin{equation}\nf_1(x) := x^1, f_2(x) := x^2,  f_3(x) := x^3, ...\n\\end{equation}\\]\nWir betrachten die Menge \\(\\phi\\) der univariaten reellwertigen Funktionen der Form \\[\\begin{equation}\n\\phi := \\{f_n|f_n : [-a,a] \\to \\mathbb{R}, x \\mapsto f_n(x) := \\sum_{k=0}^n \\frac{x^k}{k!} \\mbox{ für } n \\in \\mathbb{N}\\}\n\\end{equation}\\] Dann definiert \\[\\begin{equation}\nF : \\mathbb{N} \\to \\phi, n\\mapsto F(n)\n\\end{equation}\\] eine Funktionenfolge. Für die Funktionswerte der Folgenglieder von \\(F\\) gilt \\[\\begin{equation}\nf_1(x) := \\sum_{k=0}^1 \\frac{x^k}{k!}, f_2(x) := \\sum_{k=0}^2 \\frac{x^k}{k!},  f_3(x) := \\sum_{k=0}^3 \\frac{x^k}{k!}, ...\n\\end{equation}\\]"
  },
  {
    "objectID": "106-Folgen-Grenzwerte-Stetigkeit.html#sec-grenzwerte",
    "href": "106-Folgen-Grenzwerte-Stetigkeit.html#sec-grenzwerte",
    "title": "6  Folgen, Grenzwerte, Stetigkeit",
    "section": "6.2 Grenzwerte",
    "text": "6.2 Grenzwerte\nWenn man die Folgenglieder einer Folge betrachtet, kann man sich fragen, welche Werte eine Folge wohl annimmt, wenn der Folgenindex \\(n\\) sehr groß wird, also gegen unendlich strebt. Wenn in diesem Fall die Folgenglieder sehr ähnliche Werte annehmen (und nicht etwa auch unendlich groß werden), so ist man auf den Begriff des Grenzwerts für reelle Folgen bzw. der Grenzfunktion für Funktionenfolgen geführt.\n\nDefinition 6.3 (Grenzwert einer Folge) \\(x \\in \\mathbb{R}\\) heißt Grenzwert einer reellen Folge \\((x_n)_{n=1}^\\infty\\), wenn es zu jedem \\(\\epsilon&gt;0\\) ein \\(m \\in \\mathbb{N}\\) gibt, so dass \\[\\begin{equation}\n|x_n - x| &lt; \\epsilon \\mbox{ für alle } n \\ge m.\n\\end{equation}\\] Eine Folge, die einen Grenzwert besitzt, wird genannt, eine Folge die keinen Grenzwert besitzt, wird genannt. Dafür, dass \\(x \\in \\mathbb{R}\\) Grenzwert der Folge \\((x_n)_{n=1}^\\infty\\) ist, schreibt man auch \\[\\begin{equation}\n\\lim_{n \\to \\infty} x_n = x\n\\mbox{ oder }\nx_n \\to x \\mbox{ für } n \\to \\infty\n\\mbox{ oder }\nx_n\\xrightarrow[]{n \\to \\infty} x.\n\\end{equation}\\]\n\nDer Grenzwert einer Folge kann also, aber muss nicht existieren. So hat zum Beispiel die Folge \\[\\begin{equation}\nf : \\mathbb{N} \\to \\mathbb{R}, n \\mapsto f(n) := n\n\\end{equation}\\] keinen Grenzwert, da hier sowohl \\(n\\) als auch \\(f(n)\\) unendlich groß werden. Die oben betrachteten Beispiele für reelle Folgen dagegen haben Grenzwert. Dies ist Inhalt folgender Beispiele\nBeispiele\n\nFür die verallgemeinerten harmonischen Folgen gilt mit \\(p,q \\in \\mathbb{N}\\) \\[\n\\lim_{n\\to \\infty} \\left(\\frac{1}{n}\\right)^{\\frac{p}{q}} = 0.\n\\tag{6.1}\\]\nFür die geometrischen Folgen gilt mit \\(q \\in ]-1,1[\\) \\[\n\\lim_{n\\to \\infty} q^n = 0.\n\\tag{6.2}\\]\n\nMan nennt die harmonischen und geometrischen Folgen entsprechend auch Nullfolgen. Für Beweise von Gleichung 6.1 und Gleichung 6.2 verweisen wir auf die weiterführende Literatur. Tatsächlich sind diese Beweise nicht trivial und rühren an die Grundannahmen über das Wesen der reellen Zahlen. Wir visualisieren die ersten zehn Folgenglieder sowie die Grenzwerte der harmonischen Folge fr \\(p := q := 1\\) und der geometrischen Folge für \\(q := 1/2\\) in Abbildung 6.1.\n\n\n\nAbbildung 6.1: Beispiele für Grenzwerte reeller Folgen.\n\n\nFür Funktionenfolgen ist eine Möglichkeit der Erweiterung der Begriffe der Konvergenz und des Grenzwertes folgende.\n\nDefinition 6.4 (Punktweise Konvergenz und Grenzfunktion einer Funktionenfolge) \\(F = (f_n)_{n\\in \\mathbb{N}}\\) sei eine Funktionenfolge von univariaten reellwertigen Funktionen mit Definitionsbereich \\(D\\). \\(F\\) heißt , wenn die reelle Folge \\(\\left(f_n(x)\\right)_{n\\in \\mathbb{N}}\\) für jedes \\(x \\in D\\) eine konvergente Folge ist, also einen Grenzwert besitzt. Die Funktion, die jedem \\(x \\in D\\) diesen Grenzwert von \\(\\left(f_n(x)\\right)_{n\\in \\mathbb{N}}\\) zuordnet, heißt dann die und hat die Form \\[\\begin{equation}\nf : D \\to \\mathbb{R}, x \\mapsto f(x) := \\lim_{n\\to \\infty}f_n(x).\n\\end{equation}\\]\n\nMan beachte, dass die Grenzwerte von konvergenten reellen Folgen reelle Zahlen sind, die Grenzfunktionen von punktweise konvergenten Funktionenfolgen dagegen sind Funktionen. Neben der punktweisen Konvergenz von Funktionenfolgen gibt es noch den mächtigeren Begriff der gleichmäßigen Konvergenz von Funktionenfolgen, für den wir aber auf die weiterführende Literatur verweisen. Als Beispiel betrachten wir die Grenzfunktionen der oben diskutierten Funktionenfolgen, wobei wir für Beweise ebenfalls auf die weiterführende Literatur verweisen.\nBeispiele\n\nWir betrachten die Funktionenfolge \\[\\begin{equation}\nF : \\mathbb{N} \\to \\phi, n\\mapsto F(n)\n\\end{equation}\\] mit \\[\\begin{equation}\n\\phi := \\{f_n|f_n : [0,1] \\to \\mathbb{R}, x \\mapsto f_n(x) := x^n \\mbox{ für } n \\in \\mathbb{N}\\}\n\\end{equation}\\] Dann ist \\(F\\) punktweise konvergent mit Grenzfunktion \\[\\begin{equation}\nf : [0,1] \\to \\mathbb{R}, x \\mapsto f(x)\n:=\n\\begin{cases}\n0, & \\mbox{ für } x \\in [0,1[ \\\\\n1, & \\mbox{ für } x = 1       \\\\\n\\end{cases}\n\\end{equation}\\] da \\(f_n(x) := x^n\\) für \\(x \\in [0,1[\\) eine geometrische Folge und damit eine Nullfolge ist und \\(f_n(x) := x^n\\) für \\(x = 1\\) eine konstante Folge ist, für die alle Folgenglieder den Abstand \\(0\\) von \\(1\\) haben. Die Funktionenfolge \\(F\\) konvergiert also gegen eine Funktion, die auf dem gesamten Intervall \\([0,1]\\) gleich Null ist, außer im Punkt \\(1\\). Diese Funktion hat offenbar einen Sprung.\nWir betrachten die Funktionenfolge \\[\\begin{equation}\nF : \\mathbb{N} \\to \\phi, n\\mapsto F(n)\n\\end{equation}\\] mit \\[\\begin{equation}\n\\phi := \\{f_n|f_n : [-a,a] \\to \\mathbb{R}, x \\mapsto f_n(x) := \\sum_{k=0}^n \\frac{x^k}{k!} \\mbox{ für } n \\in \\mathbb{N}\\}\n\\end{equation}\\] Dann ist \\(F\\) punktweise konvergent mit Grenzfunktion \\[\\begin{equation}\nf : [-a,a] \\to \\mathbb{R}, x \\mapsto f(x)\n:= \\sum_{k=0}^\\infty \\frac{x^k}{k!}\n=: \\exp(x)\n\\end{equation}\\] Die Funktionenfolge \\(F\\) konvergiert also gegen die Exponentialfunktion auf \\([-a,a]\\). Umgekehrt betrachtet ist die Exponentialfunktion gerade durch \\[\\begin{equation}\n\\exp(x) :=  \\sum_{k=0}^\\infty \\frac{x^k}{k!}\n\\end{equation}\\] definiert.\n\n\n\n\nAbbildung 6.2: Beispiele für Grenzwerte von Funktionenfolgen"
  },
  {
    "objectID": "106-Folgen-Grenzwerte-Stetigkeit.html#stetigkeit",
    "href": "106-Folgen-Grenzwerte-Stetigkeit.html#stetigkeit",
    "title": "6  Folgen, Grenzwerte, Stetigkeit",
    "section": "6.3 Stetigkeit",
    "text": "6.3 Stetigkeit\nIn diesem Abschnitt versuchen wir uns dem Begriff der Stetigkeit einer Funktion zu nähern. Intuitiv ist eine Funktion stetig, wenn sie keine Sprünge hat oder äquivalent, wenn kleine Änderungen in ihren Argumenten stets nur zu kleinen Änderungen in ihren Funktionswerten (und damit eben keinen Sprüngen) führen. Zur Definition der Stetigkeit benötigen wir zunächst den Begriff des Grenzwertes einer Funktion.\n\nDefinition 6.5 (Grenzwert einer Funktion)  \nFür \\(D\\subseteq\\mathbb{R}\\) und \\(Z\\subseteq\\mathbb{R}\\) sei \\(f : D \\to Z, x \\mapsto f(x)\\) eine Funktion und es seien \\(a,b \\in \\mathbb{R}\\). \\(b\\) heißt , wenn\nWenn \\(b\\) Grenzwert der Funktion \\(f\\) für \\(x\\) gegen \\(a\\) ist, so schreibt man auch \\(\\lim_{x \\to a} f(x) = b\\).\n\nIn Abbildung 6.3 visualisieren wir den Grenzwert der Exponential funktion in \\(a = 1\\) durch Darstellung von Folgenglieder \\(x_n \\to 1\\) und den entsprechenden Folgengliedern \\(f(x_n)\\). Offenbar gilt \\(\\lim_{x\\to 1}\\exp(x) = e\\).\n\n\n\nAbbildung 6.3: Beispiele für einen Grenzwert einer Funktion\n\n\nWir können nun den Begriff der Stetigkeit einer Funktion definieren.\n\nDefinition 6.6 (Stetigkeit einer Funktion) Eine Funktion \\(f : D \\to Z\\) mit \\(D \\subseteq \\mathbb{R}, Z \\subseteq \\mathbb{R}\\) heißt , wenn \\[\\begin{equation}\n\\lim_{x\\to a} f(x) = f(a).\n\\end{equation}\\] Ist \\(f\\) in jedem \\(x \\in D\\) stetig, so heißt .\n\nMan beachte, dass für eine in \\(a\\) stetige Funktion folgt, dass \\[\\begin{equation}\n\\lim_{x \\to a} f(x) = f\\left(\\lim_{x\\to a} x\\right)\n\\end{equation}\\] Bei stetigen Funktion können also Grenzwertbildung und Auswertung der Funktion vertauscht werden."
  },
  {
    "objectID": "107-Integralrechnung.html#sec-unbestimmte-integrale",
    "href": "107-Integralrechnung.html#sec-unbestimmte-integrale",
    "title": "7  Integralrechnung",
    "section": "7.1 Unbestimmte Integrale",
    "text": "7.1 Unbestimmte Integrale\nWir beginnen mit der Definition des unbestimmen Integrals und dem Begriff der Stammfunktion.\n\nDefinition 7.1 (Unbestimmtes Integral und Stammfunktion) Für ein Intervall \\(I \\subseteq \\mathbb{R}\\) sei \\(f : I \\to \\mathbb{R}\\) eine univariate reellwertige Funktion. Dann heißt eine differenzierbare Funktion \\(F : I \\to \\mathbb{R}\\) mit der Eigenschaft \\[\\begin{equation}\nF' = f\n\\end{equation}\\] Stammfunktion von \\(f\\). Ist \\(F\\) eine Stammfunktion von \\(f\\), dann heißt \\[\\begin{equation}\n\\int f(x) \\,dx := F + c \\mbox{ mit } c \\in \\mathbb{R}\n\\end{equation}\\] unbestimmtes Integral der Funktion \\(f\\). Das unbestimmte Integral einer Funktion bezeichnet damit die Menge aller Stammfunktionen einer Funktion.\n\nObige Definition besagt, dass die Ableitung der Stammfunktion einer Funktion \\(f\\) eben \\(f\\) ist. Das unbestimmte Integral einer Funktion \\(f\\) ist darüber hinaus die Menge aller durch Addition verschiedener Konstanten \\(c \\in \\mathbb{R}\\) gegebenen Stammfunktionen von \\(f\\). Eine solche Konstante \\(c \\in \\mathbb{R}\\) heißt auch Integrationskonstante; es gilt natürlich \\(\\frac{d}{dx}c = 0\\). Das Symbol \\(\\int f(x) \\,dx\\) ist als \\(F + c\\) definiert. \\(f(x)\\) wird in diesem Ausdruck Integrand genannt.\n\\(\\int\\) und \\(\\,dx\\) haben keine eigentliche Bedeutung, sondern sind reine Symbole.\nFür die in vorherigen Abschnitten eingeführten elementaren Funktionen ergeben sich die in Tabelle aufgelisteten Stammfunktionen. Man überzeugt sich davon durch Ableiten der jeweiligen Stammfunktion mithilfe der Rechenregeln der Differentialrechnung. Die uneigentlichen Integrale dieser elementaren Funktionen ergeben sich dann direkt aus diesen Stammfunktionen durch Addition einer Integrationskonstanten.\n\n\n\nStammfunktionen elementarer Funktionen\n\n\n\n\n\n\n\nName\nDefinition\nStammfunktion\n\n\n\n\nPolynomfunktion\n\\(f(x) := \\sum_{i=0}^n a_ix^i\\)\n\\(F(x) = \\sum_{i=0}^n \\frac{a_i}{i+1}x^{i+1}\\)\n\n\nKonstante Funktion\n\\(f(x) := a\\)\n\\(F(x) = ax\\)\n\n\nIdentitätsfunktion\n\\(f(x) := x\\)\n\\(F(x) = \\frac{1}{2}x^2\\)\n\n\nLinear-affine Funktion\n\\(f(x) := ax + b\\)\n\\(F(x) = \\frac{1}{2}ax^2 + bx\\)\n\n\nQuadratfunktion\n\\(f(x) := x^2\\)\n\\(F(x) = \\frac{1}{3}x^3\\)\n\n\nExponentialfunktion\n\\(f(x) := \\exp(x)\\)\n\\(F(x) = \\exp(x)\\)\n\n\nLogarithmusfunktion\n\\(f(x) := \\ln(x)\\)\n\\(F(x) = x \\ln x - x\\)\n\n\n\n\n\nDie in nachfolgendem Theorem zusammengestellten Rechenregeln sind oft hilfreich, um Stammfunktionen von Funktionen zu bestimmen, die sich aus Funktionen mit bekannten Stammfunktionen zusammensetzen.\n\nTheorem 7.1 (Rechenregeln für Stammfunktionen) \\(f\\) und \\(g\\) seien univariate reellwertige Funktion, die Stammfunktionen besitzen, und \\(g\\) sei invertierbar. Dann gelten folgende Rechenregeln für die Bestimmung von Stammfunktionen\n\nSummenregel \\[\\begin{equation}\n\\int a f(x) + bg(x)\\,dx  = a\\int f(x)\\,dx + b\\int g(x)\\,dx \\mbox{ für } a,b \\in \\mathbb{R}\n\\end{equation}\\]\nPartielle Integration \\[\\begin{equation}\n\\int f'(x)g(x)\\,dx = f(x)g(x) - \\int f(x)g'(x)\\,dx\n\\end{equation}\\]\nSubstitionsregel \\[\\begin{equation}\n\\int f(g(x))g'(x)\\,dx = \\int f(t)\\,dt \\mbox{ mit } t  = g(x)\n\\end{equation}\\]\n\n\n\nBeweis. Für einen Beweis der Summenregel verweisen wir auf die weiterführende Literatur. Die Rechenregel der partiellen Integration ergibt sich durch Integration der Produktregel der Differentiation. Wir erinnern uns, dass gilt \\[\\begin{equation}\n(f(x)g(x))' = f'(x)g(x) + f(x)g'(x).\n\\end{equation}\\] Integration beider Seiten der Gleichung und Berücksichtigung der Summenregel für Stammfunktionen ergibt dann \\[\\begin{align}\n\\begin{split}\n\\smallint (f(x)g(x))' \\,dx & = \\smallint f'(x)g(x) + f(x)g'(x) \\,dx     \\\\\n\\Leftrightarrow\nf(x)g(x) & = \\smallint f'(x)g(x)\\,dx + \\smallint f(x)g'(x) \\,dx         \\\\\n\\Leftrightarrow\n\\smallint f'(x)g(x)\\,dx & = f(x)g(x) - \\smallint f(x)g'(x) \\,dx.\n\\end{split}\n\\end{align}\\] Die Substitutionsregel ergibt sich für \\(F' = f\\) durch Anwendung der Kettenregel der Differentiation auf die verkettete Funktion \\(F(g)\\). Speziell gilt zunächst \\[\\begin{align}\n\\begin{split}\n(F(g(x)))' = F'(g(x))g'(x) = f(g(x))g'(x).\n\\end{split}\n\\end{align}\\] Integration beider Seiten der Gleichung \\[\\begin{equation}\n(F(g(x))) ' = f(g(x))g'(x)\n\\end{equation}\\] ergibt dann \\[\\begin{align}\n\\begin{split}\n\\smallint (F(g(x)))' \\,dx  & = \\smallint f(g(x))g'(x) \\,dx              \\\\\n\\Leftrightarrow\nF(g(x)) + c & = \\smallint f(g(x))g'(x) \\,dx                          \\\\\n\\Leftrightarrow\n\\smallint f(g(x))g'(x) \\,dx & = \\smallint f(t)\\,dt  \\mbox{ mit } t := g(x).\n\\end{split}\n\\end{align}\\] Dabei ist die rechte Seite der letzten obigen Gleichung zu verstehen als \\(F(g(x)) + c\\), also als Stammfunktion von \\(f\\) evaluiert an der Stelle \\(t := g(x)\\). Das \\(dt\\) ist nicht durch \\(dg(x)\\) zu ersetzen, sondern rein notationeller Natur.\n\nUnbestimmte Integrale nehmen in der Lösung von Differentialgleichungen einen zentralen Platz ein. Naheliegender ist aber zunächst die Anwendung unbestimmter Integrale im Kontext der Auswertung bestimmter Integrale, wie im nächsten Abschnitt eingeführt."
  },
  {
    "objectID": "107-Integralrechnung.html#sec-bestimmte-integrale",
    "href": "107-Integralrechnung.html#sec-bestimmte-integrale",
    "title": "7  Integralrechnung",
    "section": "7.2 Bestimmte Integrale",
    "text": "7.2 Bestimmte Integrale\nAnschaulich entspricht ein bestimmtes Integral der vorzeichenbehafteten und auf ein Intervall \\([a,b]\\) beschränkten Fläche zwischen dem Graphen einer Funktion \\(f\\) und der \\(x\\)-Achse (vgl. Abbildung 7.1). Vorzeichenbehaftet heißt dabei, dass Flächen zwischen der \\(x\\)-Achse und positiven Werten von \\(f\\) positiv zur Fläche beitragen, Flächen zwischen der \\(x\\) und negativen Werten von \\(f\\) dagegen negativ. So ergeben sich zum Beispiel der Wert des in Abbildung 7.1 A gezeigten bestimmten Integral zu 0.68, der Wert des in Abbildung Abbildung 7.1 B gezeigten bestimmten Integrals zu 0.95 (die eingezeichnete Fläche ist offensichtlich größer als in Abbildung 7.1 A) und der Wert des in Abbildung 7.1 C gezeigten bestimmten Integrals zu 0 (die eingezeichneten positiven und negativen Flächen gleichen sich genau aus). Letzteres Beispiel legt auch die Interpretation des Integrals als Durchschnittswert einer Funktion \\(f\\) über einem Intervall \\([a,b]\\) nahe.\n\n\n\nAbbildung 7.1: Beispiele bestimmter Integrale\n\n\nUm den Begriff des bestimmten Integrals im Sinne des Riemannschen Integrals einführen zu können, müssen wir zunächst etwas Vorarbeit leisten. Wir beginnen damit, einen Begriff für die Aufteilung eines Intervalls in kleinere Abschnitte einzuführen.\n\nDefinition 7.2 (Zerlegung eines Intervalls und Feinheit) Es sei \\([a,b] \\subset \\mathbb{R}\\) ein Intervall und \\(x_0,x_1,x_2,...,x_n \\in [a,b]\\) eine Menge von Punkten mit \\[\\begin{equation}\na =: x_0 &lt; x_1 &lt;  x_2 \\cdots &lt; x_n := b\n\\end{equation}\\] und \\[\\begin{equation}\n\\Delta x_i := x_i - x_{i-1} \\mbox{ für } i = 1,...,n.\n\\end{equation}\\] Dann heißt die Menge \\[\\begin{equation}\nZ := \\{[x_0,x_1], [x_1,x_2], ..., [x_{n-1},x_n]\\}\n\\end{equation}\\] der durch \\(x_0,x_1,x_2,...,x_n\\) definierten Teilintervalle von \\([a,b]\\) eine Zerlegung von \\([a,b]\\). Weiterhin heißt \\[\\begin{equation}\nZ_{\\mbox{max}} := \\max_{i \\in n} \\Delta x_i,\n\\end{equation}\\] also die größte der Teilintervalllängen \\(\\Delta x_i\\), die Feinheit von \\(Z\\).\n\nAnschaulich ist \\(\\Delta x_i\\) die Breite der Rechtecke in Abbildung 7.2, wie wir in der Folge sehen werden. Mithilfe der Begriffe der Zerlegung eines Intervalls können wir nun den Begriff der Riemannschen Summen einführen.\n\nDefinition 7.3 (Riemannsche Summen) \\(f : [a,b] \\to \\mathbb{R}\\) sei eine beschränkte Funktion auf \\([a,b]\\), d.h. \\(|f(x)| &lt; c\\) für \\(0 &lt; c &lt; \\infty\\) und alle \\(x \\in [a,b]\\), \\(Z\\) sei eine Zerlegung von \\([a,b]\\) mit Teilintervalllängen \\(\\Delta x_i\\) für \\(i = 1,...,n\\). Weiterhin sei \\(\\xi_{i}\\) für \\(i = 1,...,n\\) ein beliebiger Punkt im Teilintervall \\([x_{i-1}, x_{i}]\\) der Zerlegung \\(Z\\). Dann heißt \\[\\begin{equation}\nR(Z) := \\sum_{i=1}^n f(\\xi_i)\\Delta x_i\n\\end{equation}\\] Riemannsche Summe von \\(f\\) auf \\([a,b]\\) bezüglich der Zerlegung \\(Z\\).\n\nWählt man zum Beispiel in der Riemannschen Summe in jedem Teilintervall das Maximum von \\(f\\), so ergibt sich die sogenannte Riemannsche Obersumme, \\[\\begin{equation}\nR_o(Z) := \\sum_{i=1}^n \\left(\\max_{[x_{i-1}, x_{i}]} f(\\xi_i) \\right)\\Delta x_i.\n\\end{equation}\\] Wählt man dagegen in jedem Teilintervall dagegen das Minimum von \\(f\\), so ergibt sich dies sogenannte Riemannsche Untersumme. \\[\\begin{equation}\nR_u(Z) := \\sum_{i=1}^n \\left(\\min_{[x_{i-1}, x_{i}]} f(\\xi_i) \\right)\\Delta x_i.\n\\end{equation}\\] Abbildung 7.2 verdeutlicht die Definition dieser Riemannschen Summen: die dunkelgrauen Rechtecke haben jeweils die Fläche \\([x_{i-1}, x_{i}] \\cdot \\min_{[x_{i-1}, x_{i}]} f(\\xi)\\) und bilden damit die Summenterme in der Riemannschen Untersumme \\[\\begin{equation}\nR_u(Z) := \\sum_{i=1}^4 \\left(\\min_{[x_{i-1}, x_{i}]} f(\\xi_i) \\right) \\cdot \\Delta x_i.\n\\end{equation}\\] Die vertikale Kombination aus dunkelgrauen und hellgrauen Rechtecken hat jeweils die Fläche \\([x_{i-1}, x_{i}] \\cdot \\max_{[x_{i-1}, x_{i}]} f(\\xi)\\) und bilden damit die Summenterme in der Riemannschen Obersumme \\[\\begin{equation}\nR_o(Z) := \\sum_{i=1}^4 \\left(\\max_{[x_{i-1}, x_{i}]} f(\\xi_i) \\right) \\cdot \\Delta x_i.\n\\end{equation}\\] Stellt man sich nun vor, dass man \\(\\Delta x_i\\) für alle \\(i = 1,...,n\\) gegen Null gehen lässt, verkleinert man die Feinheit der Zerlegung \\(Z\\) also immer weiter, so werden sich die Werte von \\(\\min_{[x_{i-1}, x_{i}]} f(\\xi_i)\\) und \\(\\max_{[x_{i-1}, x_{i}]} f(\\xi_i)\\) und damit auch die Werte von \\(R_u(Z)\\) und \\(R_o(Z)\\) immer weiter annähern. Diesen Grenzprozess macht man sich in der Definition des Riemannschen Integrals zunutze.\n\n\n\nAbbildung 7.2: Riemannsche Summen\n\n\n\nDefinition 7.4 (Bestimmtes Riemannsches Integral) \\(f : [a,b] \\to \\mathbb{R}\\) sei eine beschränkte reellwertige Funktion auf \\([a,b]\\). Weiterhin sei für \\(Z_k\\) mit \\(k = 1,2,3...\\) eine Folge von Zerlegungen von \\([a,b]\\) mit zugehörigen Feinheit \\(Z_{\\mbox{max},k}\\). Wenn für jede Folge von Zerlegungen \\(Z_1, Z_2,...\\) mit \\(|Z_{\\mbox{max},k}| \\to 0\\) für \\(k \\to \\infty\\) und für beliebig gewählte Punkte \\(\\xi_{ki}\\) mit \\(i = 1,...,n\\) im Teilintervall \\([x_{k,i-1}, x_{k,i}]\\) der Zerlegung \\(Z_k\\) gilt, dass die Folge der zugehörigen Riemannschen Summen \\(R(Z_1), R(Z_2), ...\\) gegen den gleichen Grenzwert strebt, dann heißt \\(f\\) auf \\([a,b]\\) integrierbar. Der entsprechende Grenzwert der Folge von Riemannschen Summen wird bestimmtes Riemannsches Integral genannt und mit \\[\\begin{equation}\n\\int_a^b f(x)\\,dx := \\lim_{k \\to \\infty} R(Z_k)\n\\mbox{ für } |Z_{\\mbox{max},k}| \\to 0\n\\end{equation}\\] bezeichnet. Die Werte \\(a\\) und \\(b\\) bezeichnet man in diesem Kontext als untere und obere Integrationsgrenzen, respektive, \\(f(x)\\) als Integrand und \\(x\\) als Integrationsvariable.\n\nDie Riemannsche Integrierbarkeit einer Funktion und der Wert eines bestimmten Riemannschen Integrals sind also im Sinne einer Grenzwertbildung definiert. Die Theorie der Riemannschen Integrale lässt sich allerding um die Hauptsätze der Differential- und Integralrechnung erweitern, so dass zur konkreten Berechnung eines bestimmten Integrals die Bildung von Zerlegungen und die Bestimmung eines Grenzwertes nur selten nötig ist. Der Einfachheit halber verzichten wir in der Folge auf die Bezeichungen Riemannsche und sprechen einfach von bestimmten Integralen.\nEin erster Schritt zur Vereinfachung der Berechnung von bestimmten Integralen ist das Feststellen folgender Rechenregeln, für deren Beweis wir auf die weiterführende Literatur verweisen.\n\nTheorem 7.2 (Rechenregeln für bestimmte Integrale) Es seien \\(f\\) und \\(g\\) integrierbare Funktionen auf \\([a,b]\\). Dann gelten folgende Rechenregeln.\n\nLinearität. Für \\(c_1,c_2\\in \\mathbb{R}\\) gilt \\[\\begin{equation}\n\\int_a^b (c_1 f(x) + c_2g(x))\\,dx = c_1 \\int_a^b f(x)\\,dx + c_2 \\int_a^b f(x)\\,dx.\n\\end{equation}\\]\nAdditivität. Für \\(a &lt; c &lt; b\\) gilt \\[\\begin{equation}\n\\int_a^b f(x)\\,dx = \\int_a^c f(x)\\,dx + \\int_c^b f(x)\\,dx.\n\\end{equation}\\]\nVorzeichenwechsel bei Umkehrung der Integralgrenzen \\[\\begin{equation}\n\\int_a^b f(x)\\,dx = - \\int_b^a f(x)\\,dx.\n\\end{equation}\\]\nUnabhängigkeit von der Wahl der Integrationsvariable \\[\\begin{equation}\n\\int_a^b f(x)\\,dx = \\int_a^b f(y)\\,dy.\n\\end{equation}\\]\nUnabhängigkeit des Integrals von Art des Intervalls. Es gilt \\[\\begin{equation}\n\\int_{a}^{b} f(x)\\,dx\n= \\int_{]a,b[}f(x)\\,dx\n= \\int_{[a,b[}f(x)\\,dx\n= \\int_{]a,b]}f(x)\\,dx\n= \\int_{[a,b]}f(x)\\,dx.\n\\end{equation}\\] wobei \\(\\int_I\\) das bestimmte Integral von \\(f\\) auf dem Intervall \\(I \\subseteq \\mathbb{R}\\) bezeichnet.\n\n\nEine graphische Darstellung der Rechenregel der Additivität findet sich in Abbildung 7.3. Die Summe der durch die bestimmten Integrale gegebenen Flächen \\(\\int_a^c f(x)\\,dx\\) und \\(\\int_c^b f(x)\\,dx\\) mit \\(a &lt; c &lt; b\\) ergibt sich dabei zur Fläche von \\(\\int_a^b f(x)\\,dx\\).\n\n\n\nAbbildung 7.3: Additivität bestimmter Integrale\n\n\nDie in der Nachfolge vermerkten Hauptsätze der Differential- und Integralrechnung schließlich, ermöglichen es, bestimmte Integrale einer Funktion \\(f\\) direkt mithilfe der Stammfunktion \\(F\\) von \\(f\\) zu berechnen.\n\nTheorem 7.3 (Erster Hauptsatz der Differential- und Integralrechnung) Ist \\(f : I \\to \\mathbb{R}\\) eine auf dem Intervall \\(I \\subset \\mathbb{R}\\) stetige Funktion, dann ist die Funktion \\[\\begin{equation}\nF :  I  \\to \\mathbb{R}, x \\mapsto F(x) := \\int_a^x f(t)\\,dt \\mbox{ mit } x,\na \\in I\n\\end{equation}\\] eine Stammfunktion von \\(f\\).\n\n\nBeweis. Wir betrachten den Differenzquotienten \\[\\begin{equation}\n\\frac{1}{h}(F(x+h) - F(x))\n\\end{equation}\\] Mit der Definition \\(F(x) := \\smallint_a^x f(t)\\,dt\\) und der Additivität des bestimmten Integrals gilt dann \\[\\begin{equation}\n\\frac{1}{h}(F(x+h) - F(x))\n= \\frac{1}{h}\\left(\\int_a^{x + h} f(t)\\,dt - \\int_a^{x} f(t)\\,dt\\right)\n= \\frac{1}{h} \\int_x^{x + h}f(t)\\,dt\n\\end{equation}\\] Mit dem Mittelwertsatz der Integralrechnung gibt es also ein \\(\\xi \\in ]x,x+h[\\), so dass \\[\\begin{equation}\n\\frac{1}{h}(F(x+h) - F(x)) = f(\\xi)\n\\end{equation}\\] Grenzwertbildung ergibt dann \\[\\begin{equation}\n\\lim_{h \\to 0}\\frac{1}{h}(F(x+h) - F(x)) = \\lim_{h \\to 0} f(\\xi) \\mbox{ für }\n\\xi \\in ]x, x + h[\n\\Leftrightarrow\nF'(x) = f(x).\n\\end{equation}\\]\n\nFür den Beweis des Ersten Hauptsatzes der Differential- und Integralrechnung benötigen wir offenbar den Mittelwertsatz der Integralrechnung, welchen wir hier ohne Beweis wiedergeben und in Abbildung 7.4 veranschaulichen.\n\nTheorem 7.4 (Mittelwertsatz der Integralrechnung) Für eine stetige Funktion \\(f : [a,b] \\to \\mathbb{R}\\) existiert ein \\(\\xi \\in ]a,b[\\) mit \\[\\begin{equation}\n\\int_a^b f(x)\\,dx = f(\\xi)(b-a)\n\\end{equation}\\]\n\nDer Mittelwertsatz der Integralrechnung garantiert die Existenz eines \\(\\xi \\in [a,b]\\), so dass das bestimmte Integral \\(\\int_a^b f(x)\\,dx\\) gleich dem Produkt aus der “Rechteckhöhe” \\(f(\\xi)\\) und und der “Rechteckbreite” \\((b-a)\\) ist. In Abbildung 7.4 liegt dieses \\(\\xi\\) genau mittig zwischen \\(a\\) und \\(b\\). Dass die sich so ergebene grau eingefärbte Rechteckfläche gleich \\(\\int_a^b f(x)\\,dx\\) ist, ergibt sich aus der visuell zumindest nachvollziebaren Tatsache, dass die Flächen zwischen \\(f(x)\\) und \\(f(\\xi)\\) im Intervall \\([a,\\xi]\\) und zwischen \\(f(\\xi)\\) und \\(f(x)\\) im Intervall \\([\\xi,b]\\) den gleichen Betrag haben, erstere aber mit einem negativen Vorzeichen behaftet ist. Der Mittelwertsatz der Integralrechnung garantiert im Allgemeinen aber nur die Existenz eines \\(\\xi \\in [a,b]\\) mit der diskutierten Eigenschaft, gibt aber keine Formel zu Bestimmung von \\(\\xi\\) an.\n\n\n\nAbbildung 7.4: Zum Mittelwertsatz der Integralrechnung\n\n\nDer Zweite Hauptsatz der Differential- und Integralrechnung schließlich besagt, wie man mithilfe der Stammfunktion ein bestimmtes Integral berechnet.\n\nTheorem 7.5 (Zweiter Hauptsatz der Differential- und Integralrechnung) Ist \\(F\\) eine Stammfunktion einer stetigen Funktion \\(f : I \\to \\mathbb{R}\\) auf einem Intervall \\(I\\), so gilt für \\(a,b \\in I\\) mit \\(a \\le b\\) \\[\\begin{equation}\n\\int_a^b f(x)\\,dx = F(b) - F(a) =: F(x)\\vert_a^b\n\\end{equation}\\]\n\n\nBeweis. Mit den Rechenregeln für bestimmte Integrale und dem ersten Hauptsatz der Differential- und Integralrechnung ergibt sich \\[\\begin{equation}\nF(b) - F(a) = \\int_\\alpha^b f(t)\\,dt - \\int_\\alpha^a f(t)\\,dt = \\int_a^b f(x)\\,dx\n\\end{equation}\\]\n\nWir wollen den Zweiten Haupsatz der Differential- und Integralrechnung in drei Beispielen anwenden (vgl. Abbildung 7.5).\n\n\n\nAbbildung 7.5: Beispiele zum Zweiten Hauptsatz der Differential- und Integralrechnung\n\n\nBeispiel (1)\nWir betrachten die Identitätsfunktion \\[\\begin{equation}\nf : \\mathbb{R} \\to \\mathbb{R}, x \\mapsto f(x) := x\n\\end{equation}\\] und wollen das bestimmte Integral dieser Funktion auf dem Intervall \\([0,1]\\), also \\[\\begin{equation}\n\\int_0^1 f(x)\\,dx = \\int_0^1 x \\,dx\n\\end{equation}\\] berechnen. Dazu erinnern wir uns, dass eine Stammfunktion von \\(f\\) durch \\[\\begin{equation}\nF : \\mathbb{R} \\to \\mathbb{R}, x \\mapsto F(x) := \\frac{1}{2}x^2\n\\end{equation}\\] gegeben ist, weil \\[\\begin{equation}\nF'(x) = \\frac{d}{dx}\\left(\\frac{1}{2}x^2 \\right) = 2 \\cdot \\frac{1}{2} x^{2-1} = x.\n\\end{equation}\\] Einsetzen in den Zweiten Hauptsatz der Differential- und Integralrechnung ergibt dann sofort \\[\\begin{equation}\n\\int_0^1 x \\,dx =\\frac{1}{2}1^2  - \\frac{1}{2}0^2 = \\frac{1}{2}.\n\\end{equation}\\] Dieses Ergebnis ist mit der Intuition, die sich anhand der grauen Fläche in Abbildung 7.5 A, ergibt kongruent.\nBeispiel (2)\nAls nächstes betrachten wird die Quadratfunktion \\[\\begin{equation}\nf : \\mathbb{R} \\to \\mathbb{R}, x \\mapsto f(x) := x^2\n\\end{equation}\\] und wollen das bestimmte Integral auch dieser Funktion auf dem Intervall \\([0,1]\\), also \\[\\begin{equation}\n\\int_0^1 f(x)\\,dx = \\int_0^1 x^2 \\,dx\n\\end{equation}\\] berechnen. Dazu erinnern wir uns, dass eine Stammfunktion von \\(f\\) durch \\[\\begin{equation}\nF : \\mathbb{R} \\to \\mathbb{R}, x \\mapsto F(x) := \\frac{1}{3}x^3\n\\end{equation}\\] gegeben ist, weil \\[\\begin{equation}\nF'(x) = \\frac{d}{dx}\\left(\\frac{1}{3}x^3 \\right) = 3 \\cdot \\frac{1}{3} x^{3-1} = x^2.\n\\end{equation}\\] Einsetzen in den Zweiten Hauptsatz der Differential- und Integralrechnung ergibt dann sofort \\[\\begin{equation}\n\\int_0^1 x^2 \\,dx =\\frac{1}{3}1^3  - \\frac{1}{3}0^3 = \\frac{1}{3}.\n\\end{equation}\\] Dieses Ergebnis ist mit der Intuition, die sich aus dem Vergleich der grauen Flächen in Abbildung 7.5 A und Abbildung 7.5 B ergibt, kongruent.\nBeispiel (3)\nSchließlich betrachten wir die lineare Funktion \\[\\begin{equation}\nf : \\mathbb{R} \\to \\mathbb{R}, x \\mapsto f(x) := -x + 1\n\\end{equation}\\] und wollen das bestimmte Integral auch dieser Funktion auf dem Intervall \\([0,2]\\), also \\[\\begin{equation}\n\\int_0^2 f(x)\\,dx = \\int_0^2 -x + 1 \\,dx\n\\end{equation}\\] berechnen. Dazu erinnern wir uns, dass eine Stammfunktion der linearen Funktion mit \\(a = -1\\) und \\(b = 1\\) (vgl. Tablle ) durch \\[\\begin{equation}\nF : \\mathbb{R} \\to \\mathbb{R}, x \\mapsto F(x) := -\\frac{1}{2}x^2 + x\n\\end{equation}\\] gegeben ist, weil \\[\\begin{equation}\nF'(x) = \\frac{d}{dx}\\left(-\\frac{1}{2}x^2 + x \\right) = - 2 \\cdot \\frac{1}{2} x^{2-1} + 1 \\cdot x^{1-1} = -x + 1.\n\\end{equation}\\] Einsetzen in den Zweiten Hauptsatz der Differential- und Integralrechnung ergibt dann sofort \\[\\begin{equation}\n\\int_0^2 -x + 1 \\,dx\n= \\left(-\\frac{1}{2}2^2 + 2 \\right) - \\left(-\\frac{1}{2}0^2 + 0 \\right).\n= -2 + 2 - 0\n= 0.\n\\end{equation}\\] Dieses Ergebnis ist mit der Intuition kongruent, dass sich die “positive” und die “negative” graue Fläche in Abbildung 7.5 C ausgleichen, kongruent."
  },
  {
    "objectID": "107-Integralrechnung.html#sec-uneigentliche-integrale",
    "href": "107-Integralrechnung.html#sec-uneigentliche-integrale",
    "title": "7  Integralrechnung",
    "section": "7.3 Uneigentliche Integrale",
    "text": "7.3 Uneigentliche Integrale\nUneigentliche Integrale sind bestimmte Integrale bei denen mindestens eine Integrationsgrenze keine reelle Zahl ist, sondern \\(-\\infty\\) oder \\(\\infty\\). Wir beleuchten die Natur uneigentlicher Integrale mit folgender Definition und einem Beispiel.\n\nDefinition 7.5 (Uneigentliche Integrale) \\(f : \\mathbb{R} \\to \\mathbb{R}\\) sei eine univariate reellwertige Funktion. Mit den Definitionen \\[\\begin{equation}\n\\int_{-\\infty}^b f(x)\\,dx := \\lim_{a \\to -\\infty} \\int_a^b f(x)\\,dx\n\\mbox{ und }\n\\int_a^\\infty f(x)\\,dx := \\lim_{b \\to \\infty} \\int_a^b f(x)\\,dx\n\\end{equation}\\] und der Additivität von Integralen \\[\\begin{equation}\n\\int_{-\\infty}^\\infty f(x)\\,dx = \\int_{-\\infty}^b f(x)\\,dx + \\int_b^{\\infty}f(x)\\,dx\n\\end{equation}\\] wird der Begriff des bestimmten Integrals auf die unbeschränkten Integrationsintervalle \\(]-\\infty,b]\\), \\([a,\\infty[\\) und \\(]-\\infty,\\infty[\\) erweitert. Integrale mit unbeschränkten Integrationsintervallen heißen uneigentliche Integrale. Wenn die entsprechenden Grenzwerte existieren, sagt man, dass die uneigentlichen Integrale konvergieren.\n\nAls Beispiel betrachten wir das uneigentliche Integral der Funktion \\[\\begin{equation}\nf : \\mathbb{R} \\to \\mathbb{R}, x \\mapsto f(x) \\frac{1}{x^2}\n\\end{equation}\\] auf dem Intervall \\([1, \\infty[\\), also \\[\\begin{equation}\n\\int_1^{\\infty} \\frac{1}{x^2}\\,dx.\n\\end{equation}\\] Nach den Festlegungen in der Definition uneigentlicher Integrale gilt \\[\\begin{equation}\n\\int_1^{\\infty} \\frac{1}{x^2}\\,dx = \\lim_{b \\to \\infty} \\int_1^b \\frac{1}{x^2}\\,dx.\n\\end{equation}\\] Mit der Stammfunktion \\(F(x) = -x^{-1}\\) von \\(f(x) = x^{-2}\\) ergibt sich für das bestimmte Integral in obiger Gleichung \\[\\begin{equation}\n\\int_1^b \\frac{1}{x^2}\\,dx\n= F(b) - F(1)\n= -\\frac{1}{b} - \\left(-\\frac{1}{1}\\right)\n= -\\frac{1}{b} + 1.\n\\end{equation}\\] Es ergibt sich also \\[\\begin{equation}\n\\int_1^{\\infty} \\frac{1}{x^2}\\,dx\n= \\lim_{b \\to \\infty} \\int_1^b \\frac{1}{x^2}\\,dx\n= \\lim_{b \\to \\infty}\\left(-\\frac{1}{b} + 1\\right)\n= - \\lim_{b \\to \\infty}\\frac{1}{b} + \\lim_{b \\to \\infty} 1\n= 0 + 1\n= 1.\n\\end{equation}\\]"
  },
  {
    "objectID": "107-Integralrechnung.html#sec-mehrdimensionale-integrale",
    "href": "107-Integralrechnung.html#sec-mehrdimensionale-integrale",
    "title": "7  Integralrechnung",
    "section": "7.4 Mehrdimensionale Integrale",
    "text": "7.4 Mehrdimensionale Integrale\nBisher haben wir nur Integrale univariater reellwertiger Funktionen betrachtet. Der Integralbegriff lässt sich auch auf multivariate reellwertige Funktionen erweitern. Allerdings ist dann der Integrationsbereich der Funktion nicht notwendigerweise so einfach zu beschreiben wie ein Intervall; insbesondere sind zum Beispiel schon im zweidimensionalen arbiträr geformte zweidimensionale Integrationsbereiche möglich. Wir wollen hier nun den einfachsten Fall eines Hyperrechtecks betrachten. In diesem Fall können wir mehrdimensionale bestimmte Integrale wie folgt definieren.\n\nDefinition 7.6 (Mehrdimensionale Integrale) \\(f : \\mathbb{R}^n \\to \\mathbb{R}\\) sei eine multivariate reellwertige Funktion. Dann heißen Integrale der Form \\[\\begin{equation}\n\\int\\limits_{[a_1,b_1]\\times \\cdots \\times [a_n,b_n]} f(x)\\,dx\n= \\int_{a_1}^{b_1} \\cdots \\int_{a_n}^ {b_n} f(x_1,...,x_n)\\,dx_1...\\,dx_n\n\\end{equation}\\] mehrdimensionale bestimmte Integrale auf Hyperrechtecken. Weiterhin heißen Integrale der Form \\[\\begin{equation}\n\\int_{\\mathbb{R}^n} f(x)\\,dx\n= \\int_{-\\infty}^{\\infty}  \\cdots \\int_{-\\infty}^{\\infty}\nf(x_1,...,x_n)\\,dx_1...\\,dx_n\n\\end{equation}\\] mehrdimensionale uneigentliche Integrale.\n\nWie schon erwähnt kann man multivariate reellwertige Funktion nicht nur auf Hyperrechtecken, sondern im Prinzip auf beliebigen Hyperflächen integrieren. Dies kann sich jedoch oft schwierig gestalten.\nAls Beispiel betrachten wir das zweidimensionale bestimmte Integral der Funktion \\[\\begin{equation}\nf : \\mathbb{R}^2 \\to \\mathbb{R}, (x_1,x_2) \\mapsto f(x_1,x_2) := x_1^2 + 4x_2\n\\end{equation}\\] auf dem Rechteck \\([0,1] \\times [0,1]\\). Der Satz von Fubini der Theorie mehrdimensionaler Integrale besagt, dass man mehrdimensionale Integrale in beliebiger Koordinatenfolge auswerten kann. Es gilt also zum Beispiel, dass \\[\\begin{equation}\n\\int_{a_1}^{b_1} \\left(\\int_{a_2}^{b_2} f(x_1,x_2)\\,dx_2\\right) \\,dx_1\n= \\int_{a_2}^{b_2} \\left(\\int_{a_1}^{b_1} f(x_1,x_2)\\,dx_1 \\right) \\,dx_2.\n\\end{equation}\\] In diesem Sinne betrachten wir für das Beispiel \\[\\begin{equation}\n\\int_0^1 \\int_0^1 x_1^2 + 4x_2 \\,dx_1\\,dx_2\n= \\int_0^1 \\left(\\int_0^1 x_1^2 + 4x_2 \\,dx_1\\right)\\,dx_2\n\\end{equation}\\] also zunächst das innere Integral. \\(x_2\\) nimmt dabei die Rolle einer Konstanten ein. Eine Stammfunktion von \\(g(x_1) := x_1^2 +4 x_2\\) ist \\(G(x_1) = \\frac{1}{3}x_1^3 + 4x_2x_1\\), wie man sich durch Ableiten von \\(G\\) überzeugt. Es ergibt sich also für das innere Integral \\[\\begin{align}\n\\begin{split}\n\\int_0^1 x_1^2 + 4x_2 \\,dx_1\n& = G(1) - G(0) \\\\\n& = \\frac{1}{3}\\cdot1^3 + 4x_2\\cdot 1 - \\frac{1}{3}\\cdot 0^3 - 4x_2\\cdot 0 \\\\\n& = \\frac{1}{3} + 4x_2.\n\\end{split}\n\\end{align}\\] Betrachten des äußeren Integrals ergibt dann mit der Stammfunktion \\[\\begin{equation}\nH(x_2) = \\frac{1}{3}x_2 + 2x_2^2\n\\end{equation}\\] von \\[\\begin{equation}\nh(x_2) := \\frac{1}{3} + 4x_2,\n\\end{equation}\\] dass \\[\\begin{align}\n\\begin{split}\n\\int_0^1 \\int_0^1 x_1^2 + 4x_2 \\,dx_1\\,dx_2\n& = \\int_0^1 \\frac{1}{3} + 4x_2 \\,dx_2                                          \\\\\n& = H(1) - H(0)                                                                 \\\\\n& = \\frac{1}{3}\\cdot 1 + 4\\cdot 1^2 - \\frac{1}{3}\\cdot 0 + 4\\cdot 0^2           \\\\\n& = \\frac{13}{3}.\n\\end{split}\n\\end{align}\\]"
  },
  {
    "objectID": "107-Integralrechnung.html#sec-selbstkontrollfragen-integralrechnung",
    "href": "107-Integralrechnung.html#sec-selbstkontrollfragen-integralrechnung",
    "title": "7  Integralrechnung",
    "section": "7.5 Selbstkontrollfragen",
    "text": "7.5 Selbstkontrollfragen\n\nGeben Sie die Definition des Begriffs der Stammfunktion wieder.\nGeben Sie die Definition des Begriffs des unbestimmten Integrals wieder.\nErläutern Sie die intuitive Bedeutung des Begriff des Riemannschen Integrals.\nGeben Sie den ersten Hauptsatz der Differential- und Integralrechnung wieder.\nGeben Sie den zweiten Hauptsatz der Differential- und Integralrechnung wieder.\nErläutern Sie den Begriff des uneigentlichen Integrals.\nErläutern Sie den Begriff des mehrdimensionalen Integrals."
  },
  {
    "objectID": "108-Vektoren.html#sec-reeller-vektorraum",
    "href": "108-Vektoren.html#sec-reeller-vektorraum",
    "title": "8  Vektoren",
    "section": "8.1 Reeller Vektorraum",
    "text": "8.1 Reeller Vektorraum\nWir beginnen mit der allgemeinen Definition eines Vektorraums, die grundlegende Regeln zum Rechnen mit Vektoren festlegt.\n\nDefinition 8.1 (Vektorraum) Es seien \\(V\\) eine nichtleere Menge und \\(S\\) eine Menge von Skalaren. Weiterhin sei eine Abbildung \\[\\begin{equation}\n+ : V \\times V \\to V, (v_1,v_2) \\mapsto +(v_1, v_2) =: v_1 + v_2,\n\\end{equation}\\] genannt Vektoraddition, definiert. Schließlich sei eine Abbildung \\[\\begin{equation}\n\\cdot : S \\times V \\to V, (s,v) \\mapsto \\cdot(s,v) =: sv,\n\\end{equation}\\] genannt Skalarmultiplikation definiert. Dann wird das Tupel \\((V,S,+,\\cdot)\\) genau dann Vektorraum genannt, wenn für beliebige Elemente \\(v,w,u\\in V\\) und \\(a,b \\in S\\) folgende Bedingungen gelten:\n(1) Kommutativität der Vektoraddition. \\[\nv + w = w + v.\n\\] (2) Assoziativität der Vektoraddition. \\[\n(v + w) + u = v + (w + u)\n\\] (3) Existenz eines neutralen Elements der Vektoraddition. \\[\n\\mbox{Es gibt einen Vektor } 0 \\in V \\mbox{ mit } v + 0 = 0 + v = v.\n\\] (4) Existenz inverser Elemente der Vektoraddition \\[\n\\mbox{Für alle Vektoren } v \\in V \\mbox{ gibt es einen Vektor } -v \\in V \\mbox{ mit } v + (-v) = 0.\n\\] (5) Existenz eines neutralen Elements der Skalarmultiplikation. \\[\n\\mbox{Es gibt einen Skalar } 1 \\in S \\mbox{ mit } 1 \\cdot v = v.\n\\] (6) Assoziativität der Skalarmultiplikation. \\[\na \\cdot (b \\cdot c) = (a \\cdot b)\\cdot c.\n\\] (7) Distributivität hinsichtlich der Vektoraddition. \\[\na\\cdot (v + w) = a\\cdot v + a \\cdot w.\n\\] (8) Distributivität hinsichtlich der Skalaraddition. \\[\n(a + b)\\cdot v = a\\cdot v + b\\cdot v.\n\\]\n\nEs fällt auf, dass Definition 8.1 zwar festlegt, wie mit Vektoren gerechnet werden soll, jedoch keine Aussage darüber macht, was ein Vektor, über ein ein Element einer Menge hinaus, eigentlich ist. Dies ist der Tatsache geschuldet, dass es verschiedenste mathematische Objekte gibt, für die Vektorraumstrukturen definiert werden können. Beispiele dafür sind die Menge der reellen \\(m\\)-Tupel, die Menge der Matrizen, die Menge der Polynome, die Menge der Lösungen eines linearen Gleichungssystems, die Menge der reellen Folgen, die Menge der stetigen Funktionen u.v.a.m.\nWir sind hier zunächst nur am Vektorraum der Menge reellen \\(m\\)-Tupel interessiert. Wir erinnern dazu daran, dass wir die reellen \\(m\\)-Tupel mit \\[\\begin{equation}\n\\mathbb{R}^m := \\left\\lbrace \\begin{pmatrix} x_1 \\\\ \\vdots \\\\ x_m \\end{pmatrix} | x_i \\in \\mathbb{R} \\mbox{ für alle } 1 \\le i \\le m \\right\\rbrace\n\\end{equation}\\] bezeichnen und \\(\\mathbb{R}^m\\) als “\\(\\mathbb{R}\\) hoch m” aussprechen. Die Elemente \\(x \\in \\mathbb{R}^m\\) nennen wir reelle Vektoren oder auch einfach Vektoren. Wir wollen nun der Definition eines Vektorraums die Menge \\(\\mathbb{R}^m\\) zugrunde legen. Dazu definieren wir zunächst die Vektoraddition für Elemente von \\(\\mathbb{R}^m\\) und die Skalarmultiplikation für Elemente von \\(\\mathbb{R}\\) und \\(\\mathbb{R}^m\\)\n\nDefinition 8.2 (Vektoraddition und Skalarmultiplikation in \\(\\mathbb{R}^m\\)) Für alle \\(x,y \\in \\mathbb{R}^m\\) und \\(a \\in \\mathbb{R}\\) sei die Vektoraddition durch \\[\\begin{equation}\n+ : \\mathbb{R}^m \\times \\mathbb{R}^m \\to \\mathbb{R}^m, (x,y) \\mapsto x + y =\n\\begin{pmatrix}\nx_1 \\\\ \\vdots \\\\ x_m\n\\end{pmatrix}\n+\n\\begin{pmatrix}\ny_1 \\\\ \\vdots \\\\ y_m\n\\end{pmatrix}\n:=\n\\begin{pmatrix}\nx_1 + y_1 \\\\ \\vdots \\\\ x_m + y_m\n\\end{pmatrix}\n\\end{equation}\\] und die Skalarmultiplikation durch \\[\\begin{equation}\n\\cdot : \\mathbb{R} \\times \\mathbb{R}^m \\to \\mathbb{R}^m, (a,x) \\mapsto\nax =\na\n\\begin{pmatrix}\nx_1  \\\\ \\vdots \\\\ x_m\n\\end{pmatrix}\n:=\n\\begin{pmatrix}\nax_1  \\\\ \\vdots \\\\a x_m\n\\end{pmatrix}\n\\end{equation}\\] definiert.\n\nEs ergibt sich dann folgendes Resultat.\n\nTheorem 8.1 (Reeller Vektorraum) \\((\\mathbb{R}^m,+,\\cdot)\\) mit den Rechenregeln der Addition und Multiplikation in \\(\\mathbb{R}\\) einen Vektorraum.\n\nFür einen Beweis, auf den wir hier verzichten wollen, muss man die Bedingungen (1) bis (8) aus Definition 8.1 für die hier betrachtete Menge und die hier festgelegten Formen der Vektoraddition und der Skalarmultiplikation nachweisen. Diese ergeben sich aber leicht aus den Rechenregeln von Addition und Multiplikation in \\(\\mathbb{R}\\) und der Tatsache, dass Vektoraddition und Skalarmultiplikation für Elemente von \\(\\mathbb{R}^m\\) in Definition 8.2 komponentenweise definiert wurden. Wir definieren damit den Begriff des reellen Vektorraums.\n\nDefinition 8.3 (Reeller Vektorraum) Für \\(\\mathbb{R}^m\\) seien \\(+\\) und \\(\\cdot\\) die in Definition 8.2 definierte Vektoraddition und Skalarmultiplikation. Dann nennen wir auf Grundlage von Theorem 8.1 den Vektorraum \\((\\mathbb{R}^m,+,\\cdot)\\) den reellen Vektorraum\n\nAuf Grundlage von Definition 8.3 wollen wir uns nun das Rechnen mit reellen Vektoren anhand einiger Beispiele verdeutlichen.\nBeispiele\n(1) Für\n\\[\nx:=\n\\begin{pmatrix}\n1 \\\\ 2 \\\\ 3 \\\\ 4\n\\end{pmatrix}\n\\in \\mathbb{R}^4\n\\mbox{ und }\ny:=\n\\begin{pmatrix}\n2 \\\\ 1 \\\\ 0 \\\\ 1\n\\end{pmatrix}\n\\in \\mathbb{R}^4\n\\] gilt \\[\nx + y\n=\n\\begin{pmatrix}\n1 \\\\ 2 \\\\ 3 \\\\ 4\n\\end{pmatrix}\n+\n\\begin{pmatrix}\n2 \\\\ 1 \\\\ 0 \\\\ 1\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n1 + 2 \\\\ 2 + 1 \\\\ 3 + 0\\\\ 4 + 1\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n3 \\\\ 3\\\\ 3 \\\\ 5\n\\end{pmatrix}\n\\in \\mathbb{R}^4.\n\\] In R implementiert dieses Beispiel wie folgt\n\nx = matrix(c(1,2,3,4), nrow = 4)      # Vektordefinition\ny = matrix(c(2,1,0,1), nrow = 4)      # Vektordefinition\nx + y                                 # Vektoraddition\n\n     [,1]\n[1,]    3\n[2,]    3\n[3,]    3\n[4,]    5\n\n\n(2) Für \\[\nx:=\n\\begin{pmatrix}\n2 \\\\ 3\n\\end{pmatrix}\n\\in \\mathbb{R}^2\n\\mbox{ und }\ny:=\n\\begin{pmatrix}\n1 \\\\ 3 \\\n\\end{pmatrix}\n\\in \\mathbb{R}^2\n\\] gilt \\[\nx - y\n=\n\\begin{pmatrix}\n2 \\\\ 3\n\\end{pmatrix}\n-\n\\begin{pmatrix}\n1 \\\\ 3\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n2 - 1 \\\\ 3 - 3\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n1 \\\\ 0\n\\end{pmatrix}\n\\in \\mathbb{R}^2.\n\\] In R implementiert man dieses Beispiel wie folgt \n\nx = matrix(c(2,3), nrow = 2)         # Vektordefinition\ny = matrix(c(1,3), nrow = 2)         # Vektordefinition\nx - y                                # Vektorsubtraktion\n\n     [,1]\n[1,]    1\n[2,]    0\n\n\n(3) Für \\[\nx:=\n\\begin{pmatrix}\n2 \\\\ 1 \\\\ 3\n\\end{pmatrix}\n\\in \\mathbb{R}^3\n\\mbox{ und }\na := 3 \\in \\mathbb{R}\n\\] gilt \\[\nax\n=\n3\n\\begin{pmatrix}\n2 \\\\ 1 \\\\ 3\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n3 \\cdot 2 \\\\ 3 \\cdot 1 \\\\ 3 \\cdot 3\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n6 \\\\ 3 \\\\ 9\n\\end{pmatrix}\n\\in \\mathbb{R}^3.\n\\] In R implementiert man dieses Beispiel wie folgt \n\nx = matrix(c(2,1,3), nrow = 3)       # Vektordefinition\na = 3                                # Skalardefinition\na*x                                  # Skalarmultiplikation\n\n     [,1]\n[1,]    6\n[2,]    3\n[3,]    9\n\n\nFür \\(m \\in \\{1,2,3\\}\\) kann man sich reelle Vektoren und das Rechnen mit ihnen visuell veranschaulichen. Für \\(m &gt; 3\\), wenn also zum Beispiel für eine Person mehr als drei quantitative Merkmale zu ihrem Gesundheitszustand vorliegen, was in der Anwendung regelmäßig der Fall ist, ist dies nicht möglich. Trotzdem mag die visuelle Intuition für \\(m \\le 3\\) einen Einstieg in das Verständnis von Vektorräumen erleichtern. Wir fokussieren hier auf den Fall \\(m := 2\\). In diesem Fall liegen die betrachteten reellen Vektoren in der zweidimensionalen Ebene und werden üblicherweise als Punkte oder Pfeile visualisiert (Abbildung 8.1).\n\n\n\nAbbildung 8.1: Visualisierung von Vektoren in \\(\\mathbb{R}^2\\)\n\n\nAbbildung 8.2 visualisiert die Vektoraddition \\[\\begin{equation}\n\\begin{pmatrix}\n1 \\\\ 2\n\\end{pmatrix}\n+\n\\begin{pmatrix}\n3 \\\\ 1\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n4 \\\\ 3\n\\end{pmatrix}.\n\\end{equation}\\] Der Summenvektor entspricht dabei der Diagonale des von den beiden Summanden aufgespannten Parallelogramms.\n\n\n\nAbbildung 8.2: Vektoraddition in \\(\\mathbb{R}^2\\)\n\n\nAbbildung 8.3 visualisiert die Vektorsubtraktion \\[\\begin{equation}\n\\begin{pmatrix}\n1 \\\\ 2\n\\end{pmatrix}\n-\n\\begin{pmatrix}\n3 \\\\ 1\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n1 \\\\ 2\n\\end{pmatrix}\n+\n\\begin{pmatrix}\n-3 \\\\ -1\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n-2 \\\\ \\,\\, 1\n\\end{pmatrix}\n\\end{equation}\\] Der resultierende Vektor entspricht dabei der Diagonale des von dem ersten Vektors und dem entgegensetzten Vektor des zweiten Vektors aufgespannten Parallelogramms.\n\n\n\nAbbildung 8.3: Vektorsubtraktion in \\(\\mathbb{R}^2\\)\n\n\nAbbildung 8.4 schließlich visualisiert die Skalarmultiplikation \\[\\begin{equation}\n3\n\\begin{pmatrix}\n1 \\\\ 1\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n3 \\\\ 3\n\\end{pmatrix}\n\\end{equation}\\] Die Multiplikation eines Vektors mit einem Skalar ändert dabei immer nur seine Länge, nicht jedoch seine Richtung.\n\n\n\nAbbildung 8.4: Skalarmultiplikation in \\(\\mathbb{R}^2\\)"
  },
  {
    "objectID": "108-Vektoren.html#sec-euklidischer-vektorraum",
    "href": "108-Vektoren.html#sec-euklidischer-vektorraum",
    "title": "8  Vektoren",
    "section": "8.2 Euklidischer Vektorraum",
    "text": "8.2 Euklidischer Vektorraum\nDer reelle Vektorraum kann durch Definition des Skalarprodukts im Sinne eines Euklidischen Vektorraums mit räumlich-geometrischer Intuition versehen werden. Diese ermöglicht es insbesondere, Begriffe wie die Länge eines Vektors, den Abstand zwischen zwei Vektoren, und nicht zuletzt den Winkel zwischen zwei Vektoren zu definieren und zu berechnen. Wir führen zunächst das Skalarprodukt ein.\n\nDefinition 8.4 (Skalarprodukt auf \\(\\mathbb{R}^m\\)) Das Skalarprodukt auf \\(\\mathbb{R}^m\\) ist definiert als die Abbildung \\[\\begin{equation}\n\\langle \\rangle : \\mathbb{R}^m \\times \\mathbb{R}^m \\to \\mathbb{R},\n(x,y) \\mapsto \\langle (x,y) \\rangle := \\langle x,y \\rangle := \\sum_{i=1}^m x_i y_i.\n\\end{equation}\\]\n\nDas Skalarprodukt heißt Skalarprodukt, weil es einen Skalar ergibt, nicht etwa, weil mit Skalaren multipliziert wird. Das Skalarprodukt steht in enger Beziehung zum Matrixprodukt, wie wir an späterer Stelle sehen werden. Wir betrachten zunächst ein Beispiel und seine Implementation in R.\nBeispiel\nEs seien \\[\\begin{equation}\nx :=\n\\begin{pmatrix}\n1 \\\\ 2 \\\\ 3\n\\end{pmatrix}\n\\mbox{ und }\ny :=\n\\begin{pmatrix}\n2 \\\\ 0 \\\\ 1\n\\end{pmatrix}\n\\end{equation}\\] Dann ergibt sich \\[\\begin{equation}\n\\langle x,y \\rangle\n= x_1y_1 + x_2y_2 + x_3y_3\n= 1 \\cdot 2 + 2 \\cdot 0 + 3 \\cdot 1\n= 2 + 0 + 3\n= 5.\n\\end{equation}\\]\nIn R gibt es verschiedene Möglichkeiten, ein Skalarprodukt auszuwerten. Wir führen zwei von ihnen für das gebebene Beispiel untenstehend auf.\n\n# Vektordefinitionen\nx = matrix(c(1,2,3), nrow = 3)\ny = matrix(c(2,0,1), nrow = 3)\n\n# Skalarprodukt mithilfe von R's komponentenweiser Multiplikation und sum() Funktion\nsum(x*y)\n\n[1] 5\n\n# Skalarprodukt mithilfe von R's Matrixtransposition und -multiplikation\nt(x) %*% y\n\n     [,1]\n[1,]    5\n\n\nMithilfe des Skalarprodukts kann der Begriff des reellen Vektorraums zum Begriff des reellen kanonischen Euklidischen Vektorraums erweiter werden.\n\nDefinition 8.5 (Euklidischer Vektorraum) Das Tupel \\(\\left((\\mathbb{R}^m, +, \\cdot), \\langle \\rangle \\right)\\) aus dem reellen Vektorraum \\((\\mathbb{R}^m, +, \\cdot)\\) und dem Skalarprodukt \\(\\langle \\rangle\\) auf \\(\\mathbb{R}^m\\) heißt reeller kanonischer Euklidischer Vektorraum.\n\nGenerell heißt jedes Tupel aus einem Vektorraum und einem Skalarprodukt “Euklidischer Vektorraum”. Informell sprechen wir aber oft auch einfach von \\(\\mathbb{R}^m\\) als “Euklidischer Vektorraum” und insbesondere bei \\(\\left((\\mathbb{R}^m, +, \\cdot), \\langle \\rangle \\right)\\) vom “Euklidischen Vektorraum”. Ein Euklidischer Vektorraum ist ein Vektorraum mit geometrischer Struktur, die durch das Skalarprodukt induziert wird. Insbesondere bekommen im Euklidischen Vektorraum nun die geometrischen Begriffe von Länge, Abstand und Winkel eine Bedeutung. Wir definieren sie wie folgt.\n\nDefinition 8.6 \\(\\left((\\mathbb{R}^m, +, \\cdot), \\langle \\rangle \\right)\\) sei der Euklidische Vektorraum.\n(1) Die Länge eines Vektors \\(x \\in \\mathbb{R}^m\\) ist definiert als \\[\\begin{equation}\n\\Vert x \\Vert := \\sqrt{\\langle x, x \\rangle}.\n\\end{equation}\\] (2) Der Abstand zweier Vektoren \\(x,y \\in \\mathbb{R}^m\\) ist definiert als \\[\\begin{equation}\nd(x,y) := \\Vert x - y \\Vert.\n\\end{equation}\\] (3) Der Winkel \\(\\alpha\\) zwischen zwei Vektoren \\(x,y \\in \\mathbb{R}^m\\) mit \\(x,y \\neq 0\\) ist definiert durch \\[\\begin{equation}\n0 \\le \\alpha \\le \\pi \\mbox{ und } \\cos \\alpha\n:= \\frac{\\langle x, y \\rangle}{\\Vert x \\Vert \\Vert y \\Vert}\n\\end{equation}\\]\n\nDie Länge \\(\\Vert x \\Vert\\) eines Vektors \\(x \\in \\mathbb{R}^m\\) heißt auch Euklidische Norm von \\(x\\) oder \\(\\ell_2\\)-Norm von \\(x\\) oder einfach Norm von \\(x\\). Sie wird häufig auch mit \\(\\Vert x \\Vert_2\\) bezeichnet. Wir betrachten drei Beispiele für die Bestimmung der Länge eines Vektors und ihre entsprechende R Implementation. Wir veranschaulichen diese Beispiele in Abbildung 8.5.\nBeispiel (1)\n\\[\\begin{equation}\n\\left\\lVert \\begin{pmatrix} 2 \\\\ 0 \\end{pmatrix} \\right\\rVert\n= \\sqrt{\\left\\langle \\begin{pmatrix} 2 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} 2 \\\\ 0 \\end{pmatrix} \\right\\rangle}\n= \\sqrt{2^2 + 0^2}\n= \\sqrt{4}\n= 2.00\n\\end{equation}\\]\n\nnorm(matrix(c(2,0),nrow = 2), type = \"2\")             # Vektorlänge = l_2 Norm\n\n[1] 2\n\n\nBeispiel (2)\n\\[\\begin{equation}\n\\left\\lVert \\begin{pmatrix} 2 \\\\ 2 \\end{pmatrix} \\right\\rVert\n= \\sqrt{\\left\\langle \\begin{pmatrix} 2 \\\\ 2 \\end{pmatrix}, \\begin{pmatrix} 2 \\\\ 2 \\end{pmatrix} \\right\\rangle}\n= \\sqrt{2^2 + 2^2}\n= \\sqrt{8}\n\\approx 2.83\n\\end{equation}\\]\n\nnorm(matrix(c(2,2),nrow = 2), type = \"2\")             # Vektorlänge = l_2 Norm\n\n[1] 2.828427\n\n\nBeispiel (3)\n\\[\\begin{equation}\n\\left\\lVert \\begin{pmatrix} 2 \\\\ 4 \\end{pmatrix} \\right\\rVert\n= \\sqrt{\\left\\langle \\begin{pmatrix} 2 \\\\ 4 \\end{pmatrix}, \\begin{pmatrix} 2 \\\\ 4 \\end{pmatrix} \\right\\rangle}\n= \\sqrt{2^2 + 4^2}\n= \\sqrt{20}\n\\approx 4.47\n\\end{equation}\\]\n\nnorm(matrix(c(2,4),nrow = 2), type = \"2\")             # Vektorlänge = l_2 Norm\n\n[1] 4.472136\n\n\n\n\n\nAbbildung 8.5: Vektorlänge in \\(\\mathbb{R}^2\\)\n\n\nFür den Abstand \\(d(x,y)\\) zweier Vektoren \\(x,y\\in\\mathbb{R}^m\\) halten wir ohne Beweis fest, dass er zum einen nicht-negativ und symmetrisch ist, also dass \\[\\begin{equation}\nd(x,y) \\ge 0, d(x,x) = 0 \\mbox{ und } d(x,y) = d(y,x)\n\\end{equation}\\] gelten. Zudem erfüllt \\(d(x,y)\\) die sogenannte Dreiecksungleichung, die besagt, dass die direkte Wegstrecke zwischen zwei Punkten im Raum immer kürzer ist als eine indirekte Wegstrecke über einen dritten Punkt, \\[\\begin{equation}\nd(x,y) \\le d(x,z) + d(z,y).\n\\end{equation}\\] Damit erfüllt \\(d(x,y)\\) wichtige Aspekte der räumlichen Anschauung. Wir geben zwei Beispiele für die Bestimmung von Abständen von Vektoren in \\(\\mathbb{R}^2\\), die wir in Abbildung 8.6 visualisieren.\nBeispiel (1)\n\\[\\begin{equation}\nd\\left(\\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}, \\begin{pmatrix} 2 \\\\ 2 \\end{pmatrix}\\right)\n= \\left\\lVert \\begin{pmatrix}  1 \\\\ 1 \\end{pmatrix} - \\begin{pmatrix} 2 \\\\ 2 \\end{pmatrix} \\right\\rVert\n= \\left\\lVert \\begin{pmatrix} -1 \\\\ -1 \\end{pmatrix}  \\right\\rVert\n= \\sqrt{(-1)^2 + (-1)^2}\n= \\sqrt{2}\n\\approx 1.41\n\\end{equation}\\]\n\nnorm(matrix(c(1,1),nrow = 2) - matrix(c(2,2),nrow = 2), type = \"2\")\n\n[1] 1.414214\n\n\nBeispiel (2)\n\\[\\begin{equation}\nd\\left(\\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}, \\begin{pmatrix} 4 \\\\ 1 \\end{pmatrix}\\right)\n= \\left\\lVert \\begin{pmatrix}  1 \\\\ 1 \\end{pmatrix} - \\begin{pmatrix} 4 \\\\ 1 \\end{pmatrix} \\right\\rVert\n= \\left\\lVert \\begin{pmatrix} -3 \\\\ 0 \\end{pmatrix} \\right\\rVert\n= \\sqrt{(-3)^2 + 0^2}\n= \\sqrt{9}\n= 3\n\\end{equation}\\]\n\nnorm(matrix(c(1,1),nrow = 2) - matrix(c(1,4),nrow = 2), type = \"2\")\n\n[1] 3\n\n\n\n\n\nAbbildung 8.6: Vektorabstände in \\(\\mathbb{R}^2\\)\n\n\nSchließlich halten wir fest, dass für die Berechnung des Winkels zwischen zwei Vektoren anhand obiger Definition gilt, dass die Kosinusfunktion \\(\\cos\\) auf \\([0,\\pi]\\) bijektiv, also invertierbar mit der Umkehrfunktion \\(acos\\), der Arkuskosinusfunktion, ist. Auch für den Begriff des Winkels wollen wir zwei Beispiele betrachten. Man beachte dabei insbesondere, dass die Definition 8.6 den Winkel in Radians angibt. Für eine Angabe in Grad ist eine entsprechende Umrechnung erforderlich.\nBeispiel (1)\n\\[\\begin{equation}\n\\mbox{acos}\n\\left(\\frac{\\left\\langle \\begin{pmatrix} 3 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} 3 \\\\ 3 \\end{pmatrix} \\right\\rangle}\n           {\\left\\lVert  \\begin{pmatrix} 3 \\\\ 0 \\end{pmatrix} \\right\\rVert \\left\\lVert \\begin{pmatrix} 3 \\\\ 3 \\end{pmatrix} \\right\\rVert}\n\\right)\n= \\mbox{acos}\n\\left(\\frac{3\\cdot 3 + 3 \\cdot 0}\n           {\\sqrt{3^2 + 0^2} \\cdot \\sqrt{3^2 + 3^2}}\n\\right)\n= \\mbox{acos}\n\\left(\\frac{9}\n           {3 \\cdot \\sqrt{18}}\n\\right)\n= \\frac{\\pi}{4}\n\\approx 0.785\n\\end{equation}\\] \nDie Umrechnung in Grad ergibt dann \\[\\begin{equation}\n0.785 \\cdot \\frac{180°}{\\pi} = 45°\n\\end{equation}\\] In R implementiert man dies wie folgt.\n\nx = matrix(c(3,0), nrow = 2)                                 # Vektor 1\ny = matrix(c(3,3), nrow = 2)                                 # Vektor 2\nw = acos(sum(x*y)/(sqrt(sum(x*x))*sqrt(sum(y*y)))) * 180/pi  # Winkel in Grad\nprint(w)\n\n[1] 45\n\n\nBeispiel (2)\n\\[\\begin{equation}\n\\alpha\n= \\mbox{acos}\n\\left(\\frac{\\left\\langle \\begin{pmatrix} 3 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} 0 \\\\ 3 \\end{pmatrix} \\right\\rangle}\n           {\\left\\lVert  \\begin{pmatrix} 3 \\\\ 0 \\end{pmatrix} \\right\\rVert \\left\\lVert \\begin{pmatrix} 0 \\\\ 3 \\end{pmatrix} \\right\\rVert}\n\\right)\n= \\mbox{acos}\n\\left(\\frac{3\\cdot 0 + 0 \\cdot 3}\n           {\\sqrt{3^2 + 0^2} \\cdot \\sqrt{0^2 + 3^2}}\n\\right)\n= \\mbox{acos}\n\\left(\\frac{0}\n           {3 \\cdot 3}\n\\right)\n= \\frac{\\pi}{2}\n\\approx 1.57\n\\end{equation}\\] Die Umrechnung in Grad ergibt dann \\[\\begin{equation}\n\\frac{\\pi}{2} \\cdot \\frac{180°}{\\pi} = 90°\n\\end{equation}\\] Die entsprechende R Implementation lautet wie folgt.\n\nx = matrix(c(3,0), nrow = 2)                                    # Vektor 1\ny = matrix(c(0,3), nrow = 2)                                    # Vektor 2\nw = acos(sum(x*y)/(sqrt(sum(x*x))*sqrt(sum(y*y)))) * 180/pi     # Winkel in Grad\nprint(w)\n\n[1] 90\n\n\n\n\n\nAbbildung 8.7: Winkel in \\(\\mathbb{R}^2\\)\n\n\nDie Tatsache, dass zwei Vektoren einen rechten Winkel bilden können, also gewissermaßen maximal nicht-parallel sein können, ist ein wichtiges geometrisches Prinzip und wird deshalb mit folgender Definition speziell ausgezeichnet.\n\nDefinition 8.7 (Orthogonalität und Orthonormalität von Vektoren) \\(\\left((\\mathbb{R}^m, +, \\cdot), \\langle \\rangle \\right)\\) sei der Euklidische Vektorraum.\n(1) Zwei Vektoren \\(x,y \\in \\mathbb{R}^m\\) heißen orthogonal, wenn gilt, dass \\[\\begin{equation}\n\\langle x, y \\rangle = 0\n\\end{equation}\\] (2) Zwei Vektoren \\(x,y \\in \\mathbb{R}^m\\) heißen orthonormal, wenn gilt, dass \\[\\begin{equation}\n\\langle x, y \\rangle = 0 \\mbox{ und } \\Vert x \\Vert = \\Vert y \\Vert = 1.\n\\end{equation}\\]\n\nFür orthogonale und orthonormale Vektoren gilt also insbesondere auch \\[\\begin{equation}\n\\cos \\alpha\n= \\frac{\\langle x, y \\rangle}{\\Vert x \\Vert \\Vert y \\Vert}\n= \\frac{0}{\\Vert x \\Vert \\Vert y \\Vert}\n= 0,\n\\end{equation}\\] also \\[\\begin{equation}\n\\alpha = \\frac{\\pi}{2} = 90°.\n\\end{equation}\\]"
  },
  {
    "objectID": "108-Vektoren.html#sec-lineare-unabhängigkeit",
    "href": "108-Vektoren.html#sec-lineare-unabhängigkeit",
    "title": "8  Vektoren",
    "section": "8.3 Lineare Unabhängigkeit",
    "text": "8.3 Lineare Unabhängigkeit\nIn diesem Abschnitt führen wir den Begriff der linearen Unabhängigkeit von Vektoren ein. Wir definieren dazu zunächst den Begriff der Linearkombination von Vektoren.\n\nDefinition 8.8 (Linearkombination) \\(\\{v_1, v_2, ..., v_k\\}\\) sei eine Menge von \\(k\\) Vektoren eines Vektorraums \\(V\\) und \\(a_1, a_2,...,a_k\\) seien Skalare. Dann ist die Linearkombination der Vektoren in \\(\\{v_1, v_2, ..., v_k\\}\\) mit den Koeffizienten \\(a_1, a_2,...,a_k\\) definiert als der Vektor \\[\\begin{equation}\nw := \\sum_{i=1}^k a_i v_i \\in V.\n\\end{equation}\\]\n\nBeispiel\nEs seien \\[\\begin{equation}\nv_1 := \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix},\nv_2 := \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix},\nv_3 := \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}\n\\mbox{ und }\na_1 := 2, a_2 := 3, a_3 := 0.\n\\end{equation}\\] Dann ergibt sich die Linearkombination von \\(v_1,v_2,v_3\\) mit den Koeffizienten \\(a_1,a_2,a_3\\) zu \\[\\begin{align}\n\\begin{split}\nw\n& = a_1v_1 + a_2v_2 + a_3v_3                        \\\\\n& =  2 \\cdot \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix}\n     + 3 \\cdot \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}\n     + 0 \\cdot \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}   \\\\\n& =   \\begin{pmatrix} 4 \\\\ 2 \\end{pmatrix}\n     + \\begin{pmatrix} 3 \\\\ 3 \\end{pmatrix}\n     + \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}          \\\\\n& =   \\begin{pmatrix} 7 \\\\ 5 \\end{pmatrix}.\n\\end{split}\n\\end{align}\\]\nBasierend auf dem Begriff der Linearkombination kann man nun den Begriff der Linearen Unabhängigkeit von Vektoren definieren.\n\nDefinition 8.9 (Lineare Unabhängigkeit) \\(V\\) sei ein Vektorraum. Eine Menge \\(W := \\{w_1, w_2, ...,w_k\\}\\) von Vektoren in \\(V\\) heißt linear unabhängig, wenn die einzige Repräsentation des Nullelements \\(0 \\in V\\) durch eine Linearkombination der \\(w \\in W\\) die sogenannte triviale Repräsentation \\[\\begin{equation}\n0 = a_1 w_1 + a_2 w_2 + \\cdots + a_k w_k \\mbox{ mit } a_1 = a_2 =  \\cdots = a_k = 0\n\\end{equation}\\] ist. Wenn die Menge \\(W\\) nicht linear unabhängig ist, dann heißt sie linear abhängig.\n\nUm zu prüfen, ob eine gegeben Menge von Vektoren linear abhängig oder unabhängig ist muss man prinzipiell für jede mögliche Linearkombination der gegebenen Vektoren, ob sie Null ist. Theorem 8.2 und Theorem 8.3 zeigen, wie dies für zwei bzw. endliche viele Vektoren auch mit weniger Aufwand gelingen kann.\n\nTheorem 8.2 (Lineare Abhängigkeit von zwei Vektoren) \\(V\\) sei ein Vektorraum. Zwei Vektoren \\(v_1, v_2 \\in V\\) sind linear abhängig, wenn einer der Vektoren ein skalares Vielfaches des anderen Vektors ist.\n\n\nBeweis. \\(v_1\\) sei ein skalares Vielfaches von \\(v_2\\), also \\[\\begin{equation}\nv_1 = \\lambda v_2 \\mbox{ mit } \\lambda \\neq 0.\n\\end{equation}\\] Dann gilt \\[\\begin{equation}\nv_1 - \\lambda v_2 = 0.\n\\end{equation}\\] Dies aber entspricht der Linearkombination \\[\\begin{equation}\na_1v_1 + a_2v_2 = 0\n\\end{equation}\\] mit \\(a_1 = 1 \\neq 0\\) und \\(a_2 = -\\lambda \\neq 0\\). Es gibt also eine Linearkombination des Nullelementes, die nicht die triviale Repräsentation ist, und damit sind \\(v_1\\) und \\(v_2\\) nicht linear unabhängig.\n\n\nTheorem 8.3 (Lineare Abhängigkeit einer Menge von Vektoren) \\(V\\) sei ein Vektorraum und \\(w_1,...,w_k \\in V\\) sei eine Menge von Vektoren in \\(V\\). Wenn einer der Vektoren \\(w_i\\) mit \\(i = 1,...,k\\) eine Linearkombination der anderen Vektoren ist, dann ist die Menge der Vektoren linear abhängig.\n\n\nBeweis. Die Vektoren \\(w_1,...,w_k\\) sind genau dann linear abhängig, wenn gilt, dass \\(\\sum_{i=1}^k a_i w_i = 0\\) mit mindestens einem \\(a_i \\neq 0\\) . Es sei also zum Beispiel \\(a_j \\neq 0\\). Dann gilt \\[\\begin{equation}\n0 = \\sum_{i=1}^k a_i w_i = \\sum_{i=1, i \\neq j}^k a_i w_i + a_jw_j\n\\end{equation}\\] Also folgt \\[\\begin{equation}\na_jw_j  = - \\sum_{i=1, i \\neq j}^k a_i w_i\n\\end{equation}\\] und damit \\[\\begin{equation}\nw_j  = - a_j^{-1}\\sum_{i=1, i \\neq j}^k a_i w_i = - \\sum_{i=1, i \\neq j}^k (a_j^{-1}a_i) w_i\n\\end{equation}\\] Also ist \\(w_j\\) eine Linearkombination der \\(w_i\\) für \\(i = 1,...,k\\) mit \\(i \\neq j\\)."
  },
  {
    "objectID": "108-Vektoren.html#sec-vektorraumbasen",
    "href": "108-Vektoren.html#sec-vektorraumbasen",
    "title": "8  Vektoren",
    "section": "8.4 Vektorraumbasen",
    "text": "8.4 Vektorraumbasen\nIn diesem Abschnitt wollen wir den Begriff der Vektorraumbasis einführen. Eine Basis eines Vektorraums ist eine Untermenge von Vektoren des Vektorraums, die zur Darstellung aller Vektoren des Vektorraums genutzt werden kann. Im Sinne der linearen Kombination von Vektoren enthält also eine Vektorraumbasis alle nötige Information zur Konstruktion des entsprechenden Vektorraums. Allerdings ist eine Vektorraumbasis in der Regel nicht eindeutig und die viele Vektorräume haben in der Tat unendlich viele Basen. Die folgenden Definition sagt zunächst aus, wie aus einer beschränkten Anzahl von Vektoren mithilfe von Linearkombinationen unendlich viele Vektoren gebildet werden können.\n\nDefinition 8.10 (Lineare Hülle und Aufspannen) \\(V\\) sei ein Vektorraum und es sei \\(W := \\{w_1,...,w_k\\} \\subset V\\). Dann ist die lineare Hülle von \\(W\\) definiert als die Menge aller Linearkombinationen der Elemente von \\(W\\), \\[\\begin{equation}\n\\mbox{Span}(W) := \\left\\lbrace \\sum_{i=1}^k a_iw_i \\vert a_1,...,a_k \\mbox{ sind skalare Koeffizienten } \\right\\rbrace\n\\end{equation}\\] Man sagt, dass eine Menge von Vektoren \\(W \\subseteq V\\) einen Vektorraum \\(V\\) aufspannt, wenn jedes \\(v \\in V\\) als eine Linearkombination von Vektoren in \\(W\\) geschrieben werden kann.\n\nWir definieren nun den Begriff der Basis eines Vektorraums.\n\nDefinition 8.11 (Basis) \\(V\\) sei ein Vektorraum und es sei \\(B \\subseteq V\\). \\(B\\) heißt eine Basis von \\(V\\), wenn\n\ndie Vektoren in \\(B\\) linear unabhängig sind und\ndie Vektoren in \\(B\\) den Vektorraum \\(V\\) aufspannen.\n\n\nBasen von Vektorräumen haben folgende wichtige Eigenschaften.\n\nTheorem 8.4 (Eigenschaften von Basen)  \n\nAlle Basen eines Vektorraums beinhalten die gleiche Anzahl von Vektoren.\nJede Menge von \\(m\\) linear unabhängigen Vektoren ist Basis eines \\(m\\)-dimensionalen Vektorraums.\n\n\nFür einen Beweis dieses sehr tiefen Theorems verweisen wir auf die weiterführende Literatur. Die mit obigem Theorem benannte eindeutige Anzahl der Vektoren einer Basis eines Vektorraums heißt die Dimension des Vektorraums. Da es in der Regel unendliche viele Mengen von m linear unabhängigen Vektoren in einem Vektorraum gibt haben Vektorräume in der Regel unendlich viele Basen.\nBetrachtet man nun einen einzelnen Vektor in einem Vektorraum, so kann man sich fragen, wie man diesen mithilfe einer Vektorraumbasis darstellen kann. Dies führt auf folgende Begriffsbildungen.\n\nDefinition 8.12 (Basisdarstellung und Koordinaten) \\(B := \\{b_1,...,b_m\\}\\) sei eine Basis eines \\(m\\)-dimensionalen Vektorraumes \\(V\\) und es sei \\(v \\in V\\). Dann heißt die Linearkombination \\[\\begin{equation}\nv = \\sum_{i = 1}^m c_i b_i\n\\end{equation}\\] die Darstellung von \\(v\\) bezüglich der Basis \\(B\\) und die Koeffizienten \\(c_1,...,c_m\\) heißen die Koordinaten von \\(v\\) bezüglich der Basis \\(B\\).\n\nBei fester Basis sind auch die Koordinaten eines Vektors bezüglich dieser Basis fest und eindeutig. Dies ist die Aussage folgenden Theorems.\n\nTheorem 8.5 (Eindeutigkeit der Basisdarstellung) Die Basisdarstellung eines \\(v \\in V\\) bezüglich einer Basis \\(B\\) ist eindeutig.\n\n\nBeweis. Ohne Beschränkung der Allgemeinheit nehmen wir an, dass der Vektorraum von Dimension \\(m\\) ist. Nehmen wir an, dass zwei Darstellungen von \\(v\\) bezüglich der Basis \\(B\\) existieren, also dass \\[\\begin{align}\n\\begin{split}\nv & = a_1 b_1 + \\cdots + a_m b_m \\\\\nv & = c_1 b_1 + \\cdots + c_m b_m\n\\end{split}\n\\end{align}\\] Subtraktion der unteren von dern oberen Gleichung ergibt \\[\\begin{equation}\n0 = (a_1 - c_1) b_1 + \\cdots + (a_m - c_m) b_m\n\\end{equation}\\] Weil die \\(b_1,...,b_m\\) linear unabhängig sind, gilt aber, dass \\((a_i - c_i) = 0\\) für alle \\(i = 1,...,m\\) und somit sind die beiden Darstellungen von \\(v\\) bezüglich der Basis \\(B\\) identisch.\n\nZum Abschluss dieses Abschnitts wollen wir eine spezielle Basis des reellen Vektorraums betrachten.\n\nDefinition 8.13 (Orthonormalbasis von \\(\\mathbb{R}^m\\)) Eine Menge von \\(m\\) Vektoren \\(v_1,...,v_m \\in \\mathbb{R}^m\\) heißt Orthonormalbasis von \\(\\mathbb{R}^m\\), wenn \\(v_1,...,v_m\\) jeweils die Länge 1 haben und wechselseitig orthogonal sind, also wenn \\[\\begin{equation}\n\\langle v_i, v_j \\rangle =\n\\begin{cases}\n1   & \\mbox{ für } i = j    \\\\\n0   & \\mbox{ für } i \\neq j\n\\end{cases}.\n\\end{equation}\\]\n\nWir wollen zunächst ein Beispiel für eine Orthonormalbasis betrachten.\nBeispiel (1)\nEs ist \\[\\begin{equation}\nB_1 :=\n\\left\\lbrace\n\\begin{pmatrix}\n1 \\\\ 0\n\\end{pmatrix},\n\\begin{pmatrix}\n0 \\\\ 1\n\\end{pmatrix}\n\\right\\rbrace\n\\end{equation}\\] eine Orthonormalbasis von \\(\\mathbb{R}^2\\), denn \\(B_1\\) besteht aus zwei Vektoren und es gelten \\[\\begin{equation}\n\\left\\langle\n\\begin{pmatrix}\n1 \\\\ 0\n\\end{pmatrix},\n\\begin{pmatrix}\n1 \\\\ 0\n\\end{pmatrix}\n\\right\\rangle\n= 1 \\cdot 1 + 0 \\cdot 0\n= 1 + 0\n= 1\n\\end{equation}\\] sowie \\[\\begin{equation}\n\\left \\langle\n\\begin{pmatrix}\n0 \\\\ 1\n\\end{pmatrix},\n\\begin{pmatrix}\n0 \\\\1\n\\end{pmatrix}\n\\right \\rangle\n= 0 \\cdot 0 + 1 \\cdot 1\n= 0 + 1\n= 1\n\\end{equation}\\] und \\[\\begin{equation}\n\\left \\langle\n\\begin{pmatrix}\n1 \\\\ 0\n\\end{pmatrix},\n\\begin{pmatrix}\n0 \\\\ 1\n\\end{pmatrix}\n\\right \\rangle\n=    1 \\cdot 0 +  0  \\cdot 1\n= 0 + 0\n= 0\n\\end{equation}\\]\nFür allgemeine reelle Vektorräume werden Basen der Form von \\(B_1\\) mit dem Begriff der kanonischen Basis speziell ausgezeichnet.\n\nDefinition 8.14 (Kanonische Basis und kanonische Einheitsvektoren) Die Orthonormalbasis \\[\\begin{equation}\nB :=\n\\left\\lbrace\ne_1,...,e_m\n\\vert\ne_{i_j} = 1 \\mbox{ für } i =  j \\mbox{ und } e_{i_j} =  0 \\mbox{ für } i \\neq j\n\\right\\rbrace\n\\subset \\mathbb{R}^m\n\\end{equation}\\] heißt die kanonische Basis von \\(\\mathbb{R}^m\\) und die \\(e_{i_j}\\) heißen kanonische Einheitsvektoren.\n\n\\(B_1\\) aus Beispiel (1) ist also die kanonische Basis von \\(\\mathbb{R}^2\\).\nDie kanonische Basis von \\(\\mathbb{R}^3\\) ist \\[\\begin{equation}\nB :=\n\\left\\lbrace\n\\begin{pmatrix}\n1 \\\\ 0 \\\\ 0\n\\end{pmatrix},\n\\begin{pmatrix}\n0 \\\\ 1 \\\\ 0\n\\end{pmatrix},\n\\begin{pmatrix}\n0 \\\\ 0 \\\\ 1\n\\end{pmatrix}\n\\right\\rbrace.\n\\end{equation}\\]\nAllerdings gibt es auch nicht kanonische Orthonormalbasen. Dazu betrachten wir ein weiteres Beispiel\nBeispiel (2)\nEs ist auch \\[\\begin{equation}\nB_2 :=\n\\left\\lbrace\n\\begin{pmatrix}\n\\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}}\n\\end{pmatrix},\n\\begin{pmatrix} - \\frac{1}{\\sqrt{2}} \\\\ \\quad \\frac{1}{\\sqrt{2}}\n\\end{pmatrix}\n\\right\\rbrace\n\\end{equation}\\] eine Orthonormalbasis von \\(\\mathbb{R}^2\\), denn \\(B_2\\) besteht aus zwei Vektoren und es gelten \\[\\begin{equation}\n\\left \\langle\n\\begin{pmatrix}\n\\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}}\n\\end{pmatrix},\n\\begin{pmatrix}\n\\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}}\n\\end{pmatrix}\n\\right \\rangle\n= \\frac{1}{\\sqrt{2}} \\cdot \\frac{1}{\\sqrt{2}} + \\frac{1}{\\sqrt{2}} \\cdot \\frac{1}{\\sqrt{2}}\n= \\frac{1}{2} + \\frac{1}{2}\n= 1,\n\\end{equation}\\] sowie \\[\\begin{equation}\n\\left \\langle\n\\begin{pmatrix} - \\frac{1}{\\sqrt{2}} \\\\ \\quad \\frac{1}{\\sqrt{2}}\n\\end{pmatrix},\n\\begin{pmatrix} - \\frac{1}{\\sqrt{2}} \\\\ \\quad \\frac{1}{\\sqrt{2}}\n\\end{pmatrix}\n\\right \\rangle\n= \\left(- \\frac{1}{\\sqrt{2}} \\right)\\cdot \\left(- \\frac{1}{\\sqrt{2}} \\right) + \\frac{1}{\\sqrt{2}} \\cdot \\frac{1}{\\sqrt{2}}\n= \\frac{1}{2} + \\frac{1}{2}\n= 1\n\\end{equation}\\] und \\[\\begin{equation}\n\\left \\langle\n\\begin{pmatrix} - \\frac{1}{\\sqrt{2}} \\\\ \\quad \\frac{1}{\\sqrt{2}}\n\\end{pmatrix},\n\\begin{pmatrix}\n\\frac{1}{\\sqrt{2}} \\\\  \\frac{1}{\\sqrt{2}}\n\\end{pmatrix}\n\\right \\rangle\n= - \\frac{1}{\\sqrt{2}} \\cdot \\frac{1}{\\sqrt{2}} + \\frac{1}{\\sqrt{2}}   \\cdot \\frac{1}{\\sqrt{2}}\n= - \\frac{1}{2} + \\frac{1}{2}\n= 0\n\\end{equation}\\]\nWir visualisieren die beiden Orthonormalbasen \\(B_1\\) und \\(B_2\\) von \\(\\mathbb{R}^2\\) in Abbildung 8.8.\n\n\n\nAbbildung 8.8: Zwei Basen von \\(\\mathbb{R}^2\\)"
  },
  {
    "objectID": "108-Vektoren.html#sec-selbstkontrollfragen-vektoren",
    "href": "108-Vektoren.html#sec-selbstkontrollfragen-vektoren",
    "title": "8  Vektoren",
    "section": "8.5 Selbstkontrollfragen",
    "text": "8.5 Selbstkontrollfragen\n\nGeben Sie die Definition eines Vektorraums wieder.\nGeben Sie die Definition des reellen Vektorraums wieder.\nEs seien \\[\\begin{equation}\nx := \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix},\ny := \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}\n\\mbox{ und }\na := 2.\n\\end{equation}\\] Berechnen Sie \\[\\begin{equation}\nv = a(x+y) \\mbox{ und } w = \\frac{1}{a}(y-x)\n\\end{equation}\\]\nGeben Sie die Definition des Skalarproduktes auf \\(\\mathbb{R}^m\\) wieder.\nFür \\[\nx := \\begin{pmatrix} 2 \\\\ 1 \\\\ 3 \\end{pmatrix},\ny := \\begin{pmatrix} 1 \\\\ 0 \\\\ 1 \\end{pmatrix},\nz := \\begin{pmatrix} 3 \\\\ 1 \\\\ 0 \\end{pmatrix}\n\\tag{8.1}\\] berechnen Sie \\[\\begin{equation}\n\\langle x,y \\rangle, \\langle x, z \\rangle, \\langle y,z \\rangle\n\\end{equation}\\]\nGeben Sie die Definition des Euklidischen Vektorraums wieder.\nGeben Sie die Definition der Länge eines Vektors im Euklidischen Vektorraum wieder,\nBerechnen Sie die Längen der Vektoren \\(x,y,z\\) aus Gleichung 8.1.\nGeben Sie Definition des Abstands zweier Vektoren im Euklidischen Vektorraum wieder.\nBerechnen Sie \\(d(x,y), d(x,z)\\) und \\(d(y,z)\\) für \\(x,y,z\\) aus Gleichung 8.1.\nGeben Sie die Definition des Winkels zwischen zwei Vektoren im Euklidischen Vektorraum wieder.\nBerechnen Sie die Winkel zwischen den Vektoren \\(x\\) und \\(y\\), \\(x\\) und \\(z\\), sowie \\(y\\) und \\(z\\) aus Gleichung 8.1.\nGeben Sie die Definitionen der Orthogonalität und Orthonormalität von Vektoren wieder.\nGeben Sie die Definition der Linearkombination von Vektoren wieder.\nGeben Sie die Definition der linearen Unabhängigkeit von Vektoren wieder.\nWoran kann man erkennen, ob zwei reelle Vektoren linear abhängig sind oder nicht?\nGeben Sie die Definition der linearen Hülle einer Menge von Vektoren wieder.\nGeben Sie die Definition der Basis eines Vektorraums wieder.\nGeben Sie das Theorem zu den Eigenschaften von Vektorraumbasen wieder.\nGeben Sie die Definition der Basisdarstellung eines Vektors wieder.\nGeben Sie die Definition eienr Orthonormalbasis von \\(\\mathbb{R}^m\\) wieder.\nGeben Sie die Definition der kanonischen Basis von \\(\\mathbb{R}^m\\) wieder."
  },
  {
    "objectID": "200-Wahrscheinlichkeitstheorie.html",
    "href": "200-Wahrscheinlichkeitstheorie.html",
    "title": "Wahrscheinlichkeitstheorie",
    "section": "",
    "text": "Vorbemerkungen\nDie Wahrscheinlichkeitstheorie ist ein mathematisches Modell zur Beschreibung von und zum quantitativen Schlussfolgern über Zufallsvorgänge der Wirklichkeit (Abbildung 1). Unter Zufallsvorgängen verstehen wir dabei alle Phänomene, die von uns nicht mit absoluter Sicherheit vorhergesagt werden können, deren Ergebnis also mit Unsicherheit behaftet ist. Offensichtliche und vertraute Beispiele für Zufallsvorgänge sind das Werfen eines Würfels oder einer Münze. Allerdings ist der Begriff des Zufallsvorgangs und damit der Anwendungsbereich der Wahrscheinlichkeitstheorie als sehr viel weiter gefasst zu verstehen. Nicht mit vollständiger Sicherheit vorhersagbar und damit mit Unsicherheit behaftet sind zum Beispiel auch der Ausgang einer Wahl, das morgige Wetter, der Messwert einer EEG-Elektrode zu einem bestimmten Zeitpunkt nach Applikation eines Reizes, oder der Effekt einer Psychotherapieintervention auf den Gesundheitszustand einer Patient:in. Beginnt man darüber nachzudenken, welche Phänomene der Wirklichkeit mit Unsicherheit behaftet sind, so fällt es schwer, nichttriviale Phänomene anzugeben, hinsichtlich deren Ergebnis man vollständige Sicherheit besitzt.\n\n\n\nAbbildung 1: Wahrscheinlichkeitstheorie als Modell von Zufallsvorgängen. Ausgangspunkt der Wahrscheinlichkeitstheorie ist die Absicht, über einen Zufallsvorgang, also ein mit Unsicherheit behaftetes Phänomen der Wirklichkeit, logisch-quantitative Schlüsse zu ziehen. Die Repräsentation zentraler Aspekte des Zufallsvorgang mithilfe wahrscheinlichkeitstheoretischer Begrifflichkeiten bezeichnet man als Modellierung. Das wahrscheinlichkeitstheoretische Modell selbst garantiert dann im Sinne der Wahrscheinlichkeitsrechnung die Korrektheit logisch-quantitativer Schlussfolgerungen, welche zur Vorhersage von Aspekten des Zufallsvorgangs genutzt werden können.\n\n\nAls mathematisches Modell von Zufallsvorgängen erlaubt die Wahrscheinlichkeitstheorie insbesondere das vernunftbasierte, quantitative Schlussfolgern über Zufallsvorgänge. Dies schlägt sich primär in der sogenannten Wahrscheinlichkeitsrechnung nieder. Quantitative Schlussfolgerungen der Wahrscheinlichkeitsrechnung haben beispielsweise folgende Form: Wenn ich annehme, dass das Ereignis \\(A\\) mit Wahrscheinlichkeit \\(x\\) und Ereignis \\(B\\) mit Wahrscheinlichkeit \\(y\\) eintritt, dann ergibt sich für die Wahrscheinlichkeit von Ereignis \\(C\\) eine Wahrscheinlichkeit von \\(z\\). Dabei ist der Schluss auf die Wahrscheinlichkeit von \\(C\\) logisch-mathematisch abgesichert, in dem Sinne wie zum Beispiel logisch-mathematisch abgesichert ist, dass \\(1+1=2\\) ist. Ob die Annahmen hinsichtlich der Wahrscheinlichkeiten von \\(A\\) und \\(B\\) aber den Gegebenheiten des Zufallsvorgangs in der Wirklichkeit entsprechen, darüber macht die Wahrscheinlichkeitstheorie keine Aussagen.\nDie Wahrscheinlichkeitstheorie selbst bedient sich dabei der mathematischen Theorie der Mengen und Funktionen. Spätestens seit Kolmogoroff (1933) herrscht dabei ein axiomatischer Zugang vor: Man fragt in der Wahrscheinlichkeitstheorie selbst nicht, was denn eine Wahrscheinlichkeit sei oder inwieweit die Vorhersagen der Wahrscheinlichkeitstheorie mit der Wirklichkeit übereinstimmen, sondern versucht ein in sich schlüssiges formal-mathematisches System von unbegründeten, aber intuitiv plausiblen, Grundannahmen und ihren Folgerungen zu entwickeln. Ausgangspunkt dieser Entwicklung ist das Wahrscheinlichkeitsraummodell eines Zufallsvorgangs, das wir in Kapitel 9 einführen werden. In der Tat gibt es neben dem formal-mathematischen System der Wahrscheinlichkeitstheorie bis heute mathematisch-philosophische Diskussionen darüber, was genau denn unter dem Begriff der “Wahrscheinlichkeit eines Ereignisses” zu verstehen ist (vgl. Hájek (2019)). Dabei sind grob gesagt zwei etwas gegensätzliche Interpretationen vorherrschend, die sogenannte Frequentistische Interpretation und die sogenannte Bayesianische Interpretation.\nNach der Frequentistischen Interpretation ist die Wahrscheinlichkeit eines Ereignisses die idealisierte relative Häufigkeit, mit der ein Ereignis unter den gleichen äußeren Bedingungen einzutreten pflegt. Zum Beispiel ist die Frequentistische Interpretation der Aussage “Mit einer Wahrscheinlichkeit von 1/6 zeigt der Würfel im nächsten Wurf eine 2” die folgende: “Wenn man einen Würfel unendlich oft werfen würde und dabei die relative Häufigkeit des Ereignisses, dass der Würfel eine 2 zeigt, bestimmen würde, dann wäre diese relative Häufigkeit gleich 1/6”. Man beachte bei dieser Interpretation, dass man de-facto die Wahrscheinlichkeit eines Ereignisses nicht empirisch bestimmen kann, da man einen Würfel nicht unendlich oft werfen kann. Natürlich kann man die Wahrscheinlichkeit in dieser Interpretation aber empirisch schätzen. Schätzvorgänge selbst wiederrum sind allerdings kein Teil der Wahrscheinlichkeitstheorie, sondern der Frequentistischen oder Bayesianischen Inferenz.\nNach der Bayesianischen Interpretation ist die Wahrscheinlichkeit eines Ereignisses der Grad der Sicherheit, den eine Beobachter:in aufgrund ihrer subjektiven Einschätzung der Lage dem Eintreten des Ereignisses \\(A\\) zumisst. Zum Beispiel ist die Bayesianische Interpretation der Aussage “Mit einer Wahrscheinlichkeit von 1/6 zeigt der Würfel im nächsten Wurf eine Zwei” dann etwa die folgende: “Basierend auf meiner eigenen und der tradierten Erfahrung mit dem Werfen eines Würfels bin ich mir zu 16.6% sicher, dass der Würfel beim nächsten Wurf eine Zwei zeigt.”\nIn Modellen von tatsächlich zumindest unter ähnlichen Umständen wiederholbaren Zufallsvorgängen wie dem Werfen eines Würfels ist der Unterschied zwischen Frequentistischer und Bayesianischer Interpretation oft eher subtil. Es gibt aber wie oben angedeutet viele Zufallsvorgänge, die mit Wahrscheinlichkeiten beschrieben werden können, bei denen aufgrund ihrer Einmaligkeit eine Frequentistische Interpretation nicht angemessen ist. Zum Beispiel machen Aussagen der Form “Die Wahrscheinlichkeit dafür, dass die weltweiten Hitzerekorde im Jahr 2023 nicht auf den Klimawandel zurückzuführen sind, ist kleiner als 0.01” (vgl. Philip et al. (2020)) nur unter der Bayesianischen Interpretation Sinn, da es sich bei den Wetteraufzeichnungen des Jahres 2023 um ein einmaliges, nicht wiederholbares Ereignis handelt.\nObwohl also die Interpretation des Begriffes der Wahrscheinlichkeit durchaus nicht eindeutig ist, unterscheiden sich die formalen Definitionen und Rechenregeln für Wahrscheinlichkeiten nicht. Sowohl die Frequentistische als auch die Bayesianische Inferenz, auf die wir an späterer Stelle eingehen, haben mit der Wahrscheinlichkeitstheorie also ein identisches mathematisches Bezugssystem und gemeinsames Fundament.\n\n\n\n\nHájek, A. (2019). Interpretations of Probability. In E. N. Zalta (Hrsg.), The Stanford Encyclopedia of Philosophy (Fall 2019). Metaphysics Research Lab, Stanford University.\n\n\nKolmogoroff, A. (1933). Grundbegriffe der Wahrscheinlichkeitsrechnung. Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-642-49888-6\n\n\nPhilip, S., Kew, S., Van Oldenborgh, G. J., Otto, F., Vautard, R., Van Der Wiel, K., King, A., Lott, F., Arrighi, J., Singh, R., & Van Aalst, M. (2020). A Protocol for Probabilistic Extreme Event Attribution Analyses. Advances in Statistical Climatology, Meteorology and Oceanography, 6(2), 177–203. https://doi.org/10.5194/ascmo-6-177-2020"
  },
  {
    "objectID": "201-Wahrscheinlichkeitsräume.html#sec-definition-und-erste-eigenschaften",
    "href": "201-Wahrscheinlichkeitsräume.html#sec-definition-und-erste-eigenschaften",
    "title": "9  Wahrscheinlichkeitsräume",
    "section": "9.1 Definition und erste Eigenschaften",
    "text": "9.1 Definition und erste Eigenschaften\nWir beginnen mit der Definition des Wahrscheinlichkeitsraummodells nach Kolmogoroff (1933), das wir dann nachfolgend in seinen Einzelteilen aus Frequentistischer Perspektive erläutern wollen.\n\nDefinition 9.1 (Wahrscheinlichkeitsraum) Ein Wahrscheinlichkeitsraum ist ein Triple \\((\\Omega, \\mathcal{A}, \\mathbb{P})\\), wobei\n\n\\(\\Omega\\) eine beliebige nichtleere Menge von Ergebnissen \\(\\omega\\) ist und Ergebnismenge heißt,\n\\(\\mathcal{A}\\) eine Menge von Teilmengen von \\(\\Omega\\) mit den Eigenschaften\n\n\\(\\Omega \\in \\mathcal{A}\\),\nfür alle \\(A\\in \\mathcal{A}\\) gilt, dass auch \\(A^c := \\Omega \\setminus A \\in \\mathcal{A}\\) ist,\naus \\(A_1,A_2,... \\in \\mathcal{A}\\) folgt, dass auch \\(\\cup_{i=1}^\\infty A_i \\in \\mathcal{A}\\) ist,ist, \\(\\sigma\\)-Algebra auf \\(\\Omega\\) genannt wird und Ereignissystem heißt,\n\n\\(\\mathbb{P}\\) eine Abbildung der Form \\(\\mathbb{P}:\\mathcal{A} \\to [0,1]\\) mit den Eigenschaften\n\n\\(\\mathbb{P}(A) \\ge 0\\) für alle \\(A \\in \\mathcal{A}\\) (),\n\\(\\mathbb{P}(\\Omega) = 1\\) () und\n\\(\\mathbb{P}(\\cup_{i=1}^\\infty A_i) = \\sum\\limits_{i=1}^\\infty \\mathbb{P}(A_i)\\) für paarweise disjunkte \\(A_i \\in \\mathcal{A}\\) (\\(\\sigma\\)-Additivität) ist und Wahrscheinlichkeitsmaß heißt.\n\n\n\n\nErgebnismenge und Mechanik\nWir beginnen mit Erläuterungen zum Begriff der Ergebnismenge \\(\\Omega\\) und der impliziten Mechanik des Wahrscheinlichkeitsraummodells. Um den Einstieg zu erleichtern betrachten wir im Folgenden zunächst vor allem endliche Wahrscheinlichkeitsräume, bei denen die Kardinalität von \\(\\Omega\\) nicht unendlich groß ist. Es sei also \\(|\\Omega|&lt;\\infty\\), \\(\\Omega\\) habe also nur endlich viele Elemente. Zum Modellieren des Werfen eines Würfels könnte man zum Beispiel \\(\\Omega := \\{1,2,3,4,5,6\\}\\) definieren.\nHinter der formalen Definition des Wahrscheinlichkeitsraummodells stehen folgende Frequentistisch-geprägten Annahmen über seine Mechanik als Modell eines Zufallsvorgangs. Wir stellen uns zunächst sequentielle Durchgänge eines Zufallsvorgangs vor, also zum Beispiel das wiederholte Werfen eines Würfels. Nach Annahme des Wahrscheinlichkeitsraummodells wird in jedem dieser Durchgänge genau ein \\(\\omega\\) aus \\(\\Omega\\) realisiert, also als tatsächlich vorliegend ausgewählt. Wirft man zum Beispiel einen Würfel und fällt eine Zwei, so sagt man, dass eine Zwei realisiert wurde. Die Wahrscheinlichkeit, mit der ein \\(\\omega\\) aus \\(\\Omega\\) in einem Durchgang realisiert wird, wird durch den Wert \\(\\mathbb{P}(\\{\\omega\\}) \\in [0,1]\\) beschrieben. Ist zum Beispiel \\(\\mathbb{P}(\\{\\omega\\}) = 1\\), so wird dieses \\(\\omega\\) in jedem Durchgang des Zufallsvorgangs realisiert; ist \\(\\mathbb{P}(\\{\\omega\\}) = 0\\), so wird dieses \\(\\omega\\) in keinem Durchgang des Zufallsvorgangs realisiert; und ist \\(\\mathbb{P}(\\{\\omega\\}) = 1/2\\), so wird \\(\\omega\\) in etwa der Hälfte der Durchgänge des Zufallsvorgangs realisiert. Beim Modell des Werfens eines fairen Würfels nimmt man üblicherweise \\(\\mathbb{P}(\\{\\omega\\}) = 1/6\\) für alle \\(\\omega \\in \\Omega\\) an. Hier könnte zum Beispiel im ersten Durchgang eine Vier realisiert werden, im zweiten Durchgang eine Eins, im dritten Durchgang eine Fünf, dann vielleicht wieder eine Vier und so weiter.\n\n\nEreignisse und Ereignissystem\nDen Begriff des Ereignisses \\(A \\in \\mathcal{A}\\) stellt man sich am besten als konzeptionelle Zusammenfassung ein oder mehrerer Ergebnisse vor. Beim Werfen eines Würfels sind mögliche Ereignisse zum Beispiel “Es fällt eine gerade Augenzahl”, das heißt \\(\\omega \\in \\{2,4,6\\}\\); “Es fällt eine Augenzahl größer als Zwei”, das heißt \\(\\omega \\in \\{3,4,5,6\\}\\); oder etwa “Es fällt eine Eins oder eine Fünf”, das heißt \\(\\omega \\in \\{1,5\\}\\). Man beachte, dass zum Beispiel das Ereignis “Es fällt eine gerade Augenzahl” vor dem Hintergrund der Mechanik des Wahrscheinlichkeitsraums genau dann eintritt, wenn in einem Durchgang des Zufallsvorgangs das realisierte \\(\\omega\\) ein Element der Menge \\(\\{2,4,6\\}\\) ist, wenn also zum Beispiel eine Vier fällt. Man mag das Eintreten des Ereignisses “Es fällt eine Augenzahl größer als Zwei” also auch lesen als “In einem Durchgang des Zufallsvorgangs wird ein Element von \\(\\{3,4,5,6\\}\\) realisiert”, d.h. konkret fällt entweder eine Drei, eine Vier, eine Fünf oder eine Sechs. Natürlich sind auch die Ergebnisse \\(\\omega \\in \\Omega\\) selbt mögliche Ereignisse, so dass zum Beispiel folgende Interpretationen gelten: Das Ereignis “Es fällt eine Eins” entspricht der Realisation \\(\\omega \\in \\{1\\}\\) und das Ereignis “Es fällt eine Sechs” entspricht der Realisation \\(\\omega \\in \\{6\\}\\). Betrachtet man in diesem Zusammenhang ein Ergebnis \\(\\omega \\in \\Omega\\) als Ereignis, so nennt man es Elementarereignis und schreibt es als einelementige Menge \\(\\{\\omega\\}\\).\nInsgesamt entspricht dieses Vorgehen zur Beschreibung zufälliger Ereignisse dem inhärenten Ziel der Definition des Wahrscheinlichkeitsraums. Kolmogoroff (1933) schreibt dazu “Wir haben die eigentlichen Objekte unserer weiteren Betrachtungen - die zufälligen Ereignisse - als Mengen definiert.” Dies hat den Vorteil, dass Mengen mathematische Objekte sind, mit denen mathematisch gearbeitet werden kann und damit ein Aspekt der Wirklichkeit, ein “zufälliges Ereignis”, in den Modellbereich der Mathematik übersetzt wurde.\nAlleiniger Sinn des Ereignissystems \\(\\mathcal{A}\\) ist es nun, alle Ereignisse, die sich basierend auf einer gegebenen Ergebnismenge bei Auswahl eines \\(\\omega \\in \\Omega\\) ergeben können, mathematisch zu repräsentieren. Es soll also keine Ereignisse in der Wirklichkeit geben, die nicht im Vorhinein im Wahrscheinlichkeitsraummodells des Zufallsvorgangs mitgedacht wurden. Wäre dies der Fall, so wäre das Modell defizitär, da es für bestimmte, in der Wirklichkeit eintretende Ergeignisse keine Wahrscheinlichkeiten angeben könnte. Das Ereignissystem \\(\\mathcal{A}\\) soll also die vollständige Menge aller möglichen Ereignisse bei vorgegebenem \\(\\Omega\\) sein. Die Forderung, dass \\(\\mathcal{A}\\) zu diesem Zweck die sogenannten \\(\\sigma\\)-Algebra Kriterien erfüllen soll, begründet sich dabei intuitiv wie folgt.\n\nEs soll zunächst einmal sichergestellt sein, dass \\(\\omega \\in \\Omega\\) für ein beliebiges \\(\\omega\\), dass also irgendein Ergebnis realisiert wird, eines der möglichen Ereignisse ist. Dies entspricht der Eigenschaft \\(\\Omega \\in \\mathcal{A}\\).\nZu jedem Ereignis soll es weiterhin auch möglich sein, dass dieses Ereignis gerade nicht eintritt. Dies entspricht der Eigenschaft, dass aus \\(A \\in \\mathcal{A}\\) folgen soll, dass \\(A^c := \\Omega \\setminus A\\) auch in \\(\\mathcal{A}\\) ist. Dies impliziert insbesondere auch, dass \\(\\emptyset = \\Omega \\setminus \\Omega \\in \\mathcal{A}\\). Ein Ereignis ist also, dass kein Elementarereignis eintritt, allerdings passiert dies nur mit Wahrscheinlichkeit Null, \\(\\mathbb{P}(\\emptyset) = 0\\). Es tritt also sicher immer zumindest ein Elementarereignis ein.\nSchließlich soll die Kombination von Ereignissen auch immer ein Ereignis sein. Bei der Modellierung des Werfen eines Würfels soll also zum Beispiel neben den Ereignissen “Es fällt eine gerade Zahl” und “Es fällt eine Zahl größer Zwei” auch das Ereignis “Es fällt eine gerade Zahl und/oder diese Zahl ist größer als Zwei” ein Ereignis sein. Dies entspricht, in allgemeinster Form, dass aus \\(A_1,A_2,... \\in \\mathcal{A}\\) folgen soll, dass auch \\(\\cup_{i=1}^\\infty A_i \\in \\mathcal{A}\\) ist.\n\nWenn auch die Begriffe des Ereignissystems und der \\(\\sigma\\)-Algebra etwas abstrakt anmuten mögen, so stellt ihre Definition in der praktischen Modellierung von Zufallsvorgängen meist keine großen Herausforderung dar, da sowohl für endliche Ergebnismengen als auch für unendliche (abzählbare und überabzählbare) Ergebnismengen passende Ereignissysteme schon lange bekannt sind. So erfüllt bei Ergebnismengen mit endlicher Kardinalität die Potenzmenge der Ergebnismenge immer die Anforderungen eines Ereignissystems und kann immer zur Modellformulierung eines Zufallsvorgangs mit endlicher Ergebnismenge genutzt werden. Dies ist die Aussage folgenden Theorems.\n\nTheorem 9.1 (Ereignissystem bei endlicher Ergebnismenge) \\(\\Omega := \\{\\omega_1,\\omega_2,...,\\omega_n\\}\\) mit \\(n \\in \\mathbb{N}\\) sei eine endliche Menge. Dann ist die Potenzmenge \\(\\mathcal{P}(\\Omega)\\) von \\(\\Omega\\) eine \\(\\sigma\\)-Algebra auf \\(\\Omega\\) und damit ein geeignetes Ereignisssytem im Wahrscheinlichkeitsraummodell.\n\n\nBeweis. Die Potenzmenge von \\(\\Omega\\) ist die Menge aller Teilmengen von \\(\\Omega\\). Wir überprüfen die \\(\\sigma\\)-Algebra Eigenschaften. Zunächst gilt, dass \\(\\Omega\\) selbst eine der Teilmengen von \\(\\Omega\\) ist, also ist die erste \\(\\sigma\\)-Algebra Eigenschaft erfüllt. Sei nun \\(A\\) eine Teilmenge von \\(\\Omega\\). Dann ist auch \\(A^c = \\Omega \\setminus A\\) eine Teilmenge von \\(\\Omega\\) und somit ist auch die zweite \\(\\sigma\\)-Algebra Eigenschaft erfüllt. Schließlich betrachten wir die Vereinigung von \\(n\\) Teilmengen \\(A_1, A_2, ...,A_n \\subseteq \\Omega\\). Dann ist \\(\\cup_{i=1}^n A_i\\) die Menge der \\(\\omega \\in \\Omega\\) für die gilt, dass \\(\\omega \\in A_1\\) und/oder \\(\\omega \\in A_2\\) … und/oder \\(\\omega \\in A_n\\). Da für alle diese \\(\\omega\\) gilt, dass \\(\\omega \\in \\Omega\\) ist also auch \\(\\cup_{i=1}^n A_i\\) eine Teilmenge von \\(\\Omega\\) und damit auch die dritte \\(\\sigma\\)-Algebra Eigenschaft erfüllt. Die Potenzmenge erfüllt also die geforderten Eigenschaften an ein Ereignissystem.\n\nBei überabzählbaren Ergebnismengen wie den reellen Zahlen \\(\\mathbb{R}\\) oder dem \\(n\\)-dimensionalen reellen Raum \\(\\mathbb{R}^n\\) ist die Konstruktion eines geeigneten Ereignissystems komplexer, so dass wir in dieser Hinsicht für formale Entwicklungen auf die weiterführende Literatur verweisen wollen (z.B. Meintrup & Schäffler (2005), Schmidt (2009)). Mit der auf Borel (1898) zurückgehenden sogenannten Borelschen \\(\\sigma\\)-Algebra ist jedoch ein Mengensystem bekannt, das den Anforderungen einer \\(\\sigma\\)-Algebra auf überabzähbaren Ergebnismengen genügt. Wir bezeichnen die Borelsche \\(\\sigma\\)-Algebra auf \\(\\mathbb{R}^n\\) mit \\(\\mathcal{B}(\\mathbb{R})\\) und die Borelsche \\(\\sigma\\)-Algebra auf \\(\\mathbb{R}^n\\) mit \\(\\mathcal{B}(\\mathbb{R}^n)\\). Als Menge von Teilmengen von \\(\\mathbb{R}\\) bzw. \\(\\mathbb{R}^n\\) enthalten \\(\\mathcal{B}(\\mathbb{R})\\) bzw. \\(\\mathcal{B}(\\mathbb{R}^n)\\) alle Mengen, an denen man hinsichtlich ihrer durch \\(\\mathbb{P}\\) zugeordneten Wahrscheinlichkeit interessiert sein mag. Intuitiv mag man sich die Borelschen \\(\\sigma\\)-Algebren \\(\\mathcal{B}(\\mathbb{R})\\) und \\(\\mathcal{B}(\\mathbb{R}^n)\\) also als die Potenzmengen von \\(\\mathbb{R}\\) bzw. \\(\\mathbb{R}^n\\) denken, auch wenn dies formal falsch ist. Tatsächlich enthält die Borelsche \\(\\sigma\\)-Algebra nur Teilmengen, die durch abzählbare Mengenoperationen generiert werden, nicht aber durch überabzählbare.\nInsgesamt ergibt sich also folgendes Vorgehen zur Auswahl von Ereignissystemen in Abhängigkeit von der Ergebnismenge \\(\\Omega\\). Ist \\(\\Omega\\) endlich, so wählt man als Ereignissystem \\(\\mathcal{A}\\) die Potenzmenge \\(\\mathcal{P}(\\Omega)\\) von \\(\\Omega\\). Ist \\(\\Omega\\) gegeben durch \\(\\mathbb{R}\\), so wählt man als Ereignissystem \\(\\mathcal{A}\\) die Borelsche \\(\\sigma\\)-Algebra \\(\\mathcal{B}(\\mathbb{R})\\). Ist \\(\\Omega\\) schließlich gegeben durch \\(\\mathbb{R}^n\\), so wählt man für \\(\\mathcal{A}\\) die Borelsche \\(\\sigma\\)-Algebra \\(\\mathcal{B}(\\mathbb{R}^n)\\). In Spezialfällen und für sehr spezielle Ergebnismengen \\(\\Omega\\) mag man von diesem Vorgehen abweichen wollen, allgemein decken die drei betrachteten Fälle jedoch die meisten Anwendungen ab.\n\n\nWahrscheinlichkeitsmaß \\(\\mathbb{P}\\)\nMit \\(\\Omega\\) und \\(\\mathcal{A}\\), die in Tupleform \\((\\Omega,\\mathcal{A})\\) auch als Messraum bezeichnet werden, haben wir bisher die strukturelle Basis eines Wahrscheinlichkeitsraummodells genauer betrachtet. Viele Wahrscheinlichkeitsräume, zum Beispiel für Zufallsvorgänge die reellen Zahlen betreffend, sind hinsichtlich ihres Messraums identisch. Das Wahrscheinlichkeitsmaß \\(\\mathbb{P}\\) nun repräsentiert die probabilistischen Charakteristika eines Wahrscheinlichkeitsraummodells und formt damit die funktionelle Basis eines Wahrscheinlichkeitsraummmodells. Wir werden im Folgenden, insbesondere nach Einführung der Begriffe der Zufallsvariablen und Zufallsvektoren, sehr viele verschiedene Wahrscheinlichkeitsmaße kennenlernen. An dieser Stelle wollen wir zunächst nur allgemeine Eigenschaften von Wahrscheinlichkeitsmaßen betrachten.\nMit der Definition \\[\\begin{equation}\n\\mathbb{P}: \\mathcal{A} \\to [0,1], A \\mapsto \\mathbb{P}(A)\n\\end{equation}\\] gilt zunächst einmal, dass ein Wahrscheinlichkeitsmaß auf einer Menge von Mengen definiert ist und den Elementen dieser Menge, also den Mengen \\(A \\in \\mathcal{A}\\), Wahrscheinlichkeiten, also Werte im Intervall \\([0,1]\\), zuordnet. Natürlich gilt mit \\(\\{\\omega\\} \\in \\mathcal{A}\\) für alle \\(\\omega \\in \\Omega\\), dass \\(\\mathbb{P}\\) auch den Elementareignissen Wahrscheinlichkeiten zuordnet, aber eben nicht nur. Wir betonen auch, dass nach Definition die Wahrscheinlichkeit \\(\\mathbb{P}(A)\\) eines Ereignisses \\(A \\in \\mathcal{A}\\) eine Zahl im Intervall \\([0,1]\\) ist und nicht etwa eine Prozentzahl oder ein Verhältnis. Wir wollen nachfolgend die definierenden Eigenschaften der Nicht-Negativität, der Normiertheit und der \\(\\sigma\\)-Additivität von \\(\\mathbb{P}\\) näher beleuchten.\nDie Nicht-Negativität \\(\\mathbb{P}(A) \\ge 0\\) für alle \\(A \\in \\mathcal{A}\\) ist natürlich in der Definition \\([0,1]\\) der Zielmenge von \\(\\mathbb{P}\\) implizit. Tatsächlich ist die Abbildungsform von \\(\\mathbb{P}\\) eine von uns vorgenommene Ergänzung der Formulierung von Kolmogoroff (1933), die der Klarheit dienen soll. Formal folgt die Form der Zielmenge von \\(\\mathbb{P}\\) eigentlich aus den definierenden Eigenschaften der Nicht-Negativität, Normiertheit, und \\(\\sigma\\)-Additivität von \\(\\mathbb{P}\\).\nDie Normiertheit \\(\\mathbb{P}(\\Omega) = 1\\) entspricht der Tatsache, dass in jedem Durchgang eines Zufallsvorgangs sicher gilt, dass ein realisiertes \\(\\omega\\) ein Element von \\(\\Omega\\) ist. In jedem Durchgang eines Zufallsvorgangs tritt also ein Elementarereignis ein und, je nach Beschaffenheit des Messraums, noch viele weitere. Beim Modell des Werfen eines Würfels gilt also, dass das in einem Durchgang des Zufallsvorgangs realisierte Ergebnis/Elementarereignis mit Wahrscheinlichkeit \\(1\\) ein Element von \\(\\Omega := \\{1,2,3,4,5,6\\}\\) ist. Ist das realisierte Ergebnis zum Beispiel eine Eins, so treten neben dem Ereignis “Es fällt eine Eins” auch noch die Ereignisse “Eine ungerade Zahl fällt”, “Eine Zahl kleiner als Drei fällt”, “Eine ungerade Zahl kleiner als Drei fällt” und viele weitere ein.\nDie \\(\\sigma\\)-Additivität des Wahrscheinlichkeitsmaßes \\(\\mathbb{P}\\) schließlich bildet das Fundament der Wahrscheinlichkeitsrechnung, also die Grundlage für das Rechnen mit Wahrscheinlichkeiten. Die \\(\\sigma\\)-Additivität von \\(\\mathbb{P}\\) erlaubt es nämlich, aus bereits bekannten Ereigniswahrscheinlichkeiten die Wahrscheinlichkeiten anderer Ereignisse zu berechnen. Man kann damit basierend auf einer Definition von \\(\\Omega, \\mathcal{A}\\) und \\(\\mathbb{P}\\) also Wahrscheinlichkeiten für alle möglichen Ereignisse eines Wahrscheinlichkeitsraummodells berechnen. Ob diese Wahrscheinlichkeiten nun aber tatsächlich etwas mit den realen Ereignissen bezüglich eines Zufallsvorgangs der Wirklichkeit zu tun haben, kommt darauf an, ob die Modellierung einigermaßen gelungen ist oder nicht. Dabei werden berechnete Wahrscheinlichkeiten aber zumindest rational, also nach den Regeln der Vernunft, d.h. der Logik und der Mathematik, bestimmt. Insgesamt erlaubt das Wahrscheinlichkeitsmodell damit das schlussfolgernde Nachdenken über mit Unsicherheit behaftete Phänomene.\nWir wollen abschließend das auf der \\(\\sigma\\)-Addivitität von \\(\\mathbb{P}\\) beruhende Rechnen mit Wahrscheinlichkeiten noch an zwei grundlegenden Beispielen verdeutlichen.\nDas erste Beispiel besagt, dass die Wahrscheinlichkeit dafür, dass das in einem Durchgang eines Zufallsvorgangs realisierte \\(\\omega\\) kein Element der Ergebnismenge ist, gleich Null ist.\n\nTheorem 9.2 (Wahrscheinlichkeit des unmöglichen Ereignisses) \\((\\Omega, \\mathcal{A}, \\mathbb{P})\\) sei ein Wahrscheinlichkeitsraum. Dann gilt \\[\\begin{equation}\n\\mathbb{P}(\\emptyset) = 0.\n\\end{equation}\\]\n\n\nBeweis. Für \\(i = 1,2,...\\) sei \\(A_i := \\emptyset\\). Dann ist \\(A_1,A_2,...\\) eine Folge disjunkter Ereignisse, weil gilt, dass \\(\\emptyset \\cap \\emptyset = \\emptyset\\) und es ist \\(\\cup_{i=1}^\\infty A_i = \\emptyset\\). Mit der \\(\\sigma\\)-Additivität von \\(\\mathbb{P}\\) folgt dann, dass \\[\\begin{equation}\n\\mathbb{P}(\\emptyset)\n= \\mathbb{P}\\left(\\cup_{i=1}^\\infty A_i\\right)\n= \\sum_{i=1}^\\infty \\mathbb{P}\\left(A_i\\right)\n= \\sum_{i=1}^\\infty \\mathbb{P}\\left(\\emptyset\\right).\n\\end{equation}\\] Das unendliche Aufaddieren der Zahl \\(\\mathbb{P}(\\emptyset) \\in [0,1]\\) soll also wieder \\(\\mathbb{P}(\\emptyset)\\) ergeben. Dies ist aber nur möglich, wenn \\(\\mathbb{P}(\\emptyset) = 0\\).\n\nMan beachte, dass hier intuitiv natürlich eine mögliche Unzulänglichkeit des Wahrscheinlichkeitsraums als Modell für Zufallsvorgänge in der Wirklichkeit auftritt: Fällt beim Würfelspiel der Würfel zum Beispiel unerreichbar unter das Sofa, so ist ein Elementarereignis \\(\\omega \\notin \\Omega\\) eingetreten, obwohl seine modellierte Wahrscheinlichkeit gleich Null ist.\nAls zweites Beispiel wollen wir zeigen, dass die \\(\\sigma\\)-Additivät, die in der Definition des Wahrscheinlichkeitsraums (nur) für die Vereinigung unendlich vieler disjunkter Ereignisse definiert ist, die \\(\\sigma\\)-Additivät endlich vieler disjunkter Ereignisse, wie sie in in der Anwendung oft vorkommen, impliziert.\n\nTheorem 9.3 (\\(\\sigma\\)-Additivität bei endlichen Folgen disjunkter Ereignisse) \\((\\Omega, \\mathcal{A}, \\mathbb{P})\\) sei ein Wahrscheinlichkeitsraum und \\(A_1,...,A_n\\) sei eine endliche Folge paarweise disjunkter Ereignisse. Dann gilt \\[\\begin{equation}\n\\mathbb{P}(\\cup_{i=1}^n A_i) = \\sum_{i=1}^n \\mathbb{P}(A_i).\n\\end{equation}\\]\n\n\nBeweis. Wir betrachten eine unendliche Folge von paarweise disjunkten Ereignissen \\(A_1, A_2, ...\\) wobei für ein \\(n\\in \\mathbb{N}\\) gelten soll, dass \\(A_i := \\emptyset\\) für \\(i&gt;n\\). Dann gilt mit der \\(\\sigma\\)-Additivität von \\(\\mathbb{P}\\) zunächst, dass \\[\\begin{equation}\n\\mathbb{P}\\left(\\cup_{i=1}^n A_i\\right)\n= \\mathbb{P}\\left(\\cup_{i=1}^\\infty A_i\\right)\n= \\sum_{i=1}^\\infty \\mathbb{P}\\left(A_i\\right)\n= \\sum_{i=1}^n \\mathbb{P}\\left(A_i\\right) + \\sum_{i=n+1}^\\infty \\mathbb{P}\\left(A_i\\right).\n\\end{equation}\\] Mit \\(\\mathbb{P}\\left(A_i\\right) = \\mathbb{P}(\\emptyset) = 0\\) für \\(i = n+1, n+2,...\\) folgt dann direkt \\[\\begin{equation}\n\\mathbb{P}\\left(\\cup_{i=1}^n A_i\\right)\n= \\sum_{i=1}^n \\mathbb{P}\\left(A_i\\right) + 0\n= \\sum_{i=1}^n \\mathbb{P}\\left(A_i\\right).\n\\end{equation}\\]"
  },
  {
    "objectID": "201-Wahrscheinlichkeitsräume.html#sec-wahrscheinlichkeitsfunktionen",
    "href": "201-Wahrscheinlichkeitsräume.html#sec-wahrscheinlichkeitsfunktionen",
    "title": "9  Wahrscheinlichkeitsräume",
    "section": "9.2 Wahrscheinlichkeitsfunktionen",
    "text": "9.2 Wahrscheinlichkeitsfunktionen\nIn diesem Abschnitt wollen wir mit den Wahrscheinlichkeitsfunktionen eine erste Möglichkeit kennenlernen, für Wahrscheinlichkeitsräume mit endlicher Ergebnismenge Wahrscheinlichkeitsmaße festzulegen. In Kapitel 9.3 nutzen wir dieses Hilfsmittel intensiv, um erste Beispiele für die Modellierung von Zufallsvorgängen mithilfe von Wahrscheinlichkeitsräumen geben zu können. Wir definieren den Begriff der Wahrscheinlichkeitsfunktion wie folgt.\n\nDefinition 9.2 (Wahrscheinlichkeitsfunktion) \\(\\Omega\\) sei eine endliche Menge. Dann heißt eine Funktion \\(\\pi:\\Omega \\to [0,1]\\) Wahrscheinlichkeitsfunktion, wenn gilt, dass \\[\\begin{equation}\n\\sum_{\\omega \\in \\Omega} \\pi(\\omega) = 1.\n\\end{equation}\\] Sei weiterhin \\(\\mathbb{P}\\) ein Wahrscheinlichkeitsmaß. Dann heißt die durch \\[\\begin{equation}\n\\pi : \\Omega \\to [0,1], \\omega \\mapsto \\pi(\\omega) := \\mathbb{P}(\\{\\omega\\})\n\\end{equation}\\] definierte Funktion Wahrscheinlichkeitsfunktion von \\(\\mathbb{P}\\) auf \\(\\Omega\\).\n\nWir merken an, dass weil \\(\\mathbb{P}\\) per Definition \\(\\sigma\\)-additiv ist, insbesondere auch gilt, dass \\[\\begin{equation}\n\\mathbb{P}(\\Omega)\n= \\mathbb{P}(\\cup_{\\omega \\in \\Omega}\\{\\omega\\})\n= \\sum_{\\omega \\in \\Omega}\\mathbb{P}(\\{\\omega\\})\n= \\sum_{\\omega \\in \\Omega}\\pi(\\omega)\n= 1.\n\\end{equation}\\] Zur Konstruktion von Wahrscheinlichkeitsmaßen durch Wahrscheinlichkeitsfunktionen stellt folgendes Theorem die formale Basis bereit. Es besagt insbesondere, dass bei endlichem \\(\\Omega\\) die Wahrscheinlichkeiten aller möglichen Ereignisse aus den Wahrscheinlichkeiten der Elementarereignisse \\(\\pi(\\omega)\\) berechnet werden können.\n\nTheorem 9.4 \\((\\Omega, \\mathcal{A}, \\mathbb{P})\\) sei ein Wahrscheinlichkeitsraum mit endlicher Ergebnismenge und \\(\\pi: \\Omega \\to [0,1]\\) sei eine Wahrscheinlichkeitsfunktion. Dann existiert ein Wahrscheinlichkeitsmaß \\(\\mathbb{P}\\) auf \\(\\Omega\\) mit \\(\\pi\\) als Wahrscheinlichkeitsfunktion von \\(\\mathbb{P}\\). Dieses Wahrscheinlichkeitsmaß ist definiert als \\[\\begin{equation}\n\\mathbb{P} : \\mathcal{A} \\to [0,1], A \\mapsto \\mathbb{P}(A) := \\sum_{\\omega \\in A} \\pi(\\omega).\n\\end{equation}\\]\n\n\nBeweis. Wir überprüfen zunächst die Wahrscheinlichkeitsmaßeigenschaften von \\(\\mathbb{P}\\). Weil \\(\\pi(\\omega) \\in [0,1]\\) für alle \\(\\omega \\in \\Omega\\), gilt auch immer \\(\\sum_{\\omega \\in A} \\pi(\\omega) \\ge 0\\) und damit die Nicht-Negativität von \\(\\mathbb{P}\\). Ferner folgt wie oben gesehen mit der Normiertheit von \\(\\pi\\) direkt die Normiertheit von \\(\\mathbb{P}\\). Seien nun \\(A_1, A_2,... \\in \\mathcal{A}\\). Dann gilt \\[\\begin{equation}\n\\mathbb{P}\\left(\\cup_{i=1}^\\infty A_i \\right)\n= \\sum_{\\omega \\in \\cup_{i=1}^\\infty A_i} \\pi(\\omega)\n= \\sum_{i = 1}^\\infty \\sum_{\\omega \\in A_i} \\pi(\\omega)\n= \\sum_{i = 1}^\\infty \\mathbb{P}(A_i).\n\\end{equation}\\] und damit die \\(\\sigma\\)-Addivität von \\(\\mathbb{P}\\).\n\nDefiniert man also für eine gegebene Ergebnismenge \\(\\Omega\\) eine Funktion \\(\\pi : \\Omega \\to [0,1]\\) und stellt sicher, dass sich die Funktionswerte \\(\\pi(\\omega)\\) über alle \\(\\omega \\in \\Omega\\) hinweg zu 1 summieren und interpretiert den einzelnen Funktionswert \\(\\pi(\\omega)\\) dann als die Wahrscheinlichkeit \\(\\mathbb{P}(\\{\\omega\\})\\) des Elementarereignisses \\(\\{\\omega\\} \\in \\mathcal{A}\\), so hat man ein Wahrscheinlichkeitsmaß konstruiert."
  },
  {
    "objectID": "201-Wahrscheinlichkeitsräume.html#sec-beispiele-bei-endlichem-ergebnisraum",
    "href": "201-Wahrscheinlichkeitsräume.html#sec-beispiele-bei-endlichem-ergebnisraum",
    "title": "9  Wahrscheinlichkeitsräume",
    "section": "9.3 Beispiele bei endlichem Ergebnisraum",
    "text": "9.3 Beispiele bei endlichem Ergebnisraum\nAus dem bis hierin Gesagtem lässt sich nun zusammenfassend folgendes Vorgehen zur Modellierung eines Zufallsvorganges mithilfe eines Wahrscheinlichkeitsraums \\((\\Omega, \\mathcal{A}, \\mathbb{P})\\) festhalten:\n\nIn einem ersten Schritt überlegt man sich eine sinnvolle Definition der Ergebnismenge \\(\\Omega\\), also der Ergebnisse bzw. Elementarereignisse, die in jedem Durchgang des Zufallsvorgangs realisiert werden sollen.\nIn einem zweiten Schritt wählt man dann ein geignetes Ereignissystem; im Falle einer endlichen Ergebnismenge bietet sich die Potenzmenge \\(\\mathcal{P}(\\Omega)\\) an, im Falle der überabzählbaren Ergebnismenge \\(\\Omega := \\mathbb{R}\\) bietet sich die Borelsche \\(\\sigma\\)-Algebra \\(\\mathcal{B}(\\mathbb{R})\\) an.\nSchließlich definiert man ein Wahrscheinlichkeitsmaß \\(\\mathbb{P}\\), das die Wahrscheinlichkeiten für das Auftreten aller möglichen Ereignisse repräsentiert. Im Falle einer endlichen Ergebnismenge gelingt dies inbesondere durch Definition der Wahrscheinlichkeiten der Elementarereignisse. In der Folge verdeutlichen wir dieses Vorgehen anhand von Beispielen. Im Falle der überabzählbaren Ergebnismenge \\(\\Omega := \\mathbb{R}\\) bietet sich die Definition von \\(\\mathbb{P}\\) mithilfe von Wahrscheinlichkeitsdichtefunktionen an, wie wir später sehen werden.\n\n\nWürfeln mit einem Würfel\nWir modellieren das Würfeln mit einem Würfel. Es ist sicherlich sinnvoll, die Ergebnismenge als \\(\\Omega := \\{1,2,3,4,5,6\\}\\) zu definieren. Allerdings wäre auch die Definition von \\(\\Omega := \\{ \\cdot, \\cdot\\cdot, \\cdot\\cdot\\cdot, \\cdot\\cdot\\cdot\\cdot, \\cdot\\cdot\\cdot\\cdot\\cdot, \\cdot\\cdot\\cdot\\cdot\\cdot\\cdot \\}\\) in äquivalenter Weise möglich.\nDa es sich um eine endliche Ergebnismenge handelt, wählen wir als \\(\\sigma\\)-Algebra \\(\\mathcal{A}\\) die Potenzmenge \\(\\mathcal{P}(\\Omega)\\). \\(\\mathcal{A}\\) enthält dann automatisch alle möglichen Ereignisse. Die Kardinalität von \\(\\mathcal{A} := \\mathcal{P}(\\Omega)\\) ist \\(|\\mathcal{P}(\\Omega)| = 2^{|\\Omega|} = 2^6 = 64\\). In untenstehender Tabelle listen wir sechs dieser 64 Ereignisse in ihrer verbalen Beschreibung und als Teilmenge \\(A\\) von \\(\\Omega\\) auf.\n\n\n\nAusgewählte Ereignisse beim Modell des Werfen eines Würfels.\n\n\n\n\n\n\nBeschreibung\nMengenform\n\n\n\n\nEs fällt eine beliebige Augenzahl\n\\(\\omega \\in A = \\Omega\\)\n\n\nKeine Augenzahl fällt\n\\(\\omega \\in A = \\emptyset\\)\n\n\nEs fällt eine Augenzahl größer als 4\n\\(\\omega \\in A = \\{5,6\\}\\)\n\n\nEs fällt eine gerade Augenzahl\n\\(\\omega \\in A = \\{2,4,6\\}\\)\n\n\nEs fällt eine Sechs\n\\(\\omega \\in A = \\{6\\}\\)\n\n\nEine Eins, eine Drei oder eine Sechs fällt\n\\(\\omega \\in A = \\{1,3,6\\}\\)\n\n\n\n\n\nDamit ist die Definition des Messraum \\((\\Omega, \\mathcal{A})\\) in der Modellierung des Werfens eines Würfels abgeschlossen.\nWie in Kapitel 9.2 beschrieben kann das Wahrscheinlichkeitsmaß \\(\\mathbb{P}\\) durch Festlegung von \\(\\mathbb{P}(\\{\\omega\\})\\) für alle \\(\\omega \\in \\Omega\\) festgelegt werden. Für das Modell eines unverfälschten Würfels würde man \\[\\begin{equation}\n\\mathbb{P}(\\{\\omega\\}) := \\frac{1}{|\\Omega|} := 1/6 \\mbox{ für alle } \\omega \\in \\Omega\n\\end{equation}\\] wählen. Für ein Modell eines verfälschten Würfels, der das Werfen einer Sechs bevorzugt, könnte man zum Beispiel definieren, dass \\[\\begin{equation}\n\\mathbb{P}(\\{\\omega\\}) := \\frac{1}{8} \\mbox{ für } \\omega \\in \\{1,2,3,4,5\\}\n\\mbox{ und }\n\\mathbb{P}(\\{6\\}) := \\frac{3}{8}.\n\\end{equation}\\] Im Fall des unverfälschten Würfel ergibt sich beispielsweise die Wahrscheinlichkeit für das Ereignis “Es fällt eine gerade Augenzahl” mit der \\(\\sigma\\)-Additivät von \\(\\mathbb{P}\\) dann zu \\[\\begin{equation}\n\\mathbb{P}(\\{2,4,6\\})\n= \\mathbb{P}(\\{2\\} \\cup \\{4\\} \\cup \\{6\\} )\n= \\mathbb{P}(\\{2\\}) + \\mathbb{P}(\\{4\\}) + \\mathbb{P}(\\{6\\})\n= \\frac{1}{6} + \\frac{1}{6} +  \\frac{1}{6}\n= \\frac{3}{6}.\n\\end{equation}\\] Im Fall des obigen Modells eines verfälschten Würfels ergibt sich für das gleiche Ereignis die Wahrscheinlichkeit zu \\[\\begin{equation}\n\\mathbb{P}(\\{2,4,6\\})\n= \\mathbb{P}(\\{2\\} \\cup \\{4\\} \\cup \\{6\\} )\n= \\mathbb{P}(\\{2\\}) + \\mathbb{P}(\\{4\\}) + \\mathbb{P}(\\{6\\})\n= \\frac{1}{8} + \\frac{1}{8} +  \\frac{3}{8}\n= \\frac{5}{8}.\n\\end{equation}\\] Das betrachtete Ereignis hat im Modell des verfälschten Würfels eine höhere Wahrscheinlichkeit als im Modell des unverfälschten Würfels, was intuitiv sinnvoll ist, da die Sechs eine gerade Zahl ist.\n\n\nGleichzeitiges Würfeln mit einem blauem und einem roten Würfel\nWir wollen nun das gleichzeitige Werfen eines blauen und eines roten Würfels modellieren. Dazu ist es sinnvoll, die Ergebnismenge als \\[\\begin{equation}\n\\Omega := \\{(r,b)| r \\in \\{1,2,3,4,5,6\\}, b \\in \\{1,2,3,4,5,6\\}\\}\n\\end{equation}\\] mit Kardinalität \\(|\\Omega| = 36\\) zu definieren, wobei \\(r\\) die Augenzahl des blauen Würfels und \\(b\\) die Augenzahl des roten Würfels repräsentieren soll.\nWiederum bietet sich die Wahl der Potenzmenge von \\(\\Omega\\) als \\(\\sigma\\)-Algebra an, wir definieren also wieder \\(\\mathcal{A} := \\mathcal{P}(\\Omega)\\). Die Anzahl der in diesem Modell möglichen Ereignisse ergibt sich zu \\(|\\mathcal{A}| = 2^{|\\Omega|} = 2^{36} = 68.719.476.736\\). In untenstehender Tabelle listen wir sechs dieser Ereignisse in ihrer verbalen Beschreibung und als Teilmenge \\(A\\) von \\(\\Omega\\) auf.\n\n\n\nAusgewählte Ereignisse beim Modell des Werfens eines roten und eines blauen Würfels.\n\n\n\n\n\n\nBeschreibung\nMengenform\n\n\n\n\nAuf dem roten Würfel fällt eine Drei\n\\(\\omega \\in A = \\{(3,1),(3,2),(3,3),(3,4),(3,5),(3,6)\\}\\)\n\n\nAuf dem blauen Würfel fällt eine Drei\n\\(\\omega \\in A = \\{(1,3),(2,3),(3,3),(4,3),(5,3),(6,3)\\}\\)\n\n\nAuf beiden Würfeln fällt eine Drei\n\\(\\omega \\in A = \\{(3,3)\\}\\)\n\n\nEs fällt eine Pasch\n\\(\\omega \\in A = \\{(1,1),(2,2),(3,3),(4,4),(5,5),(6,6)\\}\\)\n\n\nDie Summe der gefallenen Zahlen ist Vier\n\\(\\omega \\in A = \\{(1,3),(3,1),(2,2)\\}\\)\n\n\n\n\n\nDie Definition des Messraum \\((\\Omega, \\mathcal{A})\\) ist damit abgeschlossen. Ein Wahrscheinlichkeitsmaß \\(\\mathbb{P}\\) kann wiederum durch Definition von \\(\\mathbb{P}(\\{\\omega\\})\\) für alle \\(\\omega \\in \\Omega\\) festgelegt werden. Für das Modell zweier unverfälschter Würfel würde man \\[\\begin{equation}\n\\mathbb{P}(\\{\\omega\\}) := \\frac{1}{|\\Omega|} = \\frac{1}{36} \\mbox{ für alle } \\omega \\in \\Omega\n\\end{equation}\\] wählen. Unter diesem Wahrscheinlichkeitsmaß ergibt sich dann beispielsweise die Wahrscheinlichkeit für das Ereignis “Die Summe der gefallenen Zahlen ist Vier” mit der \\(\\sigma\\)-Additivät von \\(\\mathbb{P}\\) zu \\[\\begin{align*}\n\\begin{split}\n\\mathbb{P}\\left(\\{(1,3),(3,1),(2,2)\\}\\right)\n& = \\mathbb{P}\\left(\\{(1,3)\\}\\cup \\{(3,1)\\} \\cup \\{(2,2)\\}\\right) \\\\\n& = \\mathbb{P}\\left(\\{(1,3)\\}\\right)\n  + \\mathbb{P}\\left(\\{(3,1)\\}\\right)\n  + \\mathbb{P}\\left(\\{(2,2)\\}\\right) \\\\\n& = 1/36 + 1/36 + 1/36                  \\\\\n& = 1/12.\n\\end{split}\n\\end{align*}\\]\n\n\nWerfen einer Münze\nWir modellieren das Werfen einer Münze, deren eine Seite Kopf (Heads) und deren andere Seite Zahl (Tails) zeigt. Es ist sinnvoll, die Ergebnismenge als \\(\\Omega := \\{H,T\\}\\) zu definieren, wobei \\(H\\) “Heads” und \\(T\\) “Tails” repräsentiert. Allerdings wäre auch jede andere binäre Definition von \\(\\Omega\\) möglich, z.B. \\(\\Omega := \\{0,1\\}, \\Omega := \\{-1,1\\}\\), oder \\(\\Omega := \\{1,2\\}\\).\nDie Potenzmenge \\(\\mathcal{A} := \\mathcal{P}(\\Omega)\\) enthält alle möglichen Ereignisse. In diesem Fall können wir das gesamte Mengensystem \\(\\mathcal{A}\\) leicht, wie in untenstehender Tabelle gezeigt, komplett auflisten.\n\n\n\nEreignissystem \\(\\mathcal{A}\\) beim Modell des Werfens einer Münze.\n\n\nBeschreibung\nMengenform\n\n\n\n\nWeder Kopf noch Zahl fällt\n\\(\\omega \\in A = \\emptyset\\)\n\n\nKopf fällt\n\\(\\omega \\in A = \\{H\\}\\)\n\n\nZahl fällt\n\\(\\omega \\in A = \\{T\\}\\)\n\n\nKopf oder Zahl fällt\n\\(\\omega \\in A = \\{H,T\\}\\)\n\n\n\n\n\nDie Definition des Messraums \\((\\Omega, \\mathcal{A})\\) ist damit abgeschlossen.\nEin Wahrscheinlichkeitsmaß \\(\\mathbb{P}\\) kann wiederum durch Definition von \\(\\mathbb{P}(\\{\\omega\\})\\) für alle \\(\\omega \\in \\Omega\\) festgelegt werden. Die Normiertheit von \\(\\Omega\\) bedingt hier insbesondere, dass \\[\\begin{equation}\n\\mathbb{P}(\\Omega) = 1\n\\Leftrightarrow\n\\mathbb{P}(\\{H\\}) + \\mathbb{P}(\\{T\\})  = 1\n\\Leftrightarrow\n\\mathbb{P}(\\{T\\}) = 1 - \\mathbb{P}(\\{H\\}).\n\\end{equation}\\] Bei Festlegung der Wahrscheinlichkeit des Elementarereignisses \\(\\{H\\}\\) wird also die Wahrscheinlichkeit des Elementarereignis \\(\\{T\\}\\) sofort mit festgelegt, andersherum gilt dies natürlich ebenso. Für das Modell einer fairen Münze würde man \\(\\mathbb{P}(\\{H\\}) = \\mathbb{P}(\\{T\\}) := 1/2\\) wählen. Die Wahrscheinlichkeiten aller möglichen Ereignisse ergeben sich in diesem Fall zu \\[\\begin{equation}\n\\mathbb{P}(\\emptyset) = 0,\n\\mathbb{P}(\\{H\\}) = 1/2,\n\\mathbb{P}(\\{T\\}) = 1/2 \\mbox{ und }\n\\mathbb{P}(\\{H,T\\}) = 1.\n\\end{equation}\\]\n\n\nZweifaches Werfen einer Münze\nWir modellieren das zweifache Werfen einer Münzen. Basierend auf dem Modell des einfachen Münzwurfs ist es sinnvoll, die Ergebnismenge als \\(\\Omega := \\{HH,HT,TH,TT\\}\\) zu definieren. Die Potenzmenge \\(\\mathcal{A} := \\mathcal{P}(\\Omega)\\) enthält wiederum alle \\(2^{|\\Omega|} = 2^4 = 16\\) möglichen Ereignisse. In untenstehender Tabelle listen wir vier davon.\n\n\n\nAusgewählte Ereignisse beim Modell des zweifachen Werfens einer Münze.\n\n\nBeschreibung\nMengenform\n\n\n\n\nKopf fällt im ersten Wurf\n\\(\\omega \\in A = \\{HH,HT\\}\\)\n\n\nKopf fällt im zweiten Wurf\n\\(\\omega \\in A = \\{HH,TH\\}\\)\n\n\nKopf fällt nicht\n\\(\\omega \\in A = \\{TT\\}\\)\n\n\nZahl fällt mindestens einmal\n\\(\\omega \\in A = \\{HT, TH, TT\\}\\)\n\n\n\n\n\nDie Definition des Messraum \\((\\Omega, \\mathcal{A})\\) ist damit abgeschlossen. Ein Wahrscheinlichkeitsmaß \\(\\mathbb{P}\\) kann wiederum durch Definition von \\(\\mathbb{P}(\\{\\omega\\})\\) für alle \\(\\omega \\in \\Omega\\) festgelegt werden. Für das Modell des zweifachen Werfens einer fairen Münze würde man \\[\\begin{equation}\n\\mathbb{P}(\\{HH\\}) = \\mathbb{P}(\\{HT\\}) = \\mathbb{P}(\\{TH\\})= \\mathbb{P}(\\{TT\\}) := \\frac{1}{4}\n\\end{equation}\\] definieren."
  },
  {
    "objectID": "201-Wahrscheinlichkeitsräume.html#literaturhinweise",
    "href": "201-Wahrscheinlichkeitsräume.html#literaturhinweise",
    "title": "9  Wahrscheinlichkeitsräume",
    "section": "9.4 Literaturhinweise",
    "text": "9.4 Literaturhinweise\nDie Monographie “Grundbegriffe der Wahrscheinlichkeitsrechnung” von Andrey Kolmogorov (Kolmogoroff (1933)) symbolisiert die Grundlage der modernen Wahrscheinlichkeitsrechnung. Neben der hier diskutierten axiomatischen Einführung des Wahrscheinlichkeitsraummodells betrachtet Kolmogoroff (1933) noch viele weitere Aspekte der Wahrscheinlichkeitrechnung und bietet so einen gut lesbaren Einstieg in das gesamte Gebiet der Wahrscheinlichkeitstheorie. Natürlich ist der von Kolmogoroff (1933) formulierte Zugang nur ein vorläufiges Endprodukt der langen geschichtlichen Entwicklung der Wahrscheinlichkeitstheorie. Schließlich ist die Entwicklung der mathematischen Modellierung von Zufallvorgängen auch mit Kolmogoroff (1933) keinesfalls an einem Ende angelangt. Spätere Arbeiten im 20. Jahrhundert betrafen insbesondere die Interpretation des Wahrscheinlichkeitsbegriffs (vgl. De Finetti (1975)) oder führen verallgemeinerte quantitative Maße subjektiver Unsicherheit ein (vgl. Walley (1991)). Einen aktuellen Überblick zur Interpretation des Wahrscheinlichkeitsbegriffs und seiner formalen Grundlagen gibt Hájek (2019)."
  },
  {
    "objectID": "201-Wahrscheinlichkeitsräume.html#selbstkontrollfragen",
    "href": "201-Wahrscheinlichkeitsräume.html#selbstkontrollfragen",
    "title": "9  Wahrscheinlichkeitsräume",
    "section": "9.5 Selbstkontrollfragen",
    "text": "9.5 Selbstkontrollfragen\n\nGeben Sie die Definition des Begriffs der \\(\\sigma\\)-Algebra wieder.\nGeben Sie die Definition des Begriffs des Wahrscheinlichkeitsmaßes wieder.\nGeben Sie die Definition des Begriffs des Wahrscheinlichkeitsraums wieder.\nErläutern Sie den Begriff der Ergebnismenge \\(\\Omega\\).\nErläutern Sie die stillschweigende Mechanik des Wahrscheinlichkeitsraummodells.\nErläutern Sie den Begriff eines Ereignisses \\(A \\in \\mathcal{A}\\).\nErläutern Sie den Begriff des Ereignissystems \\(\\mathcal{A}\\).\nWelche \\(\\sigma\\)-Algebra wählt man sinnvoller Weise für einen Wahrscheinlichkeitsraum mit endlicher Ergebnismenge?\nErläutern Sie den Begriff des Wahrscheinlichkeitsmaßes \\(\\mathbb{P}\\).\nGeben Sie die Definition des Begriffs der Wahrscheinlichkeitsfunktion wieder.\nWarum ist der Begriff der Wahrscheinlichkeitsfunktion bei der Modellierung eines Zufallsvorgans durch einen Wahrscheinlichkeitsraums mit endlicher Ergebnismenge hilfreich?\nErläutern Sie die Modellierung des Werfens eines Würfels mithilfe eines Wahrscheinlichkeitsraums.\nErläutern Sie die Modellierung des gleichzeitigen Werfens eines roten und eines blauen Würfels mithilfe eines Wahrscheinlichkeitsraums. \n\n\n\n\n\nBorel, É. (1898). Leçons Sur La Théorie Des Fonctions. Paris: Gauthier Villars.\n\n\nDe Finetti, B. (1975). Theory of Probability. John Wiley & Sons.\n\n\nHájek, A. (2019). Interpretations of Probability. In E. N. Zalta (Hrsg.), The Stanford Encyclopedia of Philosophy (Fall 2019). Metaphysics Research Lab, Stanford University.\n\n\nKolmogoroff, A. (1933). Grundbegriffe der Wahrscheinlichkeitsrechnung. Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-642-49888-6\n\n\nMeintrup, D., & Schäffler, S. (2005). Stochastik: Theorie und Anwendungen. Springer.\n\n\nSchmidt, K. D. (2009). Maß und Wahrscheinlichkeit. Springer.\n\n\nWalley, P. (1991). Statistical Reasoning with Imprecise Probabilities (1st ed). Chapman and Hall."
  },
  {
    "objectID": "202-Elementare-Wahrscheinlichkeiten.html#sec-gemeinsame-wahrscheinlichkeiten",
    "href": "202-Elementare-Wahrscheinlichkeiten.html#sec-gemeinsame-wahrscheinlichkeiten",
    "title": "10  Elementare Wahrscheinlichkeiten",
    "section": "10.1 Gemeinsame Wahrscheinlichkeiten",
    "text": "10.1 Gemeinsame Wahrscheinlichkeiten\nDer Begriff der gemeinsamen Wahrscheinlichkeit zweier Ereignisse ist wie folgt definiert.\n\nDefinition 10.1 (Gemeinsame Wahrscheinlichkeit) \\((\\Omega, \\mathcal{A}, \\mathbb{P})\\) sei ein Wahrscheinlichkeitsraum und es seien \\(A,B \\in \\mathcal{A}\\). Dann heißt \\[\\begin{equation}\n\\mathbb{P}(A \\cap B)\n\\end{equation}\\] die gemeinsame Wahrscheinlichkeit von \\(A\\) und \\(B\\).\n\nWie oben angemerkt entspricht \\(\\mathbb{P}(A \\cap B)\\) der Wahrscheinlichkeit dafür, dass die Ereignisse \\(A\\) und \\(B\\) “gleichzeitig” eintreten. Dies verdeutlicht man sich am besten vor dem Hintergrund der Mechanik des Wahrscheinlichkeitsraummodells. Danach ist \\(\\mathbb{P}(A \\cap B)\\) eben die Wahrscheinlichkeit, dass in einem Durchgang eines Zufallsvorgangs ein \\(\\omega\\) realisiert wird, für das sowohl \\(\\omega \\in A\\) als auch \\(\\omega \\in B\\) gelten.\n\nBeispiel\nAls erstes Beispiel für eine gemeinsame Wahrscheinlichkeit zweier Ereignisse wollen wir wieder das Wahrscheinlichkeitsraummodells des Werfens eines fairen Würfels betrachten. Seien dazu \\(A\\) das Ereignis “Es fällt eine gerade Augenzahl”, also \\(A := \\{2,4,6\\}\\) und \\(B\\) das Ereignis “Es fällt eine Augenzahl größer als Drei”, also \\(B := \\{4,5,6\\}\\). Mengentheoretisch gilt dann \\[\\begin{equation}\nA \\cap B = \\{2,4,6\\} \\cap \\{4,5,6\\} = \\{4,6\\}.\n\\end{equation}\\] Die Interpretation von \\(A \\cap B = \\{4,6\\}\\) ist dabei gerade “Es fällt eine gerade Augenzahl und diese Augenzahl ist größer als Drei”. Bei Annahme der Fairness des Würfels, also für \\(\\mathbb{P}(\\{4\\}) = \\mathbb{P}(\\{6\\}) := 1/6\\) können wir mithilfe der \\(\\sigma\\)-Additivität von \\(\\mathbb{P}\\) die Wahrscheinlichkeit dieses Ereignisses leicht berechnen. Es ergibt sich \\[\\begin{align}\n\\begin{split}\n\\mathbb{P}(A \\cap B)\n& = \\mathbb{P}( \\{2,4,6\\} \\cap \\{4,5,6\\})       \\\\\n& = \\mathbb{P}( \\{4,6\\})                        \\\\\n& = \\mathbb{P}(\\{4\\}) + \\mathbb{P}(\\{6\\})       \\\\\n& = \\frac{1}{6} + \\frac{1}{6}                   \\\\\n& = \\frac{1}{3}.\n\\end{split}\n\\end{align}\\]\nBeim Nachdenken über gemeinsame Wahrscheinlichkeiten ist es natürlich wichtig, die gemeinsame Wahrscheinlichkeit \\(\\mathbb{P}(A \\cap B)\\) nicht mit der Wahrscheinlichkeit \\(\\mathbb{P}(A \\cup B)\\) des Ereignisses \\(A \\cup B\\) zur verwechseln. Es sei daran erinnert, dass die Vereinigung zweier Mengen \\(\\cup\\) dem inklusiven oder, also einem und/oder entspricht (vgl. Kapitel 1.3 und Kapitel 2.2). Das Ereignis \\(A \\cup B\\) entspricht also dem Ereignis, dass das Ereignis \\(A\\) und/oder das Ereignis \\(B\\) eintritt. Insbesondere ist \\(\\omega \\in A \\cup B\\) also auch schon dann erfüllt, wenn für das Ergebnis eines Durchgang eines Zufallsvorgangs nur \\(\\omega \\in A\\) oder nur \\(\\omega \\in B\\) gilt. Konkret ergibt sich etwa für die Ereignisse \\(A := \\{2,4,6\\}\\) und \\(B := \\{4,5,6\\}\\) aus obigem Würfelbeispiel \\[\\begin{equation}\nA \\cup B = \\{2,4,6\\} \\cup \\{4,5,6\\} = \\{2,4,5,6\\}\n\\end{equation}\\] mit der Interpretation “Es fällt eine gerade Augenzahl und/oder es fällt eine Augenzahl größer als Drei”. Für die entsprechende Wahrscheinlichkeit ergibt sich \\[\\begin{equation}\n\\mathbb{P}(\\{2,4,5,6\\}) = \\frac{2}{3},\n\\end{equation}\\] so dass in diesem Fall offenbar \\(\\mathbb{P}(A \\cap B) \\neq \\mathbb{P}(A \\cup B)\\) gilt.\nMithilfe folgendem Theorems wollen wir in diesem Abschnitt schließlich noch einige nützliche Eigenschaften zum Rechnen mit Wahrscheinlichkeiten festhalten, die sich direkt aus der Verbindung von Mengenverknüpfungen und der \\(\\sigma\\)-Additivität von Wahrscheinlichkeitsmaßen ergeben.\n\nTheorem 10.1 (Weitere Eigenschaften von Wahrscheinlichkeiten) \\((\\Omega, \\mathcal{A}, \\mathbb{P})\\) sei ein Wahrscheinlichkeitsraum und es seien \\(A,B \\in \\mathcal{A}\\) Ereignisse. Dann gelten\n\n\\(\\mathbb{P}(A^c) = 1 - \\mathbb{P}(A)\\).\n\\(A \\subset B \\Rightarrow \\mathbb{P}(A) \\le \\mathbb{P}(B)\\).\n\\(\\mathbb{P}(A \\cap B^c) = \\mathbb{P}(A) - \\mathbb{P}(A \\cap B)\\)\n\\(\\mathbb{P}(A \\cup B) = \\mathbb{P}(A) + \\mathbb{P}(B) - \\mathbb{P}(A \\cap B)\\).\n\\(A \\cap B = \\emptyset \\Rightarrow \\mathbb{P}(A \\cup B) = \\mathbb{P}(A) + \\mathbb{P}(B)\\).\n\n\n\nBeweis. Die zweite, dritte, und vierte Aussage dieses Theorems basieren auf elementaren mengentheoretischen Aussagen und der \\(\\sigma\\)-Addivität von \\(\\mathbb{P}\\). Wir wollen diese elementaren mengentheoretischen Aussagen hier nicht beweisen, sondern verweisen jeweils auf die Intuition, die durch die Venn-Diagramme in Abbildung 10.1 vermittelt wird.\n\n\n\nAbbildung 10.1: Venn-Diagramme zum Beweis von Theorem 10.1\n\n\nZu 1.: Wir halten zunächst fest, dass aus \\(A^c := \\Omega \\setminus A\\) folgt, dass \\(A^c \\cup A = \\Omega\\) und dass \\(A^c \\cap A = \\emptyset\\). Mit der Nomiertheit und der \\(\\sigma\\)-Additivität von \\(\\mathbb{P}\\) folgt dann \\[\\begin{equation}\n\\mathbb{P}(\\Omega) = 1\n\\Leftrightarrow\n\\mathbb{P}(A^c \\cup A) = 1\n\\Leftrightarrow\n\\mathbb{P}(A^c) + \\mathbb{P}(A)  = 1\n\\Leftrightarrow\n\\mathbb{P}(A^c) = 1 - \\mathbb{P}(A).\n\\end{equation}\\]\nZu 2.: Zunächst gilt (vgl. Abbildung A) \\[\\begin{equation}\nA \\subset B \\Rightarrow B = A \\cup (B \\cap A^c)\n\\mbox{ mit } A \\cap (B \\cap A^c) = \\emptyset.\n\\end{equation}\\] Mit der \\(\\sigma\\)-Additivät von \\(\\mathbb{P}\\) folgt dann aber \\[\\begin{equation}\n\\mathbb{P}(B) = \\mathbb{P}(A) + \\mathbb{P}(B \\cap A^c).\n\\end{equation}\\] Mit \\(\\mathbb{P}(B \\cap A^c) \\ge 0\\) folgt dann \\(\\mathbb{P}(A) \\le \\mathbb{P}(B)\\).\nZu 3.: Zunächst gilt (vgl. Abbildung B) \\[\\begin{equation}\n(A \\cap B) \\cap (A \\cap B^c)  = \\emptyset\n\\mbox{ und } A  = (A \\cap B) \\cup (A \\cap B^c).\n\\end{equation}\\] Mit der \\(\\sigma\\)-Addivität von \\(\\mathbb{P}\\) folgt dann \\[\\begin{align}\n\\begin{split}\n\\mathbb{P}(A) = \\mathbb{P}(A \\cap B) + \\mathbb{P}(A \\cap B^c)\n\\Leftrightarrow\n\\mathbb{P}(A \\cap B)\n= \\mathbb{P}(A) - \\mathbb{P}(A \\cap B^c)\n\\end{split}\n\\end{align}\\]\nZu 4.: Zunächst gilt (vgl. Abbildung C) \\[\\begin{equation}\nB \\cap (A \\cap B^c)  = \\emptyset\n\\mbox{ und } A \\cup B = B \\cup (A \\cap B^c).\n\\end{equation}\\] Mit der \\(\\sigma\\)-Addivität von \\(\\mathbb{P}\\) folgt dann \\[\\begin{equation}\n\\mathbb{P}(A \\cup B) = \\mathbb{P}(B) + \\mathbb{P}(A \\cap B^c).\n\\end{equation}\\] Mit 3. folgt dann \\[\\begin{equation}\n\\mathbb{P}(A \\cup B) = \\mathbb{P}(B) + \\mathbb{P}(A) - \\mathbb{P}(A \\cap B)\n\\end{equation}\\]\nZu 5.: Die Aussage folgt direkt aus 4. mit \\(\\mathbb{P}(A \\cap B) = \\emptyset\\) und \\(\\mathbb{P}(\\emptyset) = 0\\)."
  },
  {
    "objectID": "202-Elementare-Wahrscheinlichkeiten.html#sec-bedingte-wahrscheinlichkeiten",
    "href": "202-Elementare-Wahrscheinlichkeiten.html#sec-bedingte-wahrscheinlichkeiten",
    "title": "10  Elementare Wahrscheinlichkeiten",
    "section": "10.2 Bedingte Wahrscheinlichkeiten",
    "text": "10.2 Bedingte Wahrscheinlichkeiten\nWir wenden uns nun dem Begriff der bedingten Wahrscheinlichkeit zu.\n\nDefinition 10.2 (Bedingte Wahrscheinlichkeit) \\((\\Omega,\\mathcal{A}, \\mathbb{P})\\) sei ein Wahrscheinlichkeitsraum und \\(A, B\\in \\mathcal{A}\\) seien Ereignisse mit \\(\\mathbb{P}(B) &gt; 0\\). Die bedingte Wahrscheinlichkeit des Ereignisses \\(A\\) gegeben das Ereignis \\(B\\) ist definiert als \\[\\begin{equation}\n\\mathbb{P}(A|B) := \\frac{\\mathbb{P}(A \\cap B)}{\\mathbb{P}(B)}.\n\\end{equation}\\] Weiterhin heißt das für ein festes \\(B \\in \\mathcal{A}\\) mit \\(\\mathbb{P}(B) &gt; 0\\) definierte Wahrscheinlichkeitsmaß \\[\\begin{equation}\n\\mathbb{P}(\\,\\,|B) : \\mathcal{A} \\to [0,1],\nA \\mapsto \\mathbb{P}(A|B) := \\frac{\\mathbb{P}(A \\cap B)}{\\mathbb{P}(B)}\n\\end{equation}\\] die bedingte Wahrscheinlichkeit gegeben Ereignis \\(B\\).\n\nWir halten fest: Die bedingte Wahrscheinlichkeit \\(\\mathbb{P}(A|B)\\) eines Ereignisses \\(A\\) gegeben ein Ereignis \\(B\\) ist die mit \\(1/\\mathbb{P}(B)\\) skalierte gemeinsame Wahrscheinlichkeit \\(\\mathbb{P}(A \\cap B)\\) der Ereignisse \\(A\\) und \\(B\\). Legt man in der Formulierung eines probabilistischen Modells also die gemeinsame Wahrscheinlichkeit \\(\\mathbb{P}(A \\cap B)\\) sowie die Wahrscheinlichkeit \\(\\mathbb{P}(B) &gt; 0\\) des Ereignisses \\(B\\) fest, so legt man insbesondere auch die bedingte Wahrscheinlichkeit \\(\\mathbb{P}(A|B)\\) des Ereignisses \\(A\\) gegeben das Ereignis \\(B\\) fest.\nIm Unterschied zur gemeinsamen Wahrscheinlichkeit definiert \\(\\mathbb{P}(\\cdot \\vert B)\\) für ein fest gewähltes \\(B\\) ein Wahrscheinlichkeitsmaß für alle \\(A \\in \\mathcal{A}\\). Es gelten also insbesondere\n\n\\(\\mathbb{P}(A|B) \\ge 0\\) für alle \\(A \\in \\mathcal{A}\\),\n\\(\\mathbb{P}(\\Omega|B) = 1\\) und\n\\(\\mathbb{P}\\left(\\cup_{i=1}^\\infty A_i|B \\right) = \\sum_{i=1}^\\infty \\mathbb{P}(A_i|B)\\) für paarweise disjunkte \\(A_1,A_2,... \\in \\mathcal{A}\\).\n\nMan sollte sich in dieser Hinsicht intuitiv merken, dass die Regeln zum Rechnen mit Wahrscheinlichkeiten für die Ereignisse links des vertikalen Strichs gelten. Wir weisen ferner daraufhin, dass es keinen Grund gibt, die bedingten Wahrscheinlichkeiten \\[\\begin{equation}\n\\mathbb{P}(A|B) = \\frac{\\mathbb{P}(A \\cap B)}{\\mathbb{P}(B)}\n\\mbox{ und }\n\\mathbb{P}(B|A) = \\frac{\\mathbb{P}(B \\cap A)}{\\mathbb{P}(A)} = \\frac{\\mathbb{P}(A \\cap B)}{\\mathbb{P}(A)}\n\\end{equation}\\] zu verwechseln (vgl. Herzog & Ostwald (2013)). Insbesondere folgt aus \\(\\mathbb{P}(A) \\neq \\mathbb{P}(B)\\) immer direkt \\(\\mathbb{P}(A|B) \\neq \\mathbb{P}(B|A)\\). Schließlich sei angemerkt, dass eine Verallgemeinerung der bedingten Wahrscheinlichkeit in Definition 10.2 auf den Fall \\(\\mathbb{P}(B) = 0\\) möglich, aber technisch aufwändig ist. Wir verweisen dafür auf die weiterführende Literatur, z.B. Meintrup & Schäffler (2005) und Schmidt (2009).\n\nBeispiel\nAls erstes Beispiel für eine bedingte Wahrscheinlichkeit betrachten wir erneut das Modell \\((\\Omega, \\mathcal{A}, \\mathbb{P})\\) des fairen Würfels. Wir wollen die bedingte Wahrscheinlichkeit für das Ereignis “Es fällt eine gerade Augenzahl” gegeben das Ereignis “Es fällt eine Zahl größer als Drei” berechnen. Wir haben oben bereits gesehen, dass das Ereignis “Es fällt eine gerade Augenzahl” der Teilmenge \\(A := \\{2,4,6\\}\\) von \\(\\Omega\\) entspricht, und dass das Ereignis “Es fällt eine Zahl größer als Drei” der Teilmenge \\(B := \\{4,5,6\\}\\) von \\(\\Omega\\) entspricht. Weiterhin haben wir gesehen, dass unter der Annahme, dass der modellierte Würfel fair ist, gilt, dass \\[\\begin{align}\n\\begin{split}\n\\mathbb{P}(\\{2,4,6\\})\n= \\mathbb{P}(\\{2\\}) + \\mathbb{P}(\\{4\\}) + \\mathbb{P}(\\{6\\})\n= \\frac{1}{6} + \\frac{1}{6} + \\frac{1}{6}\n= \\frac{3}{6}   \n\\end{split}\n\\end{align}\\] und dass \\[\\begin{align}\n\\begin{split}\n\\mathbb{P}(\\{4,5,6\\})\n= \\mathbb{P}(\\{4\\}) + \\mathbb{P}(\\{5\\}) + \\mathbb{P}(\\{6\\})    \n= \\frac{1}{6} + \\frac{1}{6} + \\frac{1}{6}                                             \n= \\frac{3}{6}.        \n\\end{split}\n\\end{align}\\] Schließlich hatten wir auch gesehen, dass das Ereignis \\(A \\cap B\\), also das Ereignis “Es fällt eine gerade Augenzahl, die größer als Drei ist”, die Wahrscheinlichkeit \\[\\begin{align}\n\\begin{split}\n\\mathbb{P}(A \\cap B)\n= \\mathbb{P}(\\{2,4,6\\} \\cap \\{4,5,6\\})     \n= \\mathbb{P}(\\{4,6\\})                      \n= \\mathbb{P}(\\{4\\}) + \\mathbb{P}(\\{6\\})     \n= \\frac{1}{6} + \\frac{1}{6}                                 \n= \\frac{2}{6}\n\\end{split}\n\\end{align}\\] hat. Nach Definition der bedingten Wahrscheinlichkeit ergibt sich dann direkt \\[\\begin{align}\n\\begin{split}\n\\mathbb{P}(A|B)\n= \\frac{\\mathbb{P}(A \\cap B)}{\\mathbb{P}(B)}                   \n= \\frac{\\mathbb{P}(\\{4,6\\})}{\\mathbb{P}(\\{4,5,6\\})}            \n= \\frac{2}{6}\\cdot\\frac{6}{3}                                       \n= \\frac{2}{3}.    \n\\end{split}\n\\end{align}\\]\nIn diesem Zusammenhang bietet sich eine Interpretation der bedingten Wahrscheinlichkeit \\(\\mathbb{P}(A|B)\\) als eine Abnahme subjektiver Unsicherheit bzw. als Zugewinn an subjektiver Information gegenüber der unbedingten Wahrscheinlichkeit \\(\\mathbb{P}(A)\\) an: Wenn man weiß, dass eine Augenzahl größer als Drei gefallen ist, dass also das Ereignis \\(\\omega \\in B\\) vorliegt ist, ist die Wahrscheinlichkeit, dass es sich bei \\(\\omega\\) um eine gerade Augenzahl handelt \\(2/3\\). Wenn man dagegen nicht weiß, dass das Ereignis \\(\\omega \\in B\\) vorliegt (und auch sonst keine Information über \\(\\omega\\) hat) ist die Wahrscheinlichkeit für das Fallen einer geraden Augenzahl nur \\(1/2\\). Bedingen auf dem Vorliegen eines Ereignisses entspricht also der Inkorporation von Information und damit der Abnahme von Unsicherheit in wahrscheinlichkeitstheoretische Modellen. Dies ist die Grundlage der Bayesianischen Statistik.\nZum Schluss dieses Abschnittes wollen wir noch drei technische Konsequenzen der Definition der bedingten Wahrscheinlichkeit betrachten, die wir als Theoreme formulieren.\nDas erste Theorem betrifft den Zusammenhang von gemeinsamen und bedingten Wahrscheinlichkeiten und reiteriert, wie gemeinsame Wahrscheinlichkeiten aus bedingten und totalen Wahrscheinlichkeiten berechnet werden können.\n\nTheorem 10.2 (Gemeinsame und bedingte Wahrscheinlichkeiten) Es seien \\((\\Omega,\\mathcal{A}, \\mathbb{P})\\) ein W-Raum und \\(A,B\\in \\mathcal{A}\\) mit \\(\\mathbb{P}(A) &gt; 0\\) und \\(P(B)&gt;0\\). Dann gilt \\[\\begin{equation}\n\\mathbb{P}(A \\cap B)\n= \\mathbb{P}(A|B)\\mathbb{P}(B)\n= \\mathbb{P}(B|A)\\mathbb{P}(A).\n\\end{equation}\\]\n\n\nBeweis. Mit der Definition der jeweiligen bedingten Wahrscheinlichkeit folgen direkt \\[\\begin{equation}\n\\mathbb{P}(A|B) = \\frac{\\mathbb{P}(A \\cap B)}{\\mathbb{P}(B)}\n\\Leftrightarrow\n\\mathbb{P}(A \\cap B) =\\mathbb{P}(A|B)\\mathbb{P}(B)\n\\end{equation}\\] und \\[\\begin{equation}\n\\mathbb{P}(B|A) = \\frac{\\mathbb{P}(B \\cap A)}{\\mathbb{P}(A)}\n\\Leftrightarrow\n\\mathbb{P}(A \\cap B) =\\mathbb{P}(B|A)\\mathbb{P}(A).\n\\end{equation}\\]\n\nEbenso wie das Festlegen von \\(\\mathbb{P}(A \\cap B)\\) und \\(\\mathbb{P}(A)\\) die bedingte Wahrscheinlichkeit \\(\\mathbb{P}(B|A)\\) festlegt, legt das Festlegen von \\(\\mathbb{P}(A)\\) und \\(\\mathbb{P}(B|A)\\) also die gemeinsame Wahrscheinlichkeit \\(\\mathbb{P}(A \\cap B)\\) fest.\nDas nachfolgende sogenannte Gesetz der totalen Wahrscheinlichkeit besagt, wie basierend auf gemeinsamen Wahrscheinlichkeiten unbedingte, sogenannte totale Wahrscheinlichkeiten berechnet werden können.\n\nTheorem 10.3 (Gesetz der totalen Wahrscheinlichkeit) \\((\\Omega,\\mathcal{A},\\mathbb{P})\\) sei ein Wahrscheinlichkeitsraum und \\(A_1,...,A_k\\) sei eine Partition von \\(\\Omega\\). Dann gilt für jedes \\(B \\in \\mathcal{A}\\), dass \\[\\begin{equation}\n\\mathbb{P}(B) = \\sum_{i=1}^k \\mathbb{P}(B \\cap A_i) = \\sum_{i=1}^k \\mathbb{P}(B|A_i)\\mathbb{P}(A_i).\n\\end{equation}\\]\n\n\nBeweis. Für \\(i = 1,...,k\\) sei \\(C_i := B \\cap A_i\\), so dass \\(\\cup_{i=1}^k C_i = B\\) und \\(C_i \\cap C_j = \\emptyset\\) für \\(1 \\le i,j \\le k,i \\neq j\\). Wir verdeutlichen diese Festlegungen in Abbildung 10.2 mithilfe eines Venn-Diagramms.\n\n\n\nAbbildung 10.2: Venn-Diagramm zum Beweis von Theorem 10.3.\n\n\nAlso gilt \\[\\begin{equation}\n\\mathbb{P}(B)\n= \\sum_{i=1}^k \\mathbb{P}(C_i)\n= \\sum_{i=1}^k \\mathbb{P}(B \\cap A_i)\n= \\sum_{i=1}^k \\mathbb{P}(B|A_i)\\mathbb{P}(A_i).\n\\end{equation}\\]\n\nIntuitiv entspricht \\(\\mathbb{P}(B)\\) also der gewichteten Summe der bedingten Wahrscheinlichkeiten \\(\\mathbb{P}(B|A_i)\\) wobei die Wichtungsfaktoren gerade die unbedingten Wahrscheinlichkeiten \\(\\mathbb{P}(A_i)\\) für \\(i = 1,..,k\\) sind.\nSchließlich betrachten wir mit dem Bayesschen Theorem eine Formel zur alternativen Berechnung von bedingten Wahrscheinlichkeiten.\n\nTheorem 10.4 (Bayessches Theorem) \\((\\Omega,\\mathcal{A},\\mathbb{P})\\) sei ein Wahrscheinlichkeitsraum und \\(A_1, ...,A_k\\) sei eine Partition von \\(\\Omega\\) mit \\(\\mathbb{P}(A_i) &gt; 0\\) für alle \\(i = 1,...,k\\). Wenn \\(\\mathbb{P}(B) &gt; 0\\) gilt, dann gilt für jedes \\(i = 1,...,k\\), dass \\[\\begin{equation}\n\\mathbb{P}(A_i|B) = \\frac{\\mathbb{P}(B|A_i)\\mathbb{P}(A_i)}{\\sum_{i=1}^k \\mathbb{P}(B|A_i)\\mathbb{P}(A_i)}.\n\\end{equation}\\]\n\n\nBeweis. Mit der Definition der bedingten Wahrscheinlichkeit und dem Gesetz der totalen Wahrscheinlichkeit gilt \\[\\begin{equation}\n\\mathbb{P}(A_i|B)\n= \\frac{\\mathbb{P}(A_i \\cap B)}{\\mathbb{P}(B)}\n= \\frac{\\mathbb{P}(B|A_i)\\mathbb{P}(A_i)}{\\mathbb{P}(B)}\n= \\frac{\\mathbb{P}(B|A_i)\\mathbb{P}(A_i)}{\\sum_{i=1}^k \\mathbb{P}(B|A_i)\\mathbb{P}(A_i)}.\n\\end{equation}\\]\n\nMan beachte, dass das Theorem von Bayes unabhängig von der Frequentistischen oder Bayesianischen Interpretation von Wahrscheinlichkeiten ist und lediglich eine Aussage zum Rechnen mit bedingten Wahrscheinlichkeiten macht. Im Rahmen der Frequentistischen Inferenz wird das Theorem von Bayes allerdings recht selten benutzt. Im Rahmen der Bayesianischen Inferenz dagegen ist das Theorem von Bayes zentral. In diesem Kontext wird \\(\\mathbb{P}(A_i)\\) dann oft die und \\(\\mathbb{P}(A_i|B)\\) die genannt. Wie oben erläutert entspricht \\(\\mathbb{P}(A_i|B)\\) der Wahrscheinlichkeit von \\(A_i\\), wenn man um das Eintreten von \\(B\\) weiß."
  },
  {
    "objectID": "202-Elementare-Wahrscheinlichkeiten.html#sec-unabhängige-ereignisse",
    "href": "202-Elementare-Wahrscheinlichkeiten.html#sec-unabhängige-ereignisse",
    "title": "10  Elementare Wahrscheinlichkeiten",
    "section": "10.3 Unabhängige Ereignisse",
    "text": "10.3 Unabhängige Ereignisse\nDie Unabhängigkeit von Ereignissen dient der Modellierung der Abwesenheit von gegenseitigen Einflüssen von Ereignissen. Ihre Definition besagt, dass sich die gemeinsame Wahrscheinlichkeit zweier Ereignisse aus dem Produkt der Wahrscheinlichkeiten der einzelnen Ereignisse ergeben soll. Man spricht in diesem Kontext auch von der Faktorisierung der gemeinsamen Wahrscheinlichkeit der Ereignisse. Der Sinn dieser Definition erschließt sich dann im Lichte des Begriffs der bedingten Wahrscheinlichkeit in Theorem 10.5. Wir betrachten zunächst die Definition.\n\nDefinition 10.3 (Unabhängige Ereignisse) Zwei Ereignisse \\(A \\in \\mathcal{A}\\) and \\(B \\in \\mathcal{A}\\) heißen unabhängig, wenn \\[\\begin{equation}\n\\mathbb{P}(A \\cap B) = \\mathbb{P}(A)\\mathbb{P}(B).\n\\end{equation}\\] Eine Menge von Ereignissen \\(\\{A_i|i \\in I\\}\\subset \\mathcal{A}\\) mit beliebiger Indexmenge \\(I\\) heißt unabhängig, wenn für jede endliche Untermenge \\(J \\subseteq I\\) gilt, dass \\[\\begin{equation}\n\\mathbb{P}\\left(\\cap_{j \\in J} A_j \\right) = \\prod_{j \\in J}\\mathbb{P}(A_j).\n\\end{equation}\\]\n\nMan beachte, dass die Unabhängigkeit bestimmter Ereignissen in der Definition eines wahrscheinlichkeitstheoretischen Modells vorausgesetzt werden kann oder auch aus der Definition eines wahrscheinlichkeitstheoretischen Modells folgen kann. Sind zwei Ereignisse nicht unabhängig, so sagt man auch, dass diese Ereignisse abhängig sind. Ohne Beweis merken wir an, dass die Bedingung der beliebigen Untermengen von \\(I\\) in Definition 10.3 die paarweise Unabhängigkeit der \\(A_i, i \\in I\\) sichert (vgl. DeGroot & Schervish (2012)). Schließlich weisen wir daraufhin, dass unabhängige Ereignisse nicht mit disjunkten Ereignissen, also Ereignissen \\(A\\) und \\(B\\) für die \\(A \\cap B = \\emptyset\\) gilt, verwechselt werden sollten. Insbesondere sind disjunkte Ereignisse mit von Null verschiedenenn Wahrscheinlichkeiten \\(\\mathbb{P}(A)&gt;0\\) und \\(\\mathbb{P}(B) &gt;0\\) nie unabhängig, da in diesem Fall \\(\\mathbb{P}(A)\\mathbb{P}(B) &gt; 0\\) und \\(\\mathbb{P}(A \\cap B) = \\mathbb{P}(\\emptyset) = 0\\) gelten und damit offenbar gilt, dass \\(\\mathbb{P}(A \\cap B) \\neq \\mathbb{P}(A)\\mathbb{P}(B)\\).\nDer Sinn der Faktorisierung der gemeinsamen Wahrscheinlichkeit erschließt sich nun anhand folgenden Theorems.\n\nTheorem 10.5 (Bedingte Wahrscheinlichkeit unter Unabhängigkeit) \\((\\Omega,\\mathcal{A}, \\mathbb{P})\\) sei ein Wahrscheinlichkeitsraum und \\(A,B\\in \\mathcal{A}\\) seien unabhängige Ereignisse mit \\(\\mathbb{P}(B) \\ge 0\\). Dann gilt \\[\\begin{equation}\n\\mathbb{P}(A|B) = \\mathbb{P}(A).\n\\end{equation}\\]\n\n\nBeweis. Unter den Annahmen des Theorems gilt \\[\\begin{equation}\n\\mathbb{P}(A|B)\n= \\frac{\\mathbb{P}(A \\cap B)}{\\mathbb{P}(B)}\n= \\frac{\\mathbb{P}(A)\\mathbb{P}(B)}{\\mathbb{P}(B)}\n= \\mathbb{P}(A).\n\\end{equation}\\]\n\nBei gegebener Unabhängigkeit zweier Ereignisse \\(A\\) und \\(B\\) ist es für die Wahrscheinlichkeit des Ereignisses \\(A\\) also unerheblich, ob auch \\(B\\) eintritt oder nicht, die Wahrscheinlichkeit \\(\\mathbb{P}(A)\\) bleibt gleich. Damit wird die Unabhängigkeit von Ereignissen also gerade als Faktorisierung der gemeinsamen Wahrscheinlichkeit von \\(A\\) und \\(B\\) modelliert, damit \\(\\mathbb{P}(A|B) = \\mathbb{P}(A)\\) folgt. Aus Sicht der Modellierung subjektiver Unsicherheit durch Wahrscheinlichkeiten bedeutet die Unabhängigkeit zweier Ereignisse also, dass das Wissen um das Vorliegen eines der beiden Ereignisse die Wahrscheinlichkeit für das Vorliegen des anderen Ereignisses nicht ändert. Andersherum bedeutet die Abhängigkeit zweier Ereignisse, dass das Wissen um das Vorliegen eines der beiden Ereignisse die Wahrscheinlichkeit für das Vorliegen des anderen Ereignisses verändert, also entweder erhöht oder verringert."
  },
  {
    "objectID": "202-Elementare-Wahrscheinlichkeiten.html#literaturhinweise",
    "href": "202-Elementare-Wahrscheinlichkeiten.html#literaturhinweise",
    "title": "10  Elementare Wahrscheinlichkeiten",
    "section": "10.4 Literaturhinweise",
    "text": "10.4 Literaturhinweise\nViele der in diesem Abschnitt eingeführten Begrifflichkeiten sind auf engste mit der geschichtlichen Genese der Wahrscheinlichkeitstheorie verwoben, so dass keine einzelnen Referenzen angegeben werden sollen. Einen Einstieg in die Geschichte der Wahrscheinlichkeitstheorie der letzten zwei Jahrhunderte bietet Hald (1990), einen Überblick über modernere Entwicklungen gibt Von Plato (1994). Das Theorem von Bayes wird allgemein auf Bayes (1763) zurückgeführt, auch wenn es nicht das eigentliche Hauptthema dieser Arbeit ist."
  },
  {
    "objectID": "202-Elementare-Wahrscheinlichkeiten.html#selbstkontrollfragen",
    "href": "202-Elementare-Wahrscheinlichkeiten.html#selbstkontrollfragen",
    "title": "10  Elementare Wahrscheinlichkeiten",
    "section": "10.5 Selbstkontrollfragen",
    "text": "10.5 Selbstkontrollfragen\n\nGeben Sie die Definition der gemeinsamen Wahrscheinlichkeit zweier Ereignisse wieder.\nErläutern Sie die intuitive Bedeutung der gemeinsamen Wahrscheinlichkeit zweier Ereignisse.\nGeben Sie das Theorem zu weiteren Eigenschaften von Wahrscheinlichkeiten wieder.\nGeben Sie die Definition der bedingten Wahrscheinlichkeit eines Ereignisses wieder.\nGeben Sie die Definition der bedingten Wahrscheinlichkeit wieder.\nGeben Sie das Theorem zu gemeinsamen und bedingten Wahrscheinlichkeiten wieder.\nGeben Sie das Gesetz von der totalen Wahrscheinlichkeit wieder.\nGeben Sie das Theorem von Bayes wieder.\nGeben Sie den Beweis des Theorems von Bayes wieder.\nGeben Sie die Definition der Unabhängigkeit zweier Ereignisse wieder.\nGeben Sie das Theorem zur bedingten Wahrscheinlichkeit unter Unabhängigkeit wieder.\nGeben Sie den Beweis des Theorems zur bedingten Wahrscheinlichkeit unter Unabhängigkeit wieder.\nErläutern Sie das Theorem zur bedingten Wahrscheinlichkeit unter Unabhängigkeit.\n\n\n\n\n\nBayes, T. (1763). An essay towards solving a problem in the doctrine of chances. By the late Rev. Mr. Bayes, F. R. S. communicated by Mr. Price, in a letter to John Canton, A. M. F. R. S. Philosophical Transactions of the Royal Society of London, 53, 370–418. https://doi.org/10.1098/rstl.1763.0053\n\n\nDeGroot, M. H., & Schervish, M. J. (2012). Probability and Statistics (4th ed). Addison-Wesley.\n\n\nHald, A. (1990). A History of Probability and Statistics and Their Applications before 1750. Wiley.\n\n\nHerzog, S., & Ostwald, D. (2013). Sometimes Bayesian Statistics Are Better. Nature, 494(7435), 35–35. https://doi.org/10.1038/494035b\n\n\nMeintrup, D., & Schäffler, S. (2005). Stochastik: Theorie und Anwendungen. Springer.\n\n\nSchmidt, K. D. (2009). Maß und Wahrscheinlichkeit. Springer.\n\n\nVon Plato, J. (1994). Creating Modern Probability: Its Mathematics, Physics, and Philosophy in Historical Perspective. Cambridge University Press."
  },
  {
    "objectID": "203-Zufallsvariablen.html#sec-konstruktion-definition-und-intuition",
    "href": "203-Zufallsvariablen.html#sec-konstruktion-definition-und-intuition",
    "title": "11  Zufallsvariablen",
    "section": "11.1 Konstruktion, Definition und Intuition",
    "text": "11.1 Konstruktion, Definition und Intuition\nWir skizzieren zunächst die Konstruktion einer Zufallsvariable und ihrer Verteilung anhand von Abbildung 11.1. Dazu sei \\((\\Omega,\\mathcal{A},\\mathbb{P})\\) ein Wahrscheinlichkeitsraum und \\[\\begin{equation}\n\\xi : \\Omega \\to \\mathcal{X}, \\omega \\mapsto \\xi(\\omega)\n\\end{equation}\\] eine Abbildung. Weiterhin sei \\(\\mathcal{S}\\) eine \\(\\sigma\\)-Algebra auf der Zielmenge \\(\\mathcal{X}\\) dieser Abbildung. Für jedes \\(S \\in \\mathcal{S}\\) sei die Urbildmenge von \\(S\\) gegeben durch (vgl. Definition 4.2) \\[\\begin{equation}\n\\xi^{-1}(S) := \\{\\omega \\in \\Omega|\\xi(\\omega) \\in S\\}.\n\\end{equation}\\] Wenn nun \\(\\xi^{-1}(S) \\in \\mathcal{A}\\) für alle \\(S \\in \\mathcal{S}\\) gilt, dann nennt man die Abbildung \\(\\xi\\) . Nehmen wir also an \\(\\xi\\) sei messbar. Dann kann allen \\(S \\in \\mathcal{S}\\) die Wahrscheinlichkeit \\[\\begin{equation}\n\\mathbb{P}_\\xi : \\mathcal{S} \\to [0,1], S \\mapsto\n\\mathbb{P}_\\xi(S)\n:= \\mathbb{P}\\left(\\xi^{-1}(S)\\right)\n= \\mathbb{P}\\left(\\{\\omega \\in \\Omega|\\xi(\\omega) \\in S\\}\\right)\n\\end{equation}\\] zugeordnet werden. In diesem Kontext nennt man \\(\\xi\\) nun eine Zufallsvariable und \\(\\mathbb{P}_\\xi\\) heißt das Bildmaß oder die Verteilung von \\(\\xi\\). Insgesamt wurde damit ausgehend von dem Wahrscheinlichkeitsraum \\((\\Omega,\\mathcal{A},\\mathbb{P})\\) mithilfe der Zufallsvariable \\(\\xi\\) der Wahrscheinlichkeitsraum \\((\\mathcal{X},\\mathcal{S},\\mathbb{P}_\\xi)\\) konstruiert. Formal ist eine Zufallsvariable damit wie folgt definiert.\n\n\n\nAbbildung 11.1: Konstruktion von Zufallsvariable und Verteilung.\n\n\n\nDefinition 11.1 (Zufallsvariable) Es sei \\((\\Omega, \\mathcal{A}, \\mathbb{P})\\) ein Wahrscheinlichkeitsraum und \\((\\mathcal{X},\\mathcal{S})\\) ein . Dann ist eine definiert als eine Abbildung \\(\\xi:\\Omega \\to \\mathcal{X}\\) mit der \\[\\begin{equation}\n\\{\\omega \\in \\Omega|\\xi(\\omega) \\in S \\} \\in \\mathcal{A} \\mbox{ für alle } S \\in \\mathcal{S}.\n\\end{equation}\\]\n\nNach Definition 11.1 sind Zufallsvariablen weder “zufällig” noch “Variablen”, sondern messbare Abbildungen. Fragt man nach der Bedeutung des Zufalls für die Werte \\(\\xi(\\omega)\\) von Zufallsvariablen, so vermittelt weiterhin die implizite Frequentistische Mechanik des Wahrscheinlichkeitsraums \\((\\Omega, \\mathcal{A}, \\mathbb{P})\\) eine entsprechende Intuition: In jedem Durchgang des modellierten Zufallsvorgangs wird dabei ein \\(\\omega\\) anhand von \\(\\mathbb{P}\\) realisiert und dann (deterministisch) auf \\(\\xi(\\omega)\\) abgebildet. Wir definieren dementsprechend die Begriff des Ergebnisraums und der Realisierung einer Zufallsvariable.\n\nDefinition 11.2 (Realisierung einer Zufallsvariable) \\((\\Omega, \\mathcal{A}, \\mathbb{P})\\) sei ein Wahrscheinlichkeitsraum, \\((\\mathcal{X},\\mathcal{S})\\) sei ein Messraum und \\(\\xi : \\Omega \\to \\mathcal{X}\\) sei eine Zufallsvariable. Dann heißt \\(\\mathcal{X}\\) der Ergebnisraum der Zufallsvariable \\(\\xi\\) und ein \\(\\xi(\\omega) \\in \\mathcal{X}\\) heißt eine Realisierung der Zufallvariable \\(\\xi\\).\n\n\nBeispiel\nAufbauend auf dem in Kapitel 9.3 betrachteten Beispiel eines Wahrscheinlichkeitsraums zur Modellierung des geichzeitigen Würfelns mit einem blauem und einem roten Würfel wollen wir mit der Summe der Würfelaugenzahlen ein erstes Beispiel für eine Zufallsvariable und ihre Verteilung betrachten. Wir haben in Kapitel 9.3 gesehen, dass ein sinnvolles Wahrscheinlichkeitsraummodell für das geichzeitige Würfeln mit einem blauem und einem roten Würfel durch \\((\\Omega,\\mathcal{A}, \\mathbb{P})\\) mit\n\n\\(\\Omega := \\{(r,b)| r \\in \\mathbb{N}_6, b \\in \\mathbb{N}_6\\}\\),\n\\(\\mathcal{A} := \\mathcal{P}(\\Omega)\\) und\n\\(\\mathbb{P} : \\mathcal{A} \\to [0,1]\\) mit \\(\\mathbb{P}(\\{(r,b)\\}) = 1/36\\) für alle \\((r,b) \\in \\Omega\\).\n\ngegeben ist. Die Auswertung der Summe der beiden Würfelaugenzahlen wird dann sinnvoller Weise durch die Abbildung \\[\\begin{equation}\n\\xi : \\Omega \\to \\mathcal{X}, (r,b) \\mapsto \\xi((r,b)) := r + b,\n\\end{equation}\\] beschrieben, wobei offenbar \\(\\mathcal{X} := \\{2,3,...,12\\}\\) gelten muss. Der Ergebnisraum der Zufallsvariable ist also wiederrum endlich und \\(\\mathcal{S} := \\mathcal{P}(\\mathcal{X})\\) ist eine sinnvolle \\(\\sigma\\)-Algebra auf \\(\\mathcal{X}\\). Mithilfe der \\(\\sigma\\)-Addivität von \\(\\mathbb{P}\\) können wir nun die Verteilung \\(\\mathbb{P}_\\xi\\) von \\(\\xi\\) für alle Elementarereignisse \\(\\{x\\} \\in \\mathcal{S}\\) berechnen und damit insbesondere auch die Messbarkeit von \\(\\xi\\) nachweisen, wie in untenstehender Tabelle gezeigt.\nDie Wahrscheinlichkeiten der Elementarereignisse in \\(\\mathcal{S}\\) wiederrum erlauben mithilfe des Begriffs der Wahrscheinlichkeitsmassefunktion (vgl. Kapitel 9.2) das Berechnen beliebiger Ereigniswahrscheinlichkeiten hinsichtlich der Würfelaugenzahlsumme. Insgesamt haben wir basierend auf \\((\\Omega, \\mathcal{A}, \\mathbb{P})\\) und \\(\\xi\\) also ein weiteres Wahrscheinlichkeitsraummodell \\((\\mathcal{X}, \\mathcal{S}, \\mathbb{P}_\\xi)\\) konstruiert.\nFolgender R Code demonstriert, wie mithilfe der computerbasierten Erzeugung zufälliger Ergebnisse die Konstruktion des hier betrachteten Beispiels für einen Durchgang eines Zufallsvorgangs simuliert werden kann.\n\n# Wahrscheinlichkeitsraummodellformulierung\nOmega    = list()                                 # Ergebnisrauminitialisierung\nidx      = 1                                      # Ergebnisindexinitialisierung\nfor(r in 1:6){                                    # Ergebnisse roter  Würfel\n    for(b in 1:6){                                # Ergebnisse blauer Würfel\n        Omega[[idx]] = c(r,b)                     # \\omega \\in \\Omega\n        idx          = idx + 1 }}                 # Ergebnisindexupdate\nK        = length(Omega)                          # Kardinalität von \\Omega\npi       = rep(1/K,1,K)                           # Wahrscheinlichkeitsfunktion \\pi\n\n# Durchgang des Zufallsvorgangs\nomega    = Omega[[which(rmultinom(1,1,pi) == 1)]] # Auswahl von \\omega anhand \\mathbb{P}({\\omega})\n\n# Realisierung der Zufallsvariable\nxi_omega = sum(omega)                             # \\xi(\\omega)\n\n\n\nomega     :  1 1 \nxi(omega) :  2\n\n\nIm Kontext des Vermessens zufällig ausgewählter experimenteller Einheiten dienen Zufallsvariablen oft als Modelle für Messvorgänge. Betrachten wie beispielsweise die Bestimmung des Wertes eines Intelligenztests an zufällig ausgewählten Proband:innen (Abbildung 11.2), so ergibt sich folgende Interpretation: Der Ergebnisraum des zugrundeliegenden Wahrscheinlichkeitsraums \\((\\Omega)\\) soll die Gesamtheit aller in Frage kommender Proband:innen darstellen und die Auswahl einer Proband:in aus diesem Raum die Auswahl eines Ergebnisses \\(\\omega\\), welche mit Wahrscheinlichkeit \\(\\mathbb{P}(\\{\\omega\\})\\) geschehen soll. Wird nun eine bestimmte Eigenschaft dieser Proband:in in idealisierter Weise gemessen, so handelt es sich dabei um eine deterministische Abbildung auf einen dieser Probandin zugeordneten Messwert \\(\\xi(\\omega)\\) im Raum der Messwerte \\(\\mathcal{X}\\). Die Messwerte selbst unterliegen dann einer Wahrscheinlichkeitsverteilung, die durch die zugrundeliegende Verteilung und die Art des Messvorgangs bestimmt wird.\n\n\n\nAbbildung 11.2: Zufallsvariable als Modell eines Messvorgangs.\n\n\n\n\nNotation\nDie Konventionen zur Notation der mit Zufallsvariablen assoziierten Wahrscheinlichkeiten und Verteilungen sind etwas gewöhnungsbedürftig, so dass wir sie in folgender Definition festhalten wollen.\n\nDefinition 11.3 (Notation für Zufallsvariablen) Es seien \\((\\Omega,\\mathcal{A},\\mathbb{P})\\) und \\((\\mathcal{X},\\mathcal{S},\\mathbb{P}_\\xi)\\) Wahrscheinlichkeitsräume und \\(\\xi : \\Omega \\to \\mathcal{X}\\) sei eine Zufallsvariable. Dann gelten mit \\(S \\in \\mathcal{S}\\) und \\(x \\in \\mathcal{X}\\) folgende Notationskonventionen für Ereignisse in \\(\\mathcal{A}\\): \\[\\begin{align*}\n\\begin{split}\n\\{\\xi \\in S\\} & := \\{\\omega \\in \\Omega|\\xi(\\omega) \\in S\\}  \\\\\n\\{\\xi  =  x\\} & := \\{\\omega \\in \\Omega|\\xi(\\omega)  =  x\\}  \\\\\n\\{\\xi \\le x\\} & := \\{\\omega \\in \\Omega|\\xi(\\omega) \\le x\\}  \\\\\n\\{\\xi  &lt;  x\\} & := \\{\\omega \\in \\Omega|\\xi(\\omega)  &lt;  x\\}  \\\\\n\\{\\xi \\ge x\\} & := \\{\\omega \\in \\Omega|\\xi(\\omega) \\ge x\\}  \\\\\n\\{\\xi  &gt;  x\\} & := \\{\\omega \\in \\Omega|\\xi(\\omega)  &gt;  x\\}  \\\\\n\\end{split}\n\\end{align*}\\] Aus diesen Konventionen ergeben sich folgende Konventionen für Wahrscheinlichkeiten von Verteilungen \\[\\begin{align*}\n\\begin{split}\n    \\mathbb{P}_\\xi\\left(\\xi \\in S\\right)\n& = \\mathbb{P}\\left(\\{\\xi \\in S\\} \\right)\n  = \\mathbb{P}\\left( \\{\\omega \\in \\Omega|\\xi(\\omega) \\in S\\}\\right) \\\\\n    \\mathbb{P}_\\xi\\left(\\xi = x \\right)\n& = \\mathbb{P}\\left(\\{\\xi = x\\} \\right)\n  = \\mathbb{P}\\left( \\{\\omega \\in \\Omega|\\xi(\\omega) = x\\}\\right)  \\\\\n    \\mathbb{P}_\\xi\\left(\\xi \\le x \\right)\n& = \\mathbb{P}\\left(\\{\\xi \\le x\\} \\right)\n  = \\mathbb{P}\\left( \\{\\omega \\in \\Omega|\\xi(\\omega) \\le x\\}\\right) \\\\\n    \\mathbb{P}_\\xi\\left(\\xi &lt; x \\right)\n& = \\mathbb{P}\\left(\\{\\xi &lt; x\\} \\right)\n  = \\mathbb{P}\\left( \\{\\omega \\in \\Omega|\\xi(\\omega) &lt; x\\}\\right)   \\\\\n    \\mathbb{P}_\\xi\\left(\\xi \\ge x \\right)\n& = \\mathbb{P}\\left(\\{\\xi \\ge x\\} \\right)\n  = \\mathbb{P}\\left(\\{\\omega \\in \\Omega|\\xi(\\omega) \\ge x\\}\\right) \\\\\n    \\mathbb{P}_\\xi\\left(\\xi &gt; x \\right)\n& = \\mathbb{P}\\left(\\{\\xi &lt; x\\} \\right)\n  = \\mathbb{P}\\left( \\{\\omega \\in \\Omega|\\xi(\\omega) &gt; x\\} \\right). \\\\\n\\end{split}\n\\end{align*}\\] Oft wird zudem auf das Subskript bei Verteilungssymbolen verzichtet und zum Beispiel \\(\\mathbb{P}_\\xi\\left(\\xi \\in S\\right)\\) nur als \\(\\mathbb{P}\\left(\\xi \\in S\\right)\\) geschrieben, solange sich aus dem Kontext keine Verwechselungsmöglichkeit der beiden Wahrscheinlichkeitsmaße ergeben kann.\n\nWir wollen diesen Abschnitt mit einem technischem Theorem zum Rechnen mit Zufallsvariablen abschließen.\n\nTheorem 11.1 (Arithmetik reeller Zufallsvariablen) \\((\\Omega, \\mathcal{A}, \\mathbb{P})\\) sei ein Wahrscheinlichkeitsraum, \\((\\mathbb{R}, \\mathcal{B}(\\mathbb{R}))\\) sei der reelle Messraum, \\(\\xi : \\Omega \\to \\mathbb{R}\\), \\(\\upsilon : \\Omega \\to \\mathbb{R}\\) seien reellwertige Zufallsvariablen und \\(c \\in \\mathbb{R}\\) sei eine Konstante. Weiterhin seien \\[\\begin{align}\n\\begin{split}\n\\xi + c         & : \\Omega \\to \\mathbb{R}, \\omega \\mapsto (\\xi + c)(\\omega)\\,             := \\xi(\\omega) + c              \\mbox{ für } c \\in \\mathbb{R}   \\\\\nc\\xi            & : \\Omega \\to \\mathbb{R}, \\omega \\mapsto (c\\xi)(\\omega) \\quad\\,\\,\\,      := c\\xi(\\omega)                 \\mbox{ für } c \\in \\mathbb{R}   \\\\\n\\xi + \\upsilon  & : \\Omega \\to \\mathbb{R}, \\omega \\mapsto (\\xi + \\upsilon)(\\omega)        := \\xi(\\omega) + \\upsilon(\\omega)                               \\\\\n\\xi\\upsilon    & : \\Omega \\to \\mathbb{R}, \\omega \\mapsto (\\xi\\upsilon)(\\omega)\\quad\\,\\,\\, := \\xi(\\omega)\\upsilon(\\omega)                                  \\\\\n\\end{split}\n\\end{align}\\] die Addition einer Konstante zu einer reellwertigen Zufallsvariable, die Multiplikation einer reellwertigen Zufallsvariable mit einer Konstante, die Addition zweier reellwertiger Zufallsvariablen und die Multiplikation zweier reellwertigen Zufallsvariablen, respektive. Dann sind auch \\(\\xi + c\\), \\(c\\xi\\), \\(\\xi + \\upsilon\\) und \\(\\xi\\upsilon\\) reellwertige Zufallsvariablen.\n\nFür einen Beweis dieses Theorems verweisen wir auf die weiterführende Literatur, beispielsweise Hesse (2009). Intuitiv besagt Theorem 11.1, dass sowohl Addition einer zufälligen Größe zu einer konstanten Größe, als auch die Multiplikation einer zufälligen Größe mit einer Konstante, als auch die Addition zweier zufälliger Größen und schließlich auch die Multiplikation zweier zufälliger Größen immer wieder zufällige Größen mit ihren dann eigenen Verteilungen ergeben."
  },
  {
    "objectID": "203-Zufallsvariablen.html#sec-wahrscheinlichkeitsmassefunktionen",
    "href": "203-Zufallsvariablen.html#sec-wahrscheinlichkeitsmassefunktionen",
    "title": "11  Zufallsvariablen",
    "section": "11.2 Wahrscheinlichkeitsmassefunktionen",
    "text": "11.2 Wahrscheinlichkeitsmassefunktionen\nIn diesem Abschnitt führen wir mit den Wahrscheinlichkeitsmassefunktionen (WMFen) ein Hilfsmittel ein, um Verteilungen von Zufallsvariablen mit diskretem (genauer endlichem oder abzählbarem) Ergebnisraum zu definieren. Wir illustrieren den Begriff anhand dreier wichtiger Beispiele, den Bernoulli- und Binomialzufallsvariablen sowie den diskret-gleichverteilten Zufallsvariablen. Wir definieren zunächst den Begriff der WMF wie folgt.\n\nDefinition 11.4 (Diskrete Zufallsvariable und Wahrscheinlichkeitsmassefunktion) Eine Zufallsvariable \\(\\xi\\) heißt , wenn ihr Ergebnisraum \\(\\mathcal{X}\\) endlich oder abzählbar ist und eine Funktion der Form \\[\\begin{equation}\np_\\xi: \\mathcal{X} \\to \\mathbb{R}_{\\ge 0}, x \\mapsto p_\\xi(x)\n\\end{equation}\\] existiert, für die gilt\n\n\\(\\sum_{x \\in \\mathcal{X}} p_\\xi(x) = 1\\) und\n\\(\\mathbb{P}_\\xi(\\xi = x) = p_\\xi(x)\\) für alle \\(x \\in \\mathcal{X}\\).\n\nEine entsprechende Funktion \\(p_\\xi\\) heißt von \\(\\xi\\).\n\nWir erinnern daran, dass eine Menge abzählbar heißt, wenn sie bijektiv auf \\(\\mathbb{N}\\) abgebildet werden kann. Im Deutschen nennt man WMFen auch Zähldichten. Im Englischen nennt man WMFen probability mass functions (PMFs), an diesem Begriff orientieren wir uns hier. Der notationellen Einfachheit halber verzichtet man wie bei den Bildmaßen auch bei WMFen meist auf das Subskript \\(\\xi\\), schreibt also einfach \\(p(x)\\) anstelle von \\(p_\\xi(x)\\), wenn aus dem Kontext klar ist, auf welche Zufallsvariable sich die WMF bezieht. Ohne Beweis halten wir fest, dass jede Funktion \\(p : \\mathcal{X} \\to \\mathbb{R}_{\\ge 0}\\), die die Normiertheiteigenschaft \\(\\sum_{x \\in \\mathcal{X}} p(x) = 1\\) besitzt als WMF einer Zufallsvariable interpretiert werden kann.\n\nBeispiele\nWir wollen mit den Bernoulli-Zufallsvariablen, den Binomial-Zufallsvariablen und den Diskrete-gleichverteilten Zufallsvariablen drei erste Beispiel für die Definition von Verteilungen mithilfe von WMFen betrachten.\n\nDefinition 11.5 (Bernoulli Zufallsvariable) Es sei \\(\\xi\\) eine Zufallsvariable mit Ergebnisraum \\(\\mathcal{X} = \\{0,1\\}\\) und WMF \\[\\begin{equation}\np : \\mathcal{X} \\to [0,1], x\\mapsto p(x) := \\mu^{x}(1 - \\mu)^{1-x} \\mbox{ mit } \\mu \\in [0,1].\n\\end{equation}\\] Dann sagen wir, dass \\(\\xi\\) einer unterliegt und nennen \\(\\xi\\) eine . Wir kürzen dies mit \\(\\xi \\sim \\mbox{Bern}(\\mu)\\) ab. Die WMF einer Bernoulli-Zufallsvariable bezeichnen wir mit \\[\\begin{equation}\n\\mbox{Bern}(x;\\mu) := \\mu^x (1 - \\mu)^{1 - x}.\n\\end{equation}\\]\n\nBernoulli-Zufallsvariablen können immer dann zur probabilistischen Modellierung genutzt werden, wenn das betrachtete Phänomen binär ist und die möglichen Werte der Zufallsvariable bijektiv auf \\(\\{0,1\\}\\) abgebildet werden können. Man beachte, dass die funktionale Form der Bernoulli-Zufallsvariable \\(\\mbox{Bern}(x;\\mu)\\) nur für \\(x \\in \\{0,1\\}\\) Sinn ergibt und nicht etwa für \\(x \\in \\{\\mbox{Heads}, \\mbox{Tails}\\}\\). Bildet man aber die möglichen Ergebnisse eines Münzwurfes auf \\(\\{0,1\\}\\) ab, also definiert etwa \\(0 := \\mbox{Heads}\\) und \\(1 := \\mbox{Tails}\\), so kann eine Bernoulli-Zufallsvariable durchaus als Modell eines Münzwurfs dienen.\nDer Parameter \\(\\mu \\in [0,1]\\) einer Bernoulli-Zufallsvariable ist die Wahrscheinlichkeit dafür, dass die Zufallsvariable \\(\\xi\\) den Wert 1 annimmt, dies erkennt man anhand von \\[\\begin{equation}\n\\mathbb{P}(\\xi = 1) = \\mu^1 (1 -\\mu)^{1-1} = \\mu.\n\\end{equation}\\]\nWir visualisieren die WMFen von Bernoulli-Zufallsvariablen für \\(\\mu := 0.1, \\mu := 0.5\\) und \\(\\mu := 0.7\\) in Abbildung 11.3.\n\n\n\nAbbildung 11.3: WMFen von Bernoulli-Zufallsvariablen.\n\n\n\nDefinition 11.6 (Binomialzufallsvariable) Es sei \\(\\xi\\) eine Zufallsvariable mit Ergebnisraum \\(\\mathcal{X} := \\mathbb{N}_n^0\\) und WMF \\[\\begin{equation}\np : \\mathcal{X} \\to [0,1],\nx\\mapsto p(x) :=\n\\begin{pmatrix}\nn \\\\ x\n\\end{pmatrix}\n\\mu^{x}(1 - \\mu)^{n-x} \\mbox{ für } \\mu \\in [0,1].\n\\end{equation}\\] Dann sagen wir, dass \\(\\xi\\) einer unterliegt und nennen \\(\\xi\\) eine Binomial-Zufallsvariable. Wir kürzen dies mit \\(\\xi \\sim \\mbox{Bin}(\\mu,n)\\) ab. Die WMF einer Binomial-Zufallsvariable bezeichnen wir mit \\[\\begin{equation}\n\\mbox{Bin}(x;\\mu,n) :=\n\\begin{pmatrix}\nn \\\\ x\n\\end{pmatrix}\n\\mu^{x}(1 - \\mu)^{n-x}.\n\\end{equation}\\]\n\nOhne Beweis halten wir fest, dass eine Binomial-Zufallsvariable als Modell der Summe von \\(n\\) unabhängig und identisch verteilten Bernoulli-Zufallsvariablen genutzt werden kann. Insbesondere gilt also \\(\\mbox{Bin}(x;\\mu,1) = \\mbox{Bern}(x;\\mu)\\). Binomial-Zufallsvariablen haben die Eigenschaft, dass mit \\(n\\) einer ihrer Parameter nicht nur die funktionale Form ihrer WMF, sondern auch ihren Ergebnisraum \\(\\mathcal{X}\\) festlegt. Wir visualisieren die WMFen von Binomial-Zufallsvariablen für \\((\\mu,n) := (0.1,5), (\\mu,n) := (0.5,10)\\) und \\((\\mu,n) := (0.7,15)\\) in Abbildung 11.4.\n\n\n\nAbbildung 11.4: WMFen von Binomial-Zufallsvariablen.\n\n\n\nDefinition 11.7 (Diskret-gleichverteilte Zufallsvariable) Es sei \\(\\xi\\) eine diskrete Zufallsvariable mit endlichem Ergebnisraum \\(\\mathcal{X}\\) und WMF \\[\\begin{equation}\np : \\mathcal{X} \\to \\mathbb{R}_{\\ge 0}, x\\mapsto p(x) := \\frac{1}{|\\mathcal{X}|}.\n\\end{equation}\\] Dann sagen wir, dass \\(\\xi\\) einer unterliegt und nennen \\(\\xi\\) eine . Wir kürzen dies mit \\(\\xi \\sim U(|\\mathcal{X}|)\\) ab. Die WMF einer diskret-gleichverteilten Zufallsvariable bezeichnen wir mit \\[\\begin{equation}\nU(x;|\\mathcal{X}|) := \\frac{1}{|\\mathcal{X}|}.\n\\end{equation}\\]\n\nDiskrete-gleichverteilte Zufallsvariable können offenbar immer dann zur probabilistischen Modellierung genutzt werden, wenn die möglichen diskreten Ergebnisse des modellierten Phänomenens die gleiche Wahrscheinlichkeit haben. Im Fall der diskret-gleichverteilten Zufallsvariablen braucht es zur Definition ihrer funktionalen Form nach Festlegung des Ergebnisraums keinen weiteren Parameter. Offenbar gilt für \\(\\mathcal{X} := \\{0,1\\}\\). \\[\\begin{equation}\nU(x;|\\mathcal{X}|) = \\mbox{Bern}(x;0.5) = \\mbox{Bin}(x;1,0.5)\n\\end{equation}\\] Wir visualisieren die WMFen von diskret-gleichverteilten Zufallsvariablen für \\(\\mathcal{X} := \\{\\{0,1\\}\\, \\mathcal{X} := \\{-3,-2,-1,0,1\\}\\}\\) und \\(\\mathcal{X} := \\{-4,-3,-2,-1,0,1,2,3,4\\}\\) in Abbildung 11.5. Man beachte, dass Definition 11.7 formal die Sequentialität der Elemente von \\(\\mathcal{X}\\) nicht erfordert, man kann also genauso eine diskret-gleichverteilte Zufallsvariable mit Ergebnisraum \\(\\mathcal{X} := \\{1,5,7\\}\\) oder auch nicht numerischen Ergebnisraum \\(\\mathcal{X} := \\{a,b,x,y\\}\\) definieren.\n\n\n\nAbbildung 11.5: WMFen von diskret-gleichverteilten Zufallsvariablen."
  },
  {
    "objectID": "203-Zufallsvariablen.html#sec-wahrscheinlichkeitsdichtefunktionen",
    "href": "203-Zufallsvariablen.html#sec-wahrscheinlichkeitsdichtefunktionen",
    "title": "11  Zufallsvariablen",
    "section": "11.3 Wahrscheinlichkeitsdichtefunktionen",
    "text": "11.3 Wahrscheinlichkeitsdichtefunktionen\nIn diesem Abschnitt führen wir mit den Wahrscheinlichkeitsdichtefunktionen (WDFen) ein Hilfsmittel ein, um Verteilungen von Zufallsvariablen mit kontinuierlichem (genauer überabzählbarem) Ergebnisraum zu definieren. Wir illustrieren den Begriff zunächst an der grundlegendsten aller Zufallsvariablen, der normalverteilten Zufallsvariable. Mit der Gamma-Zufallsvariable, der Beta-Zufallsvariable und der diskret-gleichverteilten Zufallsvariable wollen wir dann noch drei Beispiele von Zufallsvariablen betrachten, die sowohl in der Modellformulierung der Frequentistischen als auch der Bayesianischen Inferenz an vielen Stellen eingesetzt werden. Wir definieren den Begriff der WDF wie folgt.\n\nDefinition 11.8 (Kontinuierliche Zufallsvariable und Wahrscheinlichkeitsdichtefunktion) Eine Zufallsvariable \\(\\xi\\) heißt , wenn \\(\\mathbb{R}\\) der Ergebnisraum von \\(\\xi\\) ist und eine Funktion \\[\\begin{equation}\np_\\xi : \\mathbb{R} \\to \\mathbb{R}_{\\ge 0}, x \\mapsto p_\\xi(x)\n\\end{equation}\\] existiert, für die gilt\n\n\\(\\int_{-\\infty}^{\\infty} p_\\xi(x)\\,dx = 1\\) und\n\\(\\mathbb{P}_\\xi(\\xi \\in [a,b]) = \\int_a^b p_\\xi(x)\\,dx\\) für alle \\(a,b\\in\\mathbb{R}\\) mit \\(a \\le b\\).\n\nEine entsprechende Funktion \\(p_\\xi\\) heißt Wahrscheinlichkeitsdichtefunktion (WDF) von \\(\\xi\\).\n\nIm Englischen nennt man WDFen probability density functions (PDFs). Der notationellen Einfachheit halber verzichtet man wie bei den Bildmaßen und den WMFen auch bei WDFen meist auf das Subskript \\(\\xi\\), schreibt also einfach \\(p(x)\\) anstelle von \\(p_\\xi(x)\\), wenn aus dem Kontext klar ist, auf welche Zufallsvariable sich die WDF bezieht. Ohne Beweis halten wir fest, dass jede Funktion \\(p : \\mathbb{R} \\to \\mathbb{R}_{\\ge 0}\\), für deren uneigentliches Integral \\(\\int_{-\\infty}^{\\infty} p_\\xi(x)\\,dx = 1\\) gilt, die also normiert ist, als WDF einer Zufallsvariable interpretiert werden kann.\nIm Umgang mit WDFen und in Abgrenzung zu WMFen sollte man sich die Dichteeigenschaft einer WDF immer bewusst machen: Die Werte einer WDF stellen keine Wahrscheinlichkeiten, sondern Wahrscheinlichkeitsdichten dar, Wahrscheinlichkeiten werden aus WDFen durch Integration berechnet. Wie im physikalischen Sinn ergibt sich die einem reellen Intervall zugeordnete Wahrscheinlichkeit(smasse) also erst durch “Multiplikation” mit dem enstprechenden “Intervallvolumen”. Man denke hierzu auch an die Approximation des bestimmten Integrals \\(\\int_a^b p_\\xi(x)\\,dx\\) durch einen Riemannschen Summenterm (vgl. Definition 7.3). Intuitiv gilt also \\[\\begin{equation}\n\\mbox{(Wahrscheinlichkeits)Masse} = \\mbox{(Wahrscheinlichkeits)Dichte} \\cdot \\mbox{(Mengen)Volumen,}\n\\end{equation}\\] wobei sich das Volumen im Sinne des Lebesgue-Maßes auf die Breite des Intervalls \\([a,b]\\) bezieht. Wie in der physikalischen Analogie ist die Wahrscheinlichkeitsmasse eines Intervalls ohne Volumen gleich Null,\n\\[\\begin{equation}\n\\mathbb{P}_\\xi(\\xi = a) = \\int_a^a p(x) \\,dx = 0.\n\\end{equation}\\] Ferner gilt, dass bei entsprechend kleinen Intervallen WDFen auch Werte größer als \\(1\\) annehmen können, auch wenn dies für die Wahrscheinlichkeit, die sich dann durch entsprechende Integration ergibt, nicht der Fall sein kann. Schließlich sei trotz dieser technischen Feinheiten folgende Intuition betont: Betrachtet man die graphische Darstellung der WDF einer Zufallsvariable und stellt sich eine Zerlegung von \\(\\mathbb{R}\\) in gleich große Intervalle vor, so besitzt die Zufallsvariable natürlich eine höhere Wahrscheinlichkeit dafür, Werte in einem Intervall mit assoziierter höherer Wahrscheinlichkeitsdichte anzunehmen als Werte in einem Intervall mit assoziierter relativ niedrigerer Wahrscheinlichkeitsdichte.\n\nNormalverteilte Zufallsvariablen\nMit der normalverteilten Zufallsvariable wollen wir als erstes Beispiel für die Definition einer kontinuierlichen Zufallsvariable mithile einer WDF nun die wichtigste Zufallsvariable der probabilistischen Modellbildung einführen.\n\nDefinition 11.9 (Normalverteilte Zufallsvariable) Es sei \\(\\xi\\) eine Zufallsvariable mit Ergebnisraum \\(\\mathbb{R}\\) und WDF \\[\\begin{equation}\np : \\mathbb{R} \\to \\mathbb{R}_{&gt;0}, x\\mapsto p(x)\n:= \\frac{1}{\\sqrt{2\\pi \\sigma^2}}\\exp\\left(-\\frac{1}{2\\sigma^2}(x - \\mu)^2\\right).\n\\end{equation}\\] Dann sagen wir, dass \\(\\xi\\) einer Normalverteilung mit Parametern \\(\\mu \\in \\mathbb{R}\\) und \\(\\sigma^2 &gt; 0\\) unterliegt und nennen \\(\\xi\\) eine normalverteilte Zufallsvariable. Wir kürzen dies mit \\(\\xi \\sim N\\left(\\mu,\\sigma^2\\right)\\) ab. Die WDF einer normalverteilten Zufallsvariable bezeichnen wir mit \\[\\begin{equation}\nN\\left(x;\\mu,\\sigma^2\\right) := \\frac{1}{\\sqrt{2\\pi \\sigma^2}}\\exp\\left(-\\frac{1}{2\\sigma^2}(x - \\mu)^2\\right).\n\\end{equation}\\] Eine normalverteilte Zufallsvariable mit \\(\\mu = 0\\) und \\(\\sigma^2 = 1\\) nennt man eine standardnormalverteilte Zufallsvariable\n\nWir visualisieren die WDFen von normalverteilten Zufallsvariablen für \\((\\mu,\\sigma^2) := (0,1), (\\mu,\\sigma^2) := (-2.5, 10)\\) und \\((\\mu,\\sigma^2) := (3, 0.5)\\) in Abbildung 11.6. Man macht sich an dieser Abbildung graphisch klar, dass die WDFen von normalverteilten Zufallsvariablen immer genau einen Werte höchster Wahrscheinlichkeitsdichte haben und zwar an der Stelle des Parameters \\(\\mu \\in \\mathbb{R}\\). Dies ergibt sich durch die Tatsache, dass das Argument der Exponentialfunktion in der funktionalen Form von \\(N(x;\\mu,\\sigma^2)\\) aufgrund des negativen Vorzeichens des Quadrates von \\(x-\\mu\\) und der Positivität von \\(\\sigma^2\\) immer nicht-positiv ist und die Exponentialfunktion auf den nicht-positiven reellen Zahlen ihr Maximum bei \\(x = \\mu\\), also \\(x-\\mu = 0\\) annimmt. Weiterhin macht man sich graphisch klar, dass der Parameter \\(\\sigma^2&gt;0\\) die Breite der WDF einer normalverteilten Zufallsvariable enkodiert.\n\n\n\nAbbildung 11.6: WDFen von normalverteilten Zufallsvariablen.\n\n\n\n\nWeitere Beispiele\nWir wollen mit den Gamma-Zufallsvariablen, den Beta-Zufallsvariablen und den gleichverteilten Zufallsvariablen drei weitere Beispiele für die Definition von Verteilungen mithilfe von WDFen betrachten.\n\nDefinition 11.10 (Gamma-Zufallsvariable) Es sei \\(\\xi\\) eine Zufallsvariable mit Ergebnisraum \\(\\mathcal{X} := \\mathbb{R}_{&gt;0}\\) und WDF \\[\\begin{equation}\np : \\mathbb{R}_{&gt;0} \\to \\mathbb{R}_{&gt;0},  x \\mapsto p(x) :=\n\\frac{1}{\\Gamma(\\alpha)\\beta^{\\alpha}}x^{\\alpha-1}\\exp\\left(-\\frac{x}{\\beta}\\right),\n\\end{equation}\\] wobei \\(\\Gamma\\) die Gammafunktion bezeichne. Dann sagen wir, dass \\(\\xi\\) einer Gammaverteilung mit Formparameter \\(\\alpha &gt;0\\) und Skalenparameter \\(\\beta &gt; 0\\) unterliegt und nennen \\(\\xi\\) eine gammaverteilte Zufallsvariable. Wir kürzen dies mit \\(\\xi \\sim G(\\alpha,\\beta)\\) ab. Die WDF einer gammaverteilen Zufallsvariable bezeichnen wir mit \\[\\begin{equation}\nG(x;\\alpha,\\beta) := \\frac{1}{\\Gamma(\\alpha)\\beta^{\\alpha}}x^{\\alpha-1}\\exp\\left(-\\frac{x}{\\beta}\\right).\n\\end{equation}\\]\n\nDie spezielle Gamma-Zufallsvariable mit WDF \\(G\\left(x;\\frac{n}{2},2\\right)\\) wird Chi-Quadrat (\\(\\chi^2\\)) Verteilung mit \\(n\\) Freiheitsgraden genannt. Wir visualisieren die WDFen von Gamma-Zufallsvariablen für \\((\\alpha,\\beta) := (1,1),(\\alpha,\\beta) := (2,2)\\) und \\((\\alpha,\\beta) := (5,1)\\) in Abbildung 11.7.\n\n\n\nAbbildung 11.7: WDFen von Gamma-Zufallsvariablen.\n\n\n\nDefinition 11.11 (Beta-Zufallvariable) Es sei \\(\\xi\\) eine Zufallsvariable mit Ergebnisraum \\(\\mathcal{X} := [0,1]\\) und WDF \\[\\begin{equation}\np : \\mathcal{X} \\to [0,1], x \\mapsto p(x)\n:= \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\nx^{\\alpha-1}(1-x)^{\\beta-1} \\mbox{ mit } \\alpha,\\beta \\in \\mathbb{R}_{&gt;0},\n\\end{equation}\\] wobei \\(\\Gamma\\) die Gammafunktion bezeichne. Dann sagen wir, dass \\(\\xi\\) einer mit Parametern \\(\\alpha &gt;0\\) und \\(\\beta&gt;0\\) unterliegt, und nennen \\(\\xi\\) eine Beta-verteilte Zufallsvariable. Wir kürzen dies mit \\(\\xi \\sim \\mbox{Beta}(\\alpha,\\beta)\\) ab. Die WDF einer Beta-verteilten Zufallsvariable bezeichnen wir mit \\[\\begin{equation}\n\\mbox{Beta}(x;\\alpha,\\beta)\n:= \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\nx^{\\alpha-1}(1-x)^{\\beta-1}.\n\\end{equation}\\]\n\nDadurch, dass der Ergebnisraum einer Beta-Zufallsvariable auf das Intervall \\(\\mathcal{X} := [0,1]\\) (für \\(\\alpha &lt; 1, \\beta &lt; 1\\) genauer \\(\\mathcal{X} := ]0,1[\\)) beschränkt ist, bietet sich eine Beta-Zufallsvariable unter anderem dafür an, Wahrscheinlichkeiten von Wahrscheinlichkeiten (also Werten zwischen 0 und 1) zu beschreiben. Wir visualisieren die WDFen von Beta-Zufallsvariablen für \\((\\alpha,\\beta) := (1,1), (\\alpha,\\beta) := (3,2)\\) und \\((\\alpha,\\beta) := (10,5)\\) in Abbildung 11.8.\n\n\n\nAbbildung 11.8: WDFen von Beta-Zufallsvariablen.\n\n\nMit den gleichverteilten Zufallsvariablen betrachten wir abschließend noch das Analogon zu diskret-gleichverteilten Zufallsvariablen für den Fall kontinuierlicher Zufallsvariablen.\n\nDefinition 11.12 (Gleichverteilte Zufallsvariable) Es sei \\(\\xi\\) eine kontinuierliche Zufallsvariable mit Ergebnisraum \\(\\mathbb{R}\\) und WDF \\[\\begin{equation}\np : \\mathbb{R} \\to \\mathbb{R}_{\\ge 0}, x\\mapsto p(x) :=\n\\begin{cases}\n\\frac{1}{b - a} & x \\in [a,b] \\\\\n0                     & x \\notin [a,b]\n\\end{cases}.\n\\end{equation}\\] Dann sagen wir, dass \\(\\xi\\) einer Gleichverteilung mit Parametern \\(a\\) und \\(b\\) unterliegt und nennen \\(\\xi\\) eine gleichverteilte Zufallsvariable. Wir kürzen dies mit \\(\\xi \\sim U(a,b)\\) ab. Die WDF einer gleichverteilten Zufallsvariable bezeichnen wir mit \\[\\begin{equation}\nU(x;a,b) := \\frac{1}{b - a}.\n\\end{equation}\\]\n\nWir visualisieren die WDFen von gleichverteilten Zufallsvariablen für \\((a,b) := (0,1), (a,b) := (-3,1)\\) und \\((a,b) := (-4,4)\\) in Abbildung 11.9.\n\n\n\nAbbildung 11.9: WDFen von gleichverteilten-Zufallsvariablen."
  },
  {
    "objectID": "203-Zufallsvariablen.html#sec-kumulative-verteilungsfunktion",
    "href": "203-Zufallsvariablen.html#sec-kumulative-verteilungsfunktion",
    "title": "11  Zufallsvariablen",
    "section": "11.4 Kumulative Verteilungsfunktionen",
    "text": "11.4 Kumulative Verteilungsfunktionen\nIm letzten Abschnitt dieses Kapitels wollen wir mit den kumulativen Verteilungsfunktionen (KVFen) eine weitere Möglichkeit einführen, die Verteilungen von diskreten oder kontinuierlichen Zufallsvariablen festzulegen. Es ist allgemein allerdings eher üblich, dies mithilfe von WMFen oder WDFen zu tun. Trotzdem sind KVFen an vielen Stellen nützlich, da sie sowohl für diskrete als nauch kontinuierliche Zufallsvariablen einen direkten Zusammenhang zwischen Werten der Zufallsvariable und bestimmten Wahrscheinlichkeiten herstellen, der in der Anwendung ohne Summation oder Integration auskommt. Wir betrachten zunächst die allgemeine Definition von KVFen für sowohl diskrete als auch kontinuierliche Zufallsvariablen und wenden uns dann den KVFen von diskreten und den KVFen von kontiniuerlichen Zufallsvariablen im einzelnen zu. Für eine beliebige Zufallsvariable definieren wir den Begriff der KVF wie folgt.\n\nDefinition 11.13 (Kumulative Verteilungsfunktion) Die kumulative Verteilungsfunktion (KVF) einer Zufallsvariable \\(\\xi\\) ist definiert als \\[\\begin{equation}\nP_\\xi : \\mathbb{R} \\to [0,1], x \\mapsto P_\\xi(x) := \\mathbb{P}_\\xi(\\xi \\le x).\n\\end{equation}\\]\n\nMan beachte, dass \\(P_\\xi(x)\\) ist für jedes \\(x \\in \\mathbb{R}\\) definiert ist, auch wenn für ein gegebenes \\(x\\in \\mathbb{R}\\) gilt, dass \\(x \\notin \\mathcal{X}\\). Wie bereits für Wahrscheinlichkeitsverteilungen, WMFen und WDFen gesehen verzichtet man meist auf das Subskript \\(_\\xi\\), wenn aus dem Kontext klar ist, auf welche Zufallsvariable sich eine gegebene KVF bezieht. Mithilfe von KVFen können zum Beispiel Überschreitungswahrscheinlichkeiten und Intervallwahrscheinlichkeiten von Zufallsvariablen direkt ausgewertet werden. Dies ist der Inhalt folgender Theoreme.\n\nTheorem 11.2 (Überschreitungswahrscheinlichkeit) Es sei \\(\\xi\\) eine Zufallsvariable mit Ergebnisraum \\(\\mathcal{X}\\) und \\(P\\) ihre kumulative Verteilungsfunktion. Dann gilt für die Überschreitungswahrscheinlichkeit \\(\\mathbb{P}(\\xi &gt; x)\\), dass \\[\\begin{equation}\n\\mathbb{P}(\\xi &gt; x) = 1 - P(x) \\mbox{ für alle } x \\in \\mathcal{X}.\n\\end{equation}\\]\n\n\nBeweis. Die Ereignisse \\(\\{\\xi &gt; x\\}\\) und \\(\\{\\xi \\le x\\}\\) sind disjunkt und \\[\\begin{equation}\n\\Omega\n= \\{\\omega\\in \\Omega| \\xi(\\omega) &gt; x\\} \\cup \\{\\omega\\in \\Omega|\\xi(\\omega) \\le x\\}\n= \\{\\xi &gt; x\\} \\cup \\{\\xi \\le x\\}.\n\\end{equation}\\] Mit der \\(\\sigma\\)-Additivität von \\(\\mathbb{P}\\) folgt dann \\[\\begin{align}\n\\begin{split}\n\\mathbb{P}(\\Omega) & = 1                                                    \\\\\n\\Leftrightarrow\n\\mathbb{P}( \\{\\xi &gt; x\\} \\cup \\{\\xi \\le x\\}) & = 1                 \\\\\n\\Leftrightarrow\n\\mathbb{P}(\\{\\xi &gt; x\\}) + \\mathbb{P}(\\{\\xi \\le x\\}) & = 1   \\\\\n\\Leftrightarrow\n\\mathbb{P}(\\{\\xi &gt; x\\}) &  =  1 -  \\mathbb{P}(\\{\\xi \\le x\\}) \\\\\n\\Leftrightarrow\n\\mathbb{P}(\\{\\xi &gt; x\\}) &  =  1 -  P(x).\n\\end{split}\n\\end{align}\\]\n\n\nTheorem 11.3 (Intervallwahrscheinlichkeiten) Es sei \\(\\xi\\) eine Zufallsvariable mit Ereignisraum \\(\\mathcal{X}\\) und \\(P\\) ihre KVF. Dann gilt für die Intervallwahrscheinlichkeit \\(\\mathbb{P}(\\xi \\in \\,]x_1,x_2])\\), dass \\[\\begin{equation}\n\\mathbb{P}(\\xi \\in \\, ]x_1,x_2]) = P(x_2) - P(x_1)\n\\mbox{ für alle } x_1,x_2 \\in \\mathcal{X}\n\\mbox{ mit } x_1 &lt; x_2.\n\\end{equation}\\]\n\n\nBeweis. Wir betrachten die Ereignisse \\(\\{\\xi \\le x_1\\}\\),\\(\\{x_1 &lt; \\xi \\le x_2\\}\\) und \\(\\{\\xi \\le x_2\\}\\), wobei \\[\\begin{equation}\n\\{\\xi \\le x_1\\} \\cap \\{x_1 &lt; \\xi \\le x_2\\} = \\emptyset\n\\mbox{ und }\n\\{\\xi \\le x_1\\} \\cup \\{x_1 &lt; \\xi \\le x_2\\} = \\{\\xi \\le x_2\\}.\n\\end{equation}\\] gelten. Mit der \\(\\sigma\\)-Additivität von \\(\\mathbb{P}\\) gilt dann \\[\\begin{align}\n\\begin{split}\n\\mathbb{P}(\\{\\xi \\le x_1\\} \\cup \\{x_1 &lt; \\xi \\le x_2\\}) & = \\mathbb{P}(\\{\\xi \\le x_2\\})              \\\\\n\\Leftrightarrow\n\\mathbb{P}(\\{\\xi \\le x_1\\}) + \\mathbb{P}(\\{x_1 &lt; \\xi \\le x_2\\}) & = \\mathbb{P}(\\{\\xi \\le x_2\\})         \\\\\n\\Leftrightarrow\n\\mathbb{P}(\\{x_1 &lt; \\xi \\le x_2\\}) & = \\mathbb{P}(\\{\\xi \\le x_2\\}) - \\mathbb{P}(\\{\\xi \\le x_1\\})         \\\\\n\\Leftrightarrow\n\\mathbb{P}(\\{x_1 &lt; \\xi \\le x_2\\}) & = P(x_2) - P(x_1)                                           \\\\\n\\Leftrightarrow\n\\mathbb{P}(\\xi \\in \\,]x_1,x_2]) & = P(x_2) - P(x_1).\n\\end{split}\n\\end{align}\\]\n\nFolgendes Theorem gibt drei zentrale Eigenschaften von KVFen an. Dabei besagt die dritte Eigenschaft, dass eine KVF keine Sprünge hat, wenn man sich Grenzpunkten von rechts nähert. Tatsächlich sind die diskutierten Eigenschaften auch gerade die definierenden Eigenschaften von KVFen, das heißt, jede Funktion \\(P\\), die die Eigenschaften von Theorem 11.4 erfüllt, kann als eine KVF einer Zufallsvariable interpretiert werden. Für einen Beweis dieser Tatsache verweisen wir auf die weiterführende Literatur.\n\nTheorem 11.4 (Eigenschaften von kumulative Verteilungsfunktionen) Es sei \\(\\xi\\) eine Zufallsvariable und \\(P\\) ihre kumulative Verteilungsfunktion. Dann hat \\(P\\) die folgenden Eigenschaften\n\n\\(P\\) ist monoton steigend, i.e., wenn \\(x_1 &lt; x_2\\), dann gilt \\(P(x_1)\\le P(x_2)\\).\n\\(\\lim_{x \\to -\\infty} P(x) = 0\\) und \\(\\lim_{x \\to \\infty} P(x) = 1\\).\n\\(P\\) ist rechtsseitig stetig, d.h., \\(P(x) = P\\left(x^+\\right) = \\lim_{y \\to x, y &gt; x} P(y)\\) für alle \\(x \\in \\mathbb{R}\\)\n\n\n\nBeweis. Wir betrachten die Eigenschaften nacheinander.\n\nWir halten zunächst fest, dass für Ereignisse \\(A \\subset B\\) gilt, dass \\(\\mathbb{P}(A)\\le \\mathbb{P}(B)\\). Wir halten dann fest, dass für \\(x_1 &lt; x_2\\), \\[\\begin{equation}\n\\{\\xi \\le x_1\\} =\n\\{\\omega \\in \\Omega|\\xi(\\omega)\\le x_1\\} \\subset\n\\{\\omega \\in \\Omega|\\xi(\\omega)\\le x_2\\} =\n\\{\\xi \\le x_2\\}.\n\\end{equation}\\] Also gilt \\[\\begin{equation}\n\\mathbb{P}(\\{\\xi \\le x_1\\})\n\\le\n\\mathbb{P}\\{\\xi \\le x_2\\}\n\\Rightarrow P(x_1) \\le P(x_2).\n\\end{equation}\\]\nFür einen Beweis verweisen wir auf die weiterführende Literatur.\nWir definieren \\[\\begin{equation}\nP\\left(x^+\\right) = \\lim_{y \\to x, y &gt; x} P(y).\n\\end{equation}\\] Seien nun \\(y_1 &gt; y_2 &gt; \\cdots\\) so, dass \\(\\lim_{n \\to \\infty}y_n = x\\). Dann gilt \\[\\begin{equation}\n\\{\\xi \\le x\\} = \\cap_{n = 1}^\\infty \\{\\xi \\le y_n\\}.\n\\end{equation}\\] Es gilt also \\[\\begin{equation}\nP(x)\n= \\mathbb{P}(\\{\\xi \\le x\\})\n= \\mathbb{P}(\\cap_{n = 1}^\\infty \\{\\xi \\le y_n\\})\n= \\lim_{n\\to \\infty}\\mathbb{P}(\\{\\xi \\le y_n\\})\n= P\\left(x^+\\right),\n\\end{equation}\\] wobei wir die dritte Gleichung unbegründet stehen lassen.\n\n\n\nKVFen von diskreten Zufallsvariablen\nAnhand von Abbildung 11.10 und Abbildung 11.11 wollen wir uns obige Eigenschaften von KVFen diskreter Zufallsvariablen visuell verdeutlichen. Dabei sollte man immer vor Augen haben, dass der Wert \\(P(x)\\) einer KVF für den Ergebniswert \\(x\\) der Zufallsvariable \\(x\\) der Wahrscheinlichkeit \\(\\mathbb{P}_\\xi(\\xi \\le x)\\) entspricht, also die Wahrscheinlichkeit dafür ist, dass die Zufallsvariable \\(\\xi\\) Werte kleiner oder gleich \\(x\\) annimmt. Liest man diese Wahrscheinlichkeiten entsprechend aus den Darstellungen der korrespondierenden WMF ab, so ergeben sich die funktionale Form der KVFen im Vergleich mit den entsprechenden WMFen intuitiv. Weiterhin erschließen sich auch folgende Eigenschaften der KVFen von diskreten Zufallsvariablen intuitiv: Wennn \\(a &lt; b\\) und \\(\\mathbb{P}(a &lt; \\xi &lt; b) = 0\\) ist, dann ist die KVF von \\(\\xi\\) konstant horizontal auf \\(]a,b[\\). Weiterhin gilt, dass an jedem Punkt \\(x\\) mit \\(\\mathbb{P}(\\xi=x)&gt;0\\) die KVF um den Betrag \\(\\mathbb{P}(\\xi=x)\\) springt, an dieser Stelle also linksseitig nicht stetig ist. Allgemein ist die KVF einer diskreten Zufallsvariable mit Ergebnisraum \\(\\mathbb{N}_0\\) durch \\[\\begin{equation}\nP : \\mathbb{R} \\to [0,1], x \\mapsto P(x) := \\sum_{k=0}^{\\lfloor x  \\rfloor} \\mathbb{P}(\\xi = k)\n\\end{equation}\\] gegeben, wobei \\(\\lfloor x \\rfloor\\) die Abrundungsfunktion bezeichnet.\n\n\n\nAbbildung 11.10: WMFen und KVFen von Bernoulli-Zufallsvariablen.\n\n\n\n\n\nAbbildung 11.11: WMFen und KVFen von Binomial-Zufallsvariablen.\n\n\n\n\nKVFen von kontinuierlichen Zufallsvariablen\nDie KVFen von kontinuierlichen Zufallsvariablen sind analytisch etwas zugänglicher als die KVFen von diskreten Zufallsvariablen, da sie keine Unstetigkeitsstellen aufweisen. Wir haben zunächst folgendes, vielleicht etwas überraschendes Theorem.\n\nTheorem 11.5 (Kumulative Verteilungsfunktionen von kontinuierlichen Zufallsvariablen) \\(\\xi\\) sei eine kontinuierliche Zufallsvariable mit WDF \\(p\\) und KVF \\(P\\). Dann gilt \\[\\begin{equation}\nP(x) = \\int_{-\\infty}^x p(s)\\,ds\n\\mbox{ und }\np(x) = P'(x).\n\\end{equation}\\]\n\n\nBeweis. Wir halten zunächst fest, dass weil \\(\\mathbb{P}(\\xi = x) = 0\\) für alle \\(x \\in \\mathbb{R}\\) gilt, die KVF von \\(\\xi\\) keine Sprünge hat, d.h. \\(P\\) ist stetig. Mit der Definitionen von WDF und KVF, folgt, dass \\(P\\) die Form einer Stammfunktion von \\(p\\) hat. Dass \\(p\\) die Ableitung von \\(P\\) ist folgt dann direkt aus dem ersten Hauptsatz der Differential- und Integralrechnung, Theorem 7.3.\n\nFür kontinuierliche Zufallsvariablen gilt also, dass die KVF der Zufallsvariable eine Stammfunktion der entsprechenden WDF ist, und umgekehrt, dass die WDF die Ableitung der KVF ist. Im Kontext des Theorem von Radon-Nikodym wird diese Einsicht auf generelle Maße generalisiert (vgl. Schmidt (2009)). KVFen kontinuierlicher Zufallsvariablen werden auch oft als kumulative Dichtefunktionen (KDFen) bezeichnet.\nAls Beispiel betrachten wir die KVF einer normalverteilten Zufallsvariable. Es sei \\(\\xi \\sim N(\\mu,\\sigma^2)\\). Dann ist die WDF von \\(\\xi\\) bekanntlich durch \\[\\begin{equation}\np : \\mathbb{R} \\to \\mathbb{R}_{&gt;0}, x \\mapsto p(x)\n:= \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left(-\\frac{1}{2\\sigma^2}(x-\\mu)^2\\right).\n\\end{equation}\\] gegeben. Für die KVF von \\(\\xi\\) folgt entsprechend, dass \\[\\begin{equation}\nP : \\mathbb{R} \\to ]0,1[, x \\mapsto P(x)\n= \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\int_{-\\infty}^x\\exp\\left(-\\frac{1}{2\\sigma^2}(s -\\mu)^2\\right)\\,ds.\n\\end{equation}\\] Interessanterweise kann das definierende Integral der KVF einer normalverteilten Zufallsvariable nur numerisch, nicht aber analytisch berechnet werden. Wir visualisieren ausgewählte WDFen und KVFen von normalverteilten Zufallsvariablen in Abbildung 11.12.\n\n\n\nAbbildung 11.12: WDFen und KVFen von normalverteilten Zufallsvariablen.\n\n\n\n\nInverse Kumulative Verteilungsfunktion\nWir beschließen dieses Kapitel mit dem Begriff der inversen kumulativen Verteilungsfunktion, einem technischen Hilfsmittel, dass insbesondere bei Konfidenzintervallen und Hypothesentests der Frequentistischen Inferenz zur Bestimmung kritischer Werte benutzt wird. Wir definieren die inverse KVF wie folgt.\n\nDefinition 11.14 (Inverse Kumulative Verteilungsfunktion) \\(\\xi\\) sei eine kontinuierliche Zufallsvariable mit KVF \\(P\\). Dann heißt die Funktion \\[\\begin{equation}\nP^{-1} : ]0,1[ \\to \\mathbb{R}, q \\mapsto P^{-1}(q) := \\{x \\in \\mathbb{R}|P(x) = q\\}\n\\end{equation}\\] die .\n\nNach Definition 11.14 gilt offenbar, dass die Funktion \\(P^{-1}\\) die Umkehrfunktion von \\(P\\) ist, also \\[\\begin{equation}\nP^{-1}(P(x)) = x.\n\\end{equation}\\] Da bekanntlich gilt, dass \\[\\begin{equation}\nP(x) = q \\Leftrightarrow \\mathbb{P}(\\xi \\le x) = q \\mbox{ für } q \\in ]0,1[,\n\\end{equation}\\] ist \\(P^{-1}(q)\\) also der Wert \\(x\\) von \\(\\xi\\), so dass \\(\\mathbb{P}(\\xi \\le x) = q\\). Wir visualisieren die KVFen und inversen KVFen normalverteilter Zufallsvariablen in Abbildung 11.13. Im Falle einer normalverteilten Zufallsvariable \\(\\xi \\sim N(0,1)\\) gilt zum Beispiel, dass \\[\\begin{equation}\nP(1.645) = 0.950\n\\Leftrightarrow\nP^{-1}(0.950) = 1.645,\n\\end{equation}\\] und \\[\\begin{equation}\nP(1.906) = 0.975\n\\Leftrightarrow\nP^{-1}(0.975) = 1.960.\n\\end{equation}\\]\n\n\n\nAbbildung 11.13: KVFen und inverse KVFen von normalverteilten Zufallsvariablen."
  },
  {
    "objectID": "203-Zufallsvariablen.html#zufallsergebnisse-und-zufallsvariablen",
    "href": "203-Zufallsvariablen.html#zufallsergebnisse-und-zufallsvariablen",
    "title": "11  Zufallsvariablen",
    "section": "11.5 Zufallsergebnisse und Zufallsvariablen",
    "text": "11.5 Zufallsergebnisse und Zufallsvariablen\nMit den in Kapitel 9 diskutierten Ergebnissen und den in diesem Kapitel diskutierten Werten von Zufallsvariablen haben wir nun zwei Konzepte kennengelernt, die die Unsicherheit über einen oft numerischen Wert eines Zufallsvorgangs beschreiben können. So kann man sich zum Beispiel die Augenzahl, die ein Würfel beim einmaligen Werfen annimmt, als Realisierung eines Ergebnisses oder einer Zufallsvariable vorstellen. Tatsächlich gibt es auch keine standardisierte Antwort auf die Frage, ob man einen Zufallsvorgang nun lediglich mit einem Wahrscheinlichkeitsraum oder aber mit einem Wahrscheinlichkeitsraum, einer Zufallsvariable, und dem durch beide induzierten Wahrscheinlichkeitsraum modellieren sollte. In der Anwendung wird meist der Begriff der Zufallsvariable bevorzugt und entsprechende WMFen oder WDFen angegeben, ohne dass ein zugrundeliegender Wahrscheinlichkeitsraum oder die Abbildungsform der Zufallsvariable spezifiziert würde. Folgende Formulierung ist beispielsweise typisch:\n\\(\\xi\\) sei eine normalverteilte Zufallsvariable mit Erwartungswertparameter \\(\\mu\\) und Varianzparameter \\(\\sigma^2\\).\nImplizit werden in dieser Aussage basierend auf der Definition der normalverteilten Zufallsvariable (vgl. Definition 11.9) für \\(\\xi\\) der Ergebnisraum \\(\\mathcal{X} := \\mathbb{R}\\), die \\(\\sigma\\)-Algebra \\(\\mathcal{S} := \\mathcal{B}(\\mathbb{R})\\), und die Verteilung \\(\\mathbb{P}_\\xi := N(\\mu,\\sigma^2)\\) festgelegt, also der “induzierte” Wahrscheinlichkeitsraum \\(\\left(\\mathbb{R},\\mathcal{B}(\\mathbb{R}), N(\\mu,\\sigma^2)\\right)\\) betrachtet. Allerdings bleibt unklar, durch welchen Wahrscheinlichkeitsraum und welche Abbildungsform genau \\(\\left(\\mathbb{R},\\mathcal{B}(\\mathbb{R}), N(\\mu,\\sigma^2)\\right)\\) nun induziert wurde. Dies kann allerdings immer durch die Annahme, dass \\(\\xi\\) die Identitätsfunktion ergänzt werden. Konkret könnte man für den zugrundeliegenden Wahrscheinlichkeitsraum hier \\(\\left(\\mathbb{R},\\mathcal{B}(\\mathbb{R}), N(\\mu,\\sigma^2)\\right)\\) und für \\(\\xi\\) dann \\[\\begin{equation}\n\\xi : \\mathbb{R} \\to \\mathbb{R}, \\omega \\mapsto \\xi(\\omega) := \\omega := x\n\\end{equation}\\] wählen. Da \\(\\xi\\) dann an dem im Rahmen des zugrundeliegenden Wahrscheinlichkeitsraum zufällig realisiertem Ergebnis \\(\\omega\\) nichts ändert und dieses lediglich in \\(x\\) umbenannt wird, entspricht die Verteilung von \\(\\xi\\) dann direkt dem Wahrscheinlichkeitsmaß des zugrundeliegenden Wahrscheinlichkeitsraums.\nAllgemein mag man festhalten, dass das Modellieren von Zufallsvorgängen mithilfe von Zufallsvariablen das elementare Wahrscheinlichkeitsraummodell also als Spezialfall der Zufallsvariable als Identititätsabbildung impliziert, über dies hinausgehend aber die Möglichkeit eröffnet, durch von der Identitätsabbildung verschiedene Zufallsvariablen die Transformation von Wahrscheinlichkeitsmaßen auf unterschiedlichen Messräumen zu formalisieren."
  },
  {
    "objectID": "203-Zufallsvariablen.html#literaturhinweise",
    "href": "203-Zufallsvariablen.html#literaturhinweise",
    "title": "11  Zufallsvariablen",
    "section": "11.6 Literaturhinweise",
    "text": "11.6 Literaturhinweise\nDie Genese des Begriffs der Zufallsvariablen ist eng mit der Entwicklung der Wahrscheinlichkeitstheorie in den letzten drei Jahrhunderten verflochten, so dass keine für den Begriff entscheidene Publikation angegeben werden kann. Die mathematischen Entwicklung des Begriffs der Normalverteilung durch Abraham De Moivre (1667-1754), Pierre Simon Laplace (1749-1827), Johann Carl Friedrich Gauss (1777-1855) und viele andere, ihre deskriptiv-statistischen Entsprechungen in der empirischen Forschung des 19. Jahrhunderts, sowie ihre multivariate Generalisierung im ausgehenden 19. Jahrhundert werden ausführlich in Stigler (1986) dargestellt."
  },
  {
    "objectID": "203-Zufallsvariablen.html#selbstkontrollfragen",
    "href": "203-Zufallsvariablen.html#selbstkontrollfragen",
    "title": "11  Zufallsvariablen",
    "section": "11.7 Selbstkontrollfragen",
    "text": "11.7 Selbstkontrollfragen\n\nGeben Sie die Definition des Begriffs der Zufallsvariable wieder.\nErläutern Sie die Gleichung \\(\\mathbb{P}_\\xi(\\xi = x) = \\mathbb{P}(\\{\\xi = x\\})\\).\nErläutern Sie die Bedeutung von \\(\\mathbb{P}(\\xi = x)\\).\nGeben Sie die Definition des Begriffs der Wahrscheinlichkeitsmassefunktion wieder.\nGeben Sie die Definition des Begriffs der Wahrscheinlichkeitsdichtefunktion wieder.\nGeben Sie die Definition des Begriffs der kumulativen Verteilungsfunktion wieder.\nSchreiben sie die Intervallwahrscheinlichkeit einer Zufallsvariable mithilfer ihrer KVF.\nGeben Sie die Definition der WDF einer normalverteilten Zufallsvariable wieder.\nGeben Sie die Definition der KVF einer normalverteilten Zufallsvariable wieder.\nSchreiben Sie den Wert \\(P(x)\\) der KVF einer Zufallsvariable mithilfe ihrer WDF.\nSchreiben Sie den Wert \\(p(x)\\) der WDF einer Zufallsvariable mithilfe ihrer KVF.\nGeben Sie die Definition des Begriffs der inversen Verteilungsfunktion wieder.\n\n\n\n\n\nHesse, C. (2009). Wahrscheinlichkeitstheorie (2. Aufl.). Vieweg + Teubner.\n\n\nSchmidt, K. D. (2009). Maß und Wahrscheinlichkeit. Springer.\n\n\nStigler, S. M. (1986). The History of Statistics: The Measurement of Uncertainty before 1900. Belknap Press of Harvard University Press."
  },
  {
    "objectID": "204-Zufallsvektoren.html#sec-definition-und-multivariate-verteilungen",
    "href": "204-Zufallsvektoren.html#sec-definition-und-multivariate-verteilungen",
    "title": "12  Zufallsvektoren",
    "section": "12.1 Definition und multivariate Verteilungen",
    "text": "12.1 Definition und multivariate Verteilungen\nDie Konstruktion und Definition eines Zufallsvektors ist analog zu der einer Zufallsvariable, mit dem Unterschied, dass es sich bei einer Zufallsvariable um eine skalarwertige, bei einem Zufallsvektor dagegen um eine vektorwertige Abbildung auf dem Ergebnisraum eines Wahrscheinlichkeitsraums handelt.\n\nDefinition 12.1 (Zufallsvektor) \\((\\Omega, \\mathcal{A}, \\mathbb{P})\\) sei ein Wahrscheinlichkeitsraum und \\((\\mathcal{X},\\mathcal{S})\\) sei ein \\(n\\)-dimensionaler Messraum. Ein \\(n\\)-dimensionaler ist definiert als eine Abbildung \\[\\begin{equation}\n\\xi:\\Omega \\to \\mathcal{X}, \\omega \\mapsto \\xi(\\omega) :=\n\\begin{pmatrix}\n\\xi_1(\\omega) \\\\\n\\vdots      \\\\\n\\xi_n(\\omega)\n\\end{pmatrix}\n\\end{equation}\\] mit der \\[\\begin{equation}\n\\{\\omega \\in \\Omega|\\xi(\\omega) \\in S \\} \\in \\mathcal{A} \\mbox{ für alle } S \\in \\mathcal{S}.\n\\end{equation}\\]\n\nDas Standardbeispiel für den Ergebisraum eines Zufallsvektors ist \\(\\mathbb{R}^n\\), das Standardbeispiel für die auf ihm definierte \\(\\sigma\\)-Algebra ist die \\(n\\)-dimensionale Borelsche \\(\\sigma\\)-Algebra \\(\\mathcal{B}(\\mathbb{R}^n)\\). Für eine explizite und formale Einführung der \\(n\\)-dimensionalen Borelschen \\(\\sigma\\)-Algebra verweisen wir auf die weiterführende Literatur (z.B. Schmidt (2009)). Wir begnügen uns hier wieder mit der (weiterhin formal falschen) Intuition der \\(n\\)-dimensionale Borelschen \\(\\sigma\\)-Algebra als Menge aller Teilmengen des \\(\\mathbb{R}^n\\). Das Standardbeispiel für einen \\(n\\)-dimensionalen Messraum ist damit \\((\\mathbb{R}^n, \\mathcal{B}(\\mathbb{R}^n))\\).\nWie bei allen vektorwertigen Funktionen nennen wir die den Zufallsvektor konstituierenden Funktionen \\(\\xi_i\\) die Komponentenfunktionen von \\(\\xi\\). Legen wir den \\(n\\)-dimensionalen Messraum \\((\\mathbb{R}^n, \\mathcal{B}(\\mathbb{R}^n))\\) dem Zufallsvektor zugrunde, so haben diese die Form \\[\\begin{equation}\n\\xi_i : \\Omega \\to \\mathbb{R}, \\omega \\mapsto \\xi_i(\\omega).\n\\end{equation}\\] Ohne Beweis halten wir fest, dass der Zufallsvektor \\(\\xi\\) messbar ist, wenn für alle \\(i = 1,...,n\\) die Funktionen \\(\\xi_i\\) messbar sind und umgekehrt. Damit sind die Komponentenfunktionen eines Zufallsvektors (letztlich nach Definition) Zufallsvariablen. Ein \\(n\\)-dimensionaler Zufallsvektor wird also als eine Konkatenation von \\(n\\) Zufallsvariablen betrachtet, für \\(n := 1\\) entspricht ein Zufallsvektor einer Zufallsvariable.\nZufallsvektoren werden manchmal auch als “multivariate Zufallsvariablen” bezeichnet. Tatsächlich stehen bei der Betrachtung von Zufallsvektoren auch zunächst primär wahrscheinlichkeitstheoretische Aspekte und nicht etwa Aspekte der geometrischen Vektorraumtheorie im Vordergrund. Die Betrachtung von Vektorraumstrukturen ist im Kontext probabilistischer Standardmodelle wie dem Allgemeinem Linearen Modell aber durchaus üblich, so dass wir hier den Begriff des Zufallsvektors bevorzugen (vgl. Christensen (2011)). Trotzdem werden wir Zufallsvektoren, wie in vielen Texten der Probabilistik üblich, auch oft in Zeilenform, also etwa als \\(\\xi:= (\\xi_1,...,\\xi_n)\\), notieren.\n\n\n\nAbbildung 12.1: Konstruktion von Zufallsvektor und multivariater Verteilung.\n\n\nDas durch die Konstruktion eines Zufallsvektors definierte Bildmaß heißt die multivariate Verteilung des Zufallsvektors, wie in folgender Definition ausgeführt (Abbildung 12.1).\n\nDefinition 12.2 (Multivariate Verteilung) \\((\\Omega, \\mathcal{A}, \\mathbb{P})\\) sei ein Wahrscheinlichkeitsraum, \\((\\mathcal{X},\\mathcal{S})\\) sei ein \\(n\\)-dimensionaler Messraum und \\[\\begin{equation}\n\\xi : \\Omega \\to \\mathcal{X}, \\omega \\mapsto \\xi(\\omega)\n\\end{equation}\\] sei ein Zufallsvektor. Dann heißt das Wahrscheinlichkeitsmaß \\(\\mathbb{P}_\\xi\\), definiert durch \\[\\begin{equation}\n\\mathbb{P}_\\xi : \\mathcal{S} \\to [0,1], S \\mapsto \\mathbb{P}_\\xi(S)\n:= \\mathbb{P}(\\xi^{-1}(S))\n= \\mathbb{P}\\left(\\{\\omega \\in \\Omega|\\xi(\\omega) \\in S\\}\\right)\n\\end{equation}\\] die .\n\nDer Einfachheit halber spricht man oft auch nur von der Verteilung des Zufallsvektors \\(\\xi\\) oder einer multivariaten Verteilung. Die Notationskonventionen für Zufallsvariablen Definition 11.3 gelten für Zufallsvektoren analog. Zum Beispiel gelten \\[\\begin{align}\n\\begin{split}\n\\mathbb{P}_\\xi(\\xi \\in S)\n& := \\mathbb{P}\\left(\\{\\xi \\in S\\} \\right)\n= \\mathbb{P}\\left(\\{\\omega \\in \\Omega|\\xi(\\omega) \\in S\\} \\right)\n\\\\\n\\mathbb{P}_\\xi(\\xi = x)\n& := \\mathbb{P}\\left(\\{\\xi = x\\} \\right)\n= \\mathbb{P}\\left(\\{\\omega \\in \\Omega|\\xi(\\omega) = x\\} \\right)\n\\\\\n\\mathbb{P}_\\xi(\\xi \\le x)\n& := \\mathbb{P}\\left(\\{\\xi \\le x\\} \\right)\n= \\mathbb{P}\\left(\\{\\omega \\in \\Omega|\\xi(\\omega) \\le x\\} \\right)\n\\\\\n\\mathbb{P}_\\xi(x_1 \\le \\xi \\le x_2)\n& := \\mathbb{P}\\left(\\{x_1 \\le \\xi \\le x_2\\} \\right)\n   = \\mathbb{P}\\left(\\{\\omega \\in \\Omega|x_1 \\le \\xi(\\omega) \\le x_2\\} \\right)\n\\end{split}\n\\end{align}\\] wobei die Relationsoperatoren \\(&lt;, \\le, &gt;, \\ge\\) werden hier komponentenweise verstanden werden. So heißt beispielsweise \\(x \\le y\\) für \\(x,y \\in \\mathbb{R}^n\\), dass für alle Komponenten \\(x_i,y_i, i = 1,...,n\\) gilt, dass \\(x_i \\le y_i\\). Eben dieser Konvention folgt auch die Definition der multivariaten kumulativen Verteilungsfunktion in Generalisierung von Definition 11.13.\n\nDefinition 12.3 (Multivariate kumulative Verteilungsfunktionen) \\(\\xi\\) sei ein Zufallsvektor mit Ergebnisraum \\(\\mathcal{X}\\). Dann heißt eine Funktion der Form \\[\\begin{equation}\nP_\\xi : \\mathcal{X} \\to [0,1],\\, x \\mapsto P_\\xi(x) := \\mathbb{P}_\\xi(\\xi \\le x)\n\\end{equation}\\] multivariate kumulative Verteilungsfunktion von \\(\\xi\\).\n\nWie kumulative Verteilungsfunktionen können auch multivariate kumulative Verteilungsfunktionen zur Definition von multivariaten Verteilungen genutzt werden. Häufiger ist allerdings, wie im univariaten Fall, die Definition multivariater Verteilungen durch multivariate Wahrscheinlichkeitsmasse - oder Wahrscheinlichkeitsdichtefunktionen. Wir generalisieren die Definitionen diskreter und kontinuierlicher Zufallsvariablen und ihren assoziierten Wahrscheinlichkeitsmasse- und Wahrscheinlichkeitsdichtefunktionen (vgl. Definition 11.4 und Definition 11.8) wie folgt.\n\nDefinition 12.4 (Diskreter Zufallsvektor und multivariate Wahrscheinlichkeitsmassefunktion) Ein Zufallsvektor \\(\\xi\\) heißt diskret, wenn sein Ergebnisraum \\(\\mathcal{X}\\) endlich oder abzählbar ist und eine Funktion \\[\\begin{equation}\np_\\xi : \\mathcal{X} \\to [0,1], x \\mapsto p_\\xi(x)  \n\\end{equation}\\] existiert, für die gilt\n\n\\(\\sum_{x \\in \\mathcal{X}}p(x) = 1\\) und\n\\(\\mathbb{P}_\\xi(\\xi = x) = p(x)\\) für alle \\(x \\in \\mathcal{X}\\).\n\nEin entsprechende Funktion \\(p_\\xi\\) heißt multivariate Wahrscheinlichkeitsmassefunktion (WMF) von \\(\\xi\\).\n\nDer Begriff der multivariaten WMF ist offenbar direkt analog zum Begriff der WMF. Wie univariate WMFen sind multivariate WMFen nicht-negativ und normiert. Der Einfachheit halber spricht man oft einfach von der WMF eines Zufallsvektors und verzichtet bei ihrer Bezeichnung, wenn der betreffende Zufallsvektor aus dem Kontext klar ist, auf das \\(\\xi\\) Subscript, schreibt also oft einfach \\(p\\) anstelle von \\(p_\\xi\\).\n\nBeispiel\nZur Illustration des Begriffs des diskreten Zufallsvektors und seiner WMF wollen wir ein Beispiel betrachten. Dazu sei \\(\\xi:= (\\xi_1,\\xi_2)\\) ein Zufallsvektors, der der Werte in \\(\\mathcal{X} := \\mathcal{X}_1 \\times \\mathcal{X}_2\\) annimmt, wobei \\(\\mathcal{X}_1 := \\{1,2,3\\}\\) und \\(\\mathcal{X}_2 = \\{1,2,3,4\\}\\) seien. Dann entspricht der Ergebnisraum von \\(\\xi\\) der in untenstehender Tabelle spezifizierten Menge an Tupeln \\((x_1,x_2)\\).\nEine exemplarische bivariate WMF der Form \\[\\begin{equation}\np_\\xi: \\{1,2,3\\} \\times \\{1,2,3,4\\} \\to [0,1], (x_1,x_2) \\mapsto p_\\xi(x_1,x_2)\n\\end{equation}\\] ist dann durch nachfolgende Tabelle definiert:\nMan beachte, dass die so spezifierte Funktion \\(p_\\xi\\) den Normiertheits- und Nichtnegativitätsansprüchen an eine WMF genügt. Insbesondere gilt hier \\[\\begin{equation}\n\\sum_{x \\in \\mathcal{X}} p_\\xi(x) = \\sum_{x_1 = 1}^3 \\sum_{x_2 = 1}^4 p_\\xi(x_1,x_2) = 1.\n\\end{equation}\\]\nDen Begriff des kontinuierlichen Zufallsvektors und der multivariaten Wahrscheinlichkeitsdichtefunktion definieren wir wie folgt.\n\nDefinition 12.5 (Kontinuierlicher Zufallsvektor und multivariate Wahrscheinlichkeitdichtefunktion) Ein Zufallsvektor \\(\\xi\\) heißt kontinuierlich, wenn sein Ergebnisraum durch \\(\\mathbb{R}^n\\) gegeben ist und eine Funktion\n\\[\\begin{equation}\np_\\xi : \\mathbb{R}^n \\to \\mathbb{R}_{\\ge 0}, x \\mapsto p_\\xi(x),\n\\end{equation}\\] existiert, für die gilt, dass\n\n\\(\\int_{\\mathbb{R}^n} p_\\xi(x)\\,dx = 1\\) und\n\\(\\mathbb{P}_\\xi(x_1 \\le \\xi \\le x_2) = \\int_{x_{1_1}}^{x_{2_1}} \\cdots \\int_{x_{1_n}}^{x_{2_n}} p_\\xi(s_1,...,s_n)\\,ds_1 \\cdots ds_n\\).\n\nEine entsprechende Funktion \\(p_\\xi\\) heißt multivariate Wahrscheinlichkeitsdichtefunktion (WDF) von \\(\\xi\\).\n\nOffenbar ist der der Begriff der multivariaten WDF eines kontinuierlichen Zufallsvektors analog zum Begriff der WDF einer kontinuierlichen Zufallsvariable und wie univariate WDFen sind multivariate WDFen nicht-negativ und normiert. Der Einfachheit halber spricht man auch hier oft einfach von multivariaten WDFen und verzichtet auf die den Zufallsvektor identifizieren Subskripte. Wie für kontinuierliche Zufallsvariablen gilt für kontinuierliche Zufallsvektoren \\[\\begin{equation}\n\\mathbb{P}_\\xi(\\xi = x)\n= \\mathbb{P}_\\xi(x \\le \\xi \\le x)\n= \\int_{x_1}^{x_1} \\cdots \\int_{x_n}^{x_n} p_\\xi(s_1,...,s_n)\\,ds_1 \\cdots ds_n\n= 0.\n\\end{equation}\\]\nDas Standardbeispiel für eine multivariate WDF ist die multivariate Normalverteilung, welcher wir mit ?sec-normalverteilungen ein eigenens Kapitel widmen."
  },
  {
    "objectID": "204-Zufallsvektoren.html#sec-marginalverteilungen",
    "href": "204-Zufallsvektoren.html#sec-marginalverteilungen",
    "title": "12  Zufallsvektoren",
    "section": "12.2 Marginalverteilungen",
    "text": "12.2 Marginalverteilungen\nHat man die Verteilung eines Zufallsvektors spezifiziert, so kann man sich fragen, welche Verteilungen daraus für die einzelnen Komponenten des Zufallsvektors, also die Zufallsvariablen, die zusammen den Zufallsvektor bilden, folgen. Im Kontext eines Zufallsvektors nennt man diese die univariaten Marginalverteilungen des Zufallsvektors. Folgende Definition ist grundlegend.\n\nDefinition 12.6 (Univariate Marginalverteilung) \\((\\Omega, \\mathcal{A}, \\mathbb{P})\\) sei ein Wahrscheinlichkeitsraum, \\((\\mathcal{X}, \\mathcal{S})\\) sei ein \\(n\\)-dimensionaler Messraum, \\(\\xi:\\Omega \\to \\mathcal{X}\\) sei ein Zufallsvektor, \\(\\mathbb{P}_\\xi\\) sei die Verteilung von \\(\\xi\\), \\(\\mathcal{X}_i \\subset \\mathcal{X}\\) sei der Ergebnisraum der \\(i\\)ten Komponente \\(\\xi_i\\) von \\(\\xi\\), und \\(\\mathcal{S}_i\\) sei eine \\(\\sigma\\)-Algebra auf \\(\\xi_i\\). Dann heißt die durch \\[\\begin{equation}\n\\mathbb{P}_{\\xi_i} : \\mathcal{S}_i \\to [0,1],\nS \\mapsto  \\mathbb{P}_\\xi\\left(\\mathcal{X}_1\n                     \\times\n                     \\cdots\n                     \\times\n                     \\mathcal{X}_{i-1}\n                     \\times S\n                     \\times \\mathcal{X}_{i+1}\n                     \\times \\cdots\n                     \\times \\mathcal{X}_n\\right)\n\\mbox{ für } S \\in \\mathcal{S}_i\n\\end{equation}\\] definierte Verteilung die \\(i\\)te univariate Marginalverteilung von \\(\\xi\\).\n\nKonkret kann man sowohl für diskrete als auch für kontinuierliche Zufallsvektoren die WMFen bzw. WDFen ihrer Komponenten direkt aus der entsprechenden multivariaten WMF bzw. WDF bestimmen. Dies ist die Aussage folgenden Theorems.\n\nTheorem 12.1 (Marginale Wahrscheinlichkeitsmasse und Wahrscheinlichkeitsdichtefunktionen) (1) \\(\\xi= (\\xi_1,...,\\xi_n)\\) sei ein \\(n\\)-dimensionaler diskreter Zufallsvektor mit Wahrscheinlichkeitsmassefunktion \\(p_\\xi\\) und Komponentenergebnisräumen \\(\\mathcal{X}_1, ..., \\mathcal{X}_n\\). Dann ergibt sich die Wahrscheinlichkeitsmassefunktion der \\(i\\)ten Komponente \\(\\xi_i\\) von \\(\\xi\\) als \\[\\begin{multline}\np_{\\xi_i} : \\mathcal{X}_i \\to [0,1], x_i \\mapsto\n\\\\ p_{\\xi_i}(x_i) := \\sum_{x_1} \\cdots \\sum_{x_{i-1}} \\sum_{x_{i+1}} \\cdots \\sum_{x_n} p_\\xi(x_1,...,x_{i-1},x_i,x_{i+1}, ...,x_n).\n\\end{multline}\\] (2) \\(\\xi= (\\xi_1,...,\\xi_n)\\) sei ein \\(n\\)-dimensionaler kontinuierlicher Zufallsvektor mit Wahrscheinlichkeitsdichtefunktion \\(p_\\xi\\) und Komponentenergebnisraum \\(\\mathbb{R}\\). Dann ergibt sich die Wahrscheinlichkeitsdichtefunktion der \\(i\\)ten Komponente \\(\\xi_i\\) von \\(\\xi\\) als \\[\\begin{multline}\np_{\\xi_i} : \\mathbb{R} \\to \\mathbb{R}_{\\ge 0},  x_i \\mapsto\n\\\\ p_{\\xi_i}(x_i) :=  \n\\int_{x_1} \\cdots \\int_{x_{i-1}} \\int_{x_{i+1}} \\cdots \\int_{x_n}\np_\\xi(x_1,..., x_{i-1},x_i,x_{i+1}, ...,x_n)\n\\,dx_1...\\,dx_{i-1}\\,dx_{i+1}...\\,dx_n.\n\\end{multline}\\]\n\nDie WMFen der univariaten Marginalverteilungen diskreter Zufallsvektoren ergeben sich also durch Summation über alle Werte der zu der jeweils betrachteten Zufallsvariable komplementären Zufallsvariablen und die WDFen der univariaten Marginalverteilungen kontinuierlicher Zufallsvektoren ergeben sich analog durch Integration über alle Werte der zu der jeweils betrachteten Zufallsvariable komplementären Zufallsvariablen. Für einen Beweis von Theorem 12.1 verweisen wir auf die weiterführende Literatur.\nBeispiel\nIn Fortführung des in Kapitel 12.1 betrachteten Beispiels eines zweidimensionalen Zufallsvektor \\(\\xi:= (\\xi_1,\\xi_2)\\) ergeben sich für die dort definierte WMF für die marginalen WMFen \\(p_{\\xi_1}\\) und \\(p_{\\xi_2}\\) die an den Rändern der unten spezifizierter Tabelle aufgelisteten WMFen anhand von \\[\\begin{equation}\np_{\\xi_1}(x_1) = \\sum_{x_2 = 1}^{4} p_\\xi(x_1,x_2) \\mbox{ und }\np_{\\xi_2}(x_2) = \\sum_{x_1 = 1}^{3} p_\\xi(x_1,x_2)\n\\end{equation}\\]\nzu\nFür die Werte von \\(p_{\\xi_1}\\) werden die entsprechenden Werte von \\(p_\\xi\\) also zeilenweise und für die Werte von \\(p_{\\xi_2}\\) spaltenweise addiert. Man beachte, dass aus der Normiertheit von \\(p_\\xi\\) die Normiertheit von \\(p_{\\xi_1}\\) und \\(p_{\\xi_2}\\) direkt folgt, da sich die Gesamtsumme an Wahrscheinlichkeitsmasse nicht ändert: \\[\\begin{equation}\n1\n= \\sum_{x_1=1}^{3}\\sum_{x_2 = 1}^{4} p_\\xi(x_1,x_2)\n= \\sum_{x_1=1}^{3} p_{\\xi_1}(x_1)\n= \\sum_{x_2=1}^{4} p_{\\xi_2}(x_2).\n\\end{equation}\\]\nEin Realisierungsbeispiel mithilfe relativer Häufigkeiten mag den Begriff der marginalen WMF intuitiv verdeutlichen. Nehmen wir an, wir hätten \\(n = 100\\) unabhängige Realisierungen von \\(\\xi\\) vorliegen. Um die Wahrscheinlichkeiten \\(p_\\xi(x_1,x_2)\\) zu schätzen, würden wir die Anzahl der Realisierungen von \\((x_1,x_2)\\) zählen und durch \\(n\\) teilen. Hätten wir beispielsweise 12 Realisierungen von \\((3,2)\\) vorliegen, so würden wir \\(p_\\xi(3,2) \\approx 12/100 = 0.12\\) schätzen. Die Frage nach der marginalen Wahrscheinlichkeit von \\(x_2 = 2\\) entspräche dann der Frage, wie oft unter den Realisierungen solche zu finden sind, bei denen \\(x_2 = 2\\) ist, irrespektive des Wertes von \\(x_1\\). Dies wäre gerade die Anzahl der Realisierungen der Form \\((1,2), (2,2)\\) und \\((3,2)\\). Gäbe es von diesen beispielsweise \\(0, 22\\) und \\(12\\) respektive, so würde man die Wahrscheinlichkeit \\(p_{\\xi_2}(2)\\) natürlicherweise durch \\[\\begin{equation}\n\\frac{0 + 22 + 12}{100} = \\frac{0}{100} + \\frac{22}{100} + \\frac{12}{100} = 0.00 + 0.22 + 0.12 = 0.34\n\\end{equation}\\] schätzen. Anstelle der Wahrscheinlichkeiten \\(p_\\xi(1,2)\\), \\(p_\\xi(2,2)\\), \\(p_\\xi(3,2)\\) addiert man hier also die entsprechenden relativen Häufigkeiten.\nMarginale Verteilungen im Fall von kontinuierlichen Zufallsvektoren behandeln wir am Standardbeispiel der multivariaten Normalverteilung in ?sec-normalverteilungen."
  },
  {
    "objectID": "204-Zufallsvektoren.html#sec-bedingte-verteilungen",
    "href": "204-Zufallsvektoren.html#sec-bedingte-verteilungen",
    "title": "12  Zufallsvektoren",
    "section": "12.3 Bedingte Verteilungen",
    "text": "12.3 Bedingte Verteilungen\nHat man die Verteilung eines Zufallsvektors spezifiziert, so kann man sich fragen, welche Verteilung daraus für eine einzelne Komponenten des Zufallsvektors folgt, wenn man den Wert einer anderen Komponente als bekannt annimmt. Dies führt auf den Begriff der bedingten Verteilung, welcher sich natürlicherweise aus dem Begriff der bedingten Wahrscheinlichkeit (vgl. Kapitel 10.2) ergibt. Wir erinnern uns zunächst, dass für einen Wahrscheinlichkeitsraum \\((\\Omega, \\mathcal{A}, \\mathbb{P})\\) und zwei Ereignisse \\(A,B \\in \\mathcal{A}\\) mit \\(\\mathbb{P}(B) &gt; 0\\) die bedingte Wahrscheinlichkeit von \\(A\\) gegeben \\(B\\) definiert ist als \\[\\begin{equation}\n\\mathbb{P}(A|B) = \\frac{\\mathbb{P}(A \\cap B)}{\\mathbb{P}(B)}.\n\\end{equation}\\] Analog wird für zwei Zufallsvariablen \\(\\xi_1,\\xi_2\\) mit Ereignisräumen \\(\\mathcal{X}_1,\\mathcal{X}_2\\) und (messbaren) Mengen \\(S_1 \\in \\mathcal{X}_1, S_2 \\in \\mathcal{X}_2\\) die bedingte Verteilung von \\(\\xi_1\\) gegeben \\(\\xi_2\\) mithilfe der Ereignisse \\[\\begin{equation}\nA := \\{\\xi_1 \\in S_1\\} \\mbox{ und } B := \\{\\xi_2 \\in S_2\\}\n\\end{equation}\\] definiert. So ergibt sich zum Beispiel die bedingte Wahrscheinlichkeit, dass \\(\\xi_1 \\in S_1\\) gegeben, dass \\(\\xi_2 \\in S_2\\) unter der Annahme, dass \\(\\mathbb{P}(\\{\\xi_2 \\in S_2\\}) &gt; 0\\), zu \\[\\begin{equation}\n\\mathbb{P}( \\{\\xi_1 \\in S_1\\}|\\{\\xi_2 \\in S_2\\})\n= \\frac{\\mathbb{P}(\\{\\xi_1 \\in S_1\\} \\cap \\{\\xi_2 \\in S_2\\})}{\\mathbb{P}(\\{\\xi_2 \\in S_2\\})}.\n\\end{equation}\\]\nWir betrachten zunächst die Definition der bedingten Verteilungen von diskreten Zufallsvektoren, die lediglich aus zwei Zufallsvariablen bestehen.\n\nDefinition 12.7 (Bedingte Wahrscheinlichkeitsmassefunktion und diskrete bedingte Verteilung) \\(\\xi:= (\\xi_1,\\xi_2)\\) sei ein diskreter Zufallsvektor mit Ergebnisraum \\(\\mathcal{X} := \\mathcal{X}_1 \\times \\mathcal{X}_2\\), WMF \\(p_\\xi = p_{\\xi_1,\\xi_2}\\) und marginalen WMFen \\(p_{\\xi_1}\\) und \\(p_{\\xi_2}\\). Die bedingte WMF von \\(\\xi_1\\) gegeben \\(\\xi_2 = x_2\\) ist dann für \\(p_{\\xi_2}(x_2) &gt; 0\\) definiert als \\[\\begin{equation}\np_{\\xi_1|\\xi_2 = x_2} : \\mathcal{X}_1 \\to [0,1],\nx_1 \\mapsto p_{\\xi_1|\\xi_2 = x_2}(x_1|x_2) := \\frac{p_{\\xi_1,\\xi_2}(x_1,x_2)}{p_{\\xi_2}(x_2)}\n\\end{equation}\\] Analog ist für \\(p_{\\xi_1}(x_1) &gt; 0\\) die bedingte WMF von \\(\\xi_2\\) gegeben \\(\\xi_1 = x_1\\) definiert als \\[\\begin{equation}\np_{\\xi_2|\\xi_1 = x_1} : \\mathcal{X}_2 \\to [0,1],\nx_2 \\mapsto p_{\\xi_2|\\xi_1 = x_2}(x_1|x_2) := \\frac{p_{\\xi_1,\\xi_2}(x_1,x_2)}{p_{\\xi_1}(x_1)}\n\\end{equation}\\] Die bedingten Verteilungen mit WMFen \\(p_{\\xi_1|\\xi_2 = x_2}\\) und \\(p_{\\xi_2|\\xi_1 = x_1}\\) heißen dann die , respektive.\n\nIn Analogie zur Definition der bedingten Wahrscheinlichkeit von Ereignissen gilt also \\[\\begin{equation}\np_{\\xi_1|\\xi_2}(x_1|x_2)\n= \\frac{p_{\\xi_1,\\xi_2}(x_1,x_2)}{p_{\\xi_2}(x_2)}\n= \\frac{\\mathbb{P}(\\{\\xi_1 = x_1\\} \\cap \\{\\xi_2 = x_2\\})}{\\mathbb{P}(\\{\\xi_2 = x_2\\})}.\n\\end{equation}\\] Es ist dabei entscheidend zu erkennen, dass bedingte Verteilungen lediglich normalisierte gemeinsame Verteilungen sind.\nBeispiel\nIn Fortführung des in Kapitel 12.1 betrachteten Beispiels eines zweidimensionalen Zufallsvektor \\(\\xi:= (\\xi_1,\\xi_2)\\) ergeben und seiner in Kapitel 12.2 bestimmten Marginalverteilungen ergeben sich folgende bedingte WMFen für \\(p_{\\xi_2|\\xi_1 = x_1}\\):\nMan beachte, dass zum einen gilt, dass \\[\\begin{equation}\n\\sum_{x_2 = 1}^4 p_{\\xi_2|\\xi_1 = x_1}(x_2|x_1) = 1 \\mbox{ für alle } x_1 \\in \\mathcal{X}_1,\n\\end{equation}\\] die bedingten WMFen sind also normiert. Zum anderen beachte man die qualitative Ähnlichkeit der WMFen \\(p_{\\xi_1,\\xi_2}(x_1,x_2)\\) und \\(p_{\\xi_2|\\xi_1}(x_2|x_1)\\), die sich einfach daraus ergibt, dass \\(p_{\\xi_1,\\xi_2}(x_1,x_2)\\) und \\(p_{\\xi_2|\\xi_1}(x_2|x_1)\\) für alle \\(x_1 \\in \\mathcal{X}_1\\) bis auf den gemeinsamen Skalierungsfaktor \\(1/p_{\\xi_1}(x_1)\\) identisch sind.\nIm Fall eines kontinuierlichen Zufallsvektors sind die analogen bedingten WDFen definiert wie folgt.\n\nDefinition 12.8 (Bedingte Wahrscheinlichkeitsdichtefunktion und kontinuierliche bedingte Verteilung) \\(\\xi:= (\\xi_1,\\xi_2)\\) sei ein kontinuierlicher Zufallsvektor mit Ergebnisraum \\(\\mathbb{R}^2\\), WDF \\(p_\\xi = p_{\\xi_1,\\xi_2}\\) und marginalen WDFen \\(p_{\\xi_1}\\) und \\(p_{\\xi_2}\\). Die bedingte WDF von \\(\\xi_1\\) gegeben \\(\\xi_2 = x_2\\) ist dann für \\(p_{\\xi_2}(x_2) &gt; 0\\) definiert als \\[\\begin{equation}\np_{\\xi_1|\\xi_2 = x_2} : \\mathbb{R} \\to \\mathbb{R}_{\\ge 0},\nx_1 \\mapsto p_{\\xi_1|\\xi_2 = x_2}(x_1|x_2) := \\frac{p_{\\xi_1,\\xi_2}(x_1,x_2)}{p_{\\xi_2}(x_2)}\n\\end{equation}\\] Analog ist für \\(p_{\\xi_1}(x_1) &gt; 0\\) die bedingte WMF von \\(\\xi_2\\) gegeben \\(\\xi_1 = x_1\\) definiert als \\[\\begin{equation}\np_{\\xi_2|\\xi_1 = x_1} : \\mathbb{R} \\to \\mathbb{R}_{\\ge 0},\nx_2 \\mapsto p_{\\xi_2|\\xi_1 = x_1}(x_2|x_1) := \\frac{p_{\\xi_1,\\xi_2}(x_1,x_2)}{p_{\\xi_1}(x_1)}\n\\end{equation}\\]\nDie Verteilungen mit WDFen \\(p_{\\xi_1|\\xi_2 = x_2}\\) und \\(p_{\\xi_2|\\xi_1 = x_1}\\) heißen dann die , respektive.\n\nMan beachte, dass im kontinuierlichen Fall zwar \\(\\mathbb{P}(\\xi = x) = 0\\), aber nicht notwendig auch \\(p_\\xi(x) = 0\\) gilt. Die bedingten Verteilungen multivariater Normalverteilungen diskutieren wir in ?sec-normalverteilungen."
  },
  {
    "objectID": "204-Zufallsvektoren.html#sec-unabhängige-zufallsvariablen",
    "href": "204-Zufallsvektoren.html#sec-unabhängige-zufallsvariablen",
    "title": "12  Zufallsvektoren",
    "section": "12.4 Unabhängige Zufallsvariablen",
    "text": "12.4 Unabhängige Zufallsvariablen\nÄhnlich wie die bedingte Wahrscheinlichkeiten von Ereignissen lässt sich auch das Konzept der unabhängigen Ereignisse auf Zufallsvektoren übertragen. Wir definieren zunächst den Begriff der unabhängigen Zufallsvariablen.\n\nDefinition 12.9 (Unabhängige Zufallsvariablen) \\((\\Omega, \\mathcal{A}, \\mathbb{P})\\) sei ein Wahrscheinlichkeitsraum und \\(\\xi: = (\\xi_1,\\xi_2)\\) ein zweidimensionaler Zufallsvektor. Die Zufallsvariablen \\(\\xi_1,\\xi_2\\) mit Ergebnisräumen \\(\\mathcal{X}_1, \\mathcal{X}_2\\) heißen , wenn für alle \\(S_1 \\subseteq \\mathcal{X}_1\\) und \\(S_2 \\subseteq \\mathcal{X}_2\\) gilt, dass \\[\\begin{equation}\n\\mathbb{P}_\\xi(\\xi_1 \\in S_1, \\xi_2 \\in S_2) =\n\\mathbb{P}_{\\xi_1}(\\xi_1 \\in S_1)\\mathbb{P}_{\\xi_2}(\\xi_2 \\in S_2).\n\\end{equation}\\]\n\nDefinition 12.9 besagt, dass die Ereignisse \\(\\{\\xi_1 \\in S_1\\}\\) und \\(\\{\\xi_2 \\in S_2\\}\\) unabhängig sind. Es gilt also auch, dass \\[\\begin{equation}\n\\mathbb{P}(\\{\\xi_1 \\in S_1\\})|\\{\\xi_2 \\in S_2\\}) = \\mathbb{P}(\\{\\xi_1 \\in S_1\\})\n\\end{equation}\\] und das Wissen um das Eintreten des Ereignisses \\(\\{\\xi_2 \\in S_2\\}\\) verändert die Wahrscheinlichkeit des Ereignisses \\(\\{\\xi_1 \\in S_1\\}\\) nicht. Das Faktorisierungsprinzip zur Modellierung probabilistischer Unabhängigkeit überträgt sich auf WMFen und WDFen von Zufallsvektoren. Dies ist die Aussagen folgenden Theorems.\n\nTheorem 12.2 (Unabhängigkeit und Faktorisierung)  \n\n\\(\\xi:= (\\xi_1,\\xi_2)\\) sei ein diskreter Zufallsvektor mit Ergebnisraum \\(\\mathcal{X}_1 \\times \\mathcal{X}_2\\), WMF \\(p_\\xi\\) und marginalen WMFen \\(p_{\\xi_1}, p_{\\xi_2}\\). Dann gilt \\[\\begin{multline}\n\\xi_1 \\mbox{ und } \\xi_2 \\mbox{ sind unabhängige Zufallsvariablen} \\Leftrightarrow \\\\\np_\\xi(x_1,x_2) = p_{\\xi_1}(x_1)p_{\\xi_2}(x_2) \\mbox{ für alle } (x_1,x_2) \\in \\mathcal{X}_1 \\times \\mathcal{X}_2.\n\\end{multline}\\]\n\\(\\xi:= (\\xi_1,\\xi_2)\\) sei ein kontinuierlicher Zufallsvektor mit Ergebnisraum \\(\\mathbb{R}^2\\), WDF \\(p_\\xi\\) und marginalen WDFen \\(p_{\\xi_1}, p_{\\xi_2}\\). Dann gilt \\[\\begin{multline}\n\\xi_1 \\mbox{ und } \\xi_2 \\mbox{ sind unabhängige Zufallsvariablen } \\Leftrightarrow \\\\\np_\\xi(x_1,x_2) = p_{\\xi_1}(x_1)p_{\\xi_2}(x_2) \\mbox{ für alle } (x_1,x_2) \\in \\mathbb{R}^2.\n\\end{multline}\\]\n\n\nGenerell ist die Unabhängigkeit zweier Zufallsvariablen also äquivalent zur Faktorisierung ihrer gemeinsamen WMF oder WDF. Für einen Beweis von Theorem 12.2 verweisen wir auf die weiterführende Literatur. Nichtsdestotrotz ist Theorem 12.2 für weite Aspekte der probabilistischen Modellierung grundlegend.\nBeispiel\nWir betrachten erneut den zweidimensionalen Zufallsvektor \\(\\xi:= (\\xi_1, \\xi_2)\\) aus Kapitel 12.1, dessen gemeinsame und marginale WMFen bekanntlich die untenstehende Form haben\nWir fragen zunächst, ob \\(\\xi_1\\) und \\(\\xi_2\\) wohl unabhängig sind. Dies ist nicht der Fall, da hier gilt, dass \\[\\begin{equation}\np_\\xi(1,1) = 0.10 \\neq 0.08 = 0.40\\cdot 0.20 =  p_{\\xi_1}(1)p_{\\xi_2}(1).\n\\end{equation}\\] Möchten wir basierend auf den Marginalverteilungen von \\(\\xi\\) eine gemeinsame Verteilung erzeugen, in der \\(\\xi_1\\) und \\(\\xi_2\\) unabhängig sind, so muss sich jeder Eintrag der gemeinsamen Verteilung \\(p_\\xi(\\xi_1,\\xi_2)\\) aus dem jeweiligen Produkt der Marginalwahrscheinlichkeiten ergeben. Die gemeinsame Verteilung von \\(\\xi_1\\) und \\(\\xi_2\\) unter der Annahme der Unabhängigkeit von \\(\\xi_1\\) und \\(\\xi_2\\) bei gleichen Marginalverteilungen wie im obigen Fall ergibt sich also zu\nWeiterhin ergeben sich im Falle der Unabhängigkeit von \\(\\xi_1\\) und \\(\\xi_2\\) beispielsweise die bedingten WMFen \\(p_{\\xi_2|\\xi_1}\\) zu wie folgt:\nIm Falle der Unabhängigkeit von \\(\\xi_1\\) und \\(\\xi_2\\) ändert sich die Verteilung von \\(\\xi_2\\) gegeben (oder im Wissen um) den Wert von \\(\\xi_1\\) also nicht und entspricht jeweils der Marginalverteilung von \\(\\xi_2\\). Dies entspricht natürlich der Intuition der Unabhängigkeit von Ereignissen im Kontext elementarer Wahrscheinlichkeiten.\nWir wollen den Begriff der unabhängigen Zufallsvariablen nun für mehr als zwei Zufallsvariablen definieren.\n\nDefinition 12.10 (\\(n\\) unabhängige Zufallsvariablen) \\(\\xi:= (\\xi_1,...,\\xi_n)\\) sei ein \\(n\\)-dimensionaler Zufallsvektor mit Ergebnisraum \\(\\mathcal{X} = \\times_{i=1}^n \\mathcal{X}_i\\). Die \\(n\\) Zufallsvariablen \\(\\xi_1,...,\\xi_n\\) heißen , wenn für alle \\(S_i \\in \\mathcal{X}_i, i = 1,...,n\\) gilt, dass \\[\\begin{equation}\n\\mathbb{P}_\\xi(\\xi_1 \\in S_1, ...,\\xi_n \\in S_n) = \\prod_{i=1}^n \\mathbb{P}_{\\xi_i}(\\xi_i \\in S_i).\n\\end{equation}\\] Wenn der Zufallsvektor eine \\(n\\)-dimensionale WMF oder WDF \\(p_\\xi\\) mit marginalen WMFen oder WDFen \\(p_{\\xi_i}, i = 1,...,n\\) besitzt, dann ist die Unabhängigkeit von \\(\\xi_1,...,\\xi_n\\) gleichbedeutend mit der Faktorisierung der gemeinsamen WMF oder WDF, also mit \\[\\begin{equation}\np_\\xi(\\xi_1,...,\\xi_n) = \\prod_{i=1}^n p_{\\xi_i}(x_i).\n\\end{equation}\\]\n\nEs handelt bei Definition 12.10 also um eine direkte Generalisierung des zweidimensionalen Falls.\nSind \\(n\\) Zufallsvariablen nicht nur unabhängig, sondern haben sie auch alle die gleiche Verteilung, so nennt man sie unabhängig und identisch verteilt (u.i.v):\n\nDefinition 12.11 (Unabhängig und identisch verteilte Zufallsvariablen) \\(n\\) Zufallsvariablen \\(\\xi_1,...,\\xi_n\\) heißen unabhängig und identisch verteilt (u.i.v.), wenn\n\n\\(\\xi_1,...,\\xi_n\\) unabhängige Zufallsvariablen sind, und\ndie Marginalverteilungen der \\(\\xi_i\\) übereinstimmen, also gilt, dass \\[\\begin{equation}\n\\mathbb{P}_{\\xi_i} = \\mathbb{P}_{\\xi_j} \\mbox{ für alle } 1 \\le i,j \\le n.\n\\end{equation}\\] Wenn die Zufallsvariablen \\(\\xi_1,...,\\xi_n\\) unabhängig und identisch verteilt sind und die \\(i\\)te Marginalverteilung \\(\\mathbb{P}_\\xi := \\mathbb{P}_{\\xi_i}\\) ist, so schreibt man auch \\[\\begin{equation}\n\\xi_1,...,\\xi_n \\sim \\mathbb{P}_\\xi.\n\\end{equation}\\]\n\n\nMan sagt kurz, dass “\\(\\xi_1,...,\\xi_n\\) u.i.v.” sind. Im Englischen spricht man von independent and identically distributed (i.i.d) Zufallsvariablen. U.i.v. Zufallsvariablen spielen an vielen Stellen der probabilistischen Modellierung eine wichtige Rolle. So werden, wie wir an späterer Stelle sehen werden, additive Fehlerterme in probabilistischen Modellen meist durch u.i.v. Zufallsvariablen modelliert.\nSchließlich halten wir fest, dass \\(n\\) u.i.v. normalverteilte Zufallsvektoren werden als \\[\\begin{equation}\n\\xi_1,...,\\xi_n \\sim N(\\mu,\\sigma^2)\n\\end{equation}\\] geschrieben werden. In ?sec-normalverteilungen zeigen wir, wie genau die gemeinsame Verteilung von \\(n\\) u.i.v. normalverteilte Zufallsvektoren beschaffen ist."
  },
  {
    "objectID": "204-Zufallsvektoren.html#selbstkontrollfragen",
    "href": "204-Zufallsvektoren.html#selbstkontrollfragen",
    "title": "12  Zufallsvektoren",
    "section": "12.5 Selbstkontrollfragen",
    "text": "12.5 Selbstkontrollfragen\n\nGeben Sie die Definition des Begriffs des Zufallsvektors wieder.\nGeben Sie die Definition des Begriffs der multivariaten Verteilung eines Zufallsvektors wieder.\nGeben Sie die Definition des Begriffs der multivariaten WMF wieder.\nGeben Sie die Definition des Begriffs der multivariaten WDF wieder.\nGeben Sie die Definition des Begriffs der univariaten Marginalverteilung eines Zufallsvektors wieder\nWie berechnet man die WMF der \\(i\\)ten Komponente eines diskreten Zufallsvektors?\nWie berechnet man die WDF der \\(i\\)ten Komponente eines kontinuierlichen Zufallsvektors?\nGeben Sie die Definition des Begriffs der Unabhängigkeit zweier Zufallsvariablen wieder.\nWie erkennt man an der gemeinsamen WMF oder WDF eines zweidimensionalen Zufallsvektors, ob die Komponenten des Zufallsvektors unabhängig sind oder nicht?\nGeben Sie die Definition des Begriffs der Unabhängigkeit von \\(n\\) Zufallsvariablen wieder.\nGeben Sie die Definition des Begriffs der \\(n\\) unabhängig und identisch verteilten Zufallsvariablen wieder.\n\n\n\n\n\nChristensen, R. (2011). Plane Answers to Complex Questions. Springer New York. https://doi.org/10.1007/978-1-4419-9816-3\n\n\nSchmidt, K. D. (2009). Maß und Wahrscheinlichkeit. Springer."
  },
  {
    "objectID": "205-Erwartungswerte.html#sec-erwartungswert",
    "href": "205-Erwartungswerte.html#sec-erwartungswert",
    "title": "13  Erwartungswerte",
    "section": "13.1 Erwartungswert",
    "text": "13.1 Erwartungswert\n\nDefinition 13.1 (Erwartungswert) \\((\\Omega, \\mathcal{A},\\mathbb{P})\\) sei ein Wahrscheinlichkeitsraum und \\(\\xi\\) sei eine Zufallsvariable. Dann ist der Erwartungswert von \\(\\xi\\) definiert als\n\n\\(\\mathbb{E}(\\xi) := \\sum_{x \\in \\mathcal{X}} x\\,p_\\xi(x)\\), wenn \\(\\xi : \\Omega \\to \\mathcal{X}\\) diskret mit WMF \\(p_\\xi\\) ist,\n\\(\\mathbb{E}(\\xi) := \\int_{-\\infty}^\\infty x \\,p_\\xi(x)\\,dx\\), wenn \\(\\xi : \\Omega \\to \\mathbb{R}\\) kontinuierlich mit WDF \\(p_\\xi\\) ist.\n\nMan sagt, dass der Erwartungswert einer Zufallsvariable existiert, wenn er endlich ist.\n\nDer Erwartungswert ist also eine skalare Zusammenfassung der Verteilung einer Zufallsvariable. Eine integrierte Definition des Erwartungswertes, die ohne eine Fallunterscheidung in kontinuierliche und diskrete Zufallsvariablen auskommt, ist möglich, erfordert aber mit der Einführung des Lebesgue-Integrals einigen technischen Aufwand. Wir verweisen dahingehend auf die weiterführende Literatur (vgl. Schmidt (2009), Meintrup & Schäffler (2005)). Intuitiv entspricht der Erwartungswert einer Zufallsvariable dem im langfristigen Mittel zu erwartenden Wert der Zufallsvariable, also etwa \\[\\begin{equation}\n\\mathbb{E}(\\xi) \\approx \\frac{1}{n}\\sum_{i=1}^n \\xi_i\n\\end{equation}\\] für eine große Zahl \\(n\\) von Kopien \\(\\xi_i\\) von \\(\\xi\\). Wir werden diese Intuition im Kontext der Gesetze der großen Zahl in Kapitel 15 weiter ausarbeiten.\n\nBeispiele\nMit dem Erwartungswert einer Bernoulli-Zufallsvariable und dem Erwartungswert einer normalverteilten Zufallsvariable wollen wir nun zwei erste Beispiele für den Erwartungswert einer diskreten und einer kontinuierlichen Zufallsvariable betrachten.\n\nTheorem 13.1 (Erwartungswert einer Bernoulli Zufallsvariable) Es sei \\(\\xi \\sim \\mbox{Bern}(\\mu)\\). Dann gilt \\(\\mathbb{E}(\\xi) = \\mu\\).\n\n\nBeweis. \\(\\xi\\) ist diskret mit \\(\\mathcal{X} = \\{0,1\\}\\). Also gilt \\[\\begin{align}\n\\begin{split}\n\\mathbb{E}(\\xi)\n& = \\sum_{x \\in \\{0,1\\}} x\\,\\mbox{Bern}(x;\\mu) \\\\\n& = 0\\cdot \\mu^0 (1 - \\mu)^{1-0} + 1\\cdot \\mu^1 (1 - \\mu)^{1-1} \\\\\n& = 1\\cdot \\mu^1 (1 - \\mu)^{0} \\\\\n& = \\mu.\n\\end{split}\n\\end{align}\\]\n\nEs ergibt sich hier also, dass der Parameter \\(\\mu \\in [0,1]\\) der Verteilung einer Bernoulli-Zufallsvariable gleichzeitig auch ihr Erwartungswert ist.\n\nTheorem 13.2 (Erwartungswert einer normalverteilten Zufallsvariable) Es sei \\(\\xi \\sim N(\\mu,\\sigma^2)\\). Dann gilt \\(\\mathbb{E}(\\xi) = \\mu\\).\n\n\nBeweis. Die Herleitung des Erwartungswerts einer normalverteilten Zufallsvariable ist überraschend aufwändig. Wir müssen in diesem Fall einige grundlegende Eigenschaften der Exponentialfunktion als gegeben annehmen. Dazu halten wir zunächst ohne Beweis fest, dass \\[\n\\int_{-\\infty}^\\infty \\exp\\left(-x^2\\right)\\,dx = \\sqrt{\\pi}\n\\tag{13.1}\\] und dass \\[\n\\lim_{x \\to -\\infty} \\exp\\left(-x^2\\right) = 0 \\mbox{ und } \\lim_{x \\to \\infty}\\exp\\left(-x^2\\right) = 0.\n\\tag{13.2}\\] Gleichung 13.1 ist unter der Bezeichnung Gauss- oder Euler-Poisson-Integral bekannt. Mit der Definition des Erwartungswerts für kontinuierliche Zufallsvariablen gilt dann zunächst \\[\\begin{equation}\n\\mathbb{E}(\\xi)\n= \\int_{-\\infty}^\\infty x \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left(-\\frac{1}{2\\sigma^2}(x - \\mu)^2\\right) \\,dx.\n\\end{equation}\\] Mit der allgemeinen Substitutionsregel (vgl. Theorem 7.1) \\[\\begin{equation}\n\\int_{g(a)}^{g(b)} f(x)\\,dx = \\int_a^b f(g(x))g'(x)\\,dx\n\\end{equation}\\] und der Definition von \\[\\begin{equation}\ng : \\mathbb{R} \\to \\mathbb{R}, x \\mapsto g(x) := \\sqrt{2\\sigma^2}x + \\mu\n\\mbox{ with } g'(x) = \\sqrt{2\\sigma^2},\n\\end{equation}\\] gilt dann \\[\\begin{align}\n\\begin{split}\n\\mathbb{E}(\\xi)\n& = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\n\\int_{-\\infty}^\\infty x\n\\exp\\left(-\\frac{1}{2\\sigma^2}(x - \\mu)^2\\right) \\,dx \\\\\n& = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\n\\int_{-\\infty}^\\infty (\\sqrt{2\\sigma^2}x + \\mu)\n\\exp\\left(-\\frac{1}{2\\sigma^2}\\left(\\left(\\sqrt{2\\sigma^2}x + \\mu \\right) - \\mu\\right)^2\\right)\n\\sqrt{2\\sigma^2}\\,dx \\\\\n& = \\frac{\\sqrt{2\\sigma^2}}{\\sqrt{2\\pi\\sigma^2}}\n\\int_{-\\infty}^\\infty (\\sqrt{2\\sigma^2}x + \\mu)\n\\exp\\left(-x^2\\right) \\,dx \\\\\n& = \\frac{1}{\\sqrt{\\pi}}\n\\left(\\sqrt{2\\sigma^2} \\int_{-\\infty}^\\infty x \\exp\\left(-x^2\\right) \\,dx\n      + \\mu \\int_{-\\infty}^\\infty \\exp\\left(-x^2\\right) \\,dx \\right) \\\\\n& = \\frac{1}{\\sqrt{\\pi}}\n\\left(\\sqrt{2\\sigma^2} \\int_{-\\infty}^\\infty x \\exp\\left(-x^2\\right) \\,dx\n      + \\mu \\sqrt{\\pi} \\right).\n\\end{split}\n\\end{align}\\] Eine Stammfunktion von \\(x \\exp\\left(-x^2\\right)\\) ist \\(-\\frac{1}{2}\\exp\\left(-x^2\\right)\\), weil \\[\\begin{equation}\n\\frac{d}{dx}\\left(-\\frac{1}{2}\\exp\\left(-x^2\\right)\\right)\n= -\\frac{1}{2} \\frac{d}{dx}\\exp\\left(-x^2\\right)\n= -\\frac{1}{2}\\exp\\left(-x^2\\right)(-2x)\n= x\\exp\\left(-x^2\\right)\n\\end{equation}\\] Mit Gleichung 13.2 und der Definition des uneigentlichen Integrals (vgl. Definition 7.5) verschwindet der Integralterm \\(\\int_{-\\infty}^\\infty x \\exp\\left(-x^2\\right) \\,dx\\) damit und wir erhalten \\[\\begin{align}\n\\mathbb{E}(\\xi)\n= \\frac{1}{\\sqrt{\\pi}}\\left(\\mu \\sqrt{\\pi}\\right)\n= \\mu.\n\\end{align}\\]\n\nDer Erwartungswert einer univariaten Normalverteilung ist also durch ihren Parameter \\(\\mu\\in \\mathbb{R}\\) gegeben.\nIn Verallgemeinerung von Definition 13.1 geben wir folgende Definition für den Erwartungswert einer Funktion einer Zufallsvariable\n\nDefinition 13.2 (Erwartungswert einer Funktion einer Zufallsvariable) \\((\\Omega, \\mathcal{A},\\mathbb{P})\\) sei ein Wahrscheinlichkeitsraum, \\(\\xi\\) sei eine Zufallsvariable mit Ergebnisraum \\(\\mathcal{X}\\) und \\(f: \\mathcal{X} \\to \\mathcal{Z}\\) sei eine Funktion mit Zielmenge \\(\\mathcal{Z}\\). Dann ist der Erwartungswert der Funktion \\(f\\) der Zufallsvariable \\(\\xi\\) definiert als\n\n\\(\\mathbb{E}(f(\\xi)) := \\sum_{x \\in \\mathcal{X}} f(x)\\,p_\\xi(x)\\), wenn \\(\\xi : \\Omega \\to \\mathcal{X}\\) diskret mit WMF \\(p_\\xi\\) ist,\n\\(\\mathbb{E}(f(\\xi)) := \\int_{-\\infty}^\\infty f(x) \\,p_\\xi(x)\\,dx\\), wenn \\(\\xi : \\Omega \\to \\mathbb{R}\\) kontinuierlich mit WDF \\(p_\\xi\\) ist.\n\n\nDer Erwartungswert einer Zufallsvariable ergibt sich anhand von Definition 13.2 als der Spezialfall, in dem gilt, dass \\[\\begin{equation}\nf : \\mathcal{X} \\to \\mathcal{Z}, x \\mapsto f(x) := x.\n\\end{equation}\\] In der englischsprachigen Literatur ist Definition 13.2 auch als “Law of the unconscious statistician” bekannt und wird oft auch direkt zur Definition des Erwartungswertes herangezogen.\nWeiterhin ist man wie im univariaten Fall manchmal darum bemüht, die Verteilung eines Zufallsvektors mit einigen wenigen Maßzahlen zu charakterisieren. Das multivariate Analogon des des Erwartungswerts einer Zufallsvariablen ist der Erwartungswert eines Zufallsvektors, der wie folgt definiert ist.\n\nDefinition 13.3 (Erwartungswert eines Zufallsvektors) \\(\\xi\\) sei ein \\(n\\)-dimensionaler Zufallvektor. Dann ist der Erwartungwert von \\(\\xi\\) definiert als der \\(n\\)-dimensionale reelle Vektor \\[\\begin{equation}\n\\mathbb{E}(\\xi) :=\n\\begin{pmatrix}\n\\mathbb{E}(\\xi_1) \\\\\n\\vdots            \\\\\n\\mathbb{E}(\\xi_n)\n\\end{pmatrix}\n\\end{equation}\\]\n\nDer Erwartungswert eines Zufallsvektors \\(\\xi\\) ist also der Vektor der Erwartungswerte der Komponenten \\(\\xi_1, ...,\\xi_n\\) von \\(\\xi\\), ist also direkt im Sinne von Erwartungswerten von Zufallsvariablen definiert. In Analogie zu Definition 13.2 definiert man für die Funktion eines Zufallsvektors den Erwartungswert dieser Transformation wie folgt.\n\nDefinition 13.4 (Erwartungswert einer Funktion eines Zufallsvektors) \\((\\Omega, \\mathcal{A},\\mathbb{P})\\) sei ein Wahrscheinlichkeitsraum, \\(\\xi\\) sei ein Zufallsvektor mit Ergebnisraum \\(\\mathcal{X}\\) und \\(f: \\mathcal{X} \\to \\mathcal{Z}\\) sei eine Funktion mit Zielmenge \\(\\mathcal{Z}\\). Dann ist der Erwartungswert der Funktion \\(f\\) des Zufallsvektors \\(\\xi\\) definiert als\n\n\\(\\mathbb{E}(f(\\xi)) := \\sum_{x \\in \\mathcal{X}} f(x)\\,p_\\xi(x)\\), wenn \\(\\xi : \\Omega \\to \\mathcal{X}\\) diskret mit WMF \\(p_\\xi\\) ist,\n\\(\\mathbb{E}(f(\\xi)) := \\int_{-\\infty}^\\infty f(x) \\,p_\\xi(x)\\,dx\\), wenn \\(\\xi : \\Omega \\to \\mathbb{R}\\) kontinuierlich mit WDF \\(p_\\xi\\) ist.\n\n\nFolgendes Theorem gibt nun einige Rechenregeln im Umgang mit Erwartungswerten an, die uns an vielen Stellen begegnen werden. Diese Rechenregeln folgen direkt aus der Summen- bzw. Integraldefinition des Erwartungswertes, im Beweis des Theorems betrachten wir dementsprechend lediglich den Fall kontinuierlicher Zufallsvariablen.\n\nTheorem 13.3 (Eigenschaften des Erwartungswerts)  \n\n(Linear-affine Transformation) Für eine Zufallsvariable \\(\\xi\\) und \\(a,b\\in \\mathbb{R}\\) gilt \\[\\begin{equation}\n\\mathbb{E}(a\\xi + b) = a\\mathbb{E}(\\xi) + b.\n\\end{equation}\\]\n(Linearkombination) Für Zufallsvariablen \\(\\xi_1,...,\\xi_n\\) und \\(a_1,...,a_n \\in \\mathbb{R}\\) gilt \\[\\begin{equation}\n\\mathbb{E}\\left(\\sum_{i=1}^n a_i\\xi_i \\right) = \\sum_{i = 1}^n a_i \\mathbb{E}(\\xi_i).\n\\end{equation}\\]\n(Faktorisierung bei Unabhängigkeit) Für unabhängige Zufallsvariablen \\(\\xi_1,...,\\xi_n\\) gilt \\[\\begin{equation}\n\\mathbb{E}\\left(\\prod_{i=1}^n \\xi_i \\right) = \\prod_{i = 1}^n \\mathbb{E}(\\xi_i).\n\\end{equation}\\]\n\n\n\nBeweis. Eigenschaft (1) folgt aus den Linearitätseigenschaften von Summen und Integralen. Wir betrachten nur den Fall einer kontinuierlichen Zufallsvariable \\(\\xi\\) mit WDF \\(p_\\xi\\) genauer und definieren zunächst \\(\\upsilon := a\\xi + b\\). Dann gilt\n\\[\\begin{align}\n\\begin{split}\n\\mathbb{E}(\\upsilon)\n& = \\mathbb{E}(a\\xi + b)                                        \\\\\n& = \\int_{-\\infty}^\\infty (ax + b)p_\\xi(x) \\,dx                             \\\\\n& = \\int_{-\\infty}^\\infty  axp_\\xi(x)  + b p_\\xi(x) \\,dx                        \\\\\n& = a\\int_{-\\infty}^\\infty xp_\\xi(x) \\,dx + b \\int_{-\\infty}^\\infty p_\\xi(x) \\,dx           \\\\\n& = a\\mathbb{E}(\\xi) + b.\n\\end{split}\n\\end{align}\\] Eigenschaft (2) folgt gleichfalls aus den Linearitätseigenschaften von Summen und Integralen. Wir wollen nur den Fall von zwei kontinuierlichen Zufallsvariablen \\(\\xi_1\\) und \\(\\xi_2\\) mit bivariater WDF \\(p_{\\xi_1,\\xi_2}\\) genauer betrachten. In diesem Fall gilt \\[\\begin{align}\n\\begin{split}\n\\mathbb{E}\\left(\\sum_{i=1}^2 a_i\\xi_i\\right)\n& = \\mathbb{E}(a_1\\xi_1 + a_2\\xi_2) \\\\\n& = \\iint_{\\mathbb{R}^2} (a_1x_1 + a_2x_2)p_{\\xi_1,\\xi_2}(x_1,x_2)\\,dx_1\\,dx_2  \\\\\n& = \\iint_{\\mathbb{R}^2} a_1x_1 p_{\\xi_1,\\xi_2}(x_1,x_2)\n                                   + a_2x_2 p_{\\xi_1,\\xi_2}(x_1,x_2)\\,dx_1\\,dx_2            \\\\\n& =  a_1\\iint_{\\mathbb{R}^2} x_1 p_{\\xi_1,\\xi_2}(x_1,x_2) \\,dx_1\\,dx_2\n  +  a_2\\iint_{\\mathbb{R}^2} x_2 p_{\\xi_1,\\xi_2}(x_1,x_2)\\,dx_1\\,dx_2           \\\\\n& =  a_1\\int_{-\\infty}^\\infty x_1 \\left(\\int_{-\\infty}^\\infty p_{\\xi_1,\\xi_2}(x_1,x_2) \\,dx_2 \\right)\\,dx_1\n  +  a_2\\int_{-\\infty}^\\infty x_2 \\left(\\int_{-\\infty}^\\infty p_{\\xi_1,\\xi_2}(x_1,x_2) \\,dx_1 \\right) \\,dx_2 \\\\\n& =  a_1\\int_{-\\infty}^\\infty x_1 p_{\\xi_1}(x_1) \\,dx_1\n  +  a_2\\int_{-\\infty}^\\infty x_2 p_{\\xi_2}(x_2) \\,dx_2 \\\\\n& =  a_1 \\mathbb{E}(\\xi_1) +  a_2\\mathbb{E}(\\xi_2) \\\\\n& = \\sum_{i=1}^2 a_i \\mathbb{E}(\\xi_i).\n\\end{split}\n\\end{align}\\] Ein Induktionsbeweis erlaubt dann die Generalisierung vom bivariaten auf den \\(n\\)-variaten Fall.\nZu Eigenschaft (3) betrachten wir den Fall von \\(n\\) kontinuierlichen Zufallsvariablen mit gemeinsamer WDF \\(p_{\\xi_1,...,\\xi_n}\\). Weil als \\(\\xi_1,...,\\xi_n\\) unabhängig vorausgesetzt sind, gilt \\[\\begin{equation}\np_{\\xi_1,...,\\xi_n}(x_1,...,x_n) = \\prod_{i=1}^n p_{\\xi_i}(x_i).\n\\end{equation}\\] Weiterhin gilt also \\[\\begin{align}\n\\begin{split}\n\\mathbb{E}\\left(\\prod_{i=1}^n \\xi_i \\right)\n& = \\int_{-\\infty}^\\infty\\cdots\\int_{-\\infty}^\\infty \\left(\\prod_{i=1}^n x_i\\right)\n        p_{\\xi_1,...,\\xi_n}(x_1,...,x_n) \\,dx_1...\\,dx_n    \\\\\n& = \\int_{-\\infty}^\\infty\\cdots\\int_{-\\infty}^\\infty  \\prod_{i=1}^n x_i\n         \\prod_{i=1}^n p_{\\xi_i}(x_i)\\,dx_1...\\,dx_n    \\\\\n& = \\int_{-\\infty}^\\infty\\cdots \\int_{-\\infty}^\\infty  \\prod_{i=1}^n x_i p_{\\xi_i}(x_i) \\,dx_1...\\,dx_n \\\\\n& = \\prod_{i=1}^n \\int_{-\\infty}^\\infty x_i p_{\\xi_i}(x_i) \\,dx_i   \\\\\n& = \\prod_{i=1}^n \\mathbb{E}(\\xi_i).\n\\end{split}\n\\end{align}\\]"
  },
  {
    "objectID": "205-Erwartungswerte.html#sec-varianz-und-standardabweichung",
    "href": "205-Erwartungswerte.html#sec-varianz-und-standardabweichung",
    "title": "13  Erwartungswerte",
    "section": "13.2 Varianz und Standardabweichung",
    "text": "13.2 Varianz und Standardabweichung\nHäufig genutzte Maße für die Streuung von Verteilungen von Zufallsvariablen sind die Varianz und die Standardabweichung. Diese sind wie folgt definiert.\n\nDefinition 13.5 (Varianz und Standardabweichung) \\(\\xi\\) sei eine Zufallsvariable mit existierendem Erwartungswert \\(\\mathbb{E}(\\xi)\\).\n\nDie ist definiert als \\[\\begin{equation}\n\\mathbb{V}(\\xi) := \\mathbb{E}\\left((\\xi - \\mathbb{E}(\\xi))^2\\right).\n\\end{equation}\\]\nDie ist definiert als \\[\\begin{equation}\n\\mathbb{S}(\\xi) := \\sqrt{\\mathbb{V}(\\xi)}.\n\\end{equation}\\]\n\n\nInwiefern die Varianz und ihre Quadratwurzel als Maße für die Streuung einer Zufallsvariable dienen, werden wir in Theorem 14.2 begründen. Die Quadrierung der Abweichung der Zufallsvariable von ihrem Erwartungswert in der Definition der Varianz ist nötig, da andernfalls mit Theorem 13.3 immer gelten würde, dass \\[\\begin{equation}\n\\mathbb{E}(\\xi-\\mathbb{E}(\\xi)) = \\mathbb{E}(\\xi) - \\mathbb{E}(\\xi) = 0.\n\\end{equation}\\] Allerdings gibt es neben der Varianz durchaus weitere Maße der Streuung von Zufallsvariablen, hier seien beispielsweise die erwartete absolute Abweichung einer Zufallsvariable von ihrem Erwartungswert, \\(\\mathbb{E}(|\\xi - \\mathbb{E}(\\xi)|)\\) und die sogenannte Entropie \\(-\\mathbb{E}(\\ln p_\\xi)\\) genannt. Im Sinne von Definition 13.2 ist die Varianz der Zufallsvariable \\(\\xi: \\Omega \\to \\mathcal{X}\\) der Erwartungswert der Funktion \\[\\begin{equation}\nf : \\mathcal{X} \\to \\mathcal{Z}, x \\mapsto f(x) := (x - \\mathbb{E}(\\xi))^2.\n\\end{equation}\\] Das Berechnen von Varianzen wird durch folgendes Theorem, den sogenannten Varianzverschiebungssatz oft erleichtert, insbesondere, wenn der Erwartungswert der quadrierten Zufallsvariable leicht zu bestimmen oder bekannt ist.\n\nTheorem 13.4 (Varianzverschiebungssatz) \\(\\xi\\) sei eine Zufallsvariable. Dann gilt \\[\\begin{equation}\n\\mathbb{V}(\\xi) = \\mathbb{E}\\left(\\xi^2 \\right) - \\mathbb{E}(\\xi)^2.\n\\end{equation}\\]\n\n\nBeweis. Mit der Definition der Varianz und der Linearität des Erwartungswerts gilt \\[\\begin{align}\n\\begin{split}\n\\mathbb{V}(\\xi)\n& = \\mathbb{E}\\left((\\xi - \\mathbb{E}(\\xi))^2\\right) \\\\\n& = \\mathbb{E}\\left(\\xi^2 - 2\\xi\\mathbb{E}(\\xi) + \\mathbb{E}(\\xi)^2 \\right) \\\\\n& =    \\mathbb{E}(\\xi^2)\n    - 2\\mathbb{E}(\\xi)\\mathbb{E}(\\xi)\n    + \\mathbb{E}\\left(\\mathbb{E}(\\xi)^2\\right)   \\\\\n& = \\mathbb{E}(\\xi^2) - 2\\mathbb{E}(\\xi)^2 + \\mathbb{E}(\\xi)^2  \\\\\n& = \\mathbb{E}(\\xi^2) - \\mathbb{E}(\\xi)^2.\n\\end{split}\n\\end{align}\\]\n\nWie für den Erwartungswert gibt es auch für die Varianz einige Rechenregeln, die den Umgang mit ihr oft erleichtern. Wir fassen sie in folgendem Theorem zusammen.\n\nTheorem 13.5 (Eigenschaften der Varianz)  \n\n(Linear-affine Transformation) Für eine Zufallsvariable \\(\\xi\\) und \\(a,b\\in \\mathbb{R}\\) gelten \\[\\begin{equation}\n\\mathbb{V}(a\\xi + b) = a^2 \\mathbb{V}(\\xi)\n\\mbox{ und }\n\\mathbb{S}(a\\xi + b) = |a|\\mathbb{S}(\\xi).\n\\end{equation}\\]\n(Linearkombination bei Unabhängigkeit) Für unabhängige Zufallsvariablen \\(\\xi_1,...,\\xi_n\\) und \\(a_1,...,a_n \\in \\mathbb{R}\\) gilt \\[\\begin{equation}\n\\mathbb{V}\\left(\\sum_{i=1}^n a_i\\xi_i\\right) = \\sum_{i=1}^n a_i^2 \\mathbb{V}(\\xi_i).\n\\end{equation}\\]\n\n\n\nBeweis. Um Eigenschaft (1) zu zeigen, definieren wir zunächst \\(\\upsilon := a\\xi + b\\) und halten fest, dass \\(\\mathbb{E}(\\upsilon) = a\\mathbb{E}(\\xi) + b\\). Für die Varianz von \\(\\upsilon\\) ergibt sich dann \\[\\begin{align}\n\\begin{split}\n\\mathbb{V}(\\upsilon)\n& = \\mathbb{E}\\left((\\upsilon - \\mathbb{E}(\\upsilon))^2\\right)      \\\\\n& = \\mathbb{E}\\left((a\\xi+b-a\\mathbb{E}(\\xi)-b)^2\\right)    \\\\\n& = \\mathbb{E}\\left((a\\xi-a\\mathbb{E}(\\xi))^2\\right)        \\\\\n& = \\mathbb{E}\\left((a(\\xi - \\mathbb{E}(\\xi))^2\\right)      \\\\\n& = \\mathbb{E}\\left(a^2(\\xi - \\mathbb{E}(\\xi))^2\\right)     \\\\\n& = a^2\\mathbb{E}\\left((\\xi - \\mathbb{E}(\\xi))^2\\right)     \\\\\n& = a^2\\mathbb{V}(\\xi)                                  \\\\\n\\end{split}\n\\end{align}\\] Wurzelziehen ergibt dann das Resultat für die Standardabweichung.\nFür Eigenschaft (2) betrachten wir den Fall zweier unabhängiger Zufallsvariablen \\(\\xi_1\\) und \\(\\xi_2\\) genauer. Wir halten zunächst fest, dass in diesem Fall gilt, dass \\[\\begin{equation}\n\\mathbb{E}\\left(a_1\\xi_1 + a_2\\xi_2\\right) = a_1\\mathbb{E}(\\xi_1) + a_2\\mathbb{E}(\\xi_2).\n\\end{equation}\\] Es ergibt sich also \\[\\begin{align}\n\\begin{split}\n\\mathbb{V}\\left(\\sum_{i=1}^2 a_i \\xi_i\\right)                                                \n& = \\mathbb{V}(a_1\\xi_1 + a_2\\xi_2)                                                               \\\\\n& = \\mathbb{E}\\left((a_1\\xi_1 + a_2\\xi_2 - \\mathbb{E}\\left(a_1\\xi_1 + a_2\\xi_2\\right))^2\\right)   \\\\\n& = \\mathbb{E}\\left((a_1\\xi_1 + a_2\\xi_2 - a_1\\mathbb{E}(\\xi_1) - a_2\\mathbb{E}(\\xi_2))^2\\right)  \\\\\n& = \\mathbb{E}\\left((a_1\\xi_1 - a_1\\mathbb{E}(\\xi_1) + a_2\\xi_2  - a_2\\mathbb{E}(\\xi_2))^2\\right) \\\\\n& = \\mathbb{E}\\left(((a_1(\\xi_1 - \\mathbb{E}(\\xi_1)) + (a_2(\\xi_2 - \\mathbb{E}(\\xi_2)))^2\\right)  \\\\\n& = \\mathbb{E}\\left((a_1(\\xi_1 - \\mathbb{E}(\\xi_1)))^2\n                   + 2(a_1(\\xi_1 - \\mathbb{E}(\\xi_1))(a_2(\\xi_2 - \\mathbb{E}(\\xi_2))\n                   + (a_2(\\xi_2 - \\mathbb{E}(\\xi_2)))^2\\right) \\\\\n& = \\mathbb{E}\\left((a_1^2(\\xi_1 - \\mathbb{E}(\\xi_1))^2\n                   + 2a_1a_2(\\xi_1 - \\mathbb{E}(\\xi_1))(\\xi_2 - \\mathbb{E}(\\xi_2))\n                   + a_2^2(\\xi_2 - \\mathbb{E}(\\xi_2))^2\\right) \\\\\n& = a_1^2\\mathbb{E}\\left((\\xi_1 - \\mathbb{E}(\\xi_1))^2\\right)\n   + 2a_1a_2\\mathbb{E}\\left((\\xi_1 - \\mathbb{E}(\\xi_1))(\\xi_2 - \\mathbb{E}(\\xi_2))\\right)\n   + a_2^2\\mathbb{E}\\left((\\xi_2 - \\mathbb{E}(\\xi_2))^2\\right) \\\\\n& = a_1^2\\mathbb{V}(\\xi_1)\n   + 2a_1a_2\\mathbb{E}\\left((\\xi_1 - \\mathbb{E}(\\xi_1))(\\xi_2 - \\mathbb{E}(\\xi_2))\\right)\n   + a_2^2\\mathbb{V}(\\xi_2) \\\\\n& = \\sum_{i=1}^2 a_i^2\\mathbb{V}(\\xi_i)\n   + 2a_1a_2\\mathbb{E}\\left((\\xi_1 - \\mathbb{E}(\\xi_1))(\\xi_2 - \\mathbb{E}(\\xi_2))\\right).\n\\end{split}.\n\\end{align}\\] Weil \\(\\xi_1\\) und \\(\\xi_2\\) unabhängig sind, ergibt sich mit den Eigenschaften des Erwartungswerts für unabhängige Zufallsvariablen, dass \\[\\begin{align}\n\\begin{split}\n\\mathbb{E}\\left((\\xi_1 - \\mathbb{E}(\\xi_1))(\\xi_2 - \\mathbb{E}(\\xi_2))\\right)\n& = \\mathbb{E}\\left((\\xi_1 - \\mathbb{E}(\\xi_1))\\right)\n    \\mathbb{E}\\left((\\xi_2 - \\mathbb{E}(\\xi_2))\\right) \\\\\n& = (\\mathbb{E}(\\xi_1) - \\mathbb{E}(\\xi_1))\n    (\\mathbb{E}(\\xi_2) - \\mathbb{E}(\\xi_2)) \\\\\n& = 0\n\\end{split}\n\\end{align}\\] ist. Damit folgt also \\[\\begin{equation}\n\\mathbb{V}\\left(\\sum_{i=1}^2 a_i \\xi_i\\right)\n=  \\sum_{i=1}^2 a_i^2\\mathbb{V}(\\xi_i).\n\\end{equation}\\] Ein Induktionsbeweis erlaubt dann die Generalisierung vom bivariaten zum \\(n\\)-variaten Fall.\n\n\nBeispiele\nMit der Varianz einer Bernoulli-Zufallsvariable und der Varianz einer normalverteilten Zufallsvariable wollen wir auch hier zwei erste Beispiele für die Varianz einer diskreten und einer kontinuierlichen Zufallsvariable betrachten.\n\nTheorem 13.6 (Varianz einer Bernoulli Zufallsvariable) Es sei \\(\\xi \\sim \\mbox{Bern}(\\mu)\\). Dann ist die Varianz von \\(\\xi\\) gegeben durch \\[\\begin{equation}\n\\mathbb{V}(\\xi) = \\mu(1-\\mu).\n\\end{equation}\\]\n\n\nBeweis. \\(\\xi\\) ist eine diskrete Zufallsvariable und es gilt \\(\\mathbb{E}(\\xi) = \\mu\\). Also gilt \\[\\begin{align}\n\\begin{split}\n\\mathbb{V}(\\xi)\n& = \\mathbb{E}\\left((\\xi - \\mu)^2\\right) \\\\\n& = \\sum_{x \\in \\{0,1\\}} (x - \\mu)^2 \\mbox{Bern}(x;\\mu) \\\\\n& = (0 - \\mu)^2 \\mu^0(1-\\mu)^{1-0}  + (1 - \\mu)^2\\mu^1(1-\\mu)^{1-1}  \\\\\n& = \\mu^2 (1-\\mu)  + (1 - \\mu)^2\\mu  \\\\\n& = \\left(\\mu^2  + (1 - \\mu)\\mu\\right)(1-\\mu)  \\\\\n& = \\left(\\mu^2 + \\mu - \\mu^2\\right)(1 - \\mu) \\\\\n& = \\mu(1-\\mu).\n\\end{split}\n\\end{align}\\]\n\n\nTheorem 13.7 (Varianz einer normalverteilten Zufallsvariable) Es sei \\(\\xi \\sim N(\\mu,\\sigma^2)\\). Dann ist die Varianz von \\(\\xi\\) gegeben durch \\[\\begin{equation}\n\\mathbb{V}(\\xi) = \\sigma^2.\n\\end{equation}\\]\n\n\nBeweis. Die Herleitung der Varianz einer normalverteilten Zufallsvariable ist nicht unaufwändig, so dass wir hier auch wieder unbewiesen die Gültigkeit von Gleichung 13.1 und Gleichung 13.2 sowie weiterhin von \\[\n\\int_{-\\infty}^\\infty x \\exp(-x^2)\\,dx = 0\n\\tag{13.3}\\] annehmen wollen. Wir halten zunächst fest, dass mit dem Varianzverschiebungssatz gilt, dass \\[\\begin{align}\\label{eq:var_gauss_1}\n\\begin{split}\n\\mathbb{V}(\\xi)\n= \\mathbb{E}(\\xi^2) - \\mathbb{E}(\\xi)^2\n= \\frac{1}{2\\pi\\sigma^2}\\int_{-\\infty}^\\infty x^2 \\exp\\left(-\\frac{1}{2\\sigma^2}(x-\\mu)^2 \\right)\\,dx - \\mu^2.\n\\end{split}\n\\end{align}\\] Mit der allgemeinen Substitutionsregel (Theorem 7.1) \\[\\begin{equation}\n\\int_{a}^{b} f(g(x))g'(x)\\,dx = \\int_{g(a)}^{g(b)} f(x)\\,dx\n\\end{equation}\\] und der Definition von \\[\\begin{equation}\ng:\\mathbb{R} \\to \\mathbb{R}, x \\mapsto \\sqrt{2\\sigma^2}x + \\mu,\ng(-\\infty) := -\\infty, g(\\infty) := \\infty,\n\\mbox{ mit }\ng'(x) = \\sqrt{2\\sigma^2}\n\\end{equation}\\] kann das Integral auf der rechten Seite von Gleichung \\(\\eqref{eq:var_gauss_1}\\) dann als \\[\\begin{align}\n\\begin{split}\n\\int_{-\\infty}^\\infty x^2 \\exp\\left(-\\frac{1}{2\\sigma^2}(x - \\mu)^2 \\right) \\,dx\n& = \\int_{-\\infty}^\\infty (\\sqrt{2\\sigma^2}x + \\mu)^2 \\exp\\left(-\\frac{1}{2\\sigma^2}((\\sqrt{2\\sigma^2}x + \\mu)-\\mu)^2 \\right)\\sqrt{2\\sigma^2}\\,dx \\\\\n& = \\sqrt{2\\sigma^2}\\int_{-\\infty}^\\infty (\\sqrt{2\\sigma^2}x + \\mu)^2 \\exp\\left(-\\frac{2\\sigma^2 x^2}{2\\sigma^2} \\right)\\,dx \\\\\n& = \\sqrt{2\\sigma^2}\\int_{-\\infty}^\\infty (\\sqrt{2\\sigma^2}x + \\mu)^2 \\exp\\left(-x^2\\right)\\,dx\n\\end{split}\n\\end{align}\\] geschrieben werden. Also gilt \\[\\begin{align}\n\\begin{split}\n\\mathbb{V}(\\xi)\n& =\n\\frac{\\sqrt{2\\sigma^2}}{\\sqrt{2\\pi\\sigma^2}}\n\\int_{-\\infty}^\\infty (\\sqrt{2\\sigma^2}x + \\mu)^2 \\exp\\left(-x^2 \\right)\\,dx\n- \\mu^2\n\\\\\n&\n= \\frac{1}{\\sqrt{\\pi}}\n\\int_{-\\infty}^\\infty(\\sqrt{2\\sigma^2}x)^2 + 2\\sqrt{2\\sigma^2}x\\mu + \\mu^2) \\exp\\left(-x^2 \\right)\\,dx\n- \\mu^2\n\\\\\n&\n= \\frac{1}{\\sqrt{\\pi}}\n\\left(\n        2\\sigma^2\\int_{-\\infty}^\\infty x^2 \\exp\\left(-x^2 \\right)\\,dx +\n        2\\sqrt{2\\sigma^2}\\mu\\int_{-\\infty}^\\infty x\\exp\\left(-x^2 \\right)\\,dx +\n        \\mu^2\\int_{-\\infty}^\\infty \\exp\\left(-x^2 \\right)\\,dx\n\\right)\n- \\mu^2.\n\\end{split}\n\\end{align}\\] Mit Gleichung 13.3 ergibt sich dann \\[\\begin{align}\n\\begin{split}\n\\mathbb{V}(\\xi)\n& = \\frac{1}{\\sqrt{\\pi}}\n\\left(2\\sigma^2\\int_{-\\infty}^\\infty x^2 \\exp\\left(-x^2 \\right)\\,dx + \\mu^2\\sqrt{\\pi} \\right)\n- \\mu^2\n\\\\\n& = \\frac{2\\sigma^2}{\\sqrt{\\pi}}\n\\int_{-\\infty}^\\infty x^2 \\exp\\left(-x^2 \\right)\\,dx\n+ \\mu^2 - \\mu^2\n\\\\\n& = \\frac{2\\sigma^2}{\\sqrt{\\pi}} \\int_{-\\infty}^\\infty x^2 \\exp\\left(-x^2 \\right)\\,dx.\n\\end{split}\n\\end{align}\\] Mit der allgemeinen Form der partiellen Integrationsregel (Theorem 7.1) \\[\\begin{equation}\n\\int_{a}^{b} f'(x)g(x)\\,dx =\nf(x)g(x)|_{a}^{b} - \\int_{a}^{b} f(x)g'(x)\\,dx\n\\end{equation}\\] und der Definition von \\[\\begin{equation}\nf : \\mathbb{R} \\to \\mathbb{R}, x \\mapsto f(x) := \\exp\\left(-x^2\\right) \\mbox{ mit } f'(x) = -2\\exp\\left(-x^2\\right)\n\\end{equation}\\] und \\[\\begin{equation}\ng : \\mathbb{R} \\to \\mathbb{R}, x\\mapsto g(x) := -\\frac{1}{2}x \\mbox{ mit } g'(x) = -\\frac{1}{2},\n\\end{equation}\\] so dass \\[\\begin{equation}\nf'(x)g(x) = -2\\exp\\left(-x^2\\right)\\left(-\\frac{1}{2}x \\right) = x^2\\exp\\left(-x^2\\right),\n\\end{equation}\\] gilt, ergibt sich dann \\[\\begin{align}\n\\begin{split}\n\\mathbb{V}(\\xi)\n& = \\frac{2\\sigma^2}{\\sqrt{\\pi}} \\int_{-\\infty}^\\infty x^2 \\exp\\left(-x^2 \\right)\\,dx  \\\\\n& = \\frac{2\\sigma^2}{\\sqrt{\\pi}}\n\\left( -\\frac{1}{2}x\\exp\\left(-x^2\\right)|_{-\\infty}^{\\infty}\n- \\int_{-\\infty}^\\infty \\exp\\left(-x^2 \\right)\\left(-\\frac{1}{2} \\right)\\,dx \\right)  \\\\\n& = \\frac{2\\sigma^2}{\\sqrt{\\pi}}\n\\left(\n-\\frac{1}{2}x\\exp\\left(-x^2\\right)|_{-\\infty}^{\\infty}\n+ \\frac{1}{2}\\int_{-\\infty}^\\infty \\exp\\left(-x^2 \\right)\\,dx\n\\right).\n\\end{split}\n\\end{align}\\] Aus Gleichung 13.2 schließen wir dann, dass der erste Term in den Klammern auf der rechten Seite der obigen Gleichung gleich \\(0\\) ist. Schließlich ergibt sich damit \\[\\begin{align}\n\\begin{split}\n\\mathbb{V}(\\xi)\n= \\frac{2\\sigma^2}{\\sqrt{\\pi}} \\left(\\frac{1}{2}\\int_{-\\infty}^\\infty \\exp\\left(-x^2 \\right)\\,dx\\right)\n= \\frac{\\sigma^2}{\\sqrt{\\pi}} \\sqrt{\\pi}\n= \\sigma^2.\n\\end{split}\n\\end{align}\\]\n\nAllgemein ergeben sich die Erwartungswerte und Varianzen parametrischer Verteilungen als Funktionen ihrer Parameter. Wir fassen die Erwartungswerte uns bekannter Verteilungen in Theorem 13.8 zusammen.\n\nTheorem 13.8 (Erwartungswerte und Varianzen einiger Wahrscheinlichkeitsverteilungen)  \n\nWir verzichten auf einen Beweis."
  },
  {
    "objectID": "205-Erwartungswerte.html#sec-stichprobenkennzahlen",
    "href": "205-Erwartungswerte.html#sec-stichprobenkennzahlen",
    "title": "13  Erwartungswerte",
    "section": "13.3 Kennzahlen univariater Stichproben",
    "text": "13.3 Kennzahlen univariater Stichproben\nWie wir ?sec-grundbegriffe-frequentistischer-inferenz noch ausführlich diskutieren, werden ist eine Charakteristikum der probabilistischen Modellierung, beobachtete Daten als Realisierungen von Zufallsvariablen zu verstehen. Hat meine Menge \\(\\xi_1,...,\\xi_n\\) von Zufallsvariablen, so nennt man diese auch eine Stichprobe. Basierend auf einer Stichprobe kann man nun Kennzahlen berechnen, die auf den ersten Blick den Begriffen von Erwartungswert, Varianz und Standardabweichung ähneln, mit diesen aber keinesfalls zu verwechseln sind. Defacto dienen die in folgender Definition aufgeführten Stichprobenkennzahlen oft als Schätzer für die Kennzahlen von Zufallsvariablen, wie wir in ?sec-parameterschätzung ausführlich darlegen wollen. Gewissermaßen Vorgriff zur Abgrenzung der Begrifflichkeiten und auch als Grundlage für Kapitel 15 definieren wir hier einige deskriptive Stichprobenkennzahlen.\n\nDefinition 13.6 (Stichprobenmittel, Stichprobenvarianz, Stichprobenstandardabweichung) \\(\\xi_1,...,\\xi_n\\) sei eine Menge von Zufallsvariablen, genannt Stichprobe.\n\nDas Stichprobenmittel von \\(\\xi_1,...,\\xi_n\\) ist definiert als \\[\\begin{equation}\n\\bar{\\xi} := \\frac{1}{n}\\sum_{i=1}^n \\xi_i.\n\\end{equation}\\]\nDie Stichprobenvarianz von \\(\\xi_1,...,\\xi_n\\) ist definiert als \\[\\begin{equation}\nS^2 := \\frac{1}{n-1}\\sum_{i=1}^n (\\xi_i - \\bar{\\xi})^2.\n\\end{equation}\\]\nDie Stichprobenstandardabweichung ist definiert als \\[\\begin{equation}\nS := \\sqrt{S^2}.\n\\end{equation}\\]\n\n\nZur Abgrenzung erinnern wir noch einmal daran, dass Erwartungswert \\(\\mathbb{E}(\\xi)\\), Varianz \\(\\mathbb{V}(\\xi)\\) und Standardabweichung \\(\\mathbb{S}(\\xi)\\) Kennzahlen einer Zufallsvariable \\(\\xi\\) sind, wohingegen \\(\\bar{\\xi}, S^2\\), und \\(S\\) Kennzahlen einer Stichprobe \\(\\xi_1,...,\\xi_n\\) sind.\nBeispiel\nWir wollen die Bestimmung der in Definition 13.6 eingeführten Stichprobenkennzahlen an einem Beispiel erläutern. Dazu halten wir nochmals fest, dass \\(\\bar{\\xi}, S^2\\), \\(S\\) Zufallsvariablen sind und wollen ihre Realisationen im Folgenden mit \\(\\bar{x}, s^2\\) und \\(s\\) bezeichnen. Nehmen wir also an, wir haben für \\(n := 10\\) die in folgender Tabelle gezeigten Realisationen von u.i.v. nach \\(N(1,2)\\) verteilten Zufallsvariable \\(\\xi_1,...,\\xi_{10}\\), wobei für \\(i = 1,...,10\\) die Realisation von \\(\\xi_i\\) mit \\(x_i\\) bezeichnen ist:\nNach Definition 13.6 ist die Stichprobenmittelrealisation dann gegeben durch \\[\\begin{equation}\n\\bar{x}\n= \\frac{1}{10}\\sum_{i = 1}^{10}x_i\n= \\frac{6.88}{10}\n= 0.68,\n\\end{equation}\\] die Stichprobenvarianzrealisation gegeben durch \\[\\begin{equation}\ns^2\n= \\frac{1}{9}\\sum_{i=1}^{10} (x_i - \\bar{x})^2\n= \\frac{1}{9}\\sum_{i=1}^{10} (x_i - 0.68)^2\n= \\frac{25.37}{9}\n= 2.82.\n\\end{equation}\\] und die Stichprobenstandardabweichungrealisation gegeben durch \\[\\begin{equation}\ns = \\sqrt{s^2} = \\sqrt{2.82} = 1.68.\n\\end{equation}\\]"
  },
  {
    "objectID": "205-Erwartungswerte.html#sec-kovarianz-und-korrelation",
    "href": "205-Erwartungswerte.html#sec-kovarianz-und-korrelation",
    "title": "13  Erwartungswerte",
    "section": "13.4 Kovarianz und Korrelation",
    "text": "13.4 Kovarianz und Korrelation\nHäufig genutzte Maße für den Zusammenhang zweier Zufallsvariablen sind die Kovarianz und die Korrelation. Diese sind wie folgt definiert.\n\nDefinition 13.7 (Kovarianz und Korrelation) Die Kovarianz zweier Zufallsvariablen \\(\\xi\\) und \\(\\upsilon\\) ist definiert als \\[\\begin{equation}\n\\mathbb{C}(\\xi,\\upsilon) :=\n\\mathbb{E}\\left(\\left(\\xi-\\mathbb{E}(\\xi)\\right)\\left(\\upsilon-\\mathbb{E}(\\upsilon)\\right)\\right).\n\\end{equation}\\] Die Korrelation zweier Zufallsvariablen \\(\\xi\\) und \\(\\upsilon\\) ist definiert als \\[\\begin{equation}\n\\rho(\\xi,\\upsilon)\n:= \\frac{\\mathbb{C}(\\xi,\\upsilon)}{\\sqrt{\\mathbb{V}(\\xi)}\\sqrt{\\mathbb{V}(\\upsilon)}}\n= \\frac{\\mathbb{C}(\\xi,\\upsilon)}{\\mathbb{S}(\\xi){\\mathbb{S}(\\upsilon)}}.\n\\end{equation}\\]\n\nDie Kovarianz einer Zufallsvariable \\(\\xi\\) mit sich entspricht ihrer Varianz, da \\[\\begin{equation}\n\\mathbb{C}(\\xi,\\xi) =\n\\mathbb{E}\\left(\\left(\\xi - \\mathbb{E}(\\xi) \\right)^2\\right) =\n\\mathbb{V}(\\xi).\n\\end{equation}\\] Im Gegensatz zur Varianz kann die Kovarianz aber auch negative Werte annehmen.\nBeispiel\nWir wollen beispielgebend für zwei Zufallsvariablen mit gemeinsamer diskreter Verteilung ihre Kovarianz berechnen. Dazu sei \\(\\zeta := (\\xi, \\upsilon)\\) ein Zufallsvektor mit WMF \\(p_{\\xi,\\upsilon}\\) definiert durch\nund damit \\(\\xi\\), \\(\\upsilon\\) zwei Zufallsvariablen mit einer bekannten bivariaten Verteilung. Um \\(\\mathbb{C}(\\xi,\\upsilon)\\) zu berechnen, halten wir zunächst fest, dass \\[\\begin{equation}\n\\mathbb{E}(\\xi) = \\sum_{x=1}^2 x p_{\\xi}(x) = 1\\cdot 0.3 + 2\\cdot 0.7 = 1.7\n\\end{equation}\\] und \\[\\begin{equation}\n\\mathbb{E}(\\upsilon) = \\sum_{y=1}^3 y p_{\\upsilon}(y) = 1\\cdot 0.7 + 2\\cdot 0.1 + 3\\cdot 0.2 = 1.5.\n\\end{equation}\\] Mit der Definition der Kovarianz von \\(\\xi\\) und \\(\\upsilon\\) gilt dann\n\\[\\begin{align}\n\\begin{split}\n\\mathbb{C}(\\xi,\\upsilon)                                                                                     \n& = \\mathbb{E}((\\xi - \\mathbb{E}(\\xi))(\\upsilon - \\mathbb{E}(\\upsilon)))                                \\\\\n& = \\sum_{x = 1}^2 \\sum_{y = 1}^3 (x - \\mathbb{E}(\\xi))(y - \\mathbb{E}(\\upsilon))p_{\\xi,\\upsilon}(x,y)  \\\\\n& = \\sum_{x = 1}^2 \\sum_{y = 1}^3 (x - 1.7)(y - 1.5)p_{\\xi,\\upsilon}(x,y)                           \\\\\n& = \\sum_{x = 1}^2 (x - 1.7)(1 - 1.5)p_{\\xi,\\upsilon}(x,1) +\n                   (x - 1.7)(2 - 1.5)p_{\\xi,\\upsilon}(x,2) +    \n                   (x - 1.7)(3 - 1.5)p_{\\xi,\\upsilon}(x,3)                                          \\\\\n& = \\quad   \n        (1 - 1.7)(1 - 1.5)p_{\\xi,\\upsilon}(1,1)\n    +   (1 - 1.7)(2 - 1.5)p_{\\xi,\\upsilon}(1,2)\n    +   (1 - 1.7)(3 - 1.5)p_{\\xi,\\upsilon}(1,3)                                                     \\\\\n& \\quad\n    +   (2 - 1.7)(1 - 1.5)p_{\\xi,\\upsilon}(2,1)\n    +   (2 - 1.7)(2 - 1.5)p_{\\xi,\\upsilon}(2,2)\n    +   (2 - 1.7)(3 - 1.5)p_{\\xi,\\upsilon}(2,3)                                                     \\\\\n& = \\quad\n    (-0.7)\\cdot(-0.5)   \\cdot 0.10       \n    + (-0.7)\\cdot 0.5   \\cdot 0.05       \n    + (-0.7)\\cdot 1.5   \\cdot 0.15                                                              \\\\\n& \\quad                                                               \n    + 0.3   \\cdot (-0.5) \\cdot 0.60     \n    + 0.3   \\cdot   0.5  \\cdot 0.05      \n    + 0.3   \\cdot   1.5  \\cdot 0.05                                                             \\\\\n& = 0.035\n    - 0.0175\n    - 0.1575\n    - 0.09\n    + 0.0075\n    + 0.0225                                                                                    \\\\\n& = - 0.2.\n\\end{split}\n\\end{align}\\] \nDie Kovarianz der Zufallsvariablen \\(\\xi\\) und \\(\\upsilon\\) mit der in obiger Tabelle festgelegter Verteilung ist also \\(\\mathbb{C}(\\xi,\\upsilon) = -0.2\\).\nDie Korrelation \\(\\rho(\\xi,\\upsilon)\\) zweier Zufallsvariablen entspricht ihrer anhand der Standardabweichungen der jeweiligen Zufallsvariablen standardisierten Kovarianz und wird manchmal auch als Korrelationskoeffizient von \\(\\xi\\) und \\(\\upsilon\\) bezeichnet. Ist die Korrelation \\(\\rho(\\xi,\\upsilon) = 0\\), so werden \\(\\xi\\) und \\(\\upsilon\\) unkorreliert genannt. Insbesondere ist die Korrelation im Gegensatz zur Kovarianz normalisiert, d.h. es gilt, wie wir an späterer Stellte mithilfe der Cauchy-Schwarz Ungleichung (Theorem 14.3) zeigen gilt \\[\\begin{equation}\n-1 \\le \\rho(\\xi,\\upsilon) \\le 1.\n\\end{equation}\\] Man sagt in diesem Kontext auch, dass die Korrelation im Gegensatz zur Kovarianz maßstabsunabhängig sei: wendet man auf eine Zufallsvariable eine linear-affine Transformation an, so ändert sich die Kovarianz der Zufallsvariablen, nicht aber ihre Korrelation. Das ist die Kernaussage folgenden Theorems.\n\nTheorem 13.9 (Kovarianz und Korrelation bei linear affinen Transformationen von Zufallsvariablen) \\(\\xi\\) und \\(\\upsilon\\) seien Zufallsvariablen und es seien \\(a,b,c,d \\in \\mathbb{R}\\). Dann gelten \\[\\begin{equation}\n\\mathbb{C}(a\\xi + b, c\\upsilon + d) = ac\\mathbb{C}(\\xi,\\upsilon)\n\\end{equation}\\] und \\[\\begin{equation}\n\\rho(a\\xi + b, c\\upsilon + d) = \\rho(\\xi,\\upsilon).\n\\end{equation}\\]\n\n\nBeweis. Es gilt zunächst \\[\\begin{align}\n\\begin{split}\n\\mathbb{C}(a\\xi+b,c\\upsilon+d)\n& = \\mathbb{E}((a\\xi+b-\\mathbb{E}(a\\xi+b))(c\\upsilon+d-\\mathbb{E}(c\\upsilon+d)))    \\\\\n& = \\mathbb{E}((a\\xi+b-a\\mathbb{E}(\\xi)-b)(c\\upsilon+d-c\\mathbb{E}(c\\upsilon)-d))   \\\\\n& = \\mathbb{E}(a(\\xi-\\mathbb{E}(\\xi))(c(\\upsilon -c\\mathbb{E}(\\upsilon)))             \\\\\n& = \\mathbb{E}(ac((\\xi-\\mathbb{E}(\\xi))(\\upsilon -c\\mathbb{E}(\\upsilon))))            \\\\\n&  = ac\\mathbb{C}(\\xi,\\upsilon)\n\\end{split}\n\\end{align}\\] Also folgt \\[\\begin{align}\n\\begin{split}\n\\rho(a\\xi + b, c\\upsilon + d)\n& = \\frac{\\mathbb{C}(a\\xi+b,c\\upsilon+d)}{\\sqrt{\\mathbb{V}(a\\xi+b)}\\sqrt{\\mathbb{V}(c\\upsilon+d)}} \\\\\n& = \\frac{ac\\mathbb{C}(\\xi,\\upsilon)}{\\sqrt{a^2\\mathbb{V}(\\xi)}\\sqrt{c^2\\mathbb{V}(\\upsilon)}}     \\\\\n& = \\frac{ac\\mathbb{C}(\\xi,\\upsilon)}{a\\mathbb{S}(\\xi)c\\mathbb{S}(\\upsilon)}         \\\\\n& = \\frac{\\mathbb{C}(\\xi,\\upsilon)}{\\mathbb{S}(\\xi)\\mathbb{S}(\\upsilon)}             \\\\\n& = \\rho(\\xi,\\upsilon).\n\\end{split}\n\\end{align}\\]\n\nWie das Berechnen von Varianzen wird auch das Berechnen von Kovarianzen manchmal durch folgendes Theorem, den sogenannten Kovarianzverschiebungssatz erleichtert.\n\nTheorem 13.10 (Kovarianzverschiebungssatz) \\(\\xi\\) und \\(\\upsilon\\) seien Zufallsvariablen. Dann gilt \\[\\begin{equation}\n\\mathbb{C}(\\xi,\\upsilon) = \\mathbb{E}(\\xi\\upsilon) - \\mathbb{E}(\\xi)\\mathbb{E}(\\upsilon).\n\\end{equation}\\]\n\n\nBeweis. Mit der Definition der Kovarianz gilt \\[\\begin{align}\n\\begin{split}\n\\mathbb{C}(\\xi,\\upsilon)\n& = \\mathbb{E}\\left((\\xi - \\mathbb{E}(\\xi))(\\upsilon - \\mathbb{E}(\\upsilon))\\right)                                             \\\\\n& = \\mathbb{E}\\left(\\xi\\upsilon - \\xi\\mathbb{E}(\\upsilon) - \\mathbb{E}(\\xi)\\upsilon  + \\mathbb{E}(\\xi) \\mathbb{E}(\\upsilon)\\right)          \\\\\n& = \\mathbb{E}(\\xi\\upsilon) - \\mathbb{E}(\\xi)\\mathbb{E}(\\upsilon) - \\mathbb{E}(\\xi)\\mathbb{E}(\\upsilon) + \\mathbb{E}(\\xi) \\mathbb{E}(\\upsilon)  \\\\\n& = \\mathbb{E}(\\xi\\upsilon) - \\mathbb{E}(\\xi)\\mathbb{E}(\\upsilon).\n\\end{split}\n\\end{align}\\]\n\nNatürlich ist Theorem 13.10 nur dann wirklich nützlich, wenn \\(\\mathbb{E}(\\xi\\upsilon)\\) leicht zu berechnen sind. Der Kovarianzverschiebungssatz in Theorem 13.4 ergibt sich aus Theorem 13.10 im Spezialfall, dass \\(\\upsilon := \\xi\\), da dann gilt \\[\\begin{equation}\n\\mathbb{V}(\\xi)\n= \\mathbb{C}(\\xi,\\xi)\n= \\mathbb{E}(\\xi\\xi) - \\mathbb{E}(\\xi)\\mathbb{E}(\\xi)\n= \\mathbb{E}(\\xi^2) - \\mathbb{E}(\\xi)\\mathbb{E}(\\xi)\n\\end{equation}\\]\nMithilfe des Begriffes des Kovarianz ist es möglich eine stärkere Aussage über die Varianzen von Summen und Differenzen von Zufallsvariablen zu treffen als es in Theorem 13.5 der Fall war, wo lediglich unabhängige Zufallsvariablen betrachtetet wurden. Folgende Aussagen gelten generell.\n\nTheorem 13.11 (Varianzen von Summen und Differenzen von Zufallsvariablen) \\(\\xi\\) und \\(\\upsilon\\) seien zwei Zufallsvariablen und es seien \\(a,b,c \\in \\mathbb{R}\\). Dann gilt \\[\\begin{equation}\n\\mathbb{V}(a\\xi + b\\upsilon + c) = a^2\\mathbb{V}(\\xi) + b^2\\mathbb{V}(\\upsilon) + 2ab\\mathbb{C}(\\xi,\\upsilon).\n\\end{equation}\\] Speziell gelten \\[\\begin{equation}\n\\mathbb{V}(\\xi+\\upsilon) = \\mathbb{V}(\\xi) + \\mathbb{V}(\\upsilon) + 2 \\mathbb{C}(\\xi,\\upsilon)\n\\end{equation}\\] und \\[\\begin{equation}\n\\mathbb{V}(\\xi-\\upsilon) = \\mathbb{V}(\\xi) + \\mathbb{V}(\\upsilon) - 2 \\mathbb{C}(\\xi,\\upsilon)\n\\end{equation}\\]\n\n\nBeweis. Wir halten zunächst fest, dass \\[\\begin{equation}\n\\mathbb{E}(a\\xi + b\\upsilon + c) = a\\mathbb{E}(\\xi) + b\\mathbb{E}(\\upsilon) + c.\n\\end{equation}\\]\nEs ergibt sich also \\[\\begin{align}\n\\begin{split}\n& \\mathbb{V}(a\\xi + b\\upsilon + c)                                                              \\\\\n& = \\mathbb{E}\\left((a\\xi + b\\upsilon + c - a\\mathbb{E}(\\xi) - b\\mathbb{E}(\\upsilon) - c)^2\\right)  \\\\\n& = \\mathbb{E}\\left((a(\\xi  - \\mathbb{E}(\\xi)) + b(\\upsilon  - \\mathbb{E}(\\upsilon)))^2\\right)      \\\\\n& = \\mathbb{E}\\left(a^2(\\xi - \\mathbb{E}(\\xi))^2\n                  + 2ab(\\xi - \\mathbb{E}(\\xi))(\\upsilon - \\mathbb{E}(\\upsilon)))\n                  + b^2(\\upsilon - \\mathbb{E}(\\upsilon))^2\n                  \\right)               \\\\\n& = a^2\\mathbb{E}\\left((\\xi - \\mathbb{E}(\\xi))^2\\right)\n  + b^2\\mathbb{E}\\left((\\upsilon - \\mathbb{E}(\\upsilon))^2\\right)\n  + 2ab\\mathbb{E}\\left((\\xi - \\mathbb{E}(\\xi))(\\upsilon - \\mathbb{E}(\\upsilon)))\\right)                 \\\\\n& = a^2\\mathbb{V}(\\xi)+ b^2\\mathbb{V}(\\upsilon) + 2ab\\mathbb{C}(\\xi,\\upsilon)\n\\end{split}\n\\end{align}\\] Die Spezialfälle folgen dann direkt mit \\(a := b := 1\\) und \\(a := 1, b := -1\\), respektive.\n\nIm Gegensatz zu Erwartungswerten addieren sich die Varianzen von Zufallsvariablen also nicht einfach, sondern die Varianz der Summe zweier Zufallsvariablen hängt von ihrer Kovarianz ab. Ist diese zum Beispiel im Fall der Summe zweier Zufallsvariablen positiv, so verstärkt sie die Varianz der Zufallsvariable, die sich aus der Addition der Zufallsvariablen ergibt. Intuitiv führt hierbei die Realisierung eines Extremwertes einer der Zufallvariablen häufigt auch zu der Realisierung eines Extremwertes der anderen Zufallsvariablen, so dass die Variabilität der Summe der Zufallsvariablen überproportional verstärkt wird.\nSchließlich wollen wir mit Theorem 13.12 einen ersten Eindruck zum Zusammenhang von Kovarianz und Korrelation mit dem Begriff der Unabhängigkeit von Zufallsvariablen erlangen. Es zeigt sich, dass Kovarianz und Korrelation lediglich für bestimmte Formen der Abhängigkeit von Zufallsvariablen sensitiv sind und insbesondere, dass von einer Kovarianz von Null nicht auf die Unabhängigkeit der Zufallsvariablen geschlossen werden kann. Anderseits impliziert die Unabhängigkeit zweier Zufallsvariablen immer, dass ihre Kovarianz Null und sie damit unkorreliert sind. Abhängigkeit und Unabhängigkeit von Zufallsvariablen sind also sehr viel allgemeinere Begrifflichkeiten zur Beschreibung des Zusammenhangs von Zufallsvariablen als Kovarianz und Korrelation.\n\nTheorem 13.12 (Korrelation und Unabhängigkeit) \\(\\xi\\) und \\(\\upsilon\\) seien zwei Zufallsvariablen. Wenn \\(\\xi\\) und \\(\\upsilon\\) unabhängig sind, dann ist \\(\\mathbb{C}(\\xi,\\upsilon) = 0\\) und \\(\\xi\\) und \\(\\upsilon\\) sind unkorreliert. Ist dagegen \\(\\mathbb{C}(\\xi,\\upsilon) = 0\\) und sind \\(\\xi\\) und \\(\\upsilon\\) somit unkorreliert, dann sind \\(\\xi\\) und \\(\\upsilon\\) nicht notwendigerweise unabhängig.\n\n\nBeweis. Wir zeigen zunächst, dass aus der Unabhängigkeit von \\(\\xi\\) und \\(\\upsilon\\) \\(\\mathbb{C}(\\xi,\\upsilon) = 0\\) folgt. Hierzu halten wir zunächst fest, dass für unabhängige Zufallsvariablen gilt, dass \\[\\begin{equation}\n\\mathbb{E}(\\xi\\upsilon) = \\mathbb{E}(\\xi)\\mathbb{E}(\\upsilon).\n\\end{equation}\\] Mit dem Kovarianzverschiebungssatz folgt dann \\[\\begin{equation}\n\\mathbb{C}(\\xi,\\upsilon)\n= \\mathbb{E}(\\xi\\upsilon) - \\mathbb{E}(\\xi)\\mathbb{E}(\\upsilon)\n= \\mathbb{E}(\\xi)\\mathbb{E}(\\upsilon) - \\mathbb{E}(\\xi)\\mathbb{E}(\\upsilon)\n= 0.\n\\end{equation}\\] Mit der Definition des Korrelationskoeffizienten folgt dann unmittelbar, dass \\(\\rho(\\xi,\\upsilon) = 0\\) und \\(\\xi\\) und \\(\\upsilon\\) somit unkorreliert sind.\nWir zeigen nun durch Angabe eines Beispiels, dass die Kovarianz von abhängigen Zufallsvariablen \\(\\xi\\) und \\(\\upsilon\\) Null sein kann. Zu diesem Zweck betrachten wir den Fall zweier diskreter Zufallsvariablen \\(\\xi\\) und \\(\\upsilon\\) mit Ergebnisräumen \\(\\mathcal{X} = \\{-1,0,1\\}\\) und \\(\\mathcal{\\upsilon} = \\{0,1\\}\\), marginaler WMF von \\(\\xi\\) gegeben durch \\(p_\\xi(x) := 1/3\\) für \\(x \\in \\mathcal{X}\\) und der Definition \\(\\upsilon := \\xi^2\\). Wir halten dann zunächst fest, dass \\[\\begin{equation}\n\\mathbb{E}(\\xi)\n= \\sum_{x \\in \\mathcal{X}} x p_\\xi(x)\n= -1 \\cdot \\frac{1}{3} + 0\\cdot \\frac{1}{3} + 1\\cdot\\frac{1}{3}\n= 0\n\\end{equation}\\] und \\[\\begin{equation}\n\\mathbb{E}(\\xi\\upsilon)\n= \\mathbb{E}(\\xi\\xi^2)\n= \\mathbb{E}(\\xi^3)\n= \\sum_{x \\in \\mathcal{X}} x^3 p_\\xi(x)\n= -1^3 \\cdot \\frac{1}{3} + 0^3\\cdot \\frac{1}{3} + 1^3\\cdot\\frac{1}{3}\n= 0.\n\\end{equation}\\] Mit dem Kovarianzverschiebungssatz ergibt sich dann \\[\\begin{equation}\n\\mathbb{C}(\\xi,\\upsilon)\n= \\mathbb{E}(\\xi\\upsilon) - \\mathbb{E}(\\xi)\\mathbb{E}(\\upsilon)\n= \\mathbb{E}(\\xi^3) - \\mathbb{E}(\\xi)\\mathbb{E}(\\upsilon)\n= 0 - 0\\cdot \\mathbb{E}(\\upsilon)\n= 0.\n\\end{equation}\\] Die Kovarianz von \\(\\xi\\) und \\(\\upsilon\\) ist also Null. Wie unten gezeigt faktorisiert die gemeinsame WMF von \\(\\xi\\) und \\(\\upsilon\\) jedoch nicht, und somit sind \\(\\xi\\) und \\(\\upsilon\\) nicht unabhängig. Wir halten zunächst fest, dass die Definition von \\(\\upsilon := \\xi^2\\) die folgende bedingte WMF von \\(\\upsilon\\) gegeben \\(\\xi\\) impliziert:\nDie marginale WMF \\(p_\\xi\\) und die bedingte WMF \\(p_{\\upsilon|\\xi}\\) implizieren wiederum die gemeinsame WMF\nvon \\(\\xi\\) und \\(\\upsilon\\). Es gilt also zum Beispiel \\[\\begin{equation}\np_{\\xi,\\upsilon}(-1,0) = 0 \\neq \\frac{1}{9} = \\frac{1}{3} \\cdot \\frac{1}{3} = p_{\\xi}(-1)p_{\\upsilon}( 0)\n\\end{equation}\\] und damit sind \\(\\xi\\) und \\(\\upsilon\\) nicht unabhängig."
  },
  {
    "objectID": "205-Erwartungswerte.html#kovarianzmatrizen",
    "href": "205-Erwartungswerte.html#kovarianzmatrizen",
    "title": "13  Erwartungswerte",
    "section": "13.5 Kovarianzmatrizen",
    "text": "13.5 Kovarianzmatrizen\nDas multivariate Analogon der Varianz einer Zufallsvariable ist die Kovarianzmatrix eines Zufallsvektors. Diese enkodiert neben den Varianzen der Komponenten des Zufallsvektors auch ihre paarweisen Kovarianzen und ist wie folgt definiert.\n\nDefinition 13.8 (Kovarianzmatrix eines Zufallsvektors) \\(\\xi\\) sei ein \\(n\\)-dimensionaler Zufallvektor. Dann ist die Kovarianzmatrix von \\(\\xi\\) definiert als die \\(n \\times n\\) Matrix \\[\\begin{equation}\n\\mathbb{C}(\\xi) := \\mathbb{E}\\left((\\xi - \\mathbb{E}(\\xi))(\\xi - \\mathbb{E}(\\xi))^T \\right).\n\\end{equation}\\]\n\nDie Kovarianzmatrix ist in Definition 13.8 formal analog zur Kovarianz zweier Zufallsvariablen definiert. Eine direkte Rückführung des Begriffs der Kovarianzmatrix eines Zufallsvektors auf den Begriff aus dem univariaten Kontext bekannten Begriff der Kovarianz zweier Zufallsvariablen erlaubt folgendes Theorem.\n\nTheorem 13.13 (Kovarianzmatrix eines Zufallsvektors) \\(\\xi\\) sei ein \\(n\\)-dimensionaler Zufallvektor und \\(\\mathbb{C}(\\xi)\\) sei seine Kovarianzmatrix. Dann gilt \\[\\begin{equation}\n\\mathbb{C}(\\xi)\n= \\left(\\mathbb{C}(\\xi_i,\\xi_j)\\right)_{1 \\le i,j \\le n}\n=\n\\begin{pmatrix}\n\\mathbb{C}(\\xi_1,\\xi_1) & \\mathbb{C}(\\xi_1,\\xi_2) & \\cdots & \\mathbb{C}(\\xi_1,\\xi_n)    \\\\\n\\mathbb{C}(\\xi_2,\\xi_1) & \\mathbb{C}(\\xi_2,\\xi_2) & \\cdots & \\mathbb{C}(\\xi_2,\\xi_n)    \\\\\n\\vdots                  & \\vdots                  & \\ddots & \\vdots                     \\\\\n\\mathbb{C}(\\xi_n,\\xi_1) & \\mathbb{C}(\\xi_n,\\xi_2) & \\cdots & \\mathbb{C}(\\xi_n,\\xi_n)    \\\\\n\\end{pmatrix}.\n\\end{equation}\\]\n\n\nBeweis. Es gilt \\[\\begin{align}\n\\mathbb{C}(\\xi)\n& := \\mathbb{E}\\left((\\xi - \\mathbb{E}(\\xi))(\\xi - \\mathbb{E}(\\xi))^T \\right) \\\\\n& =\n\\mathbb{E}\n\\left(\n\\left(\n\\begin{pmatrix}\n\\xi_1 \\\\\n\\vdots \\\\\n\\xi_n\n\\end{pmatrix}\n-\n\\begin{pmatrix}\n\\mathbb{E}(\\xi_1) \\\\\n\\vdots \\\\\n\\mathbb{E}(\\xi_n)\n\\end{pmatrix}\n\\right)\n\\left(\n\\begin{pmatrix}\n\\xi_1 \\\\\n\\vdots \\\\\n\\xi_n\n\\end{pmatrix}\n-\n\\begin{pmatrix}\n\\mathbb{E}(\\xi_1) \\\\\n\\vdots \\\\\n\\mathbb{E}(\\xi_n)\n\\end{pmatrix}\n\\right)^T\n\\right)\n\\\\\n& =\n\\mathbb{E}\n\\left(\n\\begin{pmatrix}\n\\xi_1 - \\mathbb{E}(\\xi_1) \\\\\n\\vdots \\\\\n\\xi_n - \\mathbb{E}(\\xi_n)\n\\end{pmatrix}\n\\begin{pmatrix}\n\\xi_1 - \\mathbb{E}(\\xi_1)\\\\\n\\vdots \\\\\n\\xi_n - \\mathbb{E}(\\xi_n)\n\\end{pmatrix}^T\n\\right)\n\\\\\n& =\n\\mathbb{E}\n\\left(\n\\begin{pmatrix}\n\\xi_1 - \\mathbb{E}(\\xi_1) \\\\\n\\vdots \\\\\n\\xi_n - \\mathbb{E}(\\xi_n)\n\\end{pmatrix}\n\\begin{pmatrix}\n\\xi_1 - \\mathbb{E}(\\xi_1)\n& \\dots\n& \\xi_n - \\mathbb{E}(\\xi_n)\n\\end{pmatrix}\n\\right) \\\\\n& =\n\\mathbb{E}\n\\begin{pmatrix}\n  (\\xi_1 - \\mathbb{E}(\\xi_1))(\\xi_1 - \\mathbb{E}(\\xi_1))\n& \\dots\n& (\\xi_1 - \\mathbb{E}(\\xi_1))(\\xi_n - \\mathbb{E}(\\xi_n)\n\\\\\n\\vdots\n& \\ddots\n& \\vdots\n\\\\\n  (\\xi_n - \\mathbb{E}(\\xi_n))(\\xi_1 - \\mathbb{E}(\\xi_1))\n& \\dots\n& (\\xi_n - \\mathbb{E}(\\xi_n))(\\xi_n - \\mathbb{E}(\\xi_n))\n\\\\\n\\end{pmatrix}\n\\\\\n& =\n\\left(\\mathbb{E}\\left((\\xi_i - \\mathbb{E}(\\xi_i))(\\xi_j - \\mathbb{E}(\\xi_j)) \\right) \\right)_{1 \\le i,j \\le n} \\\\\n& =\n\\left(\\mathbb{C}(\\xi_i,\\xi_j)\\right)_{1 \\le i,j \\le n}. \\\\\n\\end{align}\\]\n\nDie Kovarianzmatrix eines Zufallsvektors \\(\\xi\\) ist also die Matrix der Kovarianzen der Komponenten von \\(\\xi\\). Damit ist auch die Kovarianzmatrix direkt im Sinne des Begriffs der Kovarianz von Zufallsvektoren gegeben. Da die Kovarianz einer Zufallsvariable mit sich selbst bekanntlich ihre Varianz ist, enthält die Kovarianzmatrix auf ihrer Diagonalen die Varianzen der Komponenten von \\(\\xi\\).\nFolgendes Theorem dokumentiert eine Schreibweise für die Kovarianzmatrix eines partitionierten Zufallsvektors im Sinne von Erwartungswerten von Zufallvektorprodukten an, die zum Beispiel im Rahmen der Kanonischen Korrelationsanalyse hilfreich ist.\n\nTheorem 13.14 (Kovarianzmatrizen von Zufallsvektoren) Es seien \\[\\begin{equation}\n\\zeta = \\begin{pmatrix} \\xi \\\\ \\upsilon \\end{pmatrix}\n\\mbox{ mit }\n\\mathbb{E}(\\zeta)  := 0_m\n\\end{equation}\\] ein \\(m_\\xi + m_\\upsilon\\)-dimensionaler Zufallsvektor und sein Erwartungswertvektor, respektive. Dann kann die \\(m \\times m\\) Kovarianzmatrix von \\(\\zeta\\) geschrieben werden als \\[\\begin{equation}\n\\mathbb{C}(\\zeta) =\n\\begin{pmatrix}\n\\Sigma_{\\xi\\xi} & \\Sigma_{\\xi\\upsilon} \\\\\n\\Sigma_{\\upsilon\\xi} & \\Sigma_{\\upsilon\\upsilon} \\\\\n\\end{pmatrix}\n\\in \\mathbb{R}^{m \\times m}\n\\end{equation}\\] wobei \\[\\begin{align}\n\\begin{split}\n\\Sigma_{\\xi\\xi}   & := \\mathbb{E}\\left(\\xi\\xi^T  \\right) \\in \\mathbb{R}^{m_\\xi  \\times m_\\xi}\\\\\n\\Sigma_{\\xi\\upsilon}  & := \\mathbb{E}\\left(\\xi\\upsilon^T \\right) \\in \\mathbb{R}^{m_\\xi  \\times m_\\upsilon}\\\\\n\\Sigma_{\\upsilon\\xi}  & := \\mathbb{E}\\left(\\upsilon\\xi^T \\right) \\in \\mathbb{R}^{m_\\upsilon \\times m_\\xi}\\\\\n\\Sigma_{\\upsilon\\upsilon} & := \\mathbb{E}\\left(\\upsilon\\upsilon^T\\right) \\in \\mathbb{R}^{m_\\xi  \\times m_\\upsilon}\n\\end{split}\n\\end{align}\\]\n\n\nBeweis. Nach Definition der Kovarianzmatrix eines Zufallsvektors gilt \\[\\begin{align}\n\\begin{split}\n\\mathbb{C}(z)\n& = \\mathbb{E}\\left((\\zeta - \\mathbb{E}(\\zeta))(\\zeta - \\mathbb{E}(\\zeta))^T \\right) \\\\\n& = \\mathbb{E}\\left((\\zeta - 0_m)(\\zeta - 0_m)^T \\right) \\\\\n& = \\mathbb{E}\\left(\\zeta\\zeta^T\\right)\\\\\n& = \\mathbb{E}\\left(\\begin{pmatrix} \\xi \\\\ \\upsilon \\end{pmatrix} \\begin{pmatrix} \\xi^T & \\upsilon^T \\end{pmatrix} \\right) \\\\\n& = \\mathbb{E}\\left(\\begin{pmatrix} \\xi\\xi^T & \\xi\\upsilon^T \\\\ \\upsilon\\xi^T & \\upsilon\\upsilon^T \\end{pmatrix}\\right)\n\\\\\n& =\n\\begin{pmatrix}\n\\mathbb{E}\\left(\\xi\\xi^T\\right)   & \\mathbb{E}\\left(\\xi\\upsilon^T\\right) \\\\\n\\mathbb{E}\\left(\\upsilon\\xi^T\\right)  & \\mathbb{E}\\left(\\upsilon\\upsilon^T\\right)\n\\end{pmatrix}\n\\\\\n& =\n\\begin{pmatrix}\n\\Sigma_{\\xi\\xi}   & \\Sigma_{\\xi\\upsilon}  \\\\\n\\Sigma_{\\upsilon\\xi}  & \\Sigma_{\\upsilon\\upsilon} \\\\\n\\end{pmatrix}\n\\end{split}\n\\end{align}\\]\n\nSchließlich ist man in manchen Anwendungen an einer normalisierten, maßstabsunabhängigen Repräsentation der Kovarianzen eines Zufallsvektors interessiert. Wie im univariaten Fall bietet sich hierfür die Normalisierung der Kovarianz zweier Zufallsvariablen mithilfe ihrer jeweiligen Varianzen im Sinne einer Korrelation an. Diese Überlegung führt auf den Begriff der Korrelationsmatrix eines Zufallsvektors.\n\nDefinition 13.9 (Korrelationsmatrix) \\(\\xi\\) sei ein \\(n\\)-dimensionaler Zufallsvektor. Dann ist die Korrelationsmatrix von \\(\\xi\\) definiert als die \\(n \\times n\\) Matrix \\[\\begin{equation}\n\\mathbb{R}(\\xi)\n:= \\left(\\rho_{ij} \\right)_{1 \\le i,j\\le n}\n= \\left(\\frac{\\mathbb{C}(\\xi_i,\\xi_j)}{\\sqrt{\\mathbb{V}(\\xi_i)}\\sqrt{\\mathbb{V}(\\xi_j)}}\\right)_{1 \\le i,j\\le n}.\n\\end{equation}\\]\n\nDa es sich bei den Varianzen der Komponenten von \\(\\xi\\) um die Diagonalelement der Kovarianzmatrix von \\(\\xi\\) handelt, ist die Korrelationsmatrix natürlich in der Kovarianzmatrix imoplizit. Weiterhin gelten, wie immer für Korrelationen, für die Einträge \\(\\rho_{ij}, 1 \\le i,j \\le n\\) der Korrelationsmatrix, dass \\[\\begin{equation}\n\\rho_{ij} \\in [-1,1] \\mbox{ für } 1 \\le i,j \\in n \\mbox{ und } \\rho_{ii} = 1 \\mbox{ für } 1 \\le i \\le n.\n\\end{equation}\\]"
  },
  {
    "objectID": "205-Erwartungswerte.html#stichprobenkennzahlen-von-zufallsvektoren",
    "href": "205-Erwartungswerte.html#stichprobenkennzahlen-von-zufallsvektoren",
    "title": "13  Erwartungswerte",
    "section": "13.6 Stichprobenkennzahlen von Zufallsvektoren",
    "text": "13.6 Stichprobenkennzahlen von Zufallsvektoren\nDie Begriffe des Stichprobenmittels, der Stichprobenvarianz und der Stichprobenkovarianz lassen sich auch auf den Fall multivariater Stichproben übertragen. Wir nutzen folgende Definition.\n\nDefinition 13.10 (Stichprobenmittel, -kovarianmatrix und -korrelationsmatrix) \\(\\upsilon_1,...,\\upsilon_n\\) sei eine Menge von \\(m\\)-dimensionalen Zufallsvektoren, genannt Stichprobe.\n\nDas *Stichprobenmittel+ der \\(\\upsilon_1,...,\\upsilon_n\\) ist definiert als der \\(m\\)-dimensionale Vektor \\[\\begin{equation}\n\\bar{\\upsilon} := \\frac{1}{n} \\sum_{i=1}^n \\upsilon_i.\n\\end{equation}\\]\nDie Stichprobenkovarianzmatrix der \\(\\upsilon_1,...,\\upsilon_n\\) ist definiert als die \\(m \\times m\\) Matrix \\[\\begin{equation}\nC := \\frac{1}{n-1}\\sum_{i=1}^n (\\upsilon_i - \\bar{\\upsilon})(\\upsilon_i - \\bar{\\upsilon})^T .\n\\end{equation}\\]\nDie Stichprobenkorrelationsmatrix der \\(\\upsilon_1,...,\\upsilon_n\\) ist definiert als die \\(m \\times m\\) Matrix \\[\\begin{equation}\nD := \\left(\\frac{(C )_{ij}}{\\sqrt{ (C )_{ii}}\\sqrt{ (C )_{jj}}}\\right)_{1 \\le i,j \\le m}.\n\\end{equation}\\]\n\n\nZur konkreten Berechnung von Stichprobenmittel, Stichprobenkovarianzmatrix und Stichprobenkorrrelationsmatrix basierend auf einem multivariaten Datensatz bieten sich die Aussagen des folgenden Theorems an.\n\nTheorem 13.15 (Datenmatrix und Stichprobenstatistiken)  \nEs sei \\[\\begin{equation}\n\\upsilon :=\n\\begin{pmatrix}\n\\upsilon_1 & \\cdots & \\upsilon_n\n\\end{pmatrix}\n\\end{equation}\\] eine \\(m \\times n\\) , die durch die spaltenweise Konkatenation von \\(n\\) \\(m\\)-dimensionalen Zufallvektoren \\(\\upsilon_1, ...,\\upsilon_n\\) gegeben sei. Dann ergeben sich\n\n\nBeweis. Die Darstellung des Stichprobenmittels ergibt sich aus \\[\\begin{align}\n\\begin{split}\n\\bar{\\upsilon}\n& := \\frac{1}{n} \\sum_{i=1}^n\\upsilon_i \\\\\n&  = \\frac{1}{n}\\begin{pmatrix} \\sum_{i=1}^n\\upsilon_{i1} \\\\ \\vdots \\\\ \\sum_{i=1}^n\\upsilon_{im} \\end{pmatrix} \\\\\n&  = \\frac{1}{n}\\left(\\begin{pmatrix}\\upsilon_{11}    & \\cdots  &\\upsilon_{n1} \\\\\n                                      \\vdots    & \\ddots  & \\vdots     \\\\\n                                     \\upsilon_{1m}    & \\cdots  &\\upsilon_{nm} \\\\\n                   \\end{pmatrix}\n                   \\begin{pmatrix} 1 \\\\ \\vdots \\\\ 1 \\end{pmatrix}\n              \\right) \\\\\n& = \\frac{1}{n}\\upsilon 1_{n}.\n\\end{split}\n\\end{align}\\] Hinsichtlich der Darstellung der Stichprobenkovarianzmatrix halten wir zunächst fest, dass nach Definition gilt, dass \\[\\begin{align}\n\\begin{split}\nC  \n& := \\frac{1}{n-1}\\sum_{i=1}^n (\\upsilon_i - \\bar{\\upsilon})(\\upsilon_i - \\bar{\\upsilon})^T \\\\\n&  = \\frac{1}{n-1}\\sum_{i=1}^n \\left(\\upsilon_i\\upsilon_i^T-\\upsilon_i\\bar{\\upsilon}^T - \\bar{\\upsilon}\\upsilon_i^T+ \\bar{\\upsilon}\\bar{\\upsilon}^T\\right) \\\\\n&  = \\frac{1}{n-1}\\left(\\sum_{i=1}^n\\upsilon_i\\upsilon_i^T- \\sum_{i=1}^n\\upsilon_i\\bar{\\upsilon}^T - \\sum_{i=1}^n \\bar{\\upsilon}\\upsilon_i^T+ \\sum_{i=1}^n \\bar{\\upsilon}\\bar{\\upsilon}^T\\right) \\\\\n&  = \\frac{1}{n-1}\\left(\\sum_{i=1}^n\\upsilon_i\\upsilon_i^T- n\\bar{\\upsilon}\\bar{\\upsilon}^T - n\\bar{\\upsilon}\\bar{\\upsilon}^T + n\\bar{\\upsilon}\\bar{\\upsilon}^T\\right) \\\\\n&  = \\frac{1}{n-1}\\left(\\sum_{i=1}^n\\upsilon_i\\upsilon_i^T- n\\bar{\\upsilon}\\bar{\\upsilon}^T\\right).\n\\end{split}\n\\end{align}\\] Mit \\(1_{n}1_{n}^T = 1_{nn}\\) ergibt sich dann weiterhin \\[\\begin{align}\n\\begin{split}\n\\upsilon\\left(I_n - \\frac{1}{n}1_{nn}\\right)\\upsilon^T\n& = \\left(\\upsilon I_n - \\frac{1}{n}\\upsilon 1_{nn}\\right)\\upsilon^T                                         \\\\\n& = \\upsilon\\upsilon^T - \\frac{1}{n}\\upsilon 1_{nn}\\upsilon^T                                                      \\\\\n& = \\begin{pmatrix} \\upsilon_1 & \\cdots & \\upsilon_n\\end{pmatrix} \\begin{pmatrix} \\upsilon_1^T \\\\ \\vdots \\\\ \\upsilon_n^T\\end{pmatrix} - \\frac{1}{n}\\upsilon 1_n 1_n^T\\upsilon^T    \\\\\n& = \\sum_{i=1}^n\\upsilon_i\\upsilon_i^T- n\\left(\\frac{1}{n}\\upsilon 1_n\\right)\\left(\\frac{1}{n}1_n^T\\upsilon^T\\right)              \\\\\n& = \\sum_{i=1}^n\\upsilon_i\\upsilon_i^T- n\\bar{\\upsilon}\\bar{\\upsilon}^T                                                          \\\\\n& = \\frac{1}{n-1}\\sum_{i=1}^n (\\upsilon_i - \\bar{\\upsilon})(\\upsilon_i - \\bar{\\upsilon})^T \\\\\n& = C.\n\\end{split}\n\\end{align}\\] Hinsichtlich der Korrelationsmatrix ergibt sich nach Definition und für ein beliebiges Indexpaar \\(i,j\\) mit \\(1 \\le i,j \\le m\\) schließlich, dass \\[\\begin{align}\n\\begin{split}\nR_{{y}_{ij}}\n& = \\frac{(C)_{ij}}{\\sqrt{ (C)_{ii}}\\sqrt{ (C)_{jj}}}             \\\\\n& = \\frac{1}{\\sqrt{(C)_{ii}}}(C)_{ij}\\frac{1}{\\sqrt{(C)_{jj}}}    \\\\\n& = (DCD)_{ij}.\n\\end{split}\n\\end{align}\\]"
  },
  {
    "objectID": "205-Erwartungswerte.html#selbstkontrollfragen",
    "href": "205-Erwartungswerte.html#selbstkontrollfragen",
    "title": "13  Erwartungswerte",
    "section": "13.7 Selbstkontrollfragen",
    "text": "13.7 Selbstkontrollfragen\n\nGeben Sie die Definition des Erwartungswerts einer Zufallsvariable wieder.\nGeben Sie die Interpretation der Erwartungswerts einer Zufallsvariable wieder\nBerechnen Sie den Erwartungswert einer Bernoulli Zufallsvariable.\nGeben Sie das Theorem zu den Eigenschaften des Erwartungswerts wieder.\nGeben Sie die Definition der Varianz und der Standardabweichung einer Zufallsvariable wieder.\nGeben Sie die Interpretation der Varianz einer Zufallsvariable wieder.\nBerechnen Sie die Varianz einer Bernoulli Zufallsvariable.\nGeben Sie das Theorem zum Varianzverschiebungssatz wieder.\nGeben Sie das Theorem zu den Eigenschaften der Varianz wieder.\nGeben Sie die Definition des Begriffs einer Stichprobe wieder.\nGeben Sie die Definitionen von Stichprobenmittel, -varianz und -standardabweichung wieder.\nGeben Sie die Definition von Kovarianz und Korrelation zweier Zufallsvariablen wieder.\nGeben Sie das Theorem zum Kovarianzverschiebungssatz wieder.\nGeben Sie das Theorem zu Varianzen von Summen und Differenzen von Zufallsvariablen wieder.\nGeben Sie das Theorem zur Korrelation und Unabhängigkeit zweier Zufallsvariablen wieder. \n\n\n\n\n\nMeintrup, D., & Schäffler, S. (2005). Stochastik: Theorie und Anwendungen. Springer.\n\n\nSchmidt, K. D. (2009). Maß und Wahrscheinlichkeit. Springer."
  },
  {
    "objectID": "206-Ungleichungen.html#sec-wahrscheinlichkeitsungleichungen",
    "href": "206-Ungleichungen.html#sec-wahrscheinlichkeitsungleichungen",
    "title": "14  Ungleichungen",
    "section": "14.1 Wahrscheinlichkeitsungleichungen",
    "text": "14.1 Wahrscheinlichkeitsungleichungen\nDie Markov Ungleichung stellt einen Bezug zwischen den Überschreitungswahrscheinlichkeiten (vgl. Theorem 11.2) und dem Erwartungswert einer nicht-negativen Zufallsvariablen, also einer Zufallsvariable, für die \\(\\mathbb{P}(\\xi \\ge 0 ) = 1\\) ist, her. Im Beweis dieser Ungleichung wollen wir nur den Fall einer kontinuierlichen Zufallsvariable betrachten.\n\nTheorem 14.1 (Markov Ungleichung) \\(\\xi\\) sei eine Zufallsvariable mit \\(\\mathbb{P}(\\xi \\ge 0) = 1\\). Dann gilt für alle \\(x \\in \\mathbb{R}\\), dass \\[\\begin{equation}\n\\mathbb{P}(\\xi \\ge x) \\le \\frac{\\mathbb{E}(\\xi)}{x}.\n\\end{equation}\\]\n\n\nBeweis. Wir betrachten den Fall einer kontinuierlichen Zufallsvariable \\(\\xi\\) mit WDF \\(p\\). Wir halten zunächst fest, dass \\[\\begin{equation}\n\\mathbb{E}(\\xi)\n= \\int_{-\\infty}^\\infty s \\, p(s)\\,ds\n= \\int_0^\\infty s \\, p(s)\\,ds\n= \\int_0^x s \\, p(s)\\,ds + \\int_x^\\infty s \\, p(s)\\,ds,\n\\end{equation}\\] weil \\(\\xi\\) nicht-negativ ist. Es folgt dann \\[\\begin{equation}\n\\mathbb{E}(\\xi)\n\\ge  \\int_x^\\infty s \\, p(s)\\,ds\n\\ge  \\int_x^\\infty x \\, p(s)\\,ds\n=  x\\int_x^\\infty  p(s)\\,ds\n=  x\\, \\mathbb{P}(\\xi \\ge x).\n\\end{equation}\\] Dabei gilt die erste Ungleichung, weil \\[\\begin{equation}\n\\int_{0}^x s \\, p(s)\\,ds \\ge 0,\n\\end{equation}\\] und die zweite Ungleichung gilt, weil \\(x \\le \\xi\\) für \\(\\xi \\in [x,\\infty[\\). Es folgt also, dass \\[\\begin{equation}\n\\mathbb{E}(\\xi) \\ge x\\, \\mathbb{P}(\\xi \\ge x)\n\\Leftrightarrow\n\\mathbb{P}(\\xi \\ge x) \\le \\frac{\\mathbb{E}(\\xi)}{x}.\n\\end{equation}\\]\n\nGilt beispielweise für eine nichtnegative Zufallsvariable \\(\\xi\\), dass \\(\\mathbb{E}(\\xi) = 1\\) ist, dann folgt aus der Markov Ungleichung, dass \\[\\begin{equation}\n\\mathbb{P}(\\xi \\ge 100) \\le 0.01.\n\\end{equation}\\]\nBeispiel\nAls Beispiel für die Markov Ungleichung betrachten wir den Fall einer Gamma-Zufallsvariable \\(\\xi \\sim G(\\alpha,\\beta)\\). Gamma-Zufallsvariablen sind bekanntlich per Definition nicht-negativ (vgl. Definition 11.10) und wir haben gesehen, dass für den Erwartungswert einer Gamma-Zufallsvariable \\(\\mathbb{E}(\\xi) = \\alpha\\beta\\) gilt (vgl. Theorem 13.8). Wir betrachten konkret den Fall \\(\\alpha := 5\\) und \\(\\beta := 2\\), so dass \\(\\xi\\) auch einer \\(\\chi^2\\)-Zufallsvariable mit Freiheitsgradparameter \\(n = 10\\) entspricht. In Abbildung 14.1 A stellen wir die KVF \\(P\\) dieser Zufallsvariable dar, in Abbildung 14.1 B visualisieren wir die in der Markov Ungleichung betrachteten Größen \\(\\mathbb{E}(\\xi)/x\\) und die Überschreitungswahrscheinlichkeit \\(\\mathbb{P}(\\xi \\ge x) = 1 - P(x)\\). Offensichtlich trifft die Markov Ungleichung zu.\n\n\n\nAbbildung 14.1: Markov Ungleichung am Beispiel einer Gamma-Zufallsvariable.\n\n\nDie Chebychev Ungleichung setzt die Wahrscheinlichkeit dafür, dass eine Zufallsvariable Werte weit von ihrem Erwartungswert entfernt annimmt, in Bezug zur ihrer Varianz. Die Chebychev Ungleichung liefert damit eine Begründung dafür, warum die in Definition 13.5 formulierte Größe als ein Maß für die Streuung einer Zufallsvariable verstanden werden kann. Im Beweis der Chebyshev Ungleichung wird an entscheidender Stelle auf die Markov Ungleichung zurück gegriffen.\n\nTheorem 14.2 (Chebyshev Ungleichung) Es sei \\(\\xi\\) eine Zufallsvariable mit Varianz \\(\\mathbb{V}(\\xi)\\). Dann gilt für alle \\(x \\in \\mathbb{R}\\) \\[\\begin{equation}\n\\mathbb{P}(|\\xi - \\mathbb{E}(\\xi)| \\ge x) \\le \\frac{\\mathbb{V}(\\xi)}{x^2}.\n\\end{equation}\\]\n\n\nBeweis. Wir halten zunächst fest, dass für \\(a,b \\in \\mathbb{R}\\) gilt, dass aus \\(a^2 \\ge b^2\\) folgt, dass \\(|a| \\ge b\\). Dazu betrachten wir die folgenden vier möglichen Fälle.\n\n\\(a^2 \\ge b^2\\) für \\(a \\ge 0\\) und \\(b \\ge 0\\). Dann gilt \\[\\begin{equation}\na^2 \\ge b^2 \\Rightarrow \\sqrt{a^2} \\ge \\sqrt{b^2} \\Rightarrow a \\ge b \\Rightarrow |a| \\ge b.\n\\end{equation}\\]\n\\(a^2 \\ge b^2\\) für \\(a \\le 0\\) und \\(b \\ge 0\\). Dann gilt \\[\\begin{equation}\na^2 \\ge b^2 \\Rightarrow \\sqrt{a^2} \\ge \\sqrt{b^2} \\Rightarrow -a \\ge b \\Rightarrow |a| \\ge b.\n\\end{equation}\\]\n\\(a^2 \\ge b^2\\) für \\(a \\ge 0\\) und \\(b \\le 0\\). Dann gilt \\[\\begin{equation}\na^2 \\ge b^2 \\Rightarrow \\sqrt{a^2} \\ge \\sqrt{b^2} \\Rightarrow a \\ge -b \\ge b \\Rightarrow |a| \\ge b.\n\\end{equation}\\]\n\\(a^2 \\ge b^2\\) für \\(a \\le 0\\) und \\(b \\le 0\\). Dann gilt \\[\\begin{equation}\na^2 \\ge b^2 \\Rightarrow \\sqrt{a^2} \\ge \\sqrt{b^2} \\Rightarrow -a \\ge -b \\ge b \\Rightarrow |a| \\ge b.\n\\end{equation}\\] Als nächstes definieren wir \\(\\upsilon := (\\xi - \\mathbb{E}(\\xi))^2\\). Dann gilt offenbar \\(\\upsilon \\ge 0\\) und es folgt aus der Markov Ungleichung \\[\\begin{align}\n\\begin{split}\n\\mathbb{P}\\left(\\upsilon \\ge x^2\\right)\n& \\le \\frac{\\mathbb{E}(\\upsilon)}{x^2} \\\\\n\\Leftrightarrow\n\\mathbb{P}\\left((\\xi - \\mathbb{E}(\\xi))^2 \\ge x^2 \\right)\n& \\le \\frac{\\mathbb{E}\\left((\\xi - \\mathbb{E}(\\xi))^2 \\right)}{x^2} \\\\\n\\Leftrightarrow\n\\mathbb{P}(|\\xi - \\mathbb{E}(\\xi)| \\ge x)\n& \\le \\frac{\\mathbb{V}(\\xi)}{x^2}.\n\\end{split}\n\\end{align}\\]\n\n\nBeispielweise gilt für eine Zufallsvariable immer, dass die Wahrscheinlichkeit für eine absolute Abweichung vom doppelten ihrer Standardabweichung höchstens \\(1/4\\) ist, also Frequentistisch betrachtet nur für etwa ein Viertel ihrer Realisierungen zutrifft, und die Wahrscheinlichkeit für eine absolute Abweichung vom dreifachen ihrer Standardabweichung höchstens \\(1/9\\) ist, also Frequentistisch betrachtet nur für etwa ein Zehntel ihrer Realisierungen zutrifft, jeweils unabhängig davon, von welcher genauen Form die Verteilung der Zufallsvariable ist. Dies folgt mit der Chebyshev Ungleichung aus\n\\[\\begin{equation}\n\\mathbb{P}\\left(|\\xi - \\mathbb{E}(\\xi)| \\ge 2 \\sqrt{\\mathbb{V}(\\xi)}\\right)\n\\le  \\frac{\\mathbb{V}(\\xi)}{\\left(2 \\sqrt{\\mathbb{V}(\\xi)}\\right)^2} =\n\\frac{1}{4}\n\\end{equation}\\] und \\[\\begin{equation}\n\\mathbb{P}\\left(|\\xi - \\mathbb{E}(\\xi)| \\ge 3 \\sqrt{\\mathbb{V}(\\xi)}\\right)\n\\le  \\frac{\\mathbb{V}(\\xi)}{\\left(3 \\sqrt{\\mathbb{V}(\\xi)}\\right)^2} =\n\\frac{1}{9}.\n\\end{equation}\\]"
  },
  {
    "objectID": "206-Ungleichungen.html#sec-erwartungswertungleichungen",
    "href": "206-Ungleichungen.html#sec-erwartungswertungleichungen",
    "title": "14  Ungleichungen",
    "section": "14.2 Erwartungswertungleichungen",
    "text": "14.2 Erwartungswertungleichungen\nDie Cauchy-Schwarz Ungleichung ist eine zentrale Ungleichung der modernen Mathematik, die in verschiedenen mathematischen Bereichen wie der Analysis, der Vektorraumtheorie und eben auch der Wahrscheinlichkeitstheorie zur Anwendung kommt (vgl. Steele (2006)). In Bezug auf Erwartungswerte von Zufallsvariablen hat sie die folgende Form.\n\nTheorem 14.3 (Cauchy-Schwarz Ungleichung) \\(\\xi\\) und \\(\\upsilon\\) seien zwei Zufallsvariablen und \\(\\mathbb{E}(\\xi\\upsilon)\\) sei endlich. Dann gilt \\[\\begin{equation}\n\\mathbb{E}(\\xi\\upsilon)^2 \\le \\mathbb{E}\\left(\\xi^2\\right)\\mathbb{E}\\left(\\upsilon^2 \\right).\n\\end{equation}\\]\n\nFür einen Beweis verweisen wir auf den Beweis von Theorem 4.6.2 in DeGroot & Schervish (2012). Analog zu Theorem 14.3 gilt zum Beispiel für Vektoren \\(x,y \\in \\mathbb{R}^n\\), dass \\[\\begin{equation}\n\\langle x,y \\rangle^2 \\le \\langle x,x \\rangle \\langle x,y \\rangle.\n\\end{equation}\\]\nIm Kontext der probabilistischen Datenanalyse ist die Anwendung der Cauchy-Schwarz Ungleichung vor allem im Beweis der sogenannten Korrelationsungleichung von Relevanz.\n\nTheorem 14.4 (Korrelationsungleichung) \\(\\xi\\) und \\(\\upsilon\\) seien Zufallsvariablen mit \\(\\mathbb{V}(\\xi), \\mathbb{V}(\\upsilon) &gt; 0\\). Dann gelten \\[\\begin{equation}\n\\frac{\\mathbb{C}(\\xi,\\upsilon)^2}{\\mathbb{V}(\\xi)\\mathbb{V}(\\upsilon)} \\le 1\n\\mbox{ und }\n-1 \\le \\rho(\\xi,\\upsilon) \\le 1.\n\\end{equation}\\]\n\n\nBeweis. Mit der Cauchy-Schwarz-Ungleichung für zwei Zufallsvariablen \\(\\alpha\\) und \\(\\beta\\) gilt, dass \\[\\begin{equation}\n\\mathbb{E}(\\alpha\\beta)^2 \\le \\mathbb{E}\\left(\\alpha^2\\right)\\mathbb{E}\\left(\\beta^2\\right).\n\\end{equation}\\] Wir definieren nun \\(\\alpha := \\xi -\\mathbb{E}(\\xi)\\) und \\(\\beta := \\upsilon - \\mathbb{E}(\\upsilon)\\). Dann besagt die Cauchy-Schwarz Ungleichung gerade, dass \\[\\begin{equation}\n\\mathbb{E}\\left((\\xi -\\mathbb{E}(\\xi))(\\upsilon-\\mathbb{E}(\\upsilon))\\right)^2\n\\le  \\mathbb{E}\\left((\\xi -\\mathbb{E}(\\xi))^2 \\right) \\mathbb{E}\\left((\\upsilon-\\mathbb{E}(\\upsilon))^2 \\right).\n\\end{equation}\\] Also gilt \\[\\begin{align}\n\\begin{split}\n\\mathbb{C}(\\xi,\\upsilon)^2\n\\le  \\mathbb{V}(\\xi)\\mathbb{V}(\\upsilon)\n\\Leftrightarrow \\frac{\\mathbb{C}(\\xi,\\upsilon)^2}{\\mathbb{V}(\\xi)\\mathbb{V}(\\upsilon)}\n\\le 1.\n\\end{split}\n\\end{align}\\] Weiterhin folgt aus der Definition der Korrelation dann sofort, dass auch \\[\\begin{equation}\n\\rho(\\xi,\\upsilon)^2 \\le 1.\n\\end{equation}\\] Dann gilt aber auch \\[\\begin{equation}\n|\\rho(\\xi,\\upsilon)^2| \\le 1 \\Leftrightarrow -1 \\le \\rho(\\xi,\\upsilon) \\le 1,\n\\end{equation}\\] denn \\[\\begin{equation}\n\\rho(\\xi,\\upsilon)^2 \\le 1 \\Rightarrow \\sqrt{\\rho(\\xi,\\upsilon)^2} \\le \\sqrt{1} \\Rightarrow \\quad\\rho(\\xi,\\upsilon)  \\le 1 \\Rightarrow |\\rho(\\xi,\\upsilon)| \\le 1 \\mbox{ für } \\rho(\\xi,\\upsilon) \\ge 0\n\\end{equation}\\] und \\[\\begin{equation}\n\\rho(\\xi,\\upsilon)^2 \\le 1 \\Rightarrow \\sqrt{\\rho(\\xi,\\upsilon)^2} \\le \\sqrt{1} \\Rightarrow     -\\rho(\\xi,\\upsilon) \\le 1 \\Rightarrow |\\rho(\\xi,\\upsilon)| \\le 1 \\mbox{ für } \\rho(\\xi,\\upsilon) \\le 0\n\\end{equation}\\]\n\nDie Korrelationsungleichung wird manchmal auch als Kovarianzungleichung bezeichnet. Insbesondere besagt sie, dass die Korrelation von Zufallsvariablen normalisiert ist, also immer Werte zwischen -1 und 1 inklusive annimmt (vgl. Kapitel 13.4).\nDie Jensensche Ungleichung schließlich liefert Abschätzungen für den Erwartungswert einer durch eine konvexe oder konkave Funktion transformierte Zufallsvariable. Sie kommt in der Betrachtung von Parameterschätzereigenschaften (vgl. ?sec-parameterschätzung) und insbesondere als Grundlage der Variationalen Bayesianischen Inferenz zum Einsatz. Wir erinnern daran, dass sich eine konvexe Funktion \\(g\\) dadurch auszeichnet, dass der Funktionsgraph von \\(g\\) über einem Intervall \\([x_1,x_2]\\) immer unter der verbindenden Geraden zwischen den Funktionswerten \\(g(x_1)\\) und \\(g(x_2)\\) liegt, wohingegehn bei einer konkaven Funktion \\(g\\) dieser immer über der verbindenden Geraden zwischen den Funktionswerten \\(g(x_1)\\) zu \\(g(x_2)\\) liegt. Wir visualisieren dies für eine konvexe Funktion in Abbildung 14.2.\n\nTheorem 14.5 (Jensensche Ungleichung) \\(\\xi\\) sei eine Zufallsvariable und \\(g : \\mathbb{R} \\to \\mathbb{R}\\) eine konvexe Funktion, d.h. \\[\\begin{equation}\ng(\\lambda x_1 + (1-\\lambda)x_2) \\le \\lambda g(x_1) + (1-\\lambda)g(x_2)\n\\end{equation}\\] für alle \\(x_1,x_2 \\in \\mathbb{R}, \\lambda \\in [0,1]\\). Dann gilt \\[\\begin{equation}\n\\mathbb{E}(g(\\xi)) \\ge g(\\mathbb{E}(\\xi)).\n\\end{equation}\\] Analog sei \\(g : \\mathbb{R} \\to \\mathbb{R}\\) eine konkave Funktion, d.h. \\[\\begin{equation}\ng(\\lambda x_1 + (1-\\lambda)x_2) \\ge \\lambda g(x_1) + (1-\\lambda)g(x_2)\n\\end{equation}\\] für alle \\(x_1,x_2 \\in \\mathbb{R}, \\lambda \\in [0,1]\\). Dann gilt \\[\\begin{equation}\n\\mathbb{E}(g(\\xi)) \\le g(\\mathbb{E}(\\xi)).\n\\end{equation}\\]\n\n\nBeweis. Es sei \\(g\\) eine konvexe Funktion. Dann gilt für die Tangente \\(t\\) von \\(g\\) in \\(x_0 \\in \\mathbb{R}\\) für alle \\(x \\in \\mathbb{R}\\), dass \\[\\begin{equation}\ng(x) \\ge t(x) := g(x_0) + g'(x_0)(x - x_0)\n\\end{equation}\\] Wir setzen nun \\(x := \\xi\\) und \\(x_0 := \\mathbb{E}(\\xi)\\). Dann gilt mit obiger Ungleichung, dass \\[\\begin{equation}\ng(\\xi) \\ge g(\\mathbb{E}(\\xi)) + g'(\\mathbb{E}(\\xi))(\\xi - \\mathbb{E}(\\xi))\n\\end{equation}\\] Erwartungswertbildung ergibt dann \\[\\begin{align}\n\\begin{split}\n\\mathbb{E}(g(\\xi)) & \\ge \\mathbb{E}(g(\\mathbb{E}(\\xi))) + \\mathbb{E}(g'(\\mathbb{E}(\\xi))(\\xi - \\mathbb{E}(\\xi))) \\\\\n\\Leftrightarrow\n\\mathbb{E}(g(\\xi)) & \\ge g(\\mathbb{E}(\\xi)) + g'(\\mathbb{E}(\\xi))\\mathbb{E}((\\xi - \\mathbb{E}(\\xi))) \\\\\n\\Leftrightarrow\n\\mathbb{E}(g(\\xi)) & \\ge g(\\mathbb{E}(\\xi)) + g'(\\mathbb{E}(\\xi))(\\mathbb{E}(\\xi) - \\mathbb{E}(\\xi)) \\\\\n\\Leftrightarrow\n\\mathbb{E}(g(\\xi)) & \\ge g(\\mathbb{E}(\\xi)).\n\\end{split}\n\\end{align}\\] Sei nun \\(g\\) eine konkave Funktion. Dann ist \\(-g\\) eine konvexe Funktion. Mit der Jensenschen Ungleichung für konvexe Funktionen folgt dann die Jensensche Ungleichung für konkave Funktionen aus \\[\\begin{align}\n\\begin{split}\n\\mathbb{E}(-g(\\xi)) & \\ge -g(\\mathbb{E}(\\xi)) \\\\\n\\Leftrightarrow\n-\\mathbb{E}(g(\\xi)) & \\ge -g(\\mathbb{E}(\\xi)) \\\\\n\\Leftrightarrow\n\\mathbb{E}(g(\\xi)) & \\le g(\\mathbb{E}(\\xi)).\n\\end{split}\n\\end{align}\\]\n\nIm Kontext der Variationalen Bayesianischen Inferenz ist grundlegend, dass der Logarithmus ist eine konkave Funktion ist und damit für eine beliebige Zufallsvariable \\(\\xi\\) gilt, dass \\[\\begin{equation}\n\\mathbb{E}(\\ln \\xi) \\le \\ln \\mathbb{E}(\\xi).\n\\end{equation}\\]\n\n\n\nAbbildung 14.2: Darstellung der konvexen Funktion \\(g(x) := x^2\\) mit \\(x_1 := -\\sqrt{1.5}, x_2 := \\sqrt{3.5}, \\lambda \\in [0,1]\\) und \\(x_0 := 1\\)."
  },
  {
    "objectID": "206-Ungleichungen.html#selbstkontrollfragen",
    "href": "206-Ungleichungen.html#selbstkontrollfragen",
    "title": "14  Ungleichungen",
    "section": "14.3 Selbstkontrollfragen",
    "text": "14.3 Selbstkontrollfragen\n\nGeben Sie die Markov Ungleichung wieder.\nGeben Sie die Chebyshev Ungleichung wieder.\nGeben Sie die Cauchy-Schwarz Ungleichung wieder.\nGeben Sie die Korrelationsungleichung wieder.\nGeben Sie die Jensensche Ungleichung wider. \n\n\n\n\n\nDeGroot, M. H., & Schervish, M. J. (2012). Probability and Statistics (4th ed). Addison-Wesley.\n\n\nSteele, J. M. (2006). The Cauchy-Schwarz Master Class: An Introduction to the Art of Mathematical Inequalities (repr). Cambridge University Press [u.a.]."
  },
  {
    "objectID": "207-Grenzwerte.html#sec-gesetze-der-grossen-zahlen",
    "href": "207-Grenzwerte.html#sec-gesetze-der-grossen-zahlen",
    "title": "15  Grenzwerte",
    "section": "15.1 Gesetze der Großen Zahlen",
    "text": "15.1 Gesetze der Großen Zahlen\nEs gibt ein Schwaches Gesetz der Großen Zahlen und ein Starkes Gesetz der Großen Zahlen. Intuitiv besagen beide Gesetze, dass sich das Stichprobenmittel von unabhängigen und identisch verteilten Zufallsvariablen für eine große Anzahl an Zufallsvariablen dem Erwartungswert der zugrundeliegenden Verteilung nähert. Das Schwache und das Starke Gesetz der Großen Zahlen unterscheiden sich in Hinblick auf die zu ihrer Formulierung benutzen Formen der Konvergenz von Zufallsvariablen. Das Schwache Gesetz basiert auf der Konvergenz in Wahrscheinlichkeit. Das Starke Gesetz basiert auf der fast sicheren Konvergenz. Wir begnügen uns hier mit dem Begriff der Konvergenz in Wahrscheinlichkeit und damit dem Schwachen Gesetz der Großen Zahlen.\n\nDefinition 15.1 (Konvergenz in Wahrscheinlichkeit) Eine Folge von Zufallsvariablen \\(\\xi_1,\\xi_2,...\\) konvergiert gegen eine Zufallsvariable \\(\\xi\\) in Wahrscheinlichkeit, wenn für jedes noch so kleine \\(\\epsilon &gt; 0\\) gilt, dass \\[\\begin{equation}\n\\lim_{n \\to \\infty} \\mathbb{P}(|\\xi_n - \\xi| &lt; \\epsilon)    = 1 \\Leftrightarrow\n\\lim_{n \\to \\infty} \\mathbb{P}(|\\xi_n - \\xi| \\ge \\epsilon)  = 0.\n\\end{equation}\\] Die Konvergenz von \\(\\xi_1,\\xi_2,....\\) gegen \\(\\xi\\) in Wahrscheinlichkeit wird geschrieben als \\[\\begin{equation}\n\\xi_n\\xrightarrow[n \\to \\infty]{\\mbox{P}} \\xi.\n\\end{equation}\\]\n\n\\(\\xi_n\\xrightarrow[n \\to \\infty]{\\text{P}} \\xi\\) heißt also, dass sich die Wahrscheinlichkeit dafür, dass \\(\\xi_n\\) in dem zufälligen Intervall \\[\\begin{equation}\n]\\xi-\\epsilon, \\xi+\\epsilon[\n\\end{equation}\\] liegt, unabhängig davon, wie klein dieses Intervall sein mag, \\(1\\) nähert, wenn \\(n\\) gegen Unendlich geht. Intuitiv heißt das, dass sich für \\(n \\to \\infty\\) und eine konstante Zufallsvariable \\(\\xi := a\\) die Verteilung von \\(\\xi_n\\) mehr und mehr um \\(a\\) konzentriert, wenn \\(n\\) gegen Unendlich strebt. Mithilfe der Konvergenz in Wahrscheinlichkeit formuliert man das Schwache Gesetz der Großen Zahlen wie folgt.\n\nTheorem 15.1 (Schwaches Gesetz der Großen Zahlen) \\(\\xi_1,...,\\xi_n\\) seien unabhängig und gleichverteilte Zufallsvariablen mit \\(\\mathbb{E}(\\xi_i) = \\mu\\) für alle \\(i = 1,...,n\\). Weiterhin bezeichne \\[\\begin{equation}\n\\bar{\\xi}_n := \\frac{1}{n}\\sum_{i=1}^n \\xi_i\n\\end{equation}\\] das Stichprobenmittel der \\(\\xi_i, i = 1,...,n\\). Dann konvergiert \\(\\bar{\\xi}_n\\) in Wahrscheinlichkeit gegen \\(\\mu\\), \\[\\begin{equation}\n\\bar{\\xi}_n \\xrightarrow[n \\to \\infty]{\\mbox{P}} \\mu.\n\\end{equation}\\]\n\nFür einen Beweis dieses Theorems verweisen wir auf die weiterführende Literatur, so zum Beispiel auf Abschnitt 5.1 in Georgii (2009). Intuitiv heißt \\[\\begin{equation}\n\\bar{\\xi}_n \\xrightarrow[n\\to\\infty]{\\mbox{P}} \\mu\n\\end{equation}\\] also, dass die Wahrscheinlichkeit, dass das Stichprobenmittel nahe dem Erwartungswert der zugrundeliegenden Verteilung liegt, sich 1 nähert, wenn \\(n\\) gegen Unendlich strebt.\nSimulation\nWir betrachten den Fall von u.i.v. normalverteilten Zufallsvariablen \\(\\xi_1,...,\\xi_n \\sim N(0,1)\\). Abbildung 15.1 A zeigt Realisationen der von Stichprobenmitteln \\(\\bar{\\xi}_n\\) als Funktion von \\(n\\). Man erkennt, dass für größeres \\(n\\) mehr Realisierungen von \\(\\bar{\\xi}_n\\) in der Nähe des Erwartungswerts der \\(\\xi_i, i = 1,...,n\\) liegen. Basierend auf diesen Stichprobenmittelrealisationen zeigt Abbildung 15.1 B Schätzungen der Wahrscheinlichkeit \\(\\mathbb{P}(|\\bar{\\xi}_n - \\mu| \\ge \\epsilon)\\) als Funktionen von \\(n\\) und \\(\\epsilon\\). Für ein großes \\(\\epsilon\\) reicht ein geringes \\(n\\) aus um die Wahrscheinlichkeit für eine absolute Abwecihung des Stichprobenmittels vom Erwartungswert klein werden zu lassen, für ein kleineres \\(\\epsilon\\) ist dafür ein größeres \\(n\\) nötig. In jedem Fall sinken die Wahrscheinlichkeiten jedoch mit größerem \\(n\\).\n\n\n\nAbbildung 15.1: Simulation des schwachen Gesetz der Großen Zahlen."
  },
  {
    "objectID": "207-Grenzwerte.html#sec-zentrale-grenzwertsaetze",
    "href": "207-Grenzwerte.html#sec-zentrale-grenzwertsaetze",
    "title": "15  Grenzwerte",
    "section": "15.2 Zentrale Grenzwertsätze",
    "text": "15.2 Zentrale Grenzwertsätze\nDie Zentralen Grenzwertsätze besagen intuitiv, dass die Summe von unabhängigen Zufallsvariablen mit Erwartungswert Null asymptotisch, also für unendlich viele Zufallsvariablen, normalverteilt mit Erwartungswertparameter Null ist. Modelliert man eine beliebige Messgröße \\(\\upsilon\\) also als Summe eines deterministischen Einflusses \\(\\mu\\) und der Summe \\[\\begin{equation}\n\\varepsilon := \\sum_{i=1}^n \\xi_i\n\\end{equation}\\] einer Vielzahl von unabhängigen Zufallsvariablen \\(\\xi_i, i = 1,...,n\\), die unbekannte Störeinflüsse modellieren sollen, so ist für großes \\(n\\) die Annahme \\[\n\\upsilon = \\mu + \\varepsilon \\mbox{ mit } \\varepsilon \\sim N(0,\\sigma^2)\n\\tag{15.1}\\] mathematisch gerechtfertigt. Wie wir später sehen werden, liegt die Annahme in Gleichung Gleichung 15.1 einer großen Vielzahl von probabilistischen Modellen zugrunde.\nFormal werden verschiedene Formen von Zentralen Grenzwertsätzen, je nach Ausgestaltung der zugrundeliegenden Annahmen und ihrer Beweisführung unterschieden. In der sogenannten Lindenberg und Lévy Form des Zentralen Grenzwertsatzes werden unabhängig und identische Zufallsvariablen vorausgesetzt. In der Liapunov Form dagegen werden nur unabhängige Zufallsvariablen voraussetzt. In beiden Formulierungen des Zentralen Grenzwertsatzes ist die betrachtete Konvergenz von Zufallsvariablen die Konvergenz in Verteilung, welche wir zunächst einführen.\n\nDefinition 15.2 (Konvergenz in Verteilung) Eine Folge \\(\\xi_1,\\xi_2,...\\) von Zufallsvariablen , wenn \\[\\begin{equation}\n\\lim_{n \\to \\infty} P_{\\xi_n}(x) = P_\\xi(x)\n\\end{equation}\\] für alle \\(\\xi\\) an denen \\(P_\\xi\\) stetig ist. Die Konvergenz in Verteilung von \\(\\xi_1,\\xi_2,...\\) gegen \\(\\xi\\) wird geschrieben als \\[\\begin{equation}\n\\xi_n\\xrightarrow[n\\to \\infty]{\\text{D}} \\xi.\n\\end{equation}\\] Gilt \\(\\xi_n\\xrightarrow[n\\to \\infty]{\\text{D}} \\xi\\), dann heißt die Verteilung von \\(\\xi\\) die .\n\nDie Konvergenz in Verteilung ist also eine Aussage zur Konvergenz von Funktionenfolgen, speziell von KVFen. Ohne Begründung merken wir an, dass die oben betrachtete Konvergenz in Wahrscheinlichkeit die Konvergenz in Verteilung impliziert. Wir geben nun zunächst den Zentralen Grenzwertsatz nach Lindenberg und Lévy an.\n\nTheorem 15.2 (Zentraler Grenzwertsatz nach Lindenberg und Lévy) \\(\\xi_1,...,\\xi_n\\) seien unabhängig und identisch verteilte Zufallsvariablen mit \\[\\begin{equation}\n\\mathbb{E}(\\xi_i) := \\mu \\mbox{ und }\n\\mathbb{V}(\\xi_i) := \\sigma^2 &gt; 0\n\\mbox{ für alle } i = 1,....,n.\n\\end{equation}\\] Weiterhin sei \\(\\zeta_n\\) die Zufallsvariable definiert als \\[\\begin{equation}\n\\zeta_n := \\sqrt{n}\\left(\\frac{\\bar{\\xi}_n - \\mu}{\\sigma}\\right).\n\\end{equation}\\] Dann gilt für alle \\(z \\in \\mathbb{R}\\) \\[\\begin{equation}\n\\lim_{n \\to \\infty} P_{\\zeta_n}(z) = \\Phi(z),\n\\end{equation}\\] wobei \\(\\Phi\\) die kumulative Verteilungsfunktion der Standardnormalverteilung bezeichnet.\n\nWir zeigen an späterer Stelle, dass damit für \\(n\\to\\infty\\) auch gilt, dass \\[\n\\sum_{i=1}^n \\xi_i \\sim N(\\mu, n\\sigma^2)\n\\mbox{ und }\n\\bar{\\xi}_n \\sim N\\left(\\mu,\\frac{\\sigma^2}{n}\\right).\n\\tag{15.2}\\]\nSimulation\nWir betrachten den Fall von u.i.v. \\(\\chi^2\\)-Zufallsvariablen \\(\\xi_1,...,\\xi_n \\sim \\chi^2(3)\\). Offenbar ist die funktionale Form der \\(\\chi^2(3)\\)-Verteilung von der Standardnormalverteilung recht verschieden, insbesondere nehmen \\(\\chi^2\\)-Zufallsvariablen mit von Null verschiedener Wahrscheinlichkeit nur nicht-negative Werte an (vgl. Kapitel 11.3) Nichtsdestotrotz resultiert ihre standardisierte Summe asymptotisch in einer Normalverteilung, wie in Abbildung 15.2 visualisiert. Dazu nutzen wir auf Ebene der Implementation die Tatsache, für die \\(\\chi^2\\)-Zufallsvariablen \\(\\xi_i, i = 1,...,n\\) mit Freiheitsgradparameter \\(3\\) bekanntlich gilt (vgl. Kapitel 13.1 und Kapitel 13.2) \\[\\begin{equation}\n\\mathbb{E}(\\xi_i) = 3 \\mbox{ und }\\mathbb{V}(\\xi_i) = 6\n\\end{equation}\\] Die Abbildungen in Abbildung 15.2 A zeigen Histogrammschätzer der Wahrscheinlichkeitsdichte von \\[\\begin{equation}\n\\zeta_n := \\sqrt{n}\\left(\\frac{\\bar{\\xi}_n - \\mu}{\\sigma}\\right)\n\\end{equation}\\] basierend auf 1000 Realisationen von \\(\\zeta_n\\) für \\(n = 2\\) und \\(n = 200\\), sowie die WDF von \\(N(0,1)\\). Offenbar ist die Verteilung der Realisiationen von \\(\\zeta_2\\) der Standardnormalverteilung noch sehr unähnlich, wohingegen sich die Verteilung der Realisationen von \\(\\zeta_{200}\\) der Standardnormalverteilung schon annähert. Abbildung 15.2 B zeigt die entsprechenden geschätzten KVFen über die Theorem 15.2 formal eine Aussage trifft.\n\n\n\nAbbildung 15.2: Simulation des Zentralen Grenzwertsatzes nach Lindenberg und Lévy.\n\n\n\nTheorem 15.3 (Zentraler Grenzwertsatz nach Liapounov) \\(\\xi_1,...,\\xi_n\\) seien unabhängige aber nicht notwendigerweise identisch verteilten Zufallsvariablen mit \\[\\begin{equation}\n\\mathbb{E}(\\xi_i) := \\mu_i \\mbox{ und }\n\\mathbb{V}(\\xi_i) := \\sigma^2_i &gt; 0\n\\mbox{ für alle } i = 1,....,n.\n\\end{equation}\\] Weiterhin sollen für \\(\\xi_1,...,\\xi_n\\) folgende Eigenschaften gelten: \\[\\begin{equation}\n\\mathbb{E}(|\\xi_i - \\mu_i|^3) &lt; \\infty \\mbox{ und }\n\\lim_{n \\to \\infty} \\frac{\\sum_{i=1}^n \\mathbb{E}\\left(|\\xi_i - \\mu_i|^3\\right)}{(\\sum_{i=1}^n \\sigma_i^2)^{3/2}} = 0.\n\\end{equation}\\] Dann gilt für die Zufallsvariable \\(\\zeta_n\\) definiert als \\[\\begin{equation}\n\\zeta_n := \\frac{\\sum_{i=1}^n \\xi_i - \\sum_{i=1}^n \\mu_i}{\\sqrt{\\sum_{i=1}^n \\sigma_i^2}},\n\\end{equation}\\] für alle \\(z\\in\\mathbb{R}\\), dass \\[\\begin{equation}\n\\lim_{n \\to \\infty} P_{\\zeta_n}(z) = \\Phi(z),\n\\end{equation}\\] wobei \\(\\Phi\\) KVF der Standardnormalverteilung bezeichnet.\n\nWir zeigen an späterer Stelle, dass damit für \\(n\\to\\infty\\) auch gilt, dass \\[\n\\sum_{i=1}^n \\xi_i \\sim N\\left(\\sum_{i=1}^n \\mu_i, \\sum_{i=1}^n \\sigma_i^2\\right)\n\\tag{15.3}\\]"
  },
  {
    "objectID": "207-Grenzwerte.html#literaturhinweise",
    "href": "207-Grenzwerte.html#literaturhinweise",
    "title": "15  Grenzwerte",
    "section": "15.3 Literaturhinweise",
    "text": "15.3 Literaturhinweise\nZur mathematik-geschichtlichen Genese der Zentralen Grenzwertsätze siehe z.B. Fischer (2011)."
  },
  {
    "objectID": "207-Grenzwerte.html#selbstkontrollfragen",
    "href": "207-Grenzwerte.html#selbstkontrollfragen",
    "title": "15  Grenzwerte",
    "section": "15.4 Selbstkontrollfragen",
    "text": "15.4 Selbstkontrollfragen\n\nDefinieren Sie den Begriff der Konvergenz in Wahrscheinlichkeit.\nDefinieren Sie den Begriff der Konvergenz in Verteilung.\nGeben Sie das Schwache Gesetz der Großen Zahlen wieder.\nErläutern Sie den Zentralen Grenzwertsatz nach Lindenberg und Lévy.\nErläutern Sie den Zentralen Grenzwertsatz nach Liapunov.\nWarum sind die Zentralen Grenzwertsätze für die probabilistische Modellbildung wichtig? \n\n\n\n\n\nFischer, H. (2011). A History of the Central Limit Theorem. Springer New York. https://doi.org/10.1007/978-0-387-87857-7\n\n\nGeorgii, H.-O. (2009). Stochastik: Einführung in die Wahrscheinlichkeitstheorie und Statistik (4., überarb. und erw. Aufl). de Gruyter."
  },
  {
    "objectID": "208-Transformationstheoreme.html#sec-univariate-transformationstheoreme",
    "href": "208-Transformationstheoreme.html#sec-univariate-transformationstheoreme",
    "title": "16  Transformationstheoreme",
    "section": "16.1 Univariate Transformationstheoreme",
    "text": "16.1 Univariate Transformationstheoreme\nDabei liefert Theorem 16.2 eine Formel zur Berechnung der WDF \\(p_\\upsilon\\) von \\(\\upsilon := f(\\xi)\\), wenn \\(\\xi\\) eine Zufallsvariable mit WDF \\(p_\\xi\\) ist und \\(f\\) eine bijektive Funktion ist. Theorem 16.3 gibt weiterhin eine vereinfachte Formel zur Berechnung der WDF \\(p_\\upsilon\\) von \\(\\upsilon := f(\\xi)\\) an, wenn \\(f\\) speziell eine linear-affine Funktion ist. Theorem 16.4 schließlich gibt eine Formel zur Berechnung der WDF \\(p_\\upsilon\\) von \\(\\upsilon := f(\\xi)\\) an, wenn \\(f\\) zumindest in Teilen bijektiv ist.\n\nTheorem 16.2 (Univariate WDF Transformation bei bijektiven Abbildungen) \\(\\xi\\) sei eine Zufallsvariable mit WDF \\(p_\\xi\\) für die \\(\\mathbb{P}(]a,b[) = 1\\) gilt, wobei \\(a\\) und/oder \\(b\\) entweder endlich oder unendlich seien. Weiterhin sei \\[\\begin{equation}\n\\upsilon := f(\\xi),\n\\end{equation}\\] wobei die univariate reellwertige Funktion \\(f : ]a,b[ \\to \\mathbb{R}\\) differenzierbar und bijektiv auf \\(]a,b[\\) sei. \\(f(]a,b[)\\) sei das Bild von \\(]a,b[\\) unter \\(f\\). Schließlich sei \\(f^{-1}(y)\\) der Wert der Umkehrunktion von \\(f(x)\\) für \\(y \\in f(]a,b[)\\) und \\(f'(x)\\) sei die Ableitung von \\(f\\) an der Stelle \\(x\\). Dann ist die WDF von \\(\\upsilon\\) gegeben durch \\[\\begin{equation}\np_\\upsilon : \\mathbb{R} \\to \\mathbb{R}_{\\ge 0}, y \\mapsto p_\\upsilon(y) :=\n\\begin{cases}\n\\frac{1}{\\vert  f^{'}\\left(f^{-1}(y)\\right) \\vert}p_\\xi\\left(f^{-1}(y)\\right)\n& \\mbox{ für } y \\in f(]a,b[) \\\\\n0\n& \\mbox{ für } y \\in \\mathbb{R} \\setminus f(]a,b[).\n\\end{cases}\n\\end{equation}\\]\n\n\nBeweis. Wir halten zunächst fest, dass weil \\(f\\) eine differenzierbare bijektive Funktion auf \\(]a,b[\\) ist, \\(f\\) entweder strikt wachsend oder strikt fallend ist. Nehmen wir zunächst an, dass \\(f\\) auf \\(]a,b[\\) strikt wachsend ist. Dann ist auch \\(f^{-1}\\) für alle \\(y \\in f(]a,b[)\\) wachsend, und es gilt \\[\\begin{equation*}\nP_\\upsilon(y)\n= \\mathbb{P}(\\upsilon \\le y)\n= \\mathbb{P}\\left(f(\\xi) \\le y\\right)\n= \\mathbb{P}\\left(f^{-1}(f(\\xi)) \\le f^{-1}(y)\\right)\n= \\mathbb{P}\\left(\\xi \\le f^{-1}(y)\\right)\n= P_\\xi\\left(f^{-1}(y)\\right).\n\\end{equation*}\\] \\(P_\\upsilon\\) ist also differenzierbar an allen Stellen \\(y\\), an denen sowohl \\(f^{-1}\\) als auch \\(P_\\xi\\) differenzierbar sind. Mit der Kettenregel und dem Satz von der Umkehrabbildung \\((f^{-1}(x))' = 1/f'(f^{-1}(x))\\), folgt dann, dass die WDF \\(p_\\upsilon\\) sich ergibt wie folgt: \\[\\begin{equation*}\np_\\upsilon(y)\n= \\frac{d}{dy}P_\\upsilon(y)\n= \\frac{d}{dy}P_\\xi\\left(f^{-1}(y)\\right)\n= p_\\xi\\left(f^{-1}(y)\\right)\\frac{d}{dy}f^{-1}(y)\n= \\frac{1}{f'\\left(f^{-1}(y)\\right)} p_\\xi\\left(f^{-1}(y)\\right),\n\\end{equation*}\\] Weil \\(f^{-1}\\) strikt wachsend ist, ist \\(d/dy (f^{-1}(y))\\) positiv und das Theorem trifft zu. Analog gilt, dass wenn \\(f\\) auf \\(]a,b[\\) strikt fallend ist, dann ist auch \\(f^{-1}\\) für alle \\(y \\in f(]a,b[)\\) fallend und es gilt \\[\\begin{equation*}\nP_\\upsilon(y)\n= \\mathbb{P}(f(\\xi) \\le y)\n= \\mathbb{P}\\left(f^{-1}(f(\\xi)) \\ge f^{-1}(y)\\right)\n= \\mathbb{P}\\left(\\xi \\ge f^{-1}(y)\\right)\n= 1 - P_\\xi\\left(f^{-1}(y) \\right),\n\\end{equation*}\\] Mit der Kettenregel und dem Satz von der Umkehrabbildung folgt dann \\[\\begin{equation*}\np_\\upsilon(y)\n= \\frac{d}{dy}(1 - P_\\upsilon(y))\n= -\\frac{d}{dy}P_\\xi\\left(f^{-1}(y)\\right)\n= -p_\\xi\\left(f^{-1}(y)\\right)\\frac{d}{dy}f^{-1}(y)\n= -\\frac{1}{f'\\left(f^{-1}(y)\\right)} p_\\xi\\left(f^{-1}(y)\\right).\n\\end{equation*}\\] Weil \\(f^{-1}\\) strikt fallend ist, ist \\(d/dy (f^{-1}(y))\\) negativ, so dass \\(-d/dy (f^{-1}(y))\\) gleich \\(|d/dy (f^{-1}(y))|\\) ist und das Theorem trifft zu.\n\nEin wichtiger Anwendungsfall von Theorem 16.2 ist Theorem 16.3.\n\nTheorem 16.3 (Univariates WDF Transformationstheorem bei linear-affinen Abbildungen) \\(\\xi\\) sei eine Zufallsvariable mit WDF \\(p_\\xi\\) und es sei \\[\\begin{equation}\n\\upsilon = f(\\xi) \\mbox{ mit } f(\\xi) := a\\xi + b \\mbox{ für } a\\neq 0.\n\\end{equation}\\] Dann ist die WDF von \\(\\upsilon\\) gegeben durch \\[\\begin{equation}\np_\\upsilon : \\mathbb{R} \\to \\mathbb{R}_{\\ge 0}, y \\mapsto p_\\upsilon(y) :=\n\\frac{1}{|a|}p_\\xi\\left(\\frac{y-b}{a}\\right).\n\\end{equation}\\]\n\n\nBeweis. Wir halten zunächst fest, dass \\[\\begin{equation}\nf^{-1} : \\mathbb{R} \\to \\mathbb{R}, y  \\mapsto f^{-1}(y) = \\frac{y - b}{a}\n\\end{equation}\\] ist, weil dann \\(f \\circ f^{-1} = \\mbox{id}_{\\mathbb{R}}\\) gilt, wie man anhand von \\[\\begin{equation}\nf(f^{-1}(x)) = a \\left(\\frac{x - b}{a}\\right) + b = x - b + b = x \\mbox{ für alle } x \\in \\mathbb{R}\n\\end{equation}\\] einsieht. Wir halten weiterhin fest, dass \\[\\begin{equation}\nf' : \\mathbb{R} \\to \\mathbb{R}, x \\mapsto f'(x) = \\frac{d}{dx}(ax  + b) = a.\n\\end{equation}\\] Also folgt mit Theorem 16.2, dass \\[\\begin{align}\n\\begin{split}\np_\\upsilon : \\mathbb{R} \\to \\mathbb{R}_{\\ge 0}, y \\mapsto p_\\upsilon(y)\n& = \\frac{1}{\\vert f^{'}\\left(f^{-1}(y)\\right)\\vert}p_\\xi\\left(f^{-1}(y)\\right) \\\\\n& = \\frac{1}{|a|}p_\\xi\\left(\\frac{y - b}{a}\\right).\n\\end{split}\n\\end{align}\\]\n\nEin wichtiger Anwendungsfall dieses Theorems ist die in Kapitel 17 betrachtete \\(Z\\)-Transformation. Das folgende Theorem, dass wir nicht beweisen wollen, verallgemeinert Theorem 16.2 auf den Fall nur stückweise bijektiver Abbildungen.\n\nTheorem 16.4 (Univariate WDF Transformation bei stückweise bijektiven Abbildungen) \\(\\xi\\) sei eine Zufallsvariable mit Ergebnisraum \\(\\mathcal{X}\\) und WDF \\(p_\\xi\\). Weiterhin sei \\[\\begin{equation}\n\\upsilon = f(\\xi),\n\\end{equation}\\] wobei \\(f\\) so beschaffen sei, dass der Ergebnisraum von \\(\\xi\\) in eine endliche Anzahl von Mengen \\(\\mathcal{X}_1,...,\\mathcal{X}_k\\) mit einer entsprechenden Anzahl von Mengen \\(\\mathcal{Y}_1 := f(\\mathcal{X}_1), ..., \\mathcal{Y}_k := f(\\mathcal{X}_k)\\) im Ergebnisraum \\(\\mathcal{Y}\\) von \\(\\upsilon\\) partitioniert werden kann (wobei nicht notwendigerweise \\(\\mathcal{Y}_i \\cap \\mathcal{Y}_j = \\emptyset, 1 \\le i,j \\le k\\) gelten muss), so dass die Abbildung \\(f\\) für alle \\(\\mathcal{X}_1,...,\\mathcal{X}_k\\) bijektiv ist (d.h. \\(f\\) ist eine bijektive Abbildung). Für \\(i = 1,...,k\\) bezeichne \\(f_i^{-1}\\) die Umkehrfunktion von \\(f\\) auf \\(\\mathcal{Y}_i\\). Schließlich nehmen wir an, dass die Ableitungen \\(f_i^{\\prime}\\) für alle \\(i=1,...,k\\) existieren und stetig sind. Dann ist eine WDF von \\(\\upsilon\\) durch \\[\\begin{equation}\np_\\upsilon : \\mathcal{Y} \\to \\mathbb{R}_{\\ge 0}, y \\mapsto p_\\upsilon(y) :=\n\\sum_{i=1}^k 1_{\\mathcal{Y}_i} (y) \\frac{1}{\\vert  f^{'}_i(f^{-1}_i(y)) \\vert}p_\\xi\\left(f^{-1}_i(y)\\right).\n\\end{equation}\\] gegeben.\n\nEin wichtiger Anwendungsfall ist die in Kapitel 17 betrachtete \\(\\chi^2\\)-Transformation."
  },
  {
    "objectID": "208-Transformationstheoreme.html#sec-multivariate-wdf-transformationstheorem",
    "href": "208-Transformationstheoreme.html#sec-multivariate-wdf-transformationstheorem",
    "title": "16  Transformationstheoreme",
    "section": "16.2 Multivariate WDF Transformationstheoreme",
    "text": "16.2 Multivariate WDF Transformationstheoreme\nTheorem 16.5 liefert eine Formel zur Berechnung der WDF \\(p_\\upsilon\\) von \\(\\upsilon := f(\\xi)\\), wenn \\(\\xi\\) ein Zufallsvektor mit WDF \\(p_\\xi\\) ist und \\(f\\) eine bijektive multivariate vektorwertigeFunktion ist. Es handelt sich dabei um eine direkte Generalisierung von Theorem 16.2 und wir verzichten auf einen Beweis.\n\nTheorem 16.5 (Multivariate WDF Transformation bei bijektiven Abbildungen) \\(\\xi\\) sei ein \\(n\\)-dimensionaler Zufallsvektor mit Ergebnisraum \\(\\mathbb{R}^n\\) und WDF \\(p_\\xi\\). Weiterhin sei \\[\\begin{equation}\n\\upsilon := f(\\xi),\n\\end{equation}\\] wobei die multivariate vektorwertige Funktion \\(f : \\mathbb{R}^n \\to \\mathbb{R}^n\\) differenzierbar und bijektiv auf \\(]a,b[\\) sei. Schließlich seien \\[\\begin{equation}\nJ^f(x)\n= \\left(\\frac{\\partial}{\\partial x_j}f_i(x)\\right)_{1\\le i \\le n, 1 \\le j \\le n}\n\\in \\mathbb{R}^{n \\times n}\n\\end{equation}\\] die Jacobi-Matrix von \\(f\\) an der Stelle \\(x \\in \\mathbb{R}^n\\), \\(|J^f(x)|\\) die Determinante von \\(J^f(x)\\), und es sei \\(|J^f(x)| \\neq 0\\) für alle \\(x \\in \\mathbb{R}^n\\). Dann ist eine WDF von \\(\\upsilon\\) durch \\[\\begin{equation}\\label{eq:mpdf_transform}\np_\\upsilon : \\mathbb{R}^n \\to \\mathbb{R}_{\\ge 0}, y \\mapsto p_\\upsilon(y) :=\n\\begin{cases}\n\\frac{1}{|J^f\\left(f^{-1}(y)\\right)|}p_\\xi\\left(f^{-1}(y)\\right)\n& \\mbox{ for } y\\in f(\\mathbb{R}^n) \\\\\n0\n& \\mbox{ for } y \\in \\mathbb{R}^n \\setminus f(\\mathbb{R}^n)\n\\end{cases}\n\\end{equation}\\] gegeben.\n\nWichtige Anwendungsfälle sind die in Kapitel 17 betrachteten \\(T\\)- und \\(F\\)-Transformationen."
  },
  {
    "objectID": "208-Transformationstheoreme.html#sec-operationstheoreme",
    "href": "208-Transformationstheoreme.html#sec-operationstheoreme",
    "title": "16  Transformationstheoreme",
    "section": "16.3 Operationstheoreme",
    "text": "16.3 Operationstheoreme\nDas folgende sogenannte Konvolutionstheorem liefert eine Formel zur Berechnung der WDF \\(p_\\upsilon\\) von \\(\\upsilon := \\xi_1 + \\xi_2\\), wenn \\(\\xi_1\\) und \\(\\xi_2\\) zwei Zufallsvariablen mit WDFen \\(p_{\\xi_1}\\) und \\(p_{\\xi_2}\\) sind.\n\nTheorem 16.6 (Summe unabhängiger Zufallsvariablen (Konvolution)) \\(\\xi_1\\) und \\(\\xi_2\\) seien zwei kontinuierliche unabhängige Zufallsvariablen mit WDF \\(p_{\\xi_1}\\) und \\(p_{\\xi_2}\\), respektive. \\(\\upsilon := \\xi_1 + \\xi_2\\) sei die Summe von \\(\\xi_1\\) und \\(\\xi_2\\). Dann ergibt sich eine WDF der Verteilung von \\(\\upsilon\\) als \\[\\begin{equation}\np_\\upsilon(y)\n= \\int_{-\\infty}^\\infty p_{\\xi_1}(y - x_2)p_{\\xi_2}(x_2)\\,dx_2\n= \\int_{-\\infty}^\\infty p_{\\xi_1}(x_1)p_{\\xi_2}(y - x_1)\\,dx_1\n\\end{equation}\\] Die Formel für die WDF \\(p_\\upsilon\\) heißt oder von \\(p_{\\xi_1}\\) und \\(p_{\\xi_2}\\).\n\n\nBeweis. Wir nutzen das multivariate WDF Transformationstheorem für bijektive Abbildungen. Dazu definieren wir zunächst \\[\\begin{equation}\nf : \\mathbb{R}^2 \\to \\mathbb{R}^2, x \\mapsto f(x) :=\n\\begin{pmatrix}\nx_1 + x_2 \\\\\nx_2\n\\end{pmatrix}\n:=\n\\begin{pmatrix}\nz_1 \\\\ z_2\n\\end{pmatrix}\n\\end{equation}\\] Die inverse Funktion von \\(f\\) ist dann gegeben durch \\[\\begin{equation}\nf : \\mathbb{R}^2 \\to \\mathbb{R}^2, z \\mapsto f(z) :=\n\\begin{pmatrix}\nz_1 - x_2 \\\\\nz_2\n\\end{pmatrix}\n\\end{equation}\\] weil dann \\(f \\circ f^{-1} = \\mbox{id}_{\\mathbb{R}^2}\\) gilt, wie man anhand von \\[\\begin{equation}\nf^{-1}\\left(f(x)\\right)\n=\nf^{-1}\n\\begin{pmatrix}\nx_1 + x_2 \\\\\nx_2\n\\end{pmatrix}\n=\n\\begin{pmatrix}\nx_1 + x_2 - x_2\\\\\nx_2\n\\end{pmatrix}\n=\n\\begin{pmatrix}\nx_1 \\\\\nx_2\n\\end{pmatrix}\n\\end{equation}\\] einsieht. Die Jacobimatrix von \\(f\\) ergibt sich zu \\[\\begin{equation}\nJ^{f}(x) =\n\\begin{pmatrix}\n\\frac{\\partial}{\\partial x_1} f_1(x) &  \\frac{\\partial}{\\partial x_2} f_1(x) \\\\\n\\frac{\\partial}{\\partial x_1} f_2(x) &  \\frac{\\partial}{\\partial x_2} f_2(x) \\\\\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n    \\frac{\\partial}{\\partial x_1} (x_1 + x_2)\n&   \\frac{\\partial}{\\partial x_2} (x_1 + x_2)\n\\\\\n    \\frac{\\partial}{\\partial x_1} x_2\n&   \\frac{\\partial}{\\partial x_2} x_2 \\\\\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n1 &  1 \\\\\n0 &  1 \\\\\n\\end{pmatrix}\n\\end{equation}\\] und die Jacobideterminante damit zu \\(|J^f(x)| = 1\\). Wir halten weiterhin fest, dass die Unabhängigkeit von \\(\\xi_1\\) und \\(\\xi_2\\) impliziert, dass \\[\\begin{equation}\np_{\\xi_1,\\xi_2}(x_1,x_2) = p_{\\xi_1}(x_1)p_{\\xi_2}(x_2)\n\\end{equation}\\] impliziert. Einsetzen und Integration hinsichtlich \\(x_2\\) ergibt dann ergibt dann für \\(z \\in f(\\mathbb{R}^2)\\) \\[\\begin{align}\n\\begin{split}\np_\\zeta(z)\n& = \\frac{1}{|J^f\\left(f^{-1}(z)\\right)|}p_\\xi\\left(f^{-1}(z)\\right)  \\\\\n& = \\frac{1}{1}p_{\\xi_1,\\xi_2}\\left(z_1 - x_2, x_2\\right)  \\\\\n& = p_{\\xi_1}(z_1 - x_2)p_{\\xi_2}(x_2)\n\\end{split}\n\\end{align}\\] Integration über \\(x_2\\) ergibt dann eine WDF für die marginale Verteilung von \\(\\zeta_1\\) \\[\\begin{align}\n\\begin{split}\np_{\\zeta_1}(z_1)\n& = \\int_{-\\infty}^{\\infty} p_{\\xi_1}(z_1 - x_2)p_{\\xi_2}(x_2)\\,dx_2\n\\end{split}\n\\end{align}\\] Mit \\(\\zeta_1 = \\xi_1 + \\xi_2 = \\upsilon\\) ergibt sich dann die erste Form des Konvlutionstheorems zu \\[\\begin{align}\np_\\upsilon(y)\n& = \\int_{-\\infty}^{\\infty} p_{\\xi_1}(y - x_2)p_{\\xi_2}(x_2)\\,dx_2.\n\\end{align}\\]\n\nWichtige in Kapitel 17 betrachtete Anwendungsfällte sind die Summentransformation und die Mittelwerttransformation."
  },
  {
    "objectID": "209-Transformationen-der-Normalverteilung.html#sec-summentransformation-und-mittelwerttransformation",
    "href": "209-Transformationen-der-Normalverteilung.html#sec-summentransformation-und-mittelwerttransformation",
    "title": "17  Transformationen der Normalverteilung",
    "section": "17.1 Summentransformation und Mittelwertstransformation",
    "text": "17.1 Summentransformation und Mittelwertstransformation\nIn diesem Abschnitt betrachten wir die resultierenden Verteilung bei Summation und Mittelwertbildung von unabhängig und identisch normalverteilten Zufallsvariablen. Speziell besagt das Theorem 17.1 besagt, dass die Summe unabhängig normalverteilter Zufallsvariablen wiederum normalverteilt ist und gibt die Parameter dieser Verteilung an, während Theorem 17.2 besagt, dass das Stichprobenmittel unabhängig normalverteilter Zufallsvariablen wiederum normalverteilt ist und gibt die Parameter dieser Verteilung an.\n\nTheorem 17.1 (Summationstransformation) Für \\(i = 1,...,n\\) seien \\(\\xi_i \\sim N(\\mu_i,\\sigma^2_i)\\) unabhängige normalverteilte Zufallsvariablen. Dann gilt für die Summe \\(\\upsilon := \\sum_{i=1}^n \\xi_i\\) , dass \\[\\begin{equation}\n\\upsilon \\sim N\\left(\\sum_{i=1}^n \\mu_i, \\sum_{i=1}^n \\sigma^2_i\\right)\n\\end{equation}\\] Für unabhängige und identisch normalverteilte Zufallsvariablen \\(\\xi_i \\sim N(\\mu,\\sigma^2)\\) gilt folglich \\[\\begin{equation}\n\\upsilon \\sim N(n\\mu, n \\sigma^2).\n\\end{equation}\\]\n\n\nBeweis. Wir skizzieren mithilfe von Theorem 16.6, dass für \\(\\xi_1 \\sim N(\\mu_1,\\sigma^2_1)\\), \\(\\xi_2 \\sim N(\\mu_2,\\sigma^2_2)\\), und \\(\\upsilon := \\xi_1 + \\xi_2\\) gilt, dass \\(\\upsilon \\sim N(\\mu_1 + \\mu_2,\\sigma_1^2 + \\sigma_2^2)\\). Für \\(n &gt; 2\\) folgt das Theorem dann durch Iteration. Mit der Definition der WDF der Normalverteilung erhalten wir zunächst \\[\\begin{align}\n\\begin{split}\np_\\upsilon(y)\n& = \\int_{-\\infty}^\\infty p_{\\xi_1}(x_1)p_{\\xi_2}(y - x_1)\\,dx_1\n\\\\\n& = \\int_{-\\infty}^\\infty\n    \\frac{1}{\\sqrt{2 \\pi} \\sigma_1} \\exp\\left(-\\frac{1}{2}\\left(\\frac{x_1 - \\mu_1}{\\sigma_1}\\right)^2\\right)\n    \\frac{1}{\\sqrt{2 \\pi} \\sigma_2} \\exp\\left(-\\frac{1}{2}\\left(\\frac{y - x_1 - \\mu_2}{\\sigma_2}\\right)^2\\right)\n    \\,dx_1\n\\\\\n& = \\int_{-\\infty}^\\infty\n    \\frac{1}{2 \\pi \\sigma_1\\sigma_2}\\exp\n    \\left(\n    -\\frac{1}{2}\\left(\\frac{x_1 - \\mu_1}{\\sigma_1}\\right)^2\n    -\\frac{1}{2}\\left(\\frac{y - x_1 - \\mu_2}{\\sigma_2}\\right)^2\n    \\right)\n    \\,dx_1 .\n\\\\\n\\end{split}\n\\end{align}\\] Mit einigem algebraischen Aufwand erhält man die Identität \\[\\begin{multline}\n-\\frac{1}{2}\\left(\\frac{x_1 - \\mu_1}{\\sigma_1}\\right)^2\n-\\frac{1}{2}\\left(\\frac{y - x_1 - \\mu_2}{\\sigma_2}\\right)^2\n=\n-\\frac{(y - \\mu_1 - \\mu_2)^2}\n      {2(\\sigma_1^2 + \\sigma_2^2)}\n-\\frac{((\\sigma_1^2 + \\sigma_2^2)x_1 -\\sigma_1^2y + \\mu_2 \\sigma_1^2 - \\mu_1 \\sigma_2^2)^2}\n      {2\\sigma_1^2\\sigma_2^2(\\sigma_1^2 + \\sigma_2^2)},\n\\end{multline}\\] so dass weiterhin gilt, dass \\[\\begin{align}\n\\begin{split}\np_\\upsilon(y)\n& = \\int_{-\\infty}^\\infty\n    \\frac{1}{2 \\pi \\sigma_1\\sigma_2}\n    \\exp\\left(\n    -\\frac{(y - \\mu_1 - \\mu_2)^2}\n      {2(\\sigma_1^2 + \\sigma_2^2)}\n    -\\frac{((\\sigma_1^2 + \\sigma_2^2)x_1 -\\sigma_1^2y + \\mu_2 \\sigma_1^2 - \\mu_1 \\sigma_2^2)^2}\n      {2\\sigma_1^2\\sigma_2^2(\\sigma_1^2 + \\sigma_2^2)}\n    \\right)\n    \\,dx_1\n\\\\\n& = \\int_{-\\infty}^\\infty\n    \\frac{1}{2 \\pi \\sigma_1\\sigma_2}\n    \\exp\\left(\n    -\\frac{(y - \\mu_1 - \\mu_2)^2}\n      {2(\\sigma_1^2 + \\sigma_2^2)}\n    \\right)\n    \\exp\\left(\n    -\\frac{((\\sigma_1^2 + \\sigma_2^2)x_1 -\\sigma_1^2y + \\mu_2 \\sigma_1^2 - \\mu_1 \\sigma_2^2)^2}\n      {2\\sigma_1^2\\sigma_2^2(\\sigma_1^2 + \\sigma_2^2)}\n    \\right)\n    \\,dx_1\n\\\\\n& = \\frac{1}{2 \\pi \\sigma_1\\sigma_2}\n    \\exp\\left(\n    -\\frac{(y - \\mu_1 - \\mu_2)^2}\n      {2(\\sigma_1^2 + \\sigma_2^2)}\n    \\right)\n    \\int_{-\\infty}^\\infty\n    \\exp\\left(\n    -\\frac{((\\sigma_1^2 + \\sigma_2^2)x_1 -\\sigma_1^2y + \\mu_2 \\sigma_1^2 - \\mu_1 \\sigma_2^2)^2}\n      {2\\sigma_1^2\\sigma_2^2(\\sigma_1^2 + \\sigma_2^2)}\n    \\right)\n    \\,dx_1.\n\\end{split}\n\\end{align}\\] Für das verbleibende Integral zeigt man mithilfe der Integration durch Substitution, dass \\[\\begin{equation}\n\\int_{-\\infty}^\\infty\n    \\exp\\left(\n    -\\frac{((\\sigma_1^2 + \\sigma_2^2)x_1 -\\sigma_1^2y + \\mu_2 \\sigma_1^2 - \\mu_1 \\sigma_2^2)^2}\n      {2\\sigma_1^2\\sigma_2^2(\\sigma_1^2 + \\sigma_2^2)}\n    \\right)\n    \\,dx_1\n= \\frac{\\sqrt{2\\pi}\\sigma_1\\sigma_2}{\\sqrt{\\sigma_1^2 + \\sigma_2^2}}.\n\\end{equation}\\] Es ergibt sich also \\[\\begin{align}\n\\begin{split}\np_\\upsilon(y)\n& = \\frac{1}{2 \\pi \\sigma_1\\sigma_2}\n    \\frac{\\sqrt{2\\pi}\\sigma_1\\sigma_2}{\\sqrt{\\sigma_1^2 + \\sigma_2^2}}\n    \\exp\\left(\n    -\\frac{(y - \\mu_1 - \\mu_2)^2}\n      {2(\\sigma_1^2 + \\sigma_2^2)}\n    \\right)\n\\\\\n& = \\frac{(2\\pi)^{-1}(2\\pi)^2}{\\sqrt{\\sigma_1^2 + \\sigma_2^2}}\n    \\exp\\left(\n    -\\frac{(y - \\mu_1 - \\mu_2)^2}\n      {2(\\sigma_1^2 + \\sigma_2^2)}\n    \\right)\n\\\\\n& = \\frac{1}{\\sqrt{2\\pi}\\sqrt{\\sigma_1^2 + \\sigma_2^2}}\n    \\exp\\left(\n    -\\frac{(y - \\mu_1 - \\mu_2)^2}\n      {2(\\sigma_1^2 + \\sigma_2^2)}\n    \\right).\n\\end{split}\n\\end{align}\\] Schließlich folgt, dass \\[\\begin{align}\n\\begin{split}\np_\\upsilon(y)\n& = \\frac{1}{\\sqrt{2\\pi(\\sigma_1^2 + \\sigma_2^2)}}\n    \\exp\\left(-\\frac{1}{2(\\sigma_1^2 + \\sigma_2^2)}\\left(y - (\\mu_1 + \\mu_2)\\right)^2\\right)\n  = N(y; \\mu_1 + \\mu_2, \\sigma_1^2 + \\sigma_2^2)\n\\end{split}\n\\end{align}\\] Ein einfacheres Vorgehen ergibt sich vermutlich nach Fouriertransformation der WDF im Sinne der sogenannten charakteristischen Funktion einer Zufallsvariable. In diesem Fall würde die Faltung der WDFen der Multiplikation der charakteristischen Funktionen entsprechen.\n\nEin wichtiger Anwendungsfall von Theorem 17.1 ist das nachfolgende Theorem 17.2 sowie die in Gleichung 15.2 und Gleichung 15.3 erwähnten Generalisierungen der Zentralen Grenzwertsätze. Wir visualisieren Theorem 17.1 exemplarisch in Abbildung 17.1.\n\n\n\nAbbildung 17.1: Summation normalverteilter Zufallsvariablen.\n\n\n\nTheorem 17.2 (Mittelwertstransformation) Für \\(i = 1,...,n\\) seien \\(\\xi_i \\sim N(\\mu,\\sigma^2)\\) unabhängig und identisch normalverteilte Zufallsvariablen. Dann gilt für das Stichprobenmittel \\(\\bar{\\xi}_n := \\frac{1}{n}\\sum_{i=1}^n \\xi_i\\) , dass \\[\\begin{equation}\n\\bar{\\xi}_n \\sim N\\left(\\mu, \\frac{\\sigma^2}{n}\\right).\n\\end{equation}\\]\n\n\nBeweis. Wir halten zunächst fest, dass mit dem Theorem zur Summe von unabhängig normalverteilten Zufallsvariablen gilt, dass \\(\\bar{\\xi}_n = \\frac{1}{n}\\upsilon\\) mit \\(\\upsilon := \\sum_{i=1}^n \\xi_i \\sim N(n\\mu,n\\sigma^2)\\). Einsetzen in Theorem 16.3 ergibt dann \\[\\begin{align}\n\\begin{split}\np_{\\bar{\\xi}_n}(\\bar{x}_n)\n& = \\frac{1}{|1/n|}N\\left(n\\bar{x}_n; n\\mu , n\\sigma^2 \\right) \\\\\n& = \\frac{n}{\\sqrt{2\\pi n\\sigma^2}}\\exp\\left(-\\frac{1}{2n\\sigma^2}\n\\left(n\\bar{x}_n - n\\mu\\right)^2 \\right) \\\\\n& = \\frac{n}{\\sqrt{2\\pi n\\sigma^2}}\\exp\\left(-\\frac{1}{2n\\sigma^2}\n\\left(n\\bar{x}_n - n\\mu\\right)^2 \\right) \\\\\n& = nn^{-\\frac{1}{2}}\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\n\\exp\\left(\n            -\\frac{(n\\bar{x}_n)^2}{2n\\sigma^2}\n            + \\frac{2(n\\bar{x}_n)(n\\mu)}{2n\\sigma^2}\n            - \\frac{(n\\mu)^2}{2n\\sigma^2}\n         \\right) \\\\\n& = \\sqrt{n}\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\n\\exp\\left(\n            -\\frac{n\\bar{x}_n^2}{2\\sigma^2}\n            + \\frac{2n\\bar{x}_n\\mu}{2\\sigma^2}\n            - \\frac{n\\mu^2}{2\\sigma^2}\n         \\right) \\\\\n& = \\frac{1}{1/\\sqrt{n}}\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\n\\exp\\left(\n            -\\frac{\\bar{x}_n^2}{2(\\sigma^2/n)}\n            + \\frac{2\\bar{x}_n\\mu}{2(\\sigma^2/n)}\n            - \\frac{\\mu^2}{2(\\sigma^2/n)}\n         \\right) \\\\\n& = \\frac{1}{\\sqrt{2\\pi(\\sigma^2/n)}}\n\\exp\\left(-\\frac{1}{2(\\sigma^2/n)}\n            (\\bar{x}_n - \\mu)^2\n         \\right) \\\\\n& = N\\left(\\bar{x}_n;\\mu,\\sigma^2/n \\right)\n\\end{split}\n\\end{align}\\]\n\nWichtige Anwendungsfälle von Theorem 17.2 sind die Analyse von Erwartungswertschätzern in ?sec-punktschätzung sowie die sowie die in Gleichung 15.2 erwähnte Generalisierung des Zentralen Grenzwertsatzes nach Lindenberg-Lévy. Wir visualisieren Theorem 17.2 exemplarisch in Abbildung 17.2.\n\n\n\nAbbildung 17.2: Mittelwertbildung bei normalverteilten Zufallsvariablen."
  },
  {
    "objectID": "209-Transformationen-der-Normalverteilung.html#z-transformation",
    "href": "209-Transformationen-der-Normalverteilung.html#z-transformation",
    "title": "17  Transformationen der Normalverteilung",
    "section": "17.2 \\(Z\\)-Transformation",
    "text": "17.2 \\(Z\\)-Transformation\nDas Theorem 17.3 besagt, dass Subtraktion des Erwartungswertparameters und gleichzeitige Division mit der Wurzel des Varianzsparameters die Verteilung einer normalverteilten Zufallsvariable in eine Standardnormalverteilung transformiert.\n\nTheorem 17.3 (\\(Z\\)-Transformation) Es sei \\(\\upsilon \\sim N(\\mu,\\sigma^2)\\) eine normalverteilte Zufallsvariable. Dann ist die Zufallsvariable \\[\\begin{equation}\nZ := \\frac{\\upsilon - \\mu}{\\sigma}\n\\end{equation}\\] eine standardnormalverteilte Zufallsvariable, es gilt also \\(Z \\sim N(0,1)\\).\n\n\nBeweis. Wir nutzen Theorem 16.3. Dazu halten wir zunächst fest, dass die \\(Z\\)-Transformation einer Funktion der Form \\[\\begin{equation}\nf(\\upsilon) := \\frac{\\upsilon - \\mu}{\\sigma} =: Z\n\\end{equation}\\] entspricht. Wir stellen weiterhin fest, dass die Umkehrfunktion von \\(f\\) durch \\[\\begin{equation}\nf^{-1}(Z) := \\sigma Z + \\mu\n\\end{equation}\\] gegeben ist, da für alle \\(z \\in \\mathbb{R}\\) mit \\(z = {y - \\mu}{\\sigma}\\) gilt, dass \\[\\begin{equation}\n\\zeta^{-1}(z)\n= \\zeta^{-1}\\left(\\frac{y - \\mu}{\\sigma}\\right)\n= \\frac{\\sigma(y- \\mu)}{\\sigma} + \\mu\n= y - \\mu + \\mu\n= y.\n\\end{equation}\\] Schließlich stellen wir fest, dass für die Ableitung \\(f'\\) von \\(f\\) gilt, dass \\[\\begin{equation}\nf'(y)\n= \\frac{d}{dy}\\left(\\frac{y - \\mu}{\\sigma} \\right)\n= \\frac{d}{dy}\\left(\\frac{y}{\\sigma} -\\frac{\\mu}{\\sigma} \\right)\n= \\frac{1}{\\sigma}.\n\\end{equation}\\] Einsetzen in das univariate WDF Transformationstheorem für lineare Funktionen ergibt dann \\[\\begin{align}\n\\begin{split}\np_Z(z)\n& = \\frac{1}{|1/\\sigma|}N\\left(\\sigma z + \\mu; \\mu , \\sigma^2 \\right) \\\\\n& = \\frac{1}{1/\\sqrt{\\sigma^2}}\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left(-\\frac{1}{2\\sigma^2}\\left(\\sigma z + \\mu - \\mu\\right)^2 \\right) \\\\\n& = \\frac{\\sqrt{\\sigma^2}}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left(-\\frac{1}{2\\sigma^2}\\sigma^2 z^2\\right)\\\\\n& = \\frac{1}{\\sqrt{2\\pi}}\\exp\\left(-\\frac{1}{2} z^2\\right)\\\\\n& = N(z;0,1)\n\\end{split}\n\\end{align}\\] also, dass \\(Z \\sim N(0,1)\\).\n\nWichtige Anwendungsfälle von Theorem 17.3 sind neben der häufig angewandten Standardisierung von normalverteilten Zufallsvariablen im Sinne der sogenannten \\(Z\\)-Werte (\\(Z\\)-Scores) die \\(Z\\)-Konfidenzintervallstatistik und die \\(Z\\)-Teststatistik. Wir visualisieren Theorem 17.3 exemplarisch in Abbildung 17.3.\n\n\n\nAbbildung 17.3: \\(Z\\)-Transformation normalverteilter Zufallsvariablen."
  },
  {
    "objectID": "209-Transformationen-der-Normalverteilung.html#sec-chi-quadrat-transformation",
    "href": "209-Transformationen-der-Normalverteilung.html#sec-chi-quadrat-transformation",
    "title": "17  Transformationen der Normalverteilung",
    "section": "17.3 \\(\\chi^2\\)-Transformation",
    "text": "17.3 \\(\\chi^2\\)-Transformation\nMit der \\(\\chi^2\\)-Transformation führen wir nun eine erste Transformation unabhängig und identisch normalverteilter Zufallsvariablen ein, die nicht wiederrum auf eine Normalverteilung führt. Speziell besagt Theorem 17.4, dass die Summe quadrierter unabhängiger standardnormalverteilter Zufallsvariablen eine \\(\\chi^2\\)-verteilte Zufallsvariable ist. Dazu erinnern wir zunächst an den Begriff der \\(\\chi^2\\)-Zufallsvariable als Spezialfall der in Kapitel 11 betrachteten Gammazufallsvariablen (vgl. Definition 11.10).\n\nDefinition 17.1 (\\(\\chi^2\\)-Zufallsvariable) \\(U\\) sei eine Zufallsvariable mit Ergebnisraum \\(\\mathbb{R}_{&gt;0}\\) und WDF \\[\\begin{equation}\np : \\mathbb{R}_{&gt;0} \\to \\mathbb{R}_{&gt;0},\nu \\mapsto p(u)\n:= \\frac{1}{\\Gamma\\left(\\frac{n}{2}\\right)2^{\\frac{n}{2}}}\nu^{\\frac{n}{2}-1}\\exp\\left(-\\frac{1}{2}u\\right),\n\\end{equation}\\] wobei \\(\\Gamma\\) die Gammafunktion bezeichne. Dann sagen wir, dass \\(U\\) einer \\(\\chi^2\\)-Verteilung mit Freiheitsgradparameter \\(n\\) unterliegt und nennen \\(U\\) eine \\(\\chi^2\\)-Zufallsvariable mit Freiheitsgradparameter \\(n\\). Wir kürzen dies mit \\(U \\sim \\chi^2(n)\\) ab. Die WDF einer \\(\\chi^2\\)-Zufallsvariable bezeichnen wir mit \\[\\begin{equation}\n\\chi^2(u;n) :=\n\\frac{1}{\\Gamma\\left(\\frac{n}{2}\\right)2^{\\frac{n}{2}}}\nu^{\\frac{n}{2}-1}\\exp\\left(-\\frac{1}{2}u\\right).\n\\end{equation}\\]\n\nWir erinnern daran, dass die WDF der \\(\\chi^2\\)-Verteilung der WDF \\(G\\left(u;\\frac{n}{2},2\\right)\\) einer Gammaverteilung entspricht. In Abbildung 17.4 visualisieren wir exemplarisch einige WDFen von \\(\\chi^2\\)-Zufallsvariablen. Wir beobachten, dass mit ansteigendem \\(n\\) sich \\(\\chi^2(u;n)\\) verbreiter und Wahrscheinlichkeitsmasse zur größeren Werten von \\(u\\) verschoben wird.\n\n\n\nAbbildung 17.4: WDFen von \\(\\chi^2\\) Zufallsvariablen.\n\n\n\nTheorem 17.4 (\\(\\chi^2\\)-Transformation) \\(Z_1,...,Z_n \\sim N(0,1)\\) seien unabhängig und identisch standardnormalverteilte Zufallsvariablen. Dann ist die Zufallsvariable \\[\\begin{equation}\nU := \\sum_{i=1}^n Z_i^2\n\\end{equation}\\] eine \\(\\chi^2\\)-verteilte Zufallsvariable mit Freiheitsgradparameter \\(n\\), es gilt also \\(U \\sim \\chi^2(n)\\). Insbesondere gilt für \\(Z \\sim N(0,1)\\) und \\(U := Z^2\\), dass \\(U \\sim \\chi^2(1)\\).\n\n\nBeweis. Wir zeigen das Theorem nur für den Fall \\(n := 1\\) mithilfe von Theorem 16.4. Danach ist die WDF einer Zufallsvariable \\(U := f(Z)\\), welche aus der Transformation einer Zufallsvariable \\(Z\\) mit WDF \\(p_\\zeta\\) durch eine stückweise bijektive Abbildung hervorgeht, gegeben durch \\[\\begin{equation}\\label{eq:piecewise_pdf_transform}\np_U(u) = \\sum_{i=1}^k 1_{\\mathcal{U}_i} \\frac{1}{|f'_i(f_i^{-1}(u))|}p_\\zeta\\left(f_i^{-1} (u)\\right).\n\\end{equation}\\] Wir definieren \\[\\begin{equation}\n\\mathcal{U}_1 := ]-\\infty,0[,\n\\mathcal{U}_2 := ]0,\\infty[, \\mbox{ und }\n\\mathcal{U}_i := \\mathbb{R}_{&gt;0} \\mbox{ für } i = 1,2,\n\\end{equation}\\] sowie \\[\\begin{equation}\nf_i : \\mathcal{Z}_i \\to \\mathcal{U}_i, x \\mapsto f_i(z) := z^2 =: u \\mbox{ für } i = 1,2.\n\\end{equation}\\] Die Ableitung und die Umkehrfunktion der \\(f_i\\) ergeben sich zu \\[\\begin{equation}\nf_i' : \\mathcal{Z}_i \\to \\mathcal{Z}_i, x \\mapsto f_i'(z) = 2z \\mbox{ für } i = 1,2,\n\\end{equation}\\] und \\[\\begin{equation}\nf_1^{-1} : \\mathcal{U}_1 \\to \\mathcal{U}_1, u \\mapsto f_1^{-1}(u) = - \\sqrt{u}\n\\mbox{ und }\nf_2^{-1} : \\mathcal{U}_2 \\to \\mathcal{U}_2, u \\mapsto f_2^{-1}(u) = \\sqrt{u},\n\\end{equation}\\] respektive. Einsetzen in Gleichung \\(\\eqref{eq:piecewise_pdf_transform}\\) ergibt dann \\[\\begin{align}\n\\begin{split}\np_U(u)\n& = 1_{\\mathcal{U}_1}(u) \\frac{1}{|f'_1(f_1^{-1}(u))|}p_\\zeta\\left(f_1^{-1} (u)\\right)\n  + 1_{\\mathcal{U}_2}(u) \\frac{1}{|f'_2(f_2^{-1}(u))|}p_\\zeta\\left(f_2^{-1} (u)\\right) \\\\\n& = \\frac{1}{|2(-\\sqrt{u})|}\\frac{1}{\\sqrt{2\\pi}}\\exp\\left(-\\frac{1}{2}(-\\sqrt{u})^2\\right)\n  + \\frac{1}{|2( \\sqrt{u})|}\\frac{1}{\\sqrt{2\\pi}}\\exp\\left(-\\frac{1}{2}( \\sqrt{u})^2\\right) \\\\\n& = \\frac{1}{2\\sqrt{u}}\\frac{1}{\\sqrt{2\\pi}}\\exp\\left(-\\frac{1}{2}u\\right)\n  + \\frac{1}{2\\sqrt{u}}\\frac{1}{\\sqrt{2\\pi}}\\exp\\left(-\\frac{1}{2}u\\right)\\\\\n& = \\frac{1}{\\sqrt{2\\pi}}\\frac{1}{\\sqrt{u}}\\exp\\left(-\\frac{1}{2}u\\right).\n\\end{split}\n\\end{align}\\] Andererseits gilt, dass mit \\(\\Gamma\\left(\\frac{1}{2}\\right) = \\sqrt{\\pi}\\), die PDF einer \\(\\chi^2\\)-Zufallsvariable \\(U\\) mit \\(n = 1\\) durch \\[\\begin{equation}\n\\frac{1}{\\Gamma\\left(\\frac{1}{2}\\right)2^{\\frac{1}{2}}} u^{\\frac{1}{2}-1}\\exp\\left(-\\frac{1}{2}u\\right)\n= \\frac{1}{\\sqrt{2\\pi}}\\frac{1}{\\sqrt{u}}\\exp\\left(-\\frac{1}{2}u\\right)\n\\end{equation}\\] gegeben ist. Also gilt, dass wenn \\(Z \\sim N(0,1)\\) ist, dann ist \\(U := Z^2 \\sim \\chi^2(1)\\).\n\nWichtige Anwendungsfälle sind die \\(U\\)-Konfidenzintervallstatistik sowie die im folgenden eingeführten \\(t\\)- und \\(f\\)-Zufallsvariablen. Wir visualisieren Theorem 17.4 exemplarisch in Abbildung 17.5.\n\n\n\nAbbildung 17.5: \\(\\chi^2\\)-Transformation normalverteilter Zufallsvariablen."
  },
  {
    "objectID": "209-Transformationen-der-Normalverteilung.html#sec-t-transformation",
    "href": "209-Transformationen-der-Normalverteilung.html#sec-t-transformation",
    "title": "17  Transformationen der Normalverteilung",
    "section": "17.4 \\(T\\)-Transformation",
    "text": "17.4 \\(T\\)-Transformation\nDas in diesem Abschnitt betrachtete Theorem geht auf Student (1908) zurück und ist das zentrale und stilprägende Resultat der Entwicklung der Frequentistischen Inferenz in der ersten Hälfte der 20. Jahrhunderts. Hald (2007) und Zabell (2008) und geben hierzu einen historischen Überblick. Das zentrale Theorem 17.5 besagt dabei, dass die Zufallsvariable, die sich durch Division einer standardnormalverteilten Zufallsvariable durch die Quadratwurzel einer \\(\\chi^2\\)-verteilten Zufallsvariable geteilt durch ein \\(n\\), ergibt, eine \\(t\\)-verteilte Zufallsvariable ist. Dabei ist eine \\(t\\)-verteilte Zufallsvariable wie folgt definiert.\n\nDefinition 17.2 (\\(t\\)-Zufallsvariable) \\(T\\) sei eine Zufallsvariable mit Ergebnisraum \\(\\mathbb{R}\\) und WDF \\[\\begin{equation}\np : \\mathbb{R} \\to \\mathbb{R}_{&gt;0}, t \\mapsto p(t)\n:= \\frac{\\Gamma\\left(\\frac{n+1}{2}\\right)}{\\sqrt{n\\pi}\\Gamma\\left(\\frac{n}{2}\\right)}\n\\left(1 + \\frac{t^2}{n} \\right)^{-\\frac{n+1}{2}},\n\\end{equation}\\] wobei \\(\\Gamma\\) die Gammafunktion bezeichne. Dann sagen wir, dass \\(T\\) einer \\(t\\)-Verteilung mit Freiheitsgradparameter \\(n\\) unterliegt und nennen \\(T\\) eine \\(t\\)-Zufallsvariable mit Freiheitsgradparameter \\(n\\). Wir kürzen dies mit \\(T \\sim t(n)\\) ab. Die WDF einer \\(t\\)-Zufallsvariable bezeichnen wir mit \\[\\begin{equation}\nT(t;n) := \\frac{\\Gamma\\left(\\frac{n+1}{2}\\right)}{\\sqrt{n\\pi}\\Gamma\\left(\\frac{n}{2}\\right)}\n\\left(1 + \\frac{t^2}{n} \\right)^{-\\frac{n+1}{2}}.\n\\end{equation}\\]\n\nIn Abbildung 17.6 visualisieren wir exemplarisch einige WDFen von \\(t\\)-Zufallsvariablen. Wir beobachten, dass die \\(t\\)-Verteilung immer um \\(0\\) symmetrisch ist und ein steigendes \\(n\\) Wahrscheinlichkeitsmasse aus den Ausläufen zum Zentrum verschiebt. Wir merken an, dass ab etwa \\(n = 30\\) gilt, dass \\(T(t;n) \\approx N(0,1)\\).\n\n\n\nAbbildung 17.6: WDFen von \\(T\\)-Zufallsvariablen.\n\n\n\nTheorem 17.5 (\\(T\\)-Transformation) \\(Z \\sim N(0,1)\\) sei eine standarnormalverteilte Zufallsvariable, \\(U \\sim \\chi^2(n)\\) sei eine \\(\\chi^2\\)-Zufallsvariable mit Freiheitsgradparameter \\(n\\), und \\(Z\\) und \\(U\\) seien unabhängig. Dann ist die Zufallsvariable \\[\\begin{equation}\nT := \\frac{Z}{\\sqrt{U/n}}\n\\end{equation}\\] eine \\(t\\)-verteilte Zufallsvariable mit Freiheitsgradparameter \\(n\\), es gilt also \\(T \\sim t(n)\\).\n\n\nBeweis. Wir halten zunächst fest, dass die zweidimensionale WDF der gemeinsamen (unabhängigen) Verteilung von \\(Z\\) und \\(U\\) durch \\[\\begin{equation}\np_{Z,U}(z,u)\n=\n\\frac{1}{\\sqrt{2\\pi}}\\exp\\left(-\\frac{1}{2}z^2\\right)\n\\frac{1}{\\Gamma(\\frac{n}{2})2^{\\frac{n}{2}}}u^{\\frac{n}{2}-1} \\exp\\left(-\\frac{1}{2}u\\right).\n\\end{equation}\\] gegeben ist. Wir betrachten dann die multivariate vektorwertige Abbildung \\[\\begin{equation}\nf : \\mathbb{R}^2 \\to \\mathbb{R}^2,\n(z,u)\n\\mapsto\nf(z,u)\n:=\n\\left(\\frac{z}{\\sqrt{u/n}},u\\right)\n=:\n(t,w)\n\\end{equation}\\] und benutzen das multivariate WDF Transformationstheorem für bijektive Abbildungen um die WDF von \\((t,w)\\) herzuleiten. Dazu erinnern wir uns, dass wenn \\(\\xi\\) ein \\(n\\)-dimensionaler Zufallsvektor mit WDF \\(p_\\xi\\) und \\(\\upsilon := f(\\xi)\\) für eine differenzierbare und bijektive Abbildung \\(f : \\mathbb{R}^n \\to \\mathbb{R}^n\\) ist, die WDF des Zufallsvektors \\(\\upsilon\\) durch \\[\\begin{equation}\\label{eq:pdftmv}\np_\\upsilon : \\mathbb{R}^n \\to \\mathbb{R}_{\\ge 0},\ny \\mapsto p_\\upsilon(y) :=\n\\frac{1}{|J^f\\left(f^{-1}(y)\\right)|}p_\\xi\\left(f^{-1}(y)\\right)\n\\end{equation}\\] gegeben ist. Für die im vorliegenden Fall betrachtete Abbildung halten wir zunächst fest, dass \\[\\begin{equation}\nf^{-1}:\\mathbb{R}^2 \\to \\mathbb{R}^2,\n(t,w)\n\\mapsto\nf^{-1}\n(t,w)\n:=\\left(\\sqrt{w/n}t, w\\right).\n\\end{equation}\\] Dies ergibt sich direkt aus \\[\\begin{equation}\nf^{-1}(f(z,u))\n=\nf^{-1}\\left(\\frac{z}{\\sqrt{u/n}},u\\right)\n=\n\\left(\\frac{\\sqrt{u/n}z}{\\sqrt{u/n}}, u \\right)\n=\n(z,u)\n\\mbox{ für alle }\n(z,u)\n\\in \\mathbb{R}^2.\n\\end{equation}\\] Wir halten dann fest, dass die Determinante der Jacobi-Matrix von \\(f\\) an der Stelle \\((z,u)\\) durch \\[\\begin{equation}\n|J^f(z,u)|\n=\n\\begin{vmatrix}\n  \\frac{\\partial}{\\partial z} \\left(\\frac{z}{\\sqrt{u/n}}\\right)\n& \\frac{\\partial}{\\partial u} \\left(\\frac{z}{\\sqrt{u/n}}\\right) \\\\\n  \\frac{\\partial}{\\partial z} u\n& \\frac{\\partial}{\\partial u} u\\\\\n\\end{vmatrix}\n= \\left(\\frac{v}{n}\\right)^{-1/2},\n\\end{equation}\\] gegeben ist, sodass folgt, dass \\[\\begin{equation}\n\\frac{1}{|J^f\\left(f^{-1}(z,u)\\right)|}\n= \\left(\\frac{w}{n}\\right)^{1/2}.\n\\end{equation}\\] Einsetzen in Gleichung \\(\\eqref{eq:pdftmv}\\) ergibt dann \\[\\begin{equation}\np_{T,W}(t,w) = \\left(\\frac{w}{n}\\right)^{1/2}p_{Z,V}\\left(\\sqrt{w/n}t,w\\right),\n\\end{equation}\\] Es folgt also \\[\\begin{align}\n\\begin{split}\np_T(t)\n& =\n\\int_0^\\infty  p_{T,W}(t,w)\n\\,dw                                                    \\\\\n& =\n\\int_0^\\infty\n\\left(\\frac{w}{n}\\right)^{1/2}\np_{Z,V}\\left(\\sqrt{w/n}t,w\\right)\n\\,dw  \\\\\n& =\n\\int_0^\\infty\n\\frac{1}{\\sqrt{2\\pi}}\\exp\\left(-\\frac{1}{2}(\\sqrt{w/n}t)^2\\right)\n\\frac{1}{\\Gamma(\\frac{n}{2})2^{\\frac{n}{2}}}w^{\\frac{n}{2}-1} \\exp\\left(-\\frac{1}{2}w\\right)\n\\left(\\frac{w}{n}\\right)^{1/2}\n\\,dw \\\\\n& =\n\\frac{1}{\\sqrt{2\\pi}}\\frac{1}{\\Gamma(\\frac{n}{2})2^{\\frac{n}{2}}n^{\\frac{1}{2}}}\n\\int_0^\\infty\n\\exp\\left(-\\frac{1}{2}\\frac{w}{n}t^2\\right)\nw^{\\frac{n}{2}-1} \\exp\\left(-\\frac{1}{2}w\\right)w^{1/2}\n\\,dw \\\\\n& =\n\\frac{1}{\\sqrt{2\\pi}}\\frac{1}{\\Gamma(\\frac{n}{2})2^{\\frac{n}{2}}n^{\\frac{1}{2}}}\n\\int_0^\\infty\n\\exp\\left(-\\frac{1}{2}\\frac{w}{n}t^2 -\\frac{1}{2}w\\right)\nw^{\\frac{n}{2}-1} w^{\\frac{1}{2}}\n\\,dw \\\\\n& =\n\\frac{1}{\\sqrt{2\\pi}}\\frac{1}{\\Gamma(\\frac{n}{2})2^{\\frac{n}{2}}n^{\\frac{1}{2}}}\n\\int_0^\\infty\n\\exp\\left(-\\frac{1}{2}\\left(\\frac{w}{n}t^2 + w\\right)\\right)\nw^{\\frac{n + 1}{2}-1}\n\\,dw \\\\\n& =\n\\frac{1}{\\sqrt{2\\pi}}\\frac{1}{\\Gamma(\\frac{n}{2})2^{\\frac{n}{2}}n^{\\frac{1}{2}}}\n\\int_0^\\infty\n\\exp\\left(-\\frac{1}{2}\\left(1 + \\frac{t^2}{n}\\right)\\right)\nw^{\\frac{n + 1}{2}-1}\n\\,dw \\\\\n\\end{split}\n\\end{align}\\] Wir stellen dann fest, dass der Integrand auf der linken Seite der obigen Gleichung dem Kern einer Gamma WDF mit Parametern \\(\\alpha = \\frac{n+1}{2}\\) und \\(\\beta = \\frac{2}{1+\\frac{t^2}{n}}\\) entspricht, wie man leicht einsieht: \\[\\begin{align*}\n\\Gamma(w;\\alpha,\\beta)\n= \\frac{1}{\\Gamma(\\alpha)\\beta^{\\alpha}}w^{\\alpha-1}\\exp\\left(-\\frac{w}{\\beta}\\right) & \\\\\n\\Rightarrow\n\\Gamma\\left(w;\\frac{n+1}{2},\\frac{2}{1+\\frac{t^2}{n}}\\right)\n& = \\frac{1}{\\Gamma(\\frac{n+1}{2})\\left(\\frac{2}{1+\\frac{t^2}{n}}\\right)^{\\frac{n+1}{2}}}\nw^{\\frac{n+1}{2}-1}\\exp\\left(-\\frac{w}{\\frac{2}{1+\\frac{t^2}{n}}}\\right) \\\\\n& = \\frac{1}{\\Gamma( \\frac{n+1}{2})\\left(\\frac{2}{1+\\frac{t^2}{n}}\\right)^{ \\frac{n+1}{2}}}\n\\exp\\left(-\\frac{1}{2}\\left(1 + \\frac{t^2}{n}\\right)\\right) w^{\\frac{n+1}{2}-1}.\n\\end{align*}\\] Es ergibt sich also \\[\\begin{equation}\np_T(t)\n=\n\\frac{1}{\\sqrt{2\\pi}}\\frac{1}{\\Gamma(\\frac{n}{2})2^{\\frac{n}{2}}n^{\\frac{1}{2}}}\n\\int_0^\\infty\n\\Gamma\\left(w;\\frac{n+1}{2},\\frac{2}{1+\\frac{t^2}{n}}\\right)\n\\,dw .\n\\end{equation}\\] Schließlich stellen wir fest, dass der Integralterm in obiger Gleichung dem Normalisierungsterm einer Gamma WDF entspricht. Abschließend ergibt sich also \\[\\begin{equation}\np_T(t) =\n\\frac{1}{\\sqrt{2\\pi}}\\frac{1}{\\Gamma(\\frac{n}{2})2^{\\frac{n}{2}}n^{\\frac{1}{2}}}\n\\Gamma\\left(\\frac{n+1}{2}\\right)\\left(\\frac{2}{1 + \\frac{t^2}{n}} \\right)^{\\frac{n+1}{2}}.\n\\end{equation}\\] Die Verteilung von \\(Z/\\sqrt{U/n}\\) hat also die WDF einer \\(t\\)-Zufallsvariable.\n\nWichtige Anwendungsfälle sind die \\(T\\)-Konfidenzintervallstatistik sowie die \\(T\\)-Teststatistiken der Theorie von Hypothesentests im Kontext des Allgemeinen Linearen Modells. Wir visualisieren Theorem 17.5 exemplarisch in Abbildung 17.7.\n\n\n\nAbbildung 17.7: \\(T\\)-Transformation normalverteilter Zufallsvariablen."
  },
  {
    "objectID": "209-Transformationen-der-Normalverteilung.html#sec-nichtzentrale-t-transformation",
    "href": "209-Transformationen-der-Normalverteilung.html#sec-nichtzentrale-t-transformation",
    "title": "17  Transformationen der Normalverteilung",
    "section": "17.5 Nichtzentrale \\(T\\)-Transformation",
    "text": "17.5 Nichtzentrale \\(T\\)-Transformation\nIn diesem Abschnitt betrachten wir den Fall, dass der Erwartungswertparameter der Zählervariable der in Theorem 17.5 betrachteten Zufallsvariable \\(T\\) von Null verschieden ist, dass es sich bei der Zählervariable also nicht um eine nach \\(N(0,1)\\), sondern eine nach \\(N(\\mu,1)\\) verteilte Zufallsvariable für ein beliebiges \\(\\mu \\in \\mathbb{R}\\) handelt. Die so entstehende Zufallsvariable \\(T\\) folgt dann einer sogenannten nichtzentralen-t-Verteilung. Eine frühe ausführliche Diskussion dieser Verteilung findet sich zum Beispiel in Johnson & Welch (1940). Eine entsprechende nichtzentralen-\\(t\\)-verteilte Zufallsvariable ist wie folgt definiert (vgl. Lehmann (1986))."
  },
  {
    "objectID": "209-Transformationen-der-Normalverteilung.html#nichtzentrale-t-zufallsvariable",
    "href": "209-Transformationen-der-Normalverteilung.html#nichtzentrale-t-zufallsvariable",
    "title": "17  Transformationen der Normalverteilung",
    "section": "17.6 Nichtzentrale \\(t\\)-Zufallsvariable",
    "text": "17.6 Nichtzentrale \\(t\\)-Zufallsvariable\n\\(T\\) sei eine Zufallsvariable mit Ergebnisraum \\(\\mathbb{R}\\) und WDF \\[\\begin{multline}\np : \\mathbb{R} \\to \\mathbb{R}_{&gt;0}, t \\mapsto p(t) :=\n\\frac{1}{2^{\\frac{n-1}{2}}\\Gamma\\left(\\frac{n}{2} \\right)(n \\pi)^{\\frac{1}{2}}} \\\\\n\\times \\int_{0}^\\infty \\tau^{\\frac{n-1}{2}} \\exp\\left(-\\frac{\\tau}{2}\\right)\n\\exp\\left(-\\frac{1}{2}\\left(t \\left(\\frac{\\tau}{n}\\right)^{\\frac{1}{2}} - \\delta \\right)^2 \\right)\\,d\\tau.\n\\end{multline}\\] Dann sagen wir, dass \\(T\\) einer nichtzentralen \\(t\\)-Verteilung mit Nichtzentralitätsparameter \\(\\delta\\) und Freiheitsgradparameter \\(n\\) unterliegt und nennen \\(T\\) eine nichtzentrale \\(t\\)-Zufallsvariable mit Nichtzentralitätsparameter \\(\\delta\\) und Freiheitsgradparameter \\(n\\). Wir kürzen dies mit \\(t(\\delta, n)\\) ab. Die WDF einer nichtzentralen \\(t\\)-Zufallsvariable bezeichnen wir mit \\(t(T;\\delta,n)\\). Die KVF und inverse KVF einer nichtzentralen \\(t\\)-Zufallsvariable bezeichnen wir mit \\(\\Psi(\\cdot; \\delta, n)\\) und \\(\\Psi^{-1}(\\cdot; \\delta, n)\\), respektive."
  },
  {
    "objectID": "209-Transformationen-der-Normalverteilung.html#f-transformation",
    "href": "209-Transformationen-der-Normalverteilung.html#f-transformation",
    "title": "17  Transformationen der Normalverteilung",
    "section": "17.7 \\(F\\)-Transformation",
    "text": "17.7 \\(F\\)-Transformation\nDas in diesem Abschnitt zentrale Theorem 17.7 besagt, dass die Zufallsvariable, die sich durch Division zweier \\(\\chi^2\\) verteilter Zufallsvariablen, jeweils geteilt durch ihre jeweiligen Freiheitsgradparameter, eine \\(F\\)-verteilte Zufallsvariable ist. Dabei ist eine \\(F\\)-verteilte Zufallsvariable wie folgt definiert.\n\nDefinition 17.3 (\\(f\\)-Zufallsvariable) \\(F\\) sei eine Zufallsvariable mit Ergebnisraum \\(\\mathbb{R}_{&gt;0}\\) und WDF \\[\\begin{equation}\np_F : \\mathbb{R} \\to \\mathbb{R}_{&gt;0}, f \\mapsto p_F(f)\n:= m^{\\frac{m}{2}}n^{\\frac{n}{2}}\n   \\frac{\\Gamma\\left(\\frac{m+n}{2}\\right)}{\\Gamma\\left(\\frac{m}{2}\\right)\\Gamma\\left(\\frac{n}{2}\\right)}\n   \\frac{f^{\\frac{m}{2}-1}}{\\left(1 + \\frac{m}{n}f \\right)^{\\frac{m+n}{2}}},\n\\end{equation}\\] wobei \\(\\Gamma\\) die Gammafunktion bezeichne. Dann sagen wir, dass \\(F\\) einer \\(f\\)-Verteilung mit Freiheitsgradparametern \\(n,m\\) unterliegt und nennen \\(F\\) eine \\(f\\)-Zufallsvariable mit Freiheitsgradparametern \\(n,m\\). Wir kürzen dies mit \\(F \\sim f(n,m)\\) ab. Die WDF einer \\(f\\)-Zufallsvariable bezeichnen wir mit \\[\\begin{equation}\nF(f;n,m)\n:= m^{\\frac{m}{2}}n^{\\frac{n}{2}}\n   \\frac{\\Gamma\\left(\\frac{m+n}{2}\\right)}{\\Gamma\\left(\\frac{m}{2}\\right)\\Gamma\\left(\\frac{n}{2}\\right)}\n   \\frac{f^{\\frac{m}{2}-1}}{\\left(1 + \\frac{m}{n}f \\right)^{\\frac{m+n}{2}}}.\n\\end{equation}\\]\n\nIn Abbildung 17.10 visualisieren wir exemplarisch einige WDFen von \\(f\\)-Zufallsvariablen. Wir beobachten, dass die Form der WDFen zunächt primär durch den Freiheitsgradparameter \\(n\\) und dann sekundär durch den Freiheitsgradparameter \\(m\\) bestimmt werden.\n\n\n\nAbbildung 17.10: WDFen von \\(f\\)-verteilten Zufallsvariablen.\n\n\n\nTheorem 17.7 (\\(F\\)-Transformation) \\(V \\sim \\chi^2(n)\\) und \\(W \\sim \\chi^2(m)\\) seien zwei unabhängige \\(\\chi^2\\)-Zufallfsvariablen mit Freiheitsgradparametern \\(n\\) und \\(m\\), respektive. Dann ist die Zufallsvariable \\[\\begin{equation}\nF := \\frac{V/n}{W/m}\n\\end{equation}\\] eine \\(f\\)-verteilte Zufallsvariable mit Freiheitsgradparametern \\(n,m\\), es gilt also \\(F \\sim f(n,m)\\).\n\nDas Theorem kann bewiesen werden, in dem man zunächst ein Transformationstheorem für Quotienten von Zufallsvariablen mithilfe von Theorem 16.1 und Marginalisierung herleitet und dieses Theorem dann auf die WDF von \\(\\chi^2\\)-verteilten Zufallsvariablen anwendet. Wir visualisieren Theorem 17.7 exemplarisch in Abbildung 17.11. Wichtige Anwendungsfälle von Theorem 17.7 sind die im Rahmen der Theorie des Allgemeinen Linearen Modells betrachteten \\(F\\)-Statistiken.\n\n\n\nAbbildung 17.11: \\(F\\)-Transformation normalverteilter Zufallsvariablen."
  },
  {
    "objectID": "209-Transformationen-der-Normalverteilung.html#selbstkontrollfragen",
    "href": "209-Transformationen-der-Normalverteilung.html#selbstkontrollfragen",
    "title": "17  Transformationen der Normalverteilung",
    "section": "17.8 Selbstkontrollfragen",
    "text": "17.8 Selbstkontrollfragen\n\nErläutern Sie die Bedeutung der in diesem Abschnitt betrachteten Transformationen von normalverteilten Zufallsvariablen für die Frequentistische Inferenz.\nGeben Sie das Theorem zur Summentransformation wieder.\nGeben Sie das Theorem zur Mittelwerttransformation wieder.\nGeben Sie das Theorem zur \\(Z\\)-Transformation wieder.\nGeben Sie das Theorem zur \\(\\chi^2\\)-Transformation wieder.\nBeschreiben Sie die WDF der \\(t\\)-Verteilung in Abhängigkeit ihrer Freiheitsgradparameter.\nGeben Sie das Theorem zur \\(T\\)-Transformation wieder.\nGeben Sie das Theorem zur \\(F\\)-Transformation wieder.\n\n\n\n\n\nHald, A. (2007). A History of Parametric Statistical Inference from Bernoulli to Fisher, 1713-1935. Springer.\n\n\nJohnson, N. L., & Welch, B. L. (1940). Applications of the Non-Central t-Distribution. Biometrika, 31(3/4), 362. https://doi.org/10.2307/2332616\n\n\nLehmann, E. L. (1986). Testing Statistical Hypotheses. Wiley Series in Probability and Statistics.\n\n\nStudent. (1908). The Probable Error of a Mean. Biometrika, 6(1), 1–25.\n\n\nZabell, S. L. (2008). On Student’s 1908 Article „The Probable Error of a Mean“. Journal of the American Statistical Association, 103(481), 1–7. https://doi.org/10.1198/016214508000000030"
  }
]